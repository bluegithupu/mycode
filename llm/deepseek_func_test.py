import json
from openai import OpenAI

from llm import tools

def send_messages(messages):

    # print debug info IN
    print("\n" + "=" * 80)
    print("ğŸ“¥ Input Messages:")
    print("-" * 40)
    # for msg in messages:
    #     print(f"[{msg['role']}] {msg['content']}")
    print(messages)
    print("=" * 80)

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        tools=tools.tools
    )

    # å¢åŠ é”™è¯¯æ£€æŸ¥
    if not response.choices[0].message.content and not response.choices[0].message.tool_calls:
        print("è­¦å‘Š: API è¿”å›äº†ç©ºå“åº”!")
        # å¯ä»¥é€‰æ‹©é‡è¯•æˆ–ä½¿ç”¨é»˜è®¤å“åº”
        return ChatCompletionMessage(content="æŠ±æ­‰,æˆ‘æš‚æ—¶æ— æ³•å¤„ç†è¿™ä¸ªè¯·æ±‚ã€‚")

    # print debug info OUT
    print("\n" + "=" * 80)
    print("ğŸ“¤ API Response:")
    print("-" * 40)
    print(f"Model: {response.model}")
    print(f"Usage: {response.usage}")
    print(f"Message: {response.choices[0].message}")
    print("=" * 80 + "\n")

    return response.choices[0].message


# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = OpenAI(api_key="sk-cdjsim5KBne5thQJ2bF279E94fEa487aA347A7D85747Af10",
                base_url="https://api.rcouyi.com/v1")

# messages = [{"role": "user", "content": "How's the weather in Hangzhou?"}]
# messages = [{"role": "user", "content": "(1 + 1) * 2 / 0 = ?"}]
messages = [{"role": "user", "content": "What is the name of the album with the most tracks?"}]
message = send_messages(messages) 
print(f"User>\t {messages[0]['content']}")

tool = message.tool_calls[0]
messages.append(message)




messages.append({"role": "tool", "tool_call_id": tool.id, "content": tools.call_tool(tool.function.name, **json.loads(tool.function.arguments))})
message = send_messages(messages)
if message.content:  # æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹
    print(f"Model>\t {message.content}")
else:
    print("é”™è¯¯: æ¨¡å‹æ²¡æœ‰è¿”å›æ–‡æœ¬å“åº”")
