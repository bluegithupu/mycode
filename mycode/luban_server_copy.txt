File path: /Users/mac/Desktop/woker_code/luban_server_copy/cmd/server.go
```golang
package main

import (
	"errors"
	"flag"
	"fmt"
	"github.com/dgrijalva/jwt-go"
	restfulspec "github.com/emicklei/go-restful-openapi/v2"
	"github.com/emicklei/go-restful/v3"
	"github.com/go-openapi/spec"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/cmd/options"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/cloudproduct/block"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/cloudproduct/bm"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/cloudproduct/bucket"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/cloudproduct/eip"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/cloudproduct/load"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/cloudproduct/mysql"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/cloudproduct/nat"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/cloudproduct/redis"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/cloudproduct/vm"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/physicalServer"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/physicalSwitch"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/resourcepool/aggragate"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/resourcepool/blockstorage"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/resourcepool/database"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/resourcepool/eipPool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/resourcepool/network"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/resourcepool/objectstorage"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/logging"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/tasks"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/version"
	"net/http"

	"os"

	"k8s.io/klog/v2"
)

func main() {
	args := os.Args
	if len(args) == 2 && (args[1] == "--version" || args[1] == "-v") {
		fmt.Println(version.Info())
		return
	}

	opts := options.NewOptions()
	opts.AddFlags(flag.CommandLine)
	opts.ParseFlags()

	defer klog.Flush()

	if err := Run(opts); err != nil {
		klog.Error(err.Error())
		os.Exit(1)
	}
}

func Run(opts *options.Options) error {
	if err := opts.Validate(); err != nil {
		return err
	}

	ListenAddr := fmt.Sprintf("%s:%d", opts.ListenAddr, opts.ListenPort)
	wsContainer := restful.NewContainer()
	wsContainer.Add(version.NewVersionService())
	wsContainer.Filter(globalLogging)
	wsContainer.Add(handler.NewK8sService())
	//wsContainer.Filter(filters.ForwardKubernetes)
	wsContainer.Add(handler.NewDashboardService())
	//todo add switch hander
	wsContainer.Add(physicalServer.BuildPhysicalServerApiHandler().New()) //todo 服务器
	wsContainer.Add(physicalSwitch.BuildPhysicalSwitchApiHandler().New()) //todo 交换机
	wsContainer.Add(aggragate.BuildComputerPoolApiHandler().New())        // todo 云资源监控 / 资源池监控/ 计算
	wsContainer.Add(blockstorage.BuildBlockPoolApiHandler().New())        //todo 云资源监控 / 资源池监控/ 块存储
	wsContainer.Add(database.BuildDatabaseApiHandler().New())             //todo 云资源监控 / 资源池监控/ 数据库
	wsContainer.Add(network.BuildNetworkApiHandler().New())               //todo 云资源监控 / 资源池监控/ 网络
	wsContainer.Add(objectstorage.BuildObjectPoolApiHandler().New())      //todo 云资源监控 / 资源池监控/ 对象存储
	wsContainer.Add(eipPool.BuildEipPoolApiHandler().New())
	wsContainer.Add(eip.BuildEipApiHandler().New())       //todo 云资源监控 / 云产品监控 /弹性ip
	wsContainer.Add(vm.BuildVmApiHandler().New())         //todo 云资源监控 / 云产品监控 /云主机
	wsContainer.Add(block.BuildBlockApiHandler().New())   //todo 云资源监控 / 云产品监控 /块存储
	wsContainer.Add(bucket.BuildObjectApiHandler().New()) //todo 云资源监控 / 云产品监控 /对象存储
	wsContainer.Add(mysql.BuildMysqlApiHandler().New())   // todo 云资源监控/ 云产品监控/ mysql
	wsContainer.Add(redis.BuildRedisApiHandler().New())   // todo 云资源监控/ 云产品监控/ redis
	wsContainer.Add(load.BuildLoadApiHandler().New())     // todo 云资源监控/ 云产品监控/ 负载均衡
	wsContainer.Add(nat.BuildNatApiHandler().New())       // todo 云资源监控/ 云产品监控/ NAT
	wsContainer.Add(bm.BuildBmApiHandler().New())         // todo 云资源监控/ 裸金属/ bm
	wsContainer.Router(restful.CurlyRouter{})

	config := restfulspec.Config{
		WebServices:                   wsContainer.RegisteredWebServices(), // you control what services are visible
		WebServicesURL:                "http://luban.server.galaxy.cloud",
		APIPath:                       "/apidocs.json",
		DisableCORS:                   false,
		PostBuildSwaggerObjectHandler: enrichSwaggerObject}
	wsContainer.Add(restfulspec.NewOpenAPIService(config))

	server := &http.Server{Addr: ListenAddr, Handler: wsContainer}

	if utils.InK8s() { //任务
		utils.GoSafe(tasks.InitTasks)
	}

	return server.ListenAndServe()
}

func globalLogging(req *restful.Request, resp *restful.Response, chain *restful.FilterChain) {
	klog.Infof("[global-filter (logger)] %s,%s\n", req.Request.Method, req.Request.URL)
	//username, _ := getUserID(req)
	username := req.Request.Header.Get("x-auth-username")
	//todo test send es audit log file(next: write audit info to local logging files)
	klog.Infof("audit %s,%s\n", req.Request.Method, req.Request.URL)
	go logging.SendData(logging.NewLubanAuditOpsLog(username, req.Request.Method+" "+req.Request.URL.Path,
		req.Request.URL.Path), logging.AuditIndexName, logging.AuditType)
	klog.Infof("logging %s,%s\n", req.Request.Method, req.Request.URL)
	go logging.SendData(logging.NewLubanLog(req.Request.Method, username+" "+req.Request.Method+req.Request.URL.Path), logging.NormonIndexName, logging.LoggingType)
	chain.ProcessFilter(req, resp)
}

func validateTokenGetUserID(tokenStr string) (string, error) {
	token, _, err := new(jwt.Parser).ParseUnverified(tokenStr, jwt.MapClaims{})
	if err != nil {
		return "", errors.New("Invalide token")
	}

	claims, ok := token.Claims.(jwt.MapClaims)
	if !ok {
		return "", errors.New("Invalide token")
	}
	err = claims.Valid()
	if err != nil {
		return "", errors.New("Invalide token")
	}
	if id, ok := claims["name"]; !ok {
		return "", errors.New("username not found")
	} else {
		return id.(string), nil
	}
}

func enrichSwaggerObject(swo *spec.Swagger) {
	swo.Info = &spec.Info{
		InfoProps: spec.InfoProps{
			Title:       "Luban Service",
			Description: "Resource for managing resources of Luban",
			Contact: &spec.ContactInfo{
				ContactInfoProps: spec.ContactInfoProps{
					Name:  "wangfengteng",
					Email: "wangfengteng@kingsoft.com",
					URL:   "",
				},
				VendorExtensible: spec.VendorExtensible{}},
			License: &spec.License{
				LicenseProps: spec.LicenseProps{
					Name: "MIT",
					URL:  "http://mit.org",
				},
				VendorExtensible: spec.VendorExtensible{},
			},
			Version: "1.0.0",
		},
	}
	swo.Tags = []spec.Tag{spec.Tag{TagProps: spec.TagProps{
		Name:        "users",
		Description: "Managing users"}}}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/cmd/options/options.go
```golang
package options

import (
	"flag"

	"k8s.io/klog/v2"
)

type Options struct {
	ListenAddr string `json:"listen_addr"`
	ListenPort uint   `json:"listen_port"`

}

func NewOptions() *Options {
	return &Options{
		ListenAddr: "0.0.0.0",
		ListenPort: 80,
	}
}

func (opt *Options) AddFlags(fs *flag.FlagSet) {
	fs.StringVar(&opt.ListenAddr, "listin_addr", "0.0.0.0", "server listen address")
	fs.UintVar(&opt.ListenPort, "listin_port", 80, "listen port")
	klog.InitFlags(fs)

}
func (opt *Options) ParseFlags() {
	flag.Parse()
	flag.VisitAll(func(f *flag.Flag) {
		klog.Infof("--%s=%q", f.Name, f.Value)
	})
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/cmd/options/validate.go
```golang
package options

import (
	"errors"
	"net"
)

func (o *Options) Validate() error {
	//todo validate bind address
	if len(o.ListenAddr) > 0 {
		ip := net.ParseIP(o.ListenAddr)
		if ip.To4().String() != "" && len(ip.To4().String()) > 0 {
			o.ListenAddr = ip.To4().String()
			return nil
		}
	}

	return errors.New("validate error")
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/configs/mysql.go
```golang
package configs

import (
	"fmt"
	"gorm.io/driver/mysql"
	"gorm.io/gorm"
	"k8s.io/klog/v2"
	"os"
)

var (
	DB *gorm.DB
)

func init() {
	var err error
	//var dbHost = "asset.luban.sdns.galaxy.cloud:8300"
	//var dbHost = "asset.luban.sdns.galaxy.cloud:32582"
	var dbHost = "10.177.40.250:9306"
	if inK8s() {
		klog.Info("alert db in kubernetes")
		dbHost = "mysql.mysql:3306"
		if h := os.Getenv("RDS_MYSQL_HOST"); h != "" {
			dbHost = h
			klog.Info("get RDS_MYSQL_HOST ", h)
		}
	}
	dsn := fmt.Sprintf("luban:Kingsoft123@tcp(%s)/alert?charset=utf8mb4&parseTime=True&loc=Local", dbHost)
	DB, err = getDB(dsn)
	if err != nil {
		panic(err.Error())
	}
}

func getDB(dsn string) (db *gorm.DB, err error) {
	gdb, err := gorm.Open(mysql.Open(dsn), &gorm.Config{})
	if err != nil {
		klog.Infoln("open mysql dsn failed, %s:", err)
		return gdb, err
	}
	return gdb, nil
}

//判断是否在k8s内
func inK8s() bool {
	return len(os.Getenv("KUBERNETES_SERVICE_HOST")) > 0
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/resourcepool-handler.go
```golang
package handler

import (
	"fmt"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	"strconv"
	"time"

	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	"k8s.io/klog/v2"
)

//func NewCloudMonitorService() *restful.WebService {
//	ws := new(restful.WebService)
//	ws.
//		Path("/v1/metrics/data").
//		Consumes(restful.MIME_XML, restful.MIME_JSON).
//		Produces(restful.MIME_JSON, restful.MIME_XML)
//	ws.Route(ws.GET("/GetResourcePoolsResourcesStatisticsDetails").To(getFromCloudMonitor).Doc("Get Resource Pools Resources Details").
//		Param(ws.QueryParameter("Region", "The Region of product, eg:`beijing`")).
//		Param(ws.QueryParameter("ResourcePoolName", "The Name of resource, eg:`内存优化型N3`")).
//		Param(ws.QueryParameter("ResourcePoolTypeName", "The Name of Resource Pool Type, eg:`Calculat,BlockStorage,ObjectStorage,all`")).
//		//Param(ws.QueryParameter("Namespace", "The namespace of product, eg:`monitoring`")).
//		//Param(ws.QueryParameter("instanceID", "The id of monitoring instance, eg:`i-K7h53v49`")).
//		Param(ws.QueryParameter("MetricName", "The name of metric item, eg:`cpu`")).
//		Param(ws.QueryParameter("StartTime", "The start time timestamp, eg:`1`")).
//		Param(ws.QueryParameter("EndTime", "Every page show size, eg:`11`")).
//		Param(ws.QueryParameter("CurrentPage", "The current page you select, eg:`5")).
//		Param(ws.QueryParameter("PageSize", "The page size you select, eg:`10,20,50")).
//		//Param(ws.QueryParameter("Period", "Every page show size, eg:`11`").Required(false)).
//		//Param(ws.QueryParameter("Aggregate", "Every page show size, eg:`11`")).
//		Returns(200, "OK", ResourcesResult{}).
//		Returns(500, "Error,something went wrong", nil))
//	ws.Route(ws.GET("/getRate").To(GetRate).Doc("Get resource states from prometheus").
//		Returns(200, "OK", RegionCurrentStates{}))
//	ws.Route(ws.GET("/getCpuRateTop").To(GetCpuRateTop).Doc("Get resource states from prometheus").
//		Returns(200, "OK", RegionCurrentStates{}))
//	return ws
//}

type PointData struct {
	Date time.Time `json:"date"`
	//TypeName  string    `json:"typeName"`
	UsedRate float64 `json:"usedRate"`
}
type LineDataResult struct {
	ResourcePoolName string `json:"resourcePoolName"`
	//IPS              string      `json:"ips"`
	ResourcePoolLine []PointData `json:"resourcePoolLine"`
}

type CalculatResult struct {
	Cpu    []LineDataResult `json:"cpu"`
	Memory []LineDataResult `json:"memory"`
	Disk   []LineDataResult `json:"disk"`
}

// type BlockStorageResult struct {
// 	CpuResult    BlockStorageLineData `json:"cpuResult"`
// 	MemoryResult BlockStorageLineData `json:"memoryResult"`
// 	DiskResult   BlockStorageLineData `json:"diskResult"`
// }

type ObjectStorageResult struct {
	FileStorage     []LineDataResult `json:"fileStorage"`
	StandardStorage []LineDataResult `json:"standardStorage"`
}

type DashboardCloudSuccess struct {
	Code    int         `json:"code"`
	Message string      `json:"message"`
	Data    CloudResult `json:"data"`
}

type CloudResult struct {
	ComputerResourcesPoolStatistics     CalculatResult      `json:"computerResourcesPoolStatistics"`
	BlockStorageResourcePoolStatistics  []LineDataResult    `json:"blockStorageResourcePoolStatistics"`
	ObjectStorageResourcePoolStatistics ObjectStorageResult `json:"objectStorageResourcePoolStatistics"`
}

type ResourcesPoolResourcesStatisticsDetails struct {
	ResourcePoolTypeName string    `json:"resourcePoolTypeName"`
	ResourcePoolName     string    `json:"resourcePoolName"`
	MetricName           string    `json:"metricName"`
	Region               string    `json:"region"`
	TimeStamp            time.Time `json:"timeStamp"`
	Total                int       `json:"total"`
	Used                 int       `json:"used"`
	Available            int       `json:"available"`
	UsedRate             float64   `json:"usedRate"`
}
type ResourcesResult struct {
	TotalCount int                                       `json:"totalCount"`
	TotalPage  int                                       `json:"totalPage"`
	Data       []ResourcesPoolResourcesStatisticsDetails `json:"data"`
}

//func getFromCloudMonitor(request *restful.Request, response *restful.Response) {
//	c := http.Client{}
//	resp, err := c.Get("http://10.177.152.168:8000/api/v1/targets?state=active")
//	if err != nil {
//		klog.Error(err.Error())
//	}
//	klog.Info(resp)
//	namespace := "juxiaochao"
//	clientSet := client.GetClient()
//	cm, er := clientSet.CoreV1().ConfigMaps(namespace).Get(context.TODO(), "title", metav1.GetOptions{})
//	if er != nil {
//		klog.Error(er.Error())
//	} else {
//		response.WriteEntity(cm)
//	}
//
//}
func GetRate(request *restful.Request, response *restful.Response) {
	// RegionMap := make(map[string]string)
	// RegionMap["cn-shanghai-2"] = "SHPBSRegionOne" //上海2区(VPC)
	// RegionMap["cn-beijing-6"] = "TJWQRegion"      //北京6区
	//region := request.PathParameter("region")
	//if region == "" {
	//	response.Write([]byte("region is nil, Invalid value!!!"))
	//	return
	//}
	//
	//var cloudResult   CloudResult //返回结果
	//
	//key := "GetDashboard"
	//fieldKey := "Right"
	//klog.Infof("vm OverviewTop fieldKey", fieldKey)
	//
	//redisCon := config.RedisConfig
	//var rdb *redis.Client
	//rdb = redis.NewClient(&redis.Options{
	//	Addr:       redisCon["Host"].(string),
	//	Password:   redisCon["Password"].(string),
	//	DB:         redisCon["Db"].(int),
	//	MaxRetries: redisCon["MaxRetries"].(int),
	//})
	//
	//cache, err := utils.NewRedisCache(rdb, key)
	//if err != nil {
	//	klog.Error("get utils.NewRedisCache failed", err)
	//	success := ResponseObject{Code: 200, Message: "success", Data: cloudResult}
	//	response.WriteAsJson(success)
	//}
	//result, err := rdb.Ping(context.Background()).Result()
	//if err != nil {
	//	klog.Error("Ping redis failed", err)
	//	success := ResponseObject{Code: 200, Message: "success", Data: cloudResult}
	//	response.WriteAsJson(success)
	//}
	//
	//klog.Infof("result %s", result)
	//after := time.After(time.Second * 60)
	//
	//for {
	//	select {
	//	case <-time.After(time.Second):
	//		data, err := cache.GetData(context.Background(), fieldKey, GetDashboardRight(region), time.Minute*3)
	//		if err != nil {
	//			klog.Error("vm GetData err ", err)
	//		}
	//		if data == "" {
	//			continue
	//		}
	//		var list CloudResult
	//		ee := json.Unmarshal([]byte(data), &list)
	//		if ee != nil {
	//			klog.Error("Parsing JSON failed", ee)
	//		}
	//		klog.Infof("data111111:%s", list)
	//		success := ResponseObject{Code: 200, Message: "success", Data: list}
	//		response.WriteAsJson(success)
	//		return
	//	case <-after:
	//		success := ResponseObject{Code: 200, Message: "success", Data: cloudResult}
	//		response.WriteAsJson(success)
	//		return
	//	}
	//}

	//todo 未加缓存逻辑
	var (
		cloudResult         CloudResult //返回结果
		calculatResult      CalculatResult // 计算资源池
		objectStorageResult ObjectStorageResult // 对象存储资源池
	)

	region := request.PathParameter("region")
	if region == "" {
		response.Write([]byte("region is nil, Invalid value!!!"))
		return
	}

	//获取计算资源池数据
	cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/computePool", "post")
	aggregatesResult, err := cmdbmanager.GetAggragateResourcePoolList("", []string{}, "", "1", strconv.Itoa(cmdbCount))
	klog.Infof("aggregates_cmdbCount",cmdbCount)

	if err != nil {
		response.Write([]byte(err.Error()))
		return
	}

	aggregates 	:= aggregatesResult.Data.DataList
	servenDayAgotime := time.Now().AddDate(0, 0, -6)
	for _, aggregate := range aggregates {
		calculatResult.Cpu = append(calculatResult.Cpu, *getMonitorRateNew("cpu",aggregate.Name, servenDayAgotime))
		calculatResult.Memory = append(calculatResult.Memory, *getMonitorRateNew("mem",aggregate.Name, servenDayAgotime))
		calculatResult.Disk = append(calculatResult.Disk, *getMonitorRateNew("disk", aggregate.Name, servenDayAgotime))
		//从cmdb中获取服务器列表
		//hostsResult, _ := cmdbmanager.GetHostListByResourcePool(strconv.Itoa(aggregate.Id))
		//hostList := hostsResult.Data.DataList
		//klog.Infof("Large_screen_aggregate.Id",strconv.Itoa(aggregate.Id))
		//ips := ""
		//for _, host := range hostList {
		//	//从CMDB中获取服务器ip
		//	//ip, err := cmdbmanager.GetHostDetailByHostname(host.Name)
		//	ip := host.IP
		//	klog.Infof("aggregate.Id",strconv.Itoa(aggregate.Id),"host.name",host.Name,"host.IP",host.IP)
		//	if err == nil && ip != "" {
		//		if ips == "" {
		//			ips = ip + ":9100"
		//		} else {
		//			ips = ips + "|" + ip + ":9100"
		//		}
		//	}
		//}
		//klog.Infof("ips",ips)
		//calculatResult.Cpu = append(calculatResult.Cpu, *getCpuRate(ips, aggregate.Name, servenDayAgotime))
		//calculatResult.Memory = append(calculatResult.Memory, *getMemoryRate(ips, aggregate.Name, servenDayAgotime))
		//calculatResult.Disk = append(calculatResult.Disk, *getDiskRate(ips, aggregate.Name, servenDayAgotime))
	}

	cloudResult.ComputerResourcesPoolStatistics = calculatResult
	//cloudResult.BlockStorageResourcePoolStatistics = append(cloudResult.BlockStorageResourcePoolStatistics, *getCapRate(region, "ebs_ssd", servenDayAgotime))
	//块存储资源池
	cloudResult.BlockStorageResourcePoolStatistics = append(cloudResult.BlockStorageResourcePoolStatistics, *getCapRate(region, "ssd3.0", servenDayAgotime))
	cloudResult.BlockStorageResourcePoolStatistics = append(cloudResult.BlockStorageResourcePoolStatistics, *getCapRate(region, "ehdd", servenDayAgotime))
	//cloudResult.BlockStorageResourcePoolStatistics = append(cloudResult.BlockStorageResourcePoolStatistics, *getCapRate(region, "ebs2_sata", servenDayAgotime))

	//对象资源池
	ks3 := *getCapRate(region, "ks3", servenDayAgotime)
	objectStorageResult.FileStorage = append(objectStorageResult.FileStorage,ks3 )
	objectStorageResult.StandardStorage = append(objectStorageResult.StandardStorage,ks3)
	cloudResult.ObjectStorageResourcePoolStatistics = objectStorageResult
	//rb, _ := json.Marshal(&cloudResult)
	success := ResponseObject{Code: 200, Message: "success", Data: cloudResult}
	response.WriteAsJson(success)

}

//func GetDashboardRight(region string) func() (data string, err error) {
//	return func() (data string, err error) {
//		var (
//			cloudResult         CloudResult //返回结果
//			calculatResult      CalculatResult // 计算资源池
//			objectStorageResult ObjectStorageResult // 对象存储资源池
//		)
//		//获取计算资源池数据
//		cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/computePool", "post")
//		aggregatesResult, err := cmdbmanager.GetAggragateResourcePoolList("", []string{}, "", "1", strconv.Itoa(cmdbCount))
//		klog.Infof("aggregates_cmdbCount",cmdbCount)
//
//		if err != nil {
//			return
//		}
//		aggregates 	:= aggregatesResult.Data.DataList
//		servenDayAgotime := time.Now().AddDate(0, 0, -6)
//		for _, aggregate := range aggregates {
//			//从cmdb中获取服务器列表
//			hostsResult, _ := cmdbmanager.GetHostListByResourcePool(strconv.Itoa(aggregate.Id))
//			hostList := hostsResult.Data.DataList
//			klog.Infof("Large_screen_aggregate.Id",strconv.Itoa(aggregate.Id))
//			ips := ""
//			for _, host := range hostList {
//				//从CMDB中获取服务器ip
//				//ip, err := cmdbmanager.GetHostDetailByHostname(host.Name)
//				ip := host.IP
//				klog.Infof("aggregate.Id",strconv.Itoa(aggregate.Id),"host.name",host.Name,"host.IP",host.IP)
//				if err == nil && ip != "" {
//					if ips == "" {
//						ips = ip + ":9100"
//					} else {
//						ips = ips + "|" + ip + ":9100"
//					}
//				}
//			}
//			klog.Infof("ips",ips)
//			calculatResult.Cpu = append(calculatResult.Cpu, *getCpuRate(ips, aggregate.Name, servenDayAgotime))
//			calculatResult.Memory = append(calculatResult.Memory, *getMemoryRate(ips, aggregate.Name, servenDayAgotime))
//			calculatResult.Disk = append(calculatResult.Disk, *getDiskRate(ips, aggregate.Name, servenDayAgotime))
//		}
//		//计算资源池
//		cloudResult.ComputerResourcesPoolStatistics = calculatResult
//		//块存储资源池
//		cloudResult.BlockStorageResourcePoolStatistics = append(cloudResult.BlockStorageResourcePoolStatistics, *getCapRate(region, "ssd3.0", servenDayAgotime))
//		cloudResult.BlockStorageResourcePoolStatistics = append(cloudResult.BlockStorageResourcePoolStatistics, *getCapRate(region, "ehdd", servenDayAgotime))
//		//对象资源池
//		objectStorageResult.FileStorage = append(objectStorageResult.FileStorage, *getCapRate(region, "ks3", servenDayAgotime))
//		objectStorageResult.StandardStorage = append(objectStorageResult.StandardStorage, *getCapRate(region, "ks3", servenDayAgotime))
//		cloudResult.ObjectStorageResourcePoolStatistics = objectStorageResult
//
//		//success := ResponseObject{Code: 200, Message: "success", Data: cloudResult}
//		resq, _ := json.Marshal(cloudResult)
//		return string(resq), nil
//
//	}
//}
func getMonitorRateNew(monitorType ,poolName string, startDate time.Time) *LineDataResult {
	cpuLine := new(LineDataResult)
	cpuLine.ResourcePoolName = poolName
	var points []PointData
	for i := 0; i < 7; i++ {
		day := new(PointData)
		day.Date = startDate.AddDate(0, 0, i)
		var a   prometheusmanager.RateTopResult
		switch monitorType {
		case "cpu":
			a, _ = prometheusmanager.GetCpuRateNew(poolName, day.Date)
		case "mem":
			a, _ = prometheusmanager.GetMemoryRateNew(poolName, day.Date)
		case "disk":
			a, _ = prometheusmanager.GetDiskRateNew(poolName, day.Date)
		}
		if len(a.Result) > 0 {
			v2, _ := strconv.ParseFloat(a.Result[0].Value, 64)
			day.UsedRate = v2
		}
		points = append(points, *day)
	}
	cpuLine.ResourcePoolLine = points
	return cpuLine

}


func getCpuRate(ips string, poolName string, startDate time.Time) *LineDataResult {
	//ips = "10.178.225.231:9100|10.178.224.213:9100"
	cpuLine := new(LineDataResult)
	cpuLine.ResourcePoolName = poolName
	//cpuLine.IPS = ips
	var points []PointData
	//currentTime := time.Now()
	//cpuLine.ResourcePoolLine
	for i := 0; i < 7; i++ {
		day := new(PointData)
		day.Date = startDate.AddDate(0, 0, i)
		if ips == "" {
			day.UsedRate = 0
		} else {
			a, err := prometheusmanager.GetCpuRate(ips, day.Date)
			if err != nil {
				fmt.Println(err)
			}
			if len(a.Result) > 0 {
				v2, _ := strconv.ParseFloat(a.Result[0].Value, 64)
				day.UsedRate = v2
			}
		}

		points = append(points, *day)
	}
	cpuLine.ResourcePoolLine = points
	return cpuLine

}


func getMemoryRate(ips string, poolName string, startDate time.Time) *LineDataResult {
	//1先从dgraf中获取资源池类型和ip 进行分组   这边加一个结构体用来存储资源池类型和ips
	//2 用ip加时间点去promethus获取数据
	//tody:=new(PointData)
	//tody.Date=time.Now()
	//1
	//ips := "10.177.9.11:9100|10.177.16.2:9100"
	memoryLine := new(LineDataResult)
	memoryLine.ResourcePoolName = poolName
	//memoryLine.IPS = ips
	var points []PointData
	//currentTime := time.Now()
	//cpuLine.ResourcePoolLine
	for i := 0; i < 7; i++ {
		day := new(PointData)
		day.Date = startDate.AddDate(0, 0, i)
		if ips == "" {
			day.UsedRate = 0
		} else {
			a, err := prometheusmanager.GetMemoryRate(ips, day.Date)
			if err != nil {
				fmt.Println(err)
			}
			if len(a.Result) > 0 {
				v2, _ := strconv.ParseFloat(a.Result[0].Value, 64)
				day.UsedRate = v2
			}
		}
		points = append(points, *day)
	}
	memoryLine.ResourcePoolLine = points
	// var calculatResult []LineDataResult
	// calculatResult = append(calculatResult, *cpuLine)
	return memoryLine

}

func getDiskRate(ips string, poolName string, startDate time.Time) *LineDataResult {
	//1先从dgraf中获取资源池类型和ip 进行分组   这边加一个结构体用来存储资源池类型和ips
	//2 用ip加时间点去promethus获取数据
	//tody:=new(PointData)
	//tody.Date=time.Now()
	//1
	//ips := "10.177.9.11:9100|10.177.16.2:9100"
	diskLine := new(LineDataResult)
	diskLine.ResourcePoolName = poolName
	//diskLine.IPS = ips
	var points []PointData
	//currentTime := time.Now()
	//cpuLine.ResourcePoolLine
	for i := 0; i < 7; i++ {
		day := new(PointData)
		day.Date = startDate.AddDate(0, 0, i)
		if ips == "" {
			day.UsedRate = 0
		} else {
			a, err := prometheusmanager.GetDiskRate(ips, day.Date)
			if err != nil {
				fmt.Println(err)
			}
			if len(a.Result) > 0 {
				v2, _ := strconv.ParseFloat(a.Result[0].Value, 64)
				day.UsedRate = v2
			}
		}
		points = append(points, *day)
	}
	diskLine.ResourcePoolLine = points
	// var calculatResult []LineDataResult
	// calculatResult = append(calculatResult, *cpuLine)
	return diskLine

}

func getCapRate(region string, poolName string, startDate time.Time) *LineDataResult {
	//1先从dgraf中获取资源池类型和ip 进行分组   这边加一个结构体用来存储资源池类型和ips
	//2 用ip加时间点去promethus获取数据
	//tody:=new(PointData)
	//tody.Date=time.Now()
	//1
	//ips := "10.177.9.11:9100|10.177.16.2:9100"
	diskLine := new(LineDataResult)
	diskLine.ResourcePoolName = poolName
	//diskLine.IPS = ips
	var points []PointData

	//cpuLine.ResourcePoolLine
	for i := 0; i < 7; i++ {
		day := new(PointData)
		day.Date = startDate.AddDate(0, 0, i)
		capTotal := 0.00
		capUsed := 0.00
		CapacityTotal, err := prometheusmanager.GetCapTotal(region, poolName, day.Date)
		if err != nil {
			klog.Infoln("err:", err)
			day.UsedRate = 0
			//return objectStoragesResult, err
		} else {
			if len(CapacityTotal.Result) > 0 && len(CapacityTotal.Result[0].Values) > 0 {
				value := CapacityTotal.Result[0].Values[len(CapacityTotal.Result[0].Values)-1].([]interface{})
				v1, _ := strconv.ParseFloat(value[1].(string), 64)
				//v1, _ := strconv.ParseFloat(CapacityTotal.Result[0].Value, 64)
				capTotal = v1
			}
		}
		CapacityUsed, err := prometheusmanager.GetCapUsed(region, poolName, day.Date)
		// CapacityUsedRate, err := prom.GetCapRate(objectRe.RegionCode, config.ReasourcePoolMap[objectRe.Name], currentTime)
		if err != nil {
			klog.Infoln("err:", err)
			day.UsedRate = 0
		} else {
			if len(CapacityUsed.Result) > 0 && len(CapacityUsed.Result[0].Values) > 0 {
				value := CapacityUsed.Result[0].Values[len(CapacityUsed.Result[0].Values)-1].([]interface{})
				v2, _ := strconv.ParseFloat(value[1].(string), 64)
				//v2, _ := strconv.ParseFloat(CapacityUsed.Result[0].Value, 64)
				capUsed = v2
			}
		}

		if capTotal > 0 && capUsed < capTotal {
			v3, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", (capUsed/capTotal)*100), 64)
			day.UsedRate = v3
		} else {
			day.UsedRate = 0.00
		}
		// capacityTotal, err := prometheusmanager.GetCapRate(region, poolName, day.Date) //"cn_beijing"
		// if err != nil {
		// 	fmt.Println(err)
		// }
		// capacityUsed, err := prometheusmanager.GetCapRate(region, poolName, day.Date) //"cn_beijing"
		// if err != nil {
		// 	fmt.Println(err)
		// }
		// if len(capacityUsedRat.Result) > 0 && len(capacityUsedRat.Result[0].Values) > 0 {
		// 	value := capacityUsedRat.Result[0].Values[len(capacityUsedRat.Result[0].Values)-1].([]interface{})
		// 	v1, _ := strconv.ParseFloat(value[1].(string), 64)
		// 	day.UsedRate = v1
		// }
		points = append(points, *day)
		//fmt.Println("points", points)
	}
	diskLine.ResourcePoolLine = points
	// var calculatResult []LineDataResult
	// calculatResult = append(calculatResult, *cpuLine)
	//fmt.Println("------------------------+++++++++++++", diskLine)
	return diskLine

}

func GetCpuRateTop(request *restful.Request, response *restful.Response) {
	ips := "10.177.9.11:9100|10.177.16.2:9100"
	//result, _ := prometheusmanager.GetCpuRateTop(ips, time.Now())
	//result, _ := prometheusmanager.GetMemoryRateTop(ips, time.Now())
	result, _ := prometheusmanager.GetDiskRateTop("1", ips, time.Now())
	response.WriteEntity(result)
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/es-handler.go
```golang
package handler

import (
	"encoding/json"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/configs"
	"gorm.io/gorm"
	"io/ioutil"
	"net/http"
	"net/url"
	"sort"
	"strconv"
	"strings"
	"time"

	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/esmanager"
	"k8s.io/klog/v2"
)

func getFromES(request *restful.Request, response *restful.Response) {
	var esResult esmanager.AlertResult
	rst := new(alertmanagermodel.AlertSuccess)
	// s := fmt.Sprintf("alertmanager-%s", time.Now().Format("2006.1.2"))
	// _index := s
	// _type := "alert_group"
	// //qString := "p2"
	// var q []string
	// q = append(q, "p0")
	// q = append(q, "p1")
	// q = append(q, "p2")
	// q = append(q, "p3")
	// fmt.Printf("_index:%v;_type:%v,qstring:%v", _index, _type, q)
	// var alResult esmanager.AlertResult
	//res, _ := json.Marshal(alertList.GetAlertsList(_index, _type, qString))
	//err := alerResult.GetAlertsList(_index, _type, q, &alResult)
	// number := time.Duration(-1)
	// for {
	// 	if alResult.TotalCount < 100 && number >= -10 {
	// 		//res, _ := json.Marshal(alertList.GetAlertsList(_index, _type, qString))
	// 		s = fmt.Sprintf("alertmanager-%s", time.Now().Add(number).Format("2006.1.2"))
	// 		_index = s
	// 		err := alerResult.GetAlertsList(_index, _type, q, &alResult)
	// 		if err != nil {
	// 			break
	// 		}
	// 		number--
	// 	} else {
	// 		break
	// 	}
	// }
	t := new(alertmanagermodel.ESQuery)
	t.PageNo = 1
	t.PageSize = 100
	alertResult, err := esResult.GetEsPage(*t)
	if err != nil {
		rst.Code = 500
		rst.Message = "Please contact the administrator!!!"
		response.WriteAsJson(rst)
		return
	}
	success := ResponseObject{Code: 200, Message: "success", Data: alertResult}
	response.WriteAsJson(success)

}

func getESDataHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(alertmanagermodel.AlertSuccess)

	var esResult esmanager.AlertResult
	t := new(alertmanagermodel.ESQuery)
	request.ReadEntity(t)
	if t.PageNo == 0 {
		rst.Code = 500
		rst.Message = "pageNo false"
		response.WriteAsJson(rst)
		return
	}
	if t.PageSize == 0 {
		rst.Code = 500
		rst.Message = "pageSize false"
		response.WriteAsJson(rst)
		return
	}
	alertResult, err := esResult.GetEsPage(*t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = alertResult
		response.WriteAsJson(rst)
		return
	}

}

// GetAlertHistory 获取历史告警数据
func GetAlertHistory(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(alertmanagermodel.AlertSuccess)

	req := new(alertmanagermodel.HistoryAlertRequest)
	_ = request.ReadEntity(req)

	var alertHistorys []alertmanagermodel.AlertHistory

	offset := (req.PageNo - 1) * req.PageSize
	count := req.PageSize
	err := configs.DB.Where("policy_name = ?", req.PolicyName).Offset(offset).Limit(count).Find(&alertHistorys).Error

	if err != nil && err != gorm.ErrRecordNotFound {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	}

	rst.Data.PageNo = req.PageNo
	rst.Data.PageSize = req.PageSize
	for _, alert := range alertHistorys {
		alertData := alertmanagermodel.AlertData{
			Id:                     alert.AlertId,
			AlertName:              alert.AlertName,
			PolicyName:             alert.PolicyName,
			ResourceTypeName:       alert.ResourceType,
			ResourceSubTypeName:    alert.ResourceSubType,
			AlertLevel:             alert.Severity,
			Status:                 alert.Status,
			ExpressionWithChinaese: alert.Rule,
			ThresholdValue:         strconv.FormatFloat(*alert.ThresholdLow, 'f', 2, 64),
		}

		rst.Data.DataList = append(rst.Data.DataList, alertData)
	}
	rst.Data.TotalCount = len(rst.Data.DataList)

	rst.Code = 200
	rst.Message = "success"
	response.WriteAsJson(rst)
	return
}

func ReadRegionFromCMDB() ([]string, error) {
	regions := make([]string, 0)
	regionBody := cmdbservice.RegionResponse{}
	httpClient := http.Client{}
	urlStr := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/basic/getRegions"

	reqURL, err := url.Parse(urlStr)
	if err != nil {
		klog.Errorf("fail to parse url: %s", err.Error())
		return regions, err
	}

	regionReq := http.Request{
		Method: http.MethodGet,
		URL:    reqURL,
	}
	resp, err := httpClient.Do(&regionReq)
	if err != nil {
		klog.Errorf("fail to send request: %s", err.Error())
		return regions, err
	}
	defer resp.Body.Close()

	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		klog.Errorf("fail to read body: %s", err.Error())
		return regions, err
	}

	err = json.Unmarshal(body, &regionBody)
	if err != nil {
		klog.Errorf("fail to unmarshal body: %s", err.Error())
		return regions, err
	}

	for _, region := range regionBody.Data {
		regions = append(regions, region.RegionCode)
	}

	return regions, nil
}

func getAlertOverviewFromES(request *restful.Request, response *restful.Response) {
	region := request.QueryParameter("region")
	var regions []string
	filterAlerts := make([]alertmanagermodel.AlertData, 0)
	tmpAlertNumberByInstance := make(map[string]int)

	//var esResult esmanager.AlertResult
	t := new(alertmanagermodel.AlertQuery)
	result := new(alertmanagermodel.AlertOverviewResponse)

	tmpByLastTime := initByLastTimeStruct()
	tmpBySeverity := initSeverityOverview()
	tmpByTotalNumber := make(map[string]int)
	tmpByService := make(map[string]*alertmanagermodel.SeverityOverview)
	tmpByPhysicalHost := make(map[string]*alertmanagermodel.SeverityOverview)
	tmpByResourcePool := make(map[string]*alertmanagermodel.SeverityOverview)
	tmpByCloudProduct := make(map[string]*alertmanagermodel.SeverityOverview)

	tmpByService[alertmanagermodel.ResourceSubTypeServiceGalaxy] = initSeverityOverview()
	tmpByService[alertmanagermodel.ResourceSubTypeServiceLuban] = initSeverityOverview()

	tmpByPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalServer] = initSeverityOverview()
	tmpByPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalSwitch] = initSeverityOverview()

	tmpByResourcePool[alertmanagermodel.ResourceSubTypePoolKEC] = initSeverityOverview()
	tmpByResourcePool[alertmanagermodel.ResourceSubTypePoolEBS] = initSeverityOverview()
	//tmpByResourcePool[alertmanagermodel.ResourceSubTypePoolEHDD] = initSeverityOverview()
	tmpByResourcePool[alertmanagermodel.ResourceSubTypePoolKS3] = initSeverityOverview()

	tmpByCloudProduct[alertmanagermodel.ResourceSubTypeCloudKEC] = initSeverityOverview()
	tmpByCloudProduct[alertmanagermodel.ResourceSubTypeCloudEBS] = initSeverityOverview()
	tmpByCloudProduct[alertmanagermodel.ResourceSubTypeCloudKS3] = initSeverityOverview()

	if region == "" || region == "all" {
		cmdbRegions, err := ReadRegionFromCMDB()
		if err != nil {
			result.Code = 500
			result.Message = err.Error()
			response.WriteAsJson(result)
			return
		}
		regions = cmdbRegions
	} else {
		regions = []string{region}
	}
	// 取出所有满足条件的告警规则
	alertResult, err := alertmanager.GetAlertsDataList(*t)
	for _, alert := range alertResult.DataList {
		klog.Infof("Policy name is: %s, alert name is: %s, region: %s, az: %s",
			alert.PolicyName, alert.AlertName, alert.Region, alert.Az)
	}
	if err != nil {
		result.Code = 500
		result.Message = err.Error()
		response.WriteAsJson(result)
		return
	}

	for _, alert := range alertResult.DataList {
		for _, value := range regions {
			if alert.Region == value {
				filterAlerts = append(filterAlerts, alert)
			}
		}
	}

	for _, alert := range filterAlerts {
		// ByLastTime
		endTime := time.Now()
		if alert.EndsAt.After(alert.StartsAt) {
			endTime = alert.EndsAt
		}
		if endTime.Sub(alert.StartsAt) <= time.Minute*10 {
			tmpByLastTime[alertmanagermodel.LessThanTenMinKey].Number++
		} else if time.Minute*10 < endTime.Sub(alert.StartsAt) && endTime.Sub(alert.StartsAt) <= time.Hour*1 {
			tmpByLastTime[alertmanagermodel.TenMinToOneHourKey].Number++
		} else if time.Hour*1 < endTime.Sub(alert.StartsAt) && endTime.Sub(alert.StartsAt) <= time.Hour*24 {
			tmpByLastTime[alertmanagermodel.OneHourToOneDayKey].Number++
		} else {
			tmpByLastTime[alertmanagermodel.MoreThanOneDayKey].Number++
		}
		// ByLastTime
		// if alert.EndsAt.Sub(alert.StartsAt) <= time.Minute*10 {
		// 	tmpByLastTime[alertmanagermodel.LessThanTenMinKey].Number++
		// } else if time.Minute*10 < alert.EndsAt.Sub(alert.StartsAt) && alert.EndsAt.Sub(alert.StartsAt) <= time.Hour*1 {
		// 	tmpByLastTime[alertmanagermodel.TenMinToOneHourKey].Number++
		// } else if time.Hour*1 < alert.EndsAt.Sub(alert.StartsAt) && alert.EndsAt.Sub(alert.StartsAt) <= time.Hour*24 {
		// 	tmpByLastTime[alertmanagermodel.OneHourToOneDayKey].Number++
		// } else {
		// 	tmpByLastTime[alertmanagermodel.MoreThanOneDayKey].Number++
		// }

		// ByTotalNumber
		tmpAlertNumberByInstance[alert.AlertInstance]++

		// BySeverity
		setSeverity(alert.AlertLevel, tmpBySeverity)

		// ByService
		if alert.ResourceTypeCode == alertmanagermodel.ResourceTypeService {
			switch alert.ResourceSubTypeCode {
			case alertmanagermodel.ResourceSubTypeServiceGalaxy:
				{
					setSeverity(alert.AlertLevel, tmpByService[alertmanagermodel.ResourceSubTypeServiceGalaxy])
				}
			case alertmanagermodel.ResourceSubTypeServiceLuban:
				{
					setSeverity(alert.AlertLevel, tmpByService[alertmanagermodel.ResourceSubTypeServiceLuban])
				}
			default:
				{
					klog.Infof("invalid service sub resource type: %s", alert.ResourceSubTypeCode)
				}
			}
		}

		// ByPhysicalHost
		if alert.ResourceTypeCode == alertmanagermodel.ResourceTypePhysical {
			switch alert.ResourceSubTypeCode {
			case alertmanagermodel.ResourceSubTypePhysicalServer:
				{
					setSeverity(alert.AlertLevel, tmpByPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalServer])
				}
			case alertmanagermodel.ResourceSubTypePhysicalSwitch:
				{
					setSeverity(alert.AlertLevel, tmpByPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalSwitch])
				}
			default:
				{
					klog.Infof("invalid physical sub resource type: %s", alert.ResourceSubTypeCode)
				}
			}
		}

		// ByResourcePool
		if alert.ResourceTypeCode == alertmanagermodel.ResourceTypePool {
			switch alert.ResourceSubTypeCode {
			case alertmanagermodel.ResourceSubTypePoolKEC:
				{
					setSeverity(alert.AlertLevel, tmpByResourcePool[alertmanagermodel.ResourceSubTypePoolKEC])
				}
			case alertmanagermodel.ResourceSubTypePoolEBS:
				{
					setSeverity(alert.AlertLevel, tmpByResourcePool[alertmanagermodel.ResourceSubTypePoolEBS])
				}
			// case alertmanagermodel.ResourceSubTypePoolEHDD:
			// 	{
			// 		setSeverity(alert.AlertLevel, tmpByResourcePool[alertmanagermodel.ResourceSubTypePoolEHDD])
			// 	}
			case alertmanagermodel.ResourceSubTypePoolKS3:
				{
					setSeverity(alert.AlertLevel, tmpByResourcePool[alertmanagermodel.ResourceSubTypePoolKS3])
				}
			default:
				{
					klog.Infof("invalid pool resource type: %s", alert.ResourceSubTypeCode)
				}
			}
		}

		// ByCloudProduct
		if alert.ResourceTypeCode == alertmanagermodel.ResourceTypeCloud {
			switch alert.ResourceSubTypeCode {
			case alertmanagermodel.ResourceSubTypeCloudKEC:
				{
					setSeverity(alert.AlertLevel, tmpByCloudProduct[alertmanagermodel.ResourceSubTypeCloudKEC])
				}
			case alertmanagermodel.ResourceSubTypeCloudEBS:
				{
					setSeverity(alert.AlertLevel, tmpByCloudProduct[alertmanagermodel.ResourceSubTypeCloudEBS])
				}
			case alertmanagermodel.ResourceSubTypeCloudKS3:
				{
					setSeverity(alert.AlertLevel, tmpByCloudProduct[alertmanagermodel.ResourceSubTypeCloudKS3])
				}
			default:
				{
					klog.Infof("invalid cloud resource type: %s", alert.ResourceSubTypeCode)
				}
			}
		}
	}

	tmpBySeverity.TotalNumber = tmpBySeverity.P0Alert.Number +
		tmpBySeverity.P1Alert.Number +
		tmpBySeverity.P2Alert.Number +
		tmpBySeverity.P3Alert.Number

	sortedAlertNumberByInstance := rankByWordCount(tmpAlertNumberByInstance)
	for i := 0; i < 10; i++ {
		if i > (len(sortedAlertNumberByInstance)-1) || len(sortedAlertNumberByInstance) <= 0 {
			klog.Infof("alert number summarized by hostname is less than 10: %d", len(sortedAlertNumberByInstance))
			break
		}
		tmpByTotalNumber[sortedAlertNumberByInstance[i].Key] = sortedAlertNumberByInstance[i].Value
	}

	for k, v := range tmpByLastTime {
		klog.Infof("order alarm by lasttime, %s: %+v", k, *v)
	}
	convertToLubanFEStruct(
		&result.Data,
		tmpByLastTime,
		*tmpBySeverity,
		tmpByTotalNumber,
		tmpByService,
		tmpByPhysicalHost,
		tmpByResourcePool,
		tmpByCloudProduct,
	)

	for _, value := range result.Data.ByLastTime {
		klog.Infof("value: %+v", *value)
	}

	result.Code = 200
	result.Message = "success"
	response.WriteAsJson(result)
}

func convertToLubanFEStruct(
	data *alertmanagermodel.AlertOverview,
	byLastTime map[string]*alertmanagermodel.AlertStruct,
	bySeverity alertmanagermodel.SeverityOverview,
	byTotalNumber map[string]int,
	byService map[string]*alertmanagermodel.SeverityOverview,
	byPhysicalHost map[string]*alertmanagermodel.SeverityOverview,
	byResourcePool map[string]*alertmanagermodel.SeverityOverview,
	byCloudProduct map[string]*alertmanagermodel.SeverityOverview,
) {

	data.ByLastTime = make([]*alertmanagermodel.Value, 0)
	data.BySeverity.Values = make([]alertmanagermodel.Value, 0)
	data.ByTotalNumber.Values = make([]alertmanagermodel.Value, 0)
	data.ByService = make([]*alertmanagermodel.LubanFETileStruct, 0)
	data.ByPhysicalHost = make([]*alertmanagermodel.LubanFETileStruct, 0)
	data.ByResourcePool = make([]*alertmanagermodel.LubanFETileStruct, 0)
	data.ByCloudProduct = make([]*alertmanagermodel.LubanFETileStruct, 0)

	data.ByLastTime = []*alertmanagermodel.Value{
		{
			Value: byLastTime[alertmanagermodel.LessThanTenMinKey].Number,
			Name:  byLastTime[alertmanagermodel.LessThanTenMinKey].ChineseName,
			Key:   alertmanagermodel.LessThanTenMinKey,
		},
		{
			Value: byLastTime[alertmanagermodel.TenMinToOneHourKey].Number,
			Name:  byLastTime[alertmanagermodel.TenMinToOneHourKey].ChineseName,
			Key:   alertmanagermodel.TenMinToOneHourKey,
		},
		{
			Value: byLastTime[alertmanagermodel.OneHourToOneDayKey].Number,
			Name:  byLastTime[alertmanagermodel.OneHourToOneDayKey].ChineseName,
			Key:   alertmanagermodel.OneHourToOneDayKey,
		},
		{
			Value: byLastTime[alertmanagermodel.MoreThanOneDayKey].Number,
			Name:  byLastTime[alertmanagermodel.MoreThanOneDayKey].ChineseName,
			Key:   alertmanagermodel.MoreThanOneDayKey,
		},
	}

	data.BySeverity.Values = []alertmanagermodel.Value{
		{
			Name:  bySeverity.P0Alert.ChineseName,
			Value: bySeverity.P0Alert.Number,
		},
		{
			Name:  bySeverity.P1Alert.ChineseName,
			Value: bySeverity.P1Alert.Number,
		},
		{
			Name:  bySeverity.P2Alert.ChineseName,
			Value: bySeverity.P2Alert.Number,
		},
		{
			Name:  bySeverity.P3Alert.ChineseName,
			Value: bySeverity.P3Alert.Number,
		},
	}

	data.ByTotalNumber.Info.Name = "告警数"
	for key, value := range byTotalNumber {
		data.ByTotalNumber.Values = append(data.ByTotalNumber.Values, alertmanagermodel.Value{
			Value: value,
			Name:  key,
		})
	}

	data.ByService = []*alertmanagermodel.LubanFETileStruct{
		{
			Prefix: "总数",
			Number: byService[alertmanagermodel.ResourceSubTypeServiceGalaxy].TotalNumber,
			Unit:   "次",
			Label:  alertmanagermodel.ResourceSubTypeServiceGalaxyChinese,
			List: []alertmanagermodel.TileItem{
				{
					Number: byService[alertmanagermodel.ResourceSubTypeServiceGalaxy].P0Alert.Number,
					Label:  byService[alertmanagermodel.ResourceSubTypeServiceGalaxy].P0Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP0FEKind,
				},
				{
					Number: byService[alertmanagermodel.ResourceSubTypeServiceGalaxy].P1Alert.Number,
					Label:  byService[alertmanagermodel.ResourceSubTypeServiceGalaxy].P1Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP1FEKind,
				},
				{
					Number: byService[alertmanagermodel.ResourceSubTypeServiceGalaxy].P2Alert.Number,
					Label:  byService[alertmanagermodel.ResourceSubTypeServiceGalaxy].P2Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP2FEKind,
				},
				{
					Number: byService[alertmanagermodel.ResourceSubTypeServiceGalaxy].P3Alert.Number,
					Label:  byService[alertmanagermodel.ResourceSubTypeServiceGalaxy].P3Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP3FEKind,
				},
			},
		},
		{
			Prefix: "总数",
			Number: byService[alertmanagermodel.ResourceSubTypeServiceLuban].TotalNumber,
			Unit:   "次",
			Label:  alertmanagermodel.ResourceSubTypeServiceLubanChinese,
			List: []alertmanagermodel.TileItem{
				{
					Number: byService[alertmanagermodel.ResourceSubTypeServiceLuban].P0Alert.Number,
					Label:  byService[alertmanagermodel.ResourceSubTypeServiceLuban].P0Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP0FEKind,
				},
				{
					Number: byService[alertmanagermodel.ResourceSubTypeServiceLuban].P1Alert.Number,
					Label:  byService[alertmanagermodel.ResourceSubTypeServiceLuban].P1Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP1FEKind,
				},
				{
					Number: byService[alertmanagermodel.ResourceSubTypeServiceLuban].P2Alert.Number,
					Label:  byService[alertmanagermodel.ResourceSubTypeServiceLuban].P2Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP2FEKind,
				},
				{
					Number: byService[alertmanagermodel.ResourceSubTypeServiceLuban].P3Alert.Number,
					Label:  byService[alertmanagermodel.ResourceSubTypeServiceLuban].P3Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP3FEKind,
				},
			},
		},
	}

	/*
		for key, value := range byService {
			data.ByService = append(data.ByService, &alertmanagermodel.LubanFETileStruct{
				Prefix: "总数",
				Number: value.TotalNumber,
				Unit:   "次",
				Label:  key,
				List: []alertmanagermodel.TileItem{
					{
						Number: value.P0Alert.Number,
						Label:  value.P0Alert.ChineseName,
					},
					{
						Number: value.P1Alert.Number,
						Label:  value.P1Alert.ChineseName,
					},
					{
						Number: value.P2Alert.Number,
						Label:  value.P2Alert.ChineseName,
					},
					{
						Number: value.P3Alert.Number,
						Label:  value.P3Alert.ChineseName,
					},
				},
			})
		}
	*/

	data.ByPhysicalHost = []*alertmanagermodel.LubanFETileStruct{
		{
			Prefix: "总数",
			Number: byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalServer].TotalNumber,
			Unit:   "次",
			Label:  alertmanagermodel.ResourceSubTypePhysicalServerChinese,
			List: []alertmanagermodel.TileItem{
				{
					Number: byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalServer].P0Alert.Number,
					Label:  byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalServer].P0Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP0FEKind,
				},
				{
					Number: byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalServer].P1Alert.Number,
					Label:  byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalServer].P1Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP1FEKind,
				},
				{
					Number: byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalServer].P2Alert.Number,
					Label:  byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalServer].P2Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP2FEKind,
				},
				{
					Number: byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalServer].P3Alert.Number,
					Label:  byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalServer].P3Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP3FEKind,
				},
			},
		},
		{
			Prefix: "总数",
			Number: byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalSwitch].TotalNumber,
			Unit:   "次",
			Label:  alertmanagermodel.ResourceSubTypePhysicalSwitchChinese,
			List: []alertmanagermodel.TileItem{
				{
					Number: byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalSwitch].P0Alert.Number,
					Label:  byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalSwitch].P0Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP0FEKind,
				},
				{
					Number: byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalSwitch].P1Alert.Number,
					Label:  byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalSwitch].P1Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP1FEKind,
				},
				{
					Number: byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalSwitch].P2Alert.Number,
					Label:  byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalSwitch].P2Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP2FEKind,
				},
				{
					Number: byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalSwitch].P3Alert.Number,
					Label:  byPhysicalHost[alertmanagermodel.ResourceSubTypePhysicalSwitch].P3Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP3FEKind,
				},
			},
		},
	}

	data.ByResourcePool = []*alertmanagermodel.LubanFETileStruct{
		{
			Prefix: "总数",
			Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolKEC].TotalNumber,
			Unit:   "次",
			Label:  alertmanagermodel.ResourceSubTypePoolKECChinese,
			List: []alertmanagermodel.TileItem{
				{
					Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolKEC].P0Alert.Number,
					Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolKEC].P0Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP0FEKind,
				},
				{
					Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolKEC].P1Alert.Number,
					Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolKEC].P1Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP1FEKind,
				},
				{
					Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolKEC].P2Alert.Number,
					Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolKEC].P2Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP2FEKind,
				},
				{
					Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolKEC].P3Alert.Number,
					Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolKEC].P3Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP3FEKind,
				},
			},
		},
		{
			Prefix: "总数",
			Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolEBS].TotalNumber,
			Unit:   "次",
			Label:  alertmanagermodel.ResourceSubTypePoolEBSChinese,
			List: []alertmanagermodel.TileItem{
				{
					Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolEBS].P0Alert.Number,
					Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolEBS].P0Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP0FEKind,
				},
				{
					Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolEBS].P1Alert.Number,
					Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolEBS].P1Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP1FEKind,
				},
				{
					Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolEBS].P2Alert.Number,
					Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolEBS].P2Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP2FEKind,
				},
				{
					Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolEBS].P3Alert.Number,
					Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolEBS].P3Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP3FEKind,
				},
			},
		},
		// {
		// 	Prefix: "总数",
		// 	Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolEHDD].TotalNumber,
		// 	Unit:   "次",
		// 	Label:  alertmanagermodel.ResourceSubTypePoolEHDDChinese,
		// 	List: []alertmanagermodel.TileItem{
		// 		{
		// 			Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolEHDD].P0Alert.Number,
		// 			Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolEHDD].P0Alert.ChineseName,
		// 			Kind:   alertmanagermodel.SeverityP0FEKind,
		// 		},
		// 		{
		// 			Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolEHDD].P1Alert.Number,
		// 			Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolEHDD].P1Alert.ChineseName,
		// 			Kind:   alertmanagermodel.SeverityP1FEKind,
		// 		},
		// 		{
		// 			Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolEHDD].P2Alert.Number,
		// 			Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolEHDD].P2Alert.ChineseName,
		// 			Kind:   alertmanagermodel.SeverityP2FEKind,
		// 		},
		// 		{
		// 			Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolEHDD].P3Alert.Number,
		// 			Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolEHDD].P3Alert.ChineseName,
		// 			Kind:   alertmanagermodel.SeverityP3FEKind,
		// 		},
		// 	},
		// },
		{
			Prefix: "总数",
			Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolKS3].TotalNumber,
			Unit:   "次",
			Label:  alertmanagermodel.ResourceSubTypePoolKS3Chinese,
			List: []alertmanagermodel.TileItem{
				{
					Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolKS3].P0Alert.Number,
					Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolKS3].P0Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP0FEKind,
				},
				{
					Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolKS3].P1Alert.Number,
					Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolKS3].P1Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP1FEKind,
				},
				{
					Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolKS3].P2Alert.Number,
					Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolKS3].P2Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP2FEKind,
				},
				{
					Number: byResourcePool[alertmanagermodel.ResourceSubTypePoolKS3].P3Alert.Number,
					Label:  byResourcePool[alertmanagermodel.ResourceSubTypePoolKS3].P3Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP3FEKind,
				},
			},
		},
	}

	data.ByCloudProduct = []*alertmanagermodel.LubanFETileStruct{
		{
			Prefix: "总数",
			Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKEC].TotalNumber,
			Unit:   "次",
			Label:  alertmanagermodel.ResourceSubTypeCloudKECChinese,
			List: []alertmanagermodel.TileItem{
				{
					Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKEC].P0Alert.Number,
					Label:  byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKEC].P0Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP0FEKind,
				},
				{
					Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKEC].P1Alert.Number,
					Label:  byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKEC].P1Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP1FEKind,
				},
				{
					Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKEC].P2Alert.Number,
					Label:  byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKEC].P2Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP2FEKind,
				},
				{
					Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKEC].P3Alert.Number,
					Label:  byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKEC].P3Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP3FEKind,
				},
			},
		},
		{
			Prefix: "总数",
			Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudEBS].TotalNumber,
			Unit:   "次",
			Label:  alertmanagermodel.ResourceSubTypeCloudEBSChinese,
			List: []alertmanagermodel.TileItem{
				{
					Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudEBS].P0Alert.Number,
					Label:  byCloudProduct[alertmanagermodel.ResourceSubTypeCloudEBS].P0Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP0FEKind,
				},
				{
					Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudEBS].P1Alert.Number,
					Label:  byCloudProduct[alertmanagermodel.ResourceSubTypeCloudEBS].P1Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP1FEKind,
				},
				{
					Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudEBS].P2Alert.Number,
					Label:  byCloudProduct[alertmanagermodel.ResourceSubTypeCloudEBS].P2Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP2FEKind,
				},
				{
					Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudEBS].P3Alert.Number,
					Label:  byCloudProduct[alertmanagermodel.ResourceSubTypeCloudEBS].P3Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP3FEKind,
				},
			},
		},
		{
			Prefix: "总数",
			Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKS3].TotalNumber,
			Unit:   "次",
			Label:  alertmanagermodel.ResourceSubTypeCloudKS3Chinese,
			List: []alertmanagermodel.TileItem{
				{
					Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKS3].P0Alert.Number,
					Label:  byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKS3].P0Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP0FEKind,
				},
				{
					Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKS3].P1Alert.Number,
					Label:  byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKS3].P1Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP1FEKind,
				},
				{
					Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKS3].P2Alert.Number,
					Label:  byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKS3].P2Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP2FEKind,
				},
				{
					Number: byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKS3].P3Alert.Number,
					Label:  byCloudProduct[alertmanagermodel.ResourceSubTypeCloudKS3].P3Alert.ChineseName,
					Kind:   alertmanagermodel.SeverityP3FEKind,
				},
			},
		},
	}

}

func setSeverity(level string, severityOverview *alertmanagermodel.SeverityOverview) {
	severity := strings.ToLower(level)
	switch severity {
	case alertmanagermodel.SeverityP0Key:
		{
			severityOverview.P0Alert.Number++
		}
	case alertmanagermodel.SeverityP1Key:
		{
			severityOverview.P1Alert.Number++
		}
	case alertmanagermodel.SeverityP2Key:
		{
			severityOverview.P2Alert.Number++
		}
	case alertmanagermodel.SeverityP3Key:
		{
			severityOverview.P3Alert.Number++
		}
	default:
		// skip total number modification
		klog.Infof("invalid severity level: %s", severity)
		return
	}

	severityOverview.TotalNumber++
}

func initByLastTimeStruct() map[string]*alertmanagermodel.AlertStruct {
	result := make(map[string]*alertmanagermodel.AlertStruct)
	if _, ok := result[alertmanagermodel.LessThanTenMinKey]; !ok {
		result[alertmanagermodel.LessThanTenMinKey] = new(alertmanagermodel.AlertStruct)
	}
	result[alertmanagermodel.LessThanTenMinKey].ChineseName = alertmanagermodel.LessThanTenMinChinese

	if _, ok := result[alertmanagermodel.TenMinToOneHourKey]; !ok {
		result[alertmanagermodel.TenMinToOneHourKey] = new(alertmanagermodel.AlertStruct)
	}
	result[alertmanagermodel.TenMinToOneHourKey].ChineseName = alertmanagermodel.TenMinToOneHourChinese

	if _, ok := result[alertmanagermodel.OneHourToOneDayKey]; !ok {
		result[alertmanagermodel.OneHourToOneDayKey] = new(alertmanagermodel.AlertStruct)
	}
	result[alertmanagermodel.OneHourToOneDayKey].ChineseName = alertmanagermodel.OneHourToOneDayChinese

	if _, ok := result[alertmanagermodel.MoreThanOneDayKey]; !ok {
		result[alertmanagermodel.MoreThanOneDayKey] = new(alertmanagermodel.AlertStruct)
	}
	result[alertmanagermodel.MoreThanOneDayKey].ChineseName = alertmanagermodel.MoreThanOneDayChinese

	return result
}

func initSeverityOverview() *alertmanagermodel.SeverityOverview {
	result := new(alertmanagermodel.SeverityOverview)
	result.P0Alert.ChineseName = alertmanagermodel.SeverityP0Chinese
	result.P1Alert.ChineseName = alertmanagermodel.SeverityP1Chinese
	result.P2Alert.ChineseName = alertmanagermodel.SeverityP2Chinese
	result.P3Alert.ChineseName = alertmanagermodel.SeverityP3Chinese
	return result
}

func rankByWordCount(wordFrequencies map[string]int) PairList {
	pl := make(PairList, len(wordFrequencies))
	i := 0
	for k, v := range wordFrequencies {
		pl[i] = Pair{k, v}
		i++
	}
	sort.Sort(sort.Reverse(pl))
	return pl
}

type Pair struct {
	Key   string
	Value int
}

type PairList []Pair

func (p PairList) Len() int           { return len(p) }
func (p PairList) Less(i, j int) bool { return p[i].Value > p[j].Value }
func (p PairList) Swap(i, j int)      { p[i], p[j] = p[j], p[i] }

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/alertmanager-handler.go
```golang
package handler

import (
	"encoding/json"
	"io/ioutil"
	"net/http"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"

	"github.com/emicklei/go-restful/v3"

	alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	// "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/esmanager"
)

func getFromAlertManager(request *restful.Request, response *restful.Response) {
	client := &http.Client{}
	var body []byte
	//var alertData AlertData
	var alertResult alertmanagermodel.AlertResult
	var alertModel alertmanagermodel.AlertData
	level := request.PathParameter("AlertLevel")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	if level == "" {
		response.WriteErrorString(500, "请输入Level!")
	} else {
		//severity.Level = level
		parem := ""
		if level == "all" {

		} else {
			parem = "&filter=severity%3D%22" + level + "%22"
		}
		reqest, _ := http.NewRequest("GET", "http://"+config.GetDefaultUrl(config.AlertmanagerService)+"/api/v2/alerts/groups?silenced=false&inhibited=false&active=true"+parem, nil)

		reqest.Header.Set("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8")
		reqest.Header.Set("Accept-Charset", "GBK,utf-8;q=0.7,*;q=0.3")
		reqest.Header.Set("Accept-Encoding", "gzip,deflate,sdch")
		reqest.Header.Set("Accept-Language", "zh-CN,zh;q=0.8")
		reqest.Header.Set("Cache-Control", "max-age=0")
		reqest.Header.Set("Connection", "keep-alive")
		reqest.Header.Set("User-Agent", "chrome 100")

		respons, err1 := client.Do(reqest)
		if respons.StatusCode == 200 {
			bodyR, _ := ioutil.ReadAll(respons.Body)
			var js []interface{}
			err := json.Unmarshal(bodyR, &js)
			//fmt.Println(js)
			if err == nil {
				for _, data := range js {

					//fmt.Println(severity.LevelCount)
					wsMap := data.(map[string]interface{})
					if vCw, ok := wsMap["labels"]; ok {
						labels := vCw.(map[string]interface{})
						if alertName, ok := labels["alertname"]; ok {
							alertModel.AlertName = alertName.(string)
							//fmt.Println(alertName.(string))
						}
					}
					if vCw, ok := wsMap["alerts"]; ok {
						alerts := vCw.([]interface{})
						for _, alert := range alerts {
							alertResult.TotalCount += 1
							alertData := alert.(map[string]interface{})
							if aCw, ok := alertData["labels"]; ok {
								labels := aCw.(map[string]interface{})
								if alertName, ok := labels["alertname"]; ok {
									alertModel.AlertName = alertName.(string)
									//fmt.Println(alertName.(string))
								}
								if instance, ok := labels["instance"]; ok {
									alertModel.AlertInstance = instance.(string)
									//fmt.Println(instance.(string))
								}
								// if region, ok := labels["region"]; ok {
								// 	//alertModel.BelongRegion = region.(string)
								// 	//fmt.Println(region.(string))
								// }
								// if zone, ok := labels["zone"]; ok {
								// 	alertModel.AvailableArea = zone.(string)
								// 	//fmt.Println(zone.(string))
								// }
								if severity, ok := labels["severity"]; ok {
									alertModel.AlertLevel = severity.(string)
									//fmt.Println(zone.(string))
								}
								alertModel.ResourceTypeCode = "物理资源"
							}
							// if sAt, er := alertData["startsAt"]; er {
							// 	//fmt.Println(sAt)
							// 	tt, _ := time.Parse("2006-01-02T15:04:05Z07:00", sAt.(string))
							// 	alertModel.StartsAt = tt
							// }
							alertResult.DataList = append(alertResult.DataList, alertModel)
						}
					}
				}

				if err == nil {
					//alertData.Platform_Alert_Current_Detail = severity
					//alertResult.TotalPage = 100
					body, err = json.Marshal(&alertResult)
				} else {
					response.WriteError(500, err)
				}
			} else {
				response.WriteError(500, err)
			}

		} else {
			response.WriteError(500, err1)
		}
	}
	//response.Error()
	//response.AddHeader("Access-Control-Allow-Origin", "*")
	response.Write(body)

}

func getAlertData(request *restful.Request, response *restful.Response) {
	p0, _ := alertmanager.GetAlertsByLevel("p0")
	p1, _ := alertmanager.GetAlertsByLevel("p1")
	p2, _ := alertmanager.GetAlertsByLevel("p2")
	p3, _ := alertmanager.GetAlertsByLevel("p3")

	a := AlertLevels{len(p0), len(p1), len(p2), len(p3)}
	b, err := json.Marshal(a)
	if err != nil {
		response.Write([]byte(err.Error()))
	}
	response.Write(b)
}

func getAlertLevelDetail(request *restful.Request, response *restful.Response) {
	//l := request.PathParameter("pLevel")
	//p, _ := alertmanager.GetAlertsByLevel(l)
	//alerts := []AlertDetail{}
	//for _, al := range p {
	//	fmt.Println(al.(type))
	//	}
	//}
	//if err != nil {
	//	response.Write([]byte(err.Error()))
	//}
	//response.Write(b)
}

func PostAlertsHandler(request *restful.Request, response *restful.Response) {
	rst := new(alertmanagermodel.AlertSuccess)
	t := new(alertmanagermodel.AlertQuery)
	request.ReadEntity(t)
	//pageNo, err := strconv.Atoi(request.QueryParameter("pageNo"))
	if t.SearchKey != "" && t.SearchValue != "" {
		switch t.SearchKey {
		case "alertName":
			t.AlertName = t.SearchValue
		case "handler":
			t.Handler = t.SearchValue
		case "expressionWithChinaese":
			t.ExpressionWithChinaese = t.SearchValue
		case "id":
			t.Id = t.SearchValue
		case "instanceId":
			t.InstanceId = string(t.SearchValue) //20220108针对服务实例
		case "alertInstance":
			t.AlertInstance = t.SearchValue
			// case "alertIp":
			// 	t.InstanceIp = t.SearchValue
		}
	}
	if t.PageNo == 0 {
		rst.Code = 500
		rst.Message = "pageNo false"
		response.WriteAsJson(rst)
		return
	}

	if t.PageSize == 0 {
		rst.Code = 500
		rst.Message = "pageSize false"
		response.WriteAsJson(rst)
		return
	}
	//alertName := request.QueryParameter("alertName")
	// if t.AlertName != "" {
	// 	alertName := url.QueryEscape(t.AlertName)
	// 	t.Filter = fmt.Sprintf(`%s&filter=lubanAlarmView="%s"`, t.Filter, alertName)
	// }
	//alertInstance := request.QueryParameter("alertInstance")
	// if t.AlertInstance != "" {
	// 	t.Filter = fmt.Sprintf(`%s&filter=instance="%s"`, t.Filter, url.QueryEscape(t.AlertInstance))
	// }
	alertDataResult, err := alertmanager.GetAlertsDataListPage(*t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = alertDataResult
		response.WriteAsJson(rst)
		return
	}
}

func getCurrentDataOfAlert(request *restful.Request, response *restful.Response) {
	rst := new(alertmanagermodel.AlertSuccess)
	t := new(alertmanagermodel.AlertQuery)
	t.PageNo = 1
	t.PageSize = 100
	alertResult, err := alertmanager.GetAlertsDataListPage(*t)
	if err != nil {
		rst.Code = 500
		rst.Message = "Please contact the administrator!!!"
		response.WriteAsJson(rst)
		return
	}
	success := ResponseObject{Code: 200, Message: "success", Data: alertResult}
	response.WriteAsJson(success)

}

type AlertDetail struct {
	Name   string `json:"alertname"`
	State  string `json:"state"`
	Pool   string `json:"pool"`
	Region string `json:"region"`
	Zone   string `json:"zone"`
	SN     string `json:"fingerprint"`
	OS     string `json:"os"`
	IP     string `json:"instance"`
	Detail string
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/prometheus-handler.go
```golang
package handler

import (
	"encoding/json"
	"io"
	"net/http"
	"strings"

	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
)

type Prometheus struct {
	Status string   `json:"status"`
	Data   DataType `json:"data"`
}

type DataType struct {
	ActiveTargets []At `json:"activeTargets"`
}

type At struct {
	DiscoveredLables DisLabels `json:"discoveredLabels"`
	Labels           Lbs       `json:"labels"`
	Health           string    `json:"health"`
}

type DisLabels struct {
	Address string `json:"__address__"`
	Job     string `json:"job"`
}

type Lbs struct {
	Instance string `json:"instance"`
	Job      string `json:"job"`
	Service  string `json:"service"`
}

var (
	prome = new(Prometheus)
	//rs    = DgraphData{}
	//es    = DgraphData{}
	ri = []string{}
)

func getFromPrometheus(request *restful.Request, response *restful.Response) {

	if n := request.PathParameter("region"); n == "" {
		response.Write([]byte("region is nil, Invalid value!!!"))
		return
	}

	s, _ := getState()
	r := RegionCurrentStates{Region: request.PathParameter("region"), PhysicalRunningCount: s.PhysicalRunningCount, PhysicalErrorCount: s.PhysicalErrorCount}

	success := ResponseObject{Code: 200, Message: "success", Data: r}
	response.WriteAsJson(success)

}

// func getStateDetail(request *restful.Request, response *restful.Response) {
// 	state := request.PathParameter("state")
// 	all := GetAllPhysicals("physical_server")
// 	for i := 0; i < len(all.Host); i++ {
// 		for j := 0; j < len(ri); j++ {
// 			if ri[j] == all.Host[i].Ip {
// 				rs.Host = append(rs.Host, all.Host[i])
// 			} else {
// 				es.Host = append(es.Host, all.Host[i])
// 			}
// 		}
// 	}
// 	if state == "up" {
// 		b, _ := json.Marshal(rs)
// 		response.Write(b)
// 	} else {
// 		b, _ := json.Marshal(es)
// 		response.Write(b)
// 	}
// }

func getState() (RegionCurrentStates, error) {
	c := http.Client{}
	r := RegionCurrentStates{}
	resp, err := c.Get("http://" + config.GetDefaultUrl(config.PrometheusService) + "/api/v1/targets")
	if err != nil {
		return r, err
	}

	b, _ := io.ReadAll(resp.Body)
	json.Unmarshal(b, prome)

	for i := 0; i < len(prome.Data.ActiveTargets); i++ {
		if prome.Data.ActiveTargets[i].Labels.Job == config.PhysicalServers {
			if prome.Data.ActiveTargets[i].Health == "up" {
				s := strings.Split(prome.Data.ActiveTargets[i].Labels.Instance, ":")
				ri = append(ri, s[0])
				r.PhysicalRunningCount++
			} else {
				r.PhysicalErrorCount++
			}
		}
	}
	return r, nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/dashboard-handler.go
```golang
package handler

import (
	"context"
	temp "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/physicalSwitch"
	"strings"
	"time"

	"github.com/emicklei/go-restful/v3"
	switchmodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/physicalSwitch"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	cmdb "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/esmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/physicalSwitch"
	prom "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/klog/v2"
)

const (
	DefaultLabelKey   = "luban"
	DefaultLabelValue = "dashboard"
	DefaultName       = "default"
	DefaultMapKey     = "title"
	DefaultMapValue   = "Dashboard"
)

type DashboardDataListSuccess struct {
	Code    int               `json:"code"`
	Message string            `json:"message"`
	Data    DashboardDataList `json:"data"`
}

type DashboardDataList struct {
	DashboardDataDetails []DashboardDataDetail `json:"dashboardDataDetails"`
}

type DashboardResponseSuccess struct {
	Code    int                 `json:"code"`
	Message string              `json:"message"`
	Data    DashboardDataDetail `json:"data"`
}

type DashboardDataDetail struct {
	Name string `json:"name"`
	//Title    string            `json:"title"`
	//Type     string            `json:"type"`
	//ImageURL string            `json:"imageURL"`
	//Label    map[string]string `json:"label"`
	Data map[string]string `json:"data"`
}

type PlatformSuccess struct {
	Code    int          `json:"code"`
	Message string       `json:"message"`
	Data    PlatformJson `json:"data"`
}

type PlatformJson struct {
	Name               string                  `json:"name"`
	PlatformRegionList []RegionType            `json:"platformRegionList"`
	AlertLevel         AlertLevels             `json:"alertLevel"`
	Alerts             []esmanager.AlertResult `json:"alerts"`
}

type RegionLeftSuccess struct {
	Code    int        `json:"code"`
	Message string     `json:"message"`
	Data    RegionJson `json:"data"`
}
type RegionJson struct {
	Name                  string               `json:"name"`
	RegionResourceCount   RegionResourceCounts `json:"regionResourceCount"`
	RegionCurrentState    RegionCurrentStates  `json:"regionCurrentState"`
	RegionSwitchState     RegionSwitchState    `json:"regionSwitchState"`
	ResourceUsageRateTop5 UsageRateTop5        `json:"resourceUsageRateTop5"`
}

type RegionResourceCounts struct {
	Region            string `json:"region"`
	RegionServerCount int    `json:"regionServerCount"`
	RegionSwitchCount int    `json:"regionSwitchCount"`
}

type RegionCurrentStates struct {
	Region               string `json:"region"`
	PhysicalRunningCount int    `json:"physicalRunningCount"`
	PhysicalErrorCount   int    `json:"physicalErrorCount"`
}

type RegionSwitchState struct {
	Region             string `json:"region"`
	SwitchRunningCount int    `json:"switchRunningCount"`
	SwitchErrorCount   int    `json:"switchErrorCount"`
}

type RegionPhysicalStates struct {
	MetricName string `json:"metricName"`
	State      string `json:"state"`
	Count      int    `json:"count"`
	Timestamp  string `json:"timestamp"`
}

type RegionType struct {
	RegionCode string `json:"region_code"`
	RegionName string `json:"region_name"`
}

type AlertLevels struct {
	P0 int `json:"p0"`
	P1 int `json:"p1"`
	P2 int `json:"p2"`
	P3 int `json:"p3"`
}

type UsageRateTop5 struct {
	CpuTop5     []Column `json:"cpuTop5"`
	MemTop5     []Column `json:"memTop5"`
	StorageTop5 []Column `json:"storageTop5"`
}

type Column struct {
	Name    string `json:"name"`
	Percent string `json:"percent"`
}

type Labels struct {
	Account     string `json:"account"`
	AlertSource string `json:"alertSource"` // alert source: cluster, node, container
	Cluster     string `json:"cluster"`
	Container   string `json:"container"` // container alert message field
	Namespace   string `json:"namespace"` // container alert message field
	Node        string `json:"node"`      // node alert message field
	Pod         string `json:"pod"`       // container alert message field
	Region      string `json:"region"`
	Severity    string `json:"severity"`
}

type Annotations struct {
	Description string `json:"description"`
	Summary     string `json:"summary"`
}

func postDashboard(request *restful.Request, response *restful.Response) {
	conMap := &v1.ConfigMap{}
	t := new(DashboardDataDetail)
	request.ReadEntity(t)
	conMap.Name = t.Name

	conMap.Labels = map[string]string{
		DefaultLabelKey: DefaultLabelValue,
	}
	if len(t.Data) != 0 {
		conMap.Data = t.Data
	}
	_, e := clientSet.CoreV1().ConfigMaps(namespace).Create(context.TODO(), conMap, metav1.CreateOptions{})
	if e != nil {
		response.ResponseWriter.Write([]byte(e.Error()))
	} else {
		response.StatusCode()
		success := ResponseObject{Code: 200, Message: "success"}
		response.WriteEntity(success)
	}
}
func putDashboard(request *restful.Request, response *restful.Response) {

	if n := request.PathParameter("name"); n == "" {
		response.Write([]byte("name is nil, Invalid value!!!"))
		return
	}
	cm, err := clientSet.CoreV1().ConfigMaps(namespace).Get(context.TODO(), request.PathParameter("name"), metav1.GetOptions{})
	if err != nil {
		response.ResponseWriter.Write([]byte(err.Error()))
		return
	}
	t := new(DashboardDataDetail)
	request.ReadEntity(t)
	cm.Labels = map[string]string{
		DefaultLabelKey: DefaultLabelValue,
	}

	if len(t.Data) != 0 {
		cm.Data = t.Data
	}

	newCm, e := clientSet.CoreV1().ConfigMaps(namespace).Update(context.TODO(), cm, metav1.UpdateOptions{})
	if e != nil {
		response.ResponseWriter.Write([]byte(e.Error()))
		return
	}
	d := DashboardDataDetail{
		Name: newCm.Name,
		Data: newCm.Data,
	}
	success := ResponseObject{Code: 200, Message: "success", Data: d}
	klog.Info(success)
	response.WriteEntity(success)

}

func getDashboardList(request *restful.Request, response *restful.Response) {

	cml, err := clientSet.CoreV1().ConfigMaps(namespace).List(context.TODO(), metav1.ListOptions{
		LabelSelector: DefaultLabelKey + "=" + DefaultLabelValue,
	})
	if err != nil {
		response.ResponseWriter.Write([]byte(err.Error()))
	} else {
		dl := make([]DashboardDataDetail, 0)
		for _, cm := range cml.Items {
			d := DashboardDataDetail{
				Name: cm.Name,
				Data: cm.Data,
			}
			dl = append(dl, d)
		}
		success := ResponseObject{Code: 200, Message: "success", Data: dl}
		response.WriteAsJson(success)
	}

}

func getDashboard(request *restful.Request, response *restful.Response) {
	if n := request.PathParameter("name"); n == "" {
		response.Write([]byte("name is nil, Invalid value!!!"))
		return
	}
	cm, err := clientSet.CoreV1().ConfigMaps(namespace).Get(context.TODO(), request.PathParameter("name"), metav1.GetOptions{})
	if err != nil {
		if request.PathParameter("name") == DefaultName {
			m := make(map[string]string, 0)
			m[DefaultMapKey] = DefaultMapValue
			d := DashboardDataDetail{
				Name: DefaultName,
				Data: m,
			}
			response.WriteEntity(d)
			//todo create default dashboard
			conMap := &v1.ConfigMap{}
			conMap.Name = DefaultName
			conMap.Labels = map[string]string{
				DefaultLabelKey: DefaultLabelValue,
			}
			conMap.Data = m

			_, e := clientSet.CoreV1().ConfigMaps(namespace).Create(context.TODO(), conMap, metav1.CreateOptions{})
			if e != nil {
				response.ResponseWriter.Write([]byte(e.Error()))
				return
			}
			success := ResponseObject{Code: 200, Message: "success", Data: d}
			response.WriteAsJson(success)
			return
		}
		response.ResponseWriter.Write([]byte(err.Error()))
	} else {
		d := DashboardDataDetail{
			Name: cm.Name,
			Data: cm.Data,
		}
		response.WriteEntity(d)
	}

}

func delDashboard(request *restful.Request, response *restful.Response) {

	err := clientSet.CoreV1().ConfigMaps(namespace).Delete(context.TODO(), request.PathParameter("name"), metav1.DeleteOptions{})
	if err != nil {
		response.ResponseWriter.Write([]byte(err.Error()))
	} else {
		response.StatusCode()
		success := ResponseObject{Code: 200, Message: "success"}
		response.WriteEntity(success)
	}
}

func getPlatformData(request *restful.Request, response *restful.Response) {

	klog.Info("DEBUG - PlatformDataAlerts -1")

	p0, err := alertmanager.GetAlertsByLevel("p0")
	if err != nil {
		klog.Errorf("DEBUG - PlatformDataAlerts -2 -p0 : %v", err)
	}
	p1, err := alertmanager.GetAlertsByLevel("p1")
	if err != nil {
		klog.Errorf("DEBUG - PlatformDataAlerts -2 -p1 : %v", err)
	}
	p2, err := alertmanager.GetAlertsByLevel("p2")
	if err != nil {
		klog.Errorf("DEBUG - PlatformDataAlerts -2 -p2 : %v", err)
	}
	p3, err := alertmanager.GetAlertsByLevel("p3")
	if err != nil {
		klog.Errorf("DEBUG - PlatformDataAlerts -2 -p3 : %v", err)
	}

	a := AlertLevels{len(p0), len(p1), len(p2), len(p3)}
	r := []RegionType{}
	e := []esmanager.AlertResult{}

	klog.Errorf("DEBUG - PlatformDataAlerts -3 count : %+v", a)

	allServer, err := cmdb.GetAllPhysicalHostList("", "all", []string{}, []string{})
	if err != nil {
		klog.Error(err)
	}
	allList := allServer.Data.DataList
	for i := 0; i < len(allList); i++ {
		l := strings.ToLower(allList[i].HostRegionCode)
		re := RegionType{}
		if len(r) == 0 {
			re.RegionName = string([]rune(allList[i].HostRegionName)[:2])
			re.RegionCode = l
			r = append(r, re)
		}
		for j := 0; j < len(r); j++ {
			if r[j].RegionCode == l {
				continue
			}
			r = append(r, re)
		}
	}
	pj := &PlatformJson{"", r, a, e}

	success := ResponseObject{Code: 200, Message: "success", Data: pj}
	response.WriteAsJson(success)

}

func getRegionData(request *restful.Request, response *restful.Response) {

	re := strings.ToLower(request.PathParameter("region"))
	if re == "" {
		response.Write([]byte("region is nil, Invalid value!!!"))
		return
	}
	//获取服务器数量
	physicalRes, _ := cmdb.GetAllPhysicalHostList("", "all", []string{}, []string{})
	//获取交换机数量
	switchRes, er := physicalSwitch.GetCMDBSwitchList(&switchmodels.SwitchListQuery{PageNo: 1, PageSize: 1000, Region: "all"})
	if er != nil {
		klog.Error(er)
	}
	//物理设备总览
	resourceCounts := RegionResourceCounts{
		RegionServerCount: physicalRes.Data.TotalCount,
		RegionSwitchCount: switchRes.Data.TotalCount,
		Region:            re,
	}
	//服务器监控状态统计
	currentStates := RegionCurrentStates{Region: re, PhysicalRunningCount: 0, PhysicalErrorCount: 0}
	physicalCount := len(physicalRes.Data.DataList)
	for i := 0; i < physicalCount; i++ {
		state, _ := prom.PrometheusQuery2(false, "", "", "", `up{instance="`+physicalRes.Data.DataList[i].ManagementIP+`:9100"`+`}`)
		if len(state) > 0 {
			vv := prom.PrometheusResultToValue2(state[0])
			if vv.(float64) == 1.0 {
				currentStates.PhysicalRunningCount++
			} else {
				currentStates.PhysicalErrorCount++
			}
		} else {
			currentStates.PhysicalErrorCount++
		}
	}

	//交换机监控状态统计
	switchStates := RegionSwitchState{Region: re, SwitchRunningCount: 0, SwitchErrorCount: 0}
	switchCount := switchRes.Data.TotalCount
	for i := 0; i < switchCount; i++ {
		swtichT := temp.NewSwitchMetics(switchRes.Data.DataList[i].OutBandIP, 0)
		sql := ""
		_, err := swtichT.Get(temp.Switch_up)
		if err == nil {
			sql = swtichT.ToString(temp.Switch_up)
		}

		up, _ := prom.PrometheusQuery2(false, "", "", "", sql)
		upUp := prom.PrometheusResultToValueForPercent(up)
		if len(upUp) > 0 && upUp[0].(float64) == 1 {
			switchStates.SwitchRunningCount++
		} else {
			switchStates.SwitchErrorCount++
		}
	}

	//服务器资源使用率TOP5
	ips := strings.Join(getTopIpSlice(physicalRes.Data.DataList), ":9100|")
	ips = ips + ":9100"
	cpuTop5, cpuErr := prom.GetCpuRateTop("5", ips, time.Now())
	if cpuErr != nil {
		response.WriteAsJson(cpuErr.Error())
		return
	}
	memTop5, memErr := prom.GetMemoryRateTop("5", ips, time.Now())
	if memErr != nil {
		response.WriteAsJson(memErr.Error())
		return
	}
	diskTop5, diskErr := prom.GetDiskRateTop("5", ips, time.Now())
	if diskErr != nil {
		response.WriteAsJson(diskErr.Error())
		return
	}

	usageRateTop5 := UsageRateTop5{
		CpuTop5:     string2int(cpuTop5.Result, physicalRes.Data.DataList),
		MemTop5:     string2int(memTop5.Result, physicalRes.Data.DataList),
		StorageTop5: string2int(diskTop5.Result, physicalRes.Data.DataList),
	}

	region := RegionJson{
		request.PathParameter("region"),
		resourceCounts,
		currentStates,
		switchStates,
		usageRateTop5}
	success := ResponseObject{Code: 200, Message: "success", Data: region}
	response.WriteAsJson(success)

}

func string2int(s []prom.RateTop, d []cmdb.PhysicalHostData) []Column {
	c := []Column{}
	for i := 0; i < len(s); i++ {
		for j := 0; j < len(d); j++ {
			if s[i].Instance == d[j].ManagementIP+":9100" {
				s[i].Instance = d[j].Name
				break
			}
		}
		a := Column{Name: s[i].Instance, Percent: s[i].Value}
		c = append(c, a)
	}
	return c
}

type DgraphCount struct {
	Host []HostCount `json:"host"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/dgraph-handler.go
```golang
package handler

import (
	"context"
	"encoding/json"

	"github.com/dgraph-io/dgo/v200/protos/api"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"google.golang.org/grpc"
	"k8s.io/klog/v2"

	"github.com/dgraph-io/dgo/v200"
	cmdb "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
)

// func getFromDgraph(request *restful.Request, response *restful.Response) {
// 	if n := request.PathParameter("region"); n == "" {
// 		response.Write([]byte("region is nil, Invalid value!!!"))
// 		return
// 	}

// 	serverCount := GetAllPhysicals(true) //"physical_server"
// 	//sw := GetAllPhysicals("switch")

// 	reg := RegionResourceCounts{}
// 	reg.RegionServerCount = serverCount
// 	reg.RegionSwitchCount = 0 //len(sw.Host)

// 	reg.Region = request.PathParameter("region")
// 	success := ResponseObject{Code: 200, Message: "success", Data: reg}
// 	response.WriteAsJson(success)
// }

type DgraphDataCount struct {
	Host []DDCount `json:"host"`
}
type DDCount struct {
	Count int `json:"count"`
}

// func GetAllPhysicals(isPhysical bool) int {
// 	dg := NewDgraphClient()
// 	txn := dg.NewReadOnlyTxn().BestEffort()
// 	count := 0
// 	s := fmt.Sprintf(`{
// 		host(func: has(sn)) @filter(eq(isPhysical, %s)) {
//             count(uid)
// 		}}`, isPhysical)
// 	Dresp, err := txn.Query(context.Background(), s)
// 	if err != nil {
// 		klog.Error(err.Error())
// 	}
// 	re := DgraphDataCount{}
// 	e := json.Unmarshal(Dresp.Json, &re)
// 	if e != nil {
// 		klog.Error("json unmarshal error...." + e.Error())
// 	}
// 	if len(re.Host) > 0 {
// 		count = re.Host[0].Count
// 	}
// 	return count
// }

func getDgraph(query string) DgraphCount {
	dg := NewDgraphClient()
	txn := dg.NewReadOnlyTxn().BestEffort()

	Dresp, err := txn.Query(context.Background(), query)
	if err != nil {
		klog.Error(err.Error())
	}
	re := DgraphCount{Host: make([]HostCount, 0, 31)}
	e := json.Unmarshal(Dresp.Json, &re)
	if e != nil {
		klog.Error("json unmarshal error...." + e.Error())
	}
	return re
}

func NewDgraphClient() *dgo.Dgraph {
	// Dial a gRPC connection. The address to dial to can be configured when
	// setting up the dgraph cluster.
	once.Do(func() {
		con, err := grpc.Dial(config.GetDefaultUrl(config.DgraphGrpcService), grpc.WithInsecure())
		if err != nil {
			klog.Error("connect grpc error")
		}
		//defer con.Close()
		dgraph = dgo.NewDgraphClient(api.NewDgraphClient(con))
	})

	return dgraph
}

// func getRegionResourceDetail(request *restful.Request, response *restful.Response) {
// 	//re := request.PathParameter("region")
// 	r := request.PathParameter("resource")
// 	a := GetAllPhysicals(r)

// 	success := ResponseObject{Code: 200, Message: "success", Data: a}
// 	response.WriteAsJson(success)
// }

func getTopIpSlice(hosts []cmdb.PhysicalHostData) []string {
	s := []string{}
	for i := 0; i < len(hosts); i++ {
		s = append(s, hosts[i].ManagementIP)
	}

	return s
}

type HostCount struct {
	Count          int    `json:"count"`
	Label          string `json:"label"`
	Ip             string `json:"ip"`
	HostName       string `json:"hostname"`
	HostRegionName string `json:"hostRegionName"`
	HostRegionCode string `json:"hostRegionCode"`
	HostLabName    string `json:"hostLabName"`
	HostAzName     string `json:"hostAzName"`
	HostAzCode     string `json:"hostAzCode"`
	Sn             string `json:"sn"`
	RunStatus      string `json:"runstatus"`
	Os             string `json:"system"`
	ServiceType    string `json:"serviceType"`
}

//////

// type Data struct {
// 	Host []Host `json:"host"`
// }

//type Host struct {
//	Count int `json:"count"`
//}

// type DgraphHost struct {
// 	Host []DgraphData `json:"host"`
// }

type DgraphIpsData struct {
	Ips      string `json:"ips"`
	PoolName string `json:"poolName"`
	PoolType string `json:"poolType"`
	Role     string `json:"role"`
}

type DgraphN struct {
	Sn          string `json:"sn"`
	Ip          string `json:"ip"`
	ServiceType string `json:"serviceType"`
	Label       string `json:"label"`
}

type Dgraph struct {
	DgraphResult []DgraphN `json:"dgraphResult"`
}

type DgraphD struct {
	Data Dgraph `json:"data"`
}

func GetAllPhysicalsDetails(typeName string, region string) Dgraph {
	//1从dgraph中获取ip hostname 资源池类型（等晓哲） 资源池
	//2根据资源池类型分组ip
	//3拿IP去Prometheus获取cpu 内存 磁盘使用量 总量 以当前时间点往前推七天的值
	//4将相同资源池类型的从Prometheus获取的值 使用量 总量相加相除算百分比
	//5
	//var DgraphDataList DgraphHost
	var dgraph Dgraph
	dg := NewDgraphClient()
	//ctx := context.Background()
	txn := dg.NewReadOnlyTxn().BestEffort()
	s := `{
		dgraphResult(func:has(sn))@filter(eq(serviceType,"` + typeName + `")and allofterms(label,"` + region + `")) {
		 
			  ip
			  sn
			  serviceType
			  label
		  
		}
	  }`

	Dresp, err := txn.Query(context.Background(), s)
	if err != nil {
		klog.Error("Query dgraph error...")
	}
	e := json.Unmarshal(Dresp.Json, &dgraph)
	if e != nil {
		klog.Error("json unmarshal error...." + e.Error())
	}
	return dgraph
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/k8s-handler.go
```golang
package handler

import "github.com/emicklei/go-restful/v3"

func NewK8sService() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/k8s").
		Consumes(restful.MIME_XML, restful.MIME_JSON).
		Produces(restful.MIME_JSON, restful.MIME_XML)
	return ws
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/main-handler.go
```golang
package handler

import (
	"net/http"
	"sync"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/cmdbservice"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"

	"github.com/dgraph-io/dgo/v200"
	restfulspec "github.com/emicklei/go-restful-openapi"
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/resourcepool/aggragate"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/resourcepool/blockstorage"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/resourcepool/objectstorage"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/servicemonitor"
	alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	servicemodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/servicemonitor"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/esmanager"
)

func NewDashboardService() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1").
		Consumes(restful.MIME_XML, restful.MIME_JSON).
		Produces(restful.MIME_JSON, restful.MIME_XML)
	tagDashboard := []string{"Dashboard"}
	ws.Route(ws.POST("/dashboard").To(postDashboard).
		Metadata(restfulspec.KeyOpenAPITags, tagDashboard).
		Doc("Create dashboard").
		//Param(ws.PathParameter("Action", "Create")).
		Param(ws.QueryParameter("name", "The metadata name of dashboard, if null, it will be generated by backend").Required(false)).
		//Param(ws.QueryParameter("title", "The dashboard title").Required(true)).
		//Param(ws.QueryParameter("type", "The dashboard type").Required(true)).
		//Param(ws.QueryParameter("imageURL", "The image's url for dashboad").Required(false)).
		Param(ws.QueryParameter("data", "The else data").Required(false)).
		Returns(200, "OK", DashboardResponseSuccess{}))
	ws.Route(ws.PUT("/dashboard/{name}").To(putDashboard).
		Metadata(restfulspec.KeyOpenAPITags, tagDashboard).
		Doc("Update dashboard").
		Param(ws.PathParameter("name", "The metadata name of dashboard")).
		//Param(ws.BodyParameter("title", "The dashboard title").Required(true)).
		//Param(ws.BodyParameter("imageURL", "The image's url for dashboad").Required(false)).
		Param(ws.BodyParameter("data", "The else data").DefaultValue(`{"name": "default","data": {"title" :"wonderful"}}`).Required(false).Description("json body")).
		Returns(200, "OK", DashboardResponseSuccess{}))
	ws.Route(ws.GET("/dashboard").To(getDashboardList).
		Metadata(restfulspec.KeyOpenAPITags, tagDashboard).
		Doc("Get dashboard list").
		//Param(ws.QueryParameter("label", "The label of tiles, default value is `dashboard-title`").Required(true)).
		Returns(200, "OK", DashboardDataListSuccess{}))
	ws.Route(ws.GET("/dashboard/{name}").To(getDashboard).
		Metadata(restfulspec.KeyOpenAPITags, tagDashboard).
		Doc("Get dashboard by name").
		Param(ws.PathParameter("name", "The name of dashboard metadata")).
		Returns(200, "OK", DashboardResponseSuccess{}))
	ws.Route(ws.DELETE("/dashboard/{name}").To(delDashboard).
		Metadata(restfulspec.KeyOpenAPITags, tagDashboard).
		Doc("Delete dashboard").
		Param(ws.PathParameter("name", "The name of dashboard metadata")).
		Returns(200, "OK", ""))
	//data
	//ws.Route(ws.GET("data/alertHistoryData").To(getFromES).
	ws.Route(ws.GET("data/alertHistoryData").To(getCurrentDataOfAlert).
		Metadata(restfulspec.KeyOpenAPITags, tagDashboard).
		Doc("Get alert history from elasticsearch").
		Returns(200, "OK", esmanager.AlertsSuccess{}))
	ws.Route(ws.GET("data/platformData").To(getPlatformData).
		Metadata(restfulspec.KeyOpenAPITags, tagDashboard).
		Doc("Get platform overview data").
		Returns(200, "OK", PlatformSuccess{}))
	ws.Route(ws.GET("data/regionData/left/{region}").To(getRegionData).
		Metadata(restfulspec.KeyOpenAPITags, tagDashboard).
		Doc("Get The region data").
		Param(ws.PathParameter("region", "The region that show left and right data in dashboard.")).
		Returns(200, "OK", RegionLeftSuccess{}))
	ws.Route(ws.GET("data/regionData/right/{region}").To(GetRate).
		Metadata(restfulspec.KeyOpenAPITags, tagDashboard).
		Doc("Get resource states from prometheus").
		Param(ws.PathParameter("region", "The region that show left and right data in dashboard.")).
		Returns(200, "OK", DashboardCloudSuccess{}))
	//cmd service 相关
	cmdbService := []string{"CMDB service"}
	ws.Route(ws.POST("/cmdb/serviceInstanceList").To(cmdbservice.ServiceInstanceListHandler).
		Metadata(restfulspec.KeyOpenAPITags, cmdbService).
		Reads(cmdbmanager.QueryServiceInstanceListParams{}, "").
		Doc("cmdb 服务实例列表信息").
		Returns(http.StatusOK, "ok", cmdbmanager.InstanceResultData{}))

	//块存储资源池监控
	tag2 := []string{"block Reasource Pool Monitor"}

	ws.Route(ws.POST("/storage/monitorMetrics").To(blockstorage.StorageMonitorTargetHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag2).
		Doc("get monitor metrics line/").
		//Param(ws.QueryParameter("query", "The monitor metric query eg:块存储资源池总量：CapTotal;资源池用量趋势：CapRate;IO读取：DiskIoReadsCompletedTota;IO写：DiskIoWritesCompletedTotal;IO读延迟：DiskIoReadtimeTotal;IO写延迟：DiskIoWritetimeTotal")).
		Param(ws.BodyParameter("list", "The list of query string IO读取：DiskIoReadsCompletedTotal;IO写：DiskIoWritesCompletedTotal;IO读延迟：DiskIoReadtimeTotal;IO写延迟：DiskIoWritetimeTotal").Required(true).DataType("array")).
		Param(ws.QueryParameter("start", "The start time of range query")).
		Param(ws.QueryParameter("end", "The end time of range query")).
		Param(ws.QueryParameter("step", "The step time of range query")).
		Param(ws.QueryParameter("region", "区域;默认值：全部").DataType("string").Required(false).DefaultValue("all")).
		Param(ws.QueryParameter("name", "实例名称").DataType("string").Required(false)).
		Returns(http.StatusOK, "ok", resourcepoolmodel.StorageLineDataSuccess{}))
	ws.Route(ws.POST("/storage/storagePoolMonitor").To(blockstorage.StoragePoolMonitorTargetHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag2).
		Doc("get storage monitor metrics line/").
		//Param(ws.QueryParameter("query", "The monitor metric query eg:块存储资源池总量：CapTotal;资源池用量趋势：CapRate;IO读取：DiskIoReadsCompletedTota;IO写：DiskIoWritesCompletedTotal;IO读延迟：DiskIoReadtimeTotal;IO写延迟：DiskIoWritetimeTotal")).
		Param(ws.BodyParameter("list", "The list of query string eg:块存储资源池总量：CapTotal;资源池用量趋势：CapRate").Required(true).DataType("array")).
		Param(ws.QueryParameter("start", "The start time of range query")).
		Param(ws.QueryParameter("end", "The end time of range query")).
		Param(ws.QueryParameter("step", "The step time of range query")).
		Param(ws.QueryParameter("region", "区域;默认值：全部").DataType("string").Required(false).DefaultValue("all")).
		Param(ws.QueryParameter("az", "可用区code")).
		Param(ws.QueryParameter("name", "实例名称").DataType("string").Required(false)).
		Returns(http.StatusOK, "ok", resourcepoolmodel.StorageLineDataSuccess{}))

	//服务监控
	tagService := []string{"service"}
	ws.Route(ws.GET("/service/overview").To(servicemonitor.Overview).Doc("Get overview of object pool").
		Metadata(restfulspec.KeyOpenAPITags, tagService).
		Param(ws.QueryParameter("region", "Region of service").DefaultValue("").DataType("string").Required(false)).
		//Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		//Param(ws.BodyParameter("lab", "机房").Required(false)).
		//Param(ws.BodyParameter("pool", "资源池").Required(false)).
		Returns(200, "OK", servicemodel.OverView{}))
	ws.Route(ws.POST("/service/list").To(servicemonitor.ListServiceHandler).
		Metadata(restfulspec.KeyOpenAPITags, tagService).
		Doc("list all service /").
		Param(ws.BodyParameter("pageNo", "eg:1,页码，默认值1。").DataType("int32").Required(true).DefaultValue("1")).
		Param(ws.BodyParameter("pageSize", "eg:10, 页大小，默认值10。").DataType("int32").Required(true).DefaultValue("10")).
		Param(ws.QueryParameter("region", "区域;默认值：全部").DataType("string").Required(false).DefaultValue("")).
		Param(ws.QueryParameter("az", "可用区;默认值：全部").DataType("[]string").Required(false).DefaultValue("[]string{}")).
		//Param(ws.QueryParameter("name", "实例名称").DataType("string").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`cpuLoad`;`memLoad`;`diskLoad`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升：asc;降：desc").Required(false)).
		Param(ws.BodyParameter("searchKey", "The key of search.eg:`name`").Required(false).DataType("string")).
		Param(ws.BodyParameter("searchValue", "The value of search.eg:`127.0.0.1`").Required(false).DataType("string")).
		Param(ws.BodyParameter("runState", "The list of run state.eg:正常/异常").Required(false)).
		Returns(http.StatusOK, "ok", servicemodel.ServiceSuccess{}))
	ws.Route(ws.POST("/service/listServiceProcess").To(servicemonitor.ListProcessHandler).
		Metadata(restfulspec.KeyOpenAPITags, tagService).
		Doc("list all service /").
		Param(ws.BodyParameter("pageNo", "eg:1,页码，默认值1。").DataType("int32").Required(true).DefaultValue("1")).
		Param(ws.BodyParameter("pageSize", "eg:10, 页大小，默认值10。").DataType("int32").Required(true).DefaultValue("10")).
		// Param(ws.QueryParameter("region", "区域;默认值：全部").DataType("string").Required(false).DefaultValue("全部")).
		// Param(ws.QueryParameter("az", "可用区;默认值：全部").DataType("string").Required(false).DefaultValue("全部")).
		Param(ws.BodyParameter("name", "服务名称").DataType("string").Required(true)).
		Param(ws.BodyParameter("cmdline", "实例名称").DataType("string").Required(true)).
		Param(ws.BodyParameter("ip", "pyhsicalHost").DataType("string").Required(true)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`cpuLoad`;`memLoad`;`diskLoad`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升：asc;降：desc").Required(false)).
		Param(ws.BodyParameter("runState", "The list of run state.").Required(false)).
		Returns(http.StatusOK, "ok", servicemodel.ProcessSuccess{}))
	ws.Route(ws.GET("/getServiceInstanceList/{serviceId}").To(servicemonitor.GetBusinessServiceInstanceListHandler).
		Doc("Get Service Instance List by service id./根据服务id获取对应的服务实例").
		Metadata(restfulspec.KeyOpenAPITags, tagService).
		Param(ws.PathParameter("serviceId", "The id of service.").DataType("string").Required(true)).
		Param(ws.QueryParameter("pageNo", "page no.").DataType("int").Required(true)).
		Param(ws.QueryParameter("pageSize", "page size.").DataType("int").Required(true)).
		Returns(200, "ok", servicemodel.BusinessserviceinstanceResult{}))
	//alert
	tagAlert := []string{"alert"}
	ws.Route(ws.POST("data/alert/list").To(PostAlertsHandler).
		Metadata(restfulspec.KeyOpenAPITags, tagAlert).
		Doc("Get alert list from alertmanager").
		//Param(ws.BodyParameter("id", "The id of alert (过滤条件: 告警id)").Required(false).DataType("string")).
		//Param(ws.BodyParameter("alertName", "The name of alert(过滤条件: 告警中文名)")).
		Param(ws.BodyParameter("alertLevel", "The level list of alert").Required(false)).
		Param(ws.BodyParameter("instanceIp", "The ip  of switch alert instance").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:StartsAt;EndsAt").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升：asc;降：desc").Required(false)).
		Param(ws.BodyParameter("resourceTypeCode", "The resourceTypeCode of alert(过滤条件: 告警对象类型)").Required(false)).
		Param(ws.BodyParameter("resourceSubTypeCode", "The resourceSubTypeCode of alert（过滤条件: 告警对象子类型）").Required(false)).
		Param(ws.BodyParameter("stateList", "The state list of alert,eg:待处理：todo;进行中：active;已解决：resolved;已屏蔽：blocked").Required(false)).
		Param(ws.BodyParameter("alertInstance", "The instance of alert (过滤条件: 告警实例)").Required(false)).
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("searchKey", "The key of search.eg:`alertName`;`id`;`resourceTypeCode`;`alertInstance`;`handler`;`expressionWithChinaese`").Required(false).DataType("string")).
		Param(ws.BodyParameter("searchValue", "The value of search.").Required(false).DataType("string")).
		Returns(200, "ok", alertmanagermodel.AlertSuccess{}))
	//ws.Route(ws.POST("data/alert/history").To(getESDataHandler).
	ws.Route(ws.POST("data/alert/history").To(GetAlertHistory).
		Metadata(restfulspec.KeyOpenAPITags, tagAlert).
		Doc("Get alert history from es").
		//Param(ws.PathParameter("id", "The id of alert").Required(false).DataType("string")).
		Param(ws.BodyParameter("resourceTypeCode", "The resourceTypeCode of alert").Required(false)).
		Param(ws.BodyParameter("resourceSubTypeCode", "The resourceSubTypeCode of alert").Required(false)).
		Param(ws.BodyParameter("policyName", "The name of alert").Required(false)).
		Param(ws.BodyParameter("alertLevel", "The level list of alert").Required(false)).
		Param(ws.BodyParameter("stateList", "The state list of alert,eg:进行中：firing;已解决：resolved;已屏蔽：blocked").Required(false)).
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Returns(200, "ok", alertmanagermodel.AlertSuccess{}))

	ws.Route(ws.GET("data/alert/overview").
		To(getAlertOverviewFromES).
		Metadata(restfulspec.KeyOpenAPITags, tagAlert).
		Doc("Get alert overview from es").
		Param(ws.QueryParameter("region", "alert generated from which region").Required(true)).
		Returns(200, "ok", alertmanagermodel.AlertOverviewResponse{}))
	//cmdb 资源池概览页数据，勿动。。。
	overview := []string{"CMDB overview"}
	ws.Route(ws.GET("/computePool/CMDBOverView").To(aggragate.GetCMDBOverViewHandler).
		Metadata(restfulspec.KeyOpenAPITags, overview).
		Doc("get CMDB aggregate overview").
		Param(ws.QueryParameter("region", "区域;all").DataType("string").Required(false).DefaultValue("all")).
		Param(ws.QueryParameter("az", "可用区;默认值：all").DataType("string").Required(false).DefaultValue("all")).
		Returns(http.StatusOK, "ok", resourcepoolmodel.CMDBAggregateOverview{}))
	ws.Route(ws.GET("/cmdbOverView/blockStorage").To(blockstorage.GetCMDBBlockStorageOverViewHandler).
		Metadata(restfulspec.KeyOpenAPITags, overview).
		Doc("get CMDB blockStorage overview").
		Param(ws.QueryParameter("region", "区域;all").DataType("string").Required(false).DefaultValue("cn-shanghai-2")).
		Param(ws.QueryParameter("az", "可用区;默认值：all").DataType("string").Required(false).DefaultValue("cn-shanghai-2a")).
		Returns(http.StatusOK, "ok", resourcepoolmodel.CMDBBlockStorageOverview{}))
	ws.Route(ws.GET("/cmdbOverView/objectStorage").To(objectstorage.GetCMDBObjectStorageOverViewHandler).
		Metadata(restfulspec.KeyOpenAPITags, overview).
		Doc("get CMDB objectStorage overview").
		Param(ws.QueryParameter("region", "区域;all").DataType("string").Required(false).DefaultValue("cn-shanghai-2")).
		//Param(ws.QueryParameter("az", "可用区;默认值：all").DataType("string").Required(false).DefaultValue("cn-shanghai-2a")).
		Returns(http.StatusOK, "ok", resourcepoolmodel.CMDBBlockStorageOverview{}))
	return ws
}

var (
	once      sync.Once
	dgraph    *dgo.Dgraph
	clientSet = client.GetClient()
	namespace = "luban"
)

type ResponseObject struct {
	Code    int         `json:"code"`
	Message string      `json:"message"`
	Data    interface{} `json:"data"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/bm/handler.go
```golang
package bm

import (
	restfulspec "github.com/emicklei/go-restful-openapi/v2"
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	bmmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/bm"
	bmservice "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct/bm"
	"k8s.io/klog/v2"
	"net/http"
)

type BmApiHandler struct {
	BmService bmservice.IBmService
}

func BuildBmApiHandler() *BmApiHandler {
	bmService := bmservice.NewBmService()
	return &BmApiHandler{
		BmService: bmService,
	}
}



func (s *BmApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/cloud/bm").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)
	tag := []string{"cloud product bm"}
	ws.Route(ws.POST("/list").To(s.List).Doc("Redis监控列表").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("region", "区域编码 eg:`cn-shanghai-2`").DataType("string").Required(false)).
		Param(ws.BodyParameter("id", "id`").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "名称`").DataType("string").Required(false)).
		Param(ws.BodyParameter("ip", "ip地址").DataType("string").Required(false)).
		Param(ws.BodyParameter("tenantId", "租户id").DataType("string").Required(false)).
		Param(ws.BodyParameter("tenantName", "租户名称").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("tenantIdList", "租户id列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("tenantNameList", "租户名称列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("poolName", "资源池列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("instanceStates", "实例状态列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("instanceType", "实例类型列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("projectName", "所属项目列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("searchKey", "搜索的Key").Required(false)).
		Param(ws.BodyParameter("searchValue", "搜索的value").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`createTime`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升 asc;降 desc").Required(false)).
		Returns(200, "OK", bmmodel.MonitorBmSuccess{}))

	return ws
}

//获取裸金属监控列表
func (s *BmApiHandler) List(request *restful.Request, response *restful.Response) {
	klog.Infof("get bm  MonitorList")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	q := &bmmodel.ListQuery{PageNo: 1, PageSize: 10}
	err := request.ReadEntity(q)
	if err != nil {
		klog.Errorf("request readEntity error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.BmService.GetBmList(q)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/redis/handler.go
```golang
package redis

import (
	restfulspec "github.com/emicklei/go-restful-openapi/v2"
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	redismodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/redis"
	redisservice "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct/redis"
	"k8s.io/klog/v2"
	"net/http"
)

type RedisApiHandler struct {
	RedisService redisservice.IRedisService
}

func BuildRedisApiHandler() *RedisApiHandler {
	redisService := redisservice.NewRedisService()
	return &RedisApiHandler{
		RedisService: redisService,
	}
}

func (s *RedisApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/cloud/redis").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)
	tag := []string{"cloud product redis"}

	ws.Route(ws.POST("/overview").To(s.overview).Doc("redis 概览页").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", redismodel.OverViewSuccess{}))
	ws.Route(ws.POST("/overviewTop").To(s.overviewTop).Doc("redis 概览页top").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "的监控项名称,eg:cpu:cpu使用率/mem:内存使用率/inRatio:入流量使用率/outRatio:出流量使用率/connectionRatio:连接数使用率/hitRate:缓存命中率").Required(false).DataType("[]string")).
		Param(ws.BodyParameter("topK", "topk的k").DataType("int").Required(false)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", redismodel.OverViewTopSuccess{}))
	ws.Route(ws.POST("/list").To(s.List).Doc("Redis监控列表").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("region", "区域编码 eg:`cn-shanghai-2`").DataType("string").Required(false)).
		Param(ws.BodyParameter("id", "id`").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "名称`").DataType("string").Required(false)).
		Param(ws.BodyParameter("ip", "ip地址").DataType("string").Required(false)).
		Param(ws.BodyParameter("tenantId", "租户id").DataType("string").Required(false)).
		Param(ws.BodyParameter("tenantName", "租户名称").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("tenantIdList", "租户id列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("tenantNameList", "租户名称列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("poolName", "资源池列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("status", "状态列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("searchKey", "搜索的Key").Required(false)).
		Param(ws.BodyParameter("searchValue", "搜索的value").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`createTime`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升 asc;降 desc").Required(false)).
		Returns(200, "OK", redismodel.MonitorRedisPage{}))
	ws.Route(ws.POST("metricLine").To(s.MetricLine).Doc("Redis监控指标").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.PathParameter("id", "The id of redis").Required(true)).
		Param(ws.BodyParameter("name", "的监控项名称,eg:cpu/mem/usedMem").Required(false).DataType("[]string")).
		Param(ws.BodyParameter("start", "The start time of line").Required(false)).
		Param(ws.BodyParameter("end", "The end time of line").Required(false)).
		Returns(200, "OK", redismodel.MetricLineSuccess{}))
	ws.Route(ws.POST("/logmsg").To(s.LogMsg).Doc("Redis日志信息").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.PathParameter("id", "The id of redis instance").Required(true)).
		Param(ws.BodyParameter("start", "The start timestamp(ms)").Required(false)).
		Param(ws.BodyParameter("end", "The end timestamp(ms)").Required(false)).
		Param(ws.BodyParameter("log_type", "日志类别: redis.slowlog, redis.log").Required(false).DataType("string")).
		Param(ws.BodyParameter("page_num", "").Required(false).DataType("int").DefaultValue("1")).
		Param(ws.BodyParameter("page_size", "").Required(false).DataType("int").DefaultValue("10")).
		Param(ws.BodyParameter("context", "日志内容").Required(false).DataType("string")).
		Returns(http.StatusOK, http.StatusText(http.StatusOK), redismodel.SlowLogResponse{}).
		Returns(http.StatusBadRequest, http.StatusText(http.StatusBadRequest), redismodel.ErrorResponse{}).
		Returns(http.StatusInternalServerError, http.StatusText(http.StatusInternalServerError), redismodel.ErrorResponse{}))
	return ws
}

func (s *RedisApiHandler) overview(request *restful.Request, response *restful.Response) {
	klog.Infof("get redis overview")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	param := &redismodel.OverviewQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.RedisService.Overview(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

func (s *RedisApiHandler) overviewTop(request *restful.Request, response *restful.Response) {
	klog.Infof("get redis overview top")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	param := &redismodel.TopQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.RedisService.OverviewTopKey(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

//获取redis监控列表
func (s *RedisApiHandler) List(request *restful.Request, response *restful.Response) {
	klog.Infof("get redis  MonitorList")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	q := &redismodel.ListQuery{PageNo: 1, PageSize: 10}
	err := request.ReadEntity(q)
	if err != nil {
		klog.Errorf("request readEntity error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}

	res, err := s.RedisService.GetRedisListNew(q)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

// 监控指标
func (s *RedisApiHandler) MetricLine(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	klog.Info("cloud_mysql_metric_line")
	param := new(redismodel.MetricQuery)
	request.ReadEntity(param)
	responseMetric, err := s.RedisService.GetRedisMetricLine(param)
	if err != nil {
		fail := redismodel.MetricLineSuccess{Code: 500, Message: err.Error(), Data: nil}
		response.WriteAsJson(fail)
		return
	}
	success := redismodel.MetricLineSuccess{Code: 200, Message: "success", Data: responseMetric}
	response.WriteAsJson(success)
}

func (s *RedisApiHandler) LogMsg(request *restful.Request, response *restful.Response) {
	queryParams := redismodel.LogQueryParam{}
	if err := request.ReadEntity(&queryParams); err != nil {
		klog.Error(err)
		response.WriteAsJson(redismodel.ErrorResponse{}.BadRequestResponse(err))
		return
	}
	klog.Infof("Get redis instance log prarm: %+v", queryParams)
	if queryParams.LogType != "redis.slowlog" && queryParams.LogType != "redis.log" {
		queryParams.LogType = "redis.slowlog"
	}
	logData, err := s.RedisService.GetLogMsg(&queryParams)
	if err != nil {
		response.WriteAsJson(redismodel.ErrorResponse{}.InternalServerErrorResponse(err))
		return
	}
	response.WriteAsJson(redismodel.LogResponse{Code: http.StatusOK, Message: "success", Hits: logData})
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/nat/handler.go
```golang
package nat

import (
	"net/http"
	"strconv"

	restfulspec "github.com/emicklei/go-restful-openapi"
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	vmmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cloudproduct"
	natmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/nat"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/nat"
	"k8s.io/klog/v2"
)

type Handler struct {
	NatService nat.Interface
}

func BuildNatApiHandler() *Handler {
	natService := nat.New()
	return &Handler{NatService: natService}
}

func (h *Handler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.Path("/metrics/v1/cloud/nat").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)
	tag := []string{"nat"}

	// 云资源监控 / 云产品监控 / nat
	ws.Route(ws.POST("/overview").To(h.overview).Doc("Nat 概览页").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", natmodel.OverViewSuccess{}))
	ws.Route(ws.POST("/overviewTop").To(h.OverviewTop).Doc("Nat 概览页top").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "的监控项名称,eg:natBps:Nat带宽/natPps:NAT每秒收发包次数/natBpsPublic:Nat带宽(公网)/natPpsPublic:NAT每秒收发包次数(公网)").Required(false).DataType("[]string")).
		Param(ws.BodyParameter("topK", "topk的k").DataType("int").Required(false)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", natmodel.OverViewTopSuccess{}))
	ws.Route(ws.POST("/list").To(h.listHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Doc("nat列表").
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true).DefaultValue("1")).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true).DefaultValue("10")).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("resourcePoolName", "资源池名称").DataType("string").Required(false)).
		Param(ws.BodyParameter("scope", "作用范围  [classic,custom] 所属的vpc,绑定的子网").DataType("string").Required(false)).
		Param(ws.BodyParameter("vpcName", "所属vpc").Required(false)).
		Param(ws.BodyParameter("natType", "类型 ['public', 'private']").Required(false)).
		Param(ws.BodyParameter("tenantId", "租户ID").Required(false)).
		Param(ws.BodyParameter("tenantName", "租户名称").Required(false)).
		Param(ws.BodyParameter("projectName", "所属项目名称").Required(false)).
		Param(ws.BodyParameter("searchKey", "搜索的K.eg:`instanceName`").Required(false)).
		Param(ws.BodyParameter("searchValue", "搜索的value. eg:`实例名称`").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`createTime`，`bandwidth`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升：ascending;降：descending").Required(false)).
		Returns(http.StatusOK, "OK", natmodel.NatListRsp{}))

	ws.Route(ws.POST("/metricLine").To(h.MetricLine).Doc("nat监控指标详情").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.PathParameter("id", "The id of nat").Required(true)).
		Param(ws.BodyParameter("name", "The name of metric,eg:bps/pps/bpsPublic/ppsPublic/utilization/ipconflict").Required(false)).
		Param(ws.BodyParameter("start", "The start time of line").Required(false)).
		Param(ws.BodyParameter("end", "The end time of line").Required(false)).
		Returns(200, "OK", natmodel.MetricLineSuccess{}))

	return ws
}

func (h *Handler) overview(request *restful.Request, response *restful.Response) {
	klog.Infof("get nat overview")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	param := &natmodel.OverviewQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := h.NatService.Overview(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

func (h *Handler) overviewTop(request *restful.Request, response *restful.Response) {
	klog.Infof("get nat overview top")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	param := &natmodel.TopQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := h.NatService.OverviewTop(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

func (h *Handler) OverviewTop(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	t := new(vmmodel.TopQuery)
	request.ReadEntity(t)
	ms, err := h.NatService.GetNatTop(t)
	for _, k := range ms {
		for _, t := range k.Echarts {
			for j, _ := range t.Values {
				t.Values[j].Name = "top" + strconv.Itoa(j+1)
			}
		}
	}
	rst := new(vmmodel.OverViewTopSuccess)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = ms
		response.WriteAsJson(rst)
		return
	}
}

func (h *Handler) listHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get nat list")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	q := &natmodel.ListQuery{}

	if err := request.ReadEntity(q); err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		_ = response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}

	natList, err := h.NatService.GetNatList(q)
	if err == nil {
		_ = response.WriteEntity(models.NewSuccessResponse().SetData(natList))
		return
	}

	_ = response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
}

func (h *Handler) MetricLine(request *restful.Request, response *restful.Response) {
	klog.Infof("get nat metricLine")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	q := &natmodel.MetricQuery{}

	if err := request.ReadEntity(q); err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		_ = response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	if len(q.Name) == 0 {
		q.Name = []string{"bps", "pps", "bpsPublic", "ppsPublic", "utilization", "ipconflict"}
	}
	responseMetric, err := h.NatService.GetMetricLine(q)
	if err == nil {
		_ = response.WriteEntity(models.NewSuccessResponse().SetData(responseMetric))
		return
	}

	_ = response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/vm/handler.go
```golang
package vm

import (
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	"strconv"
	"time"

	kts "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/ktsmanager"

	"net/http"

	restfulspec "github.com/emicklei/go-restful-openapi"
	vmmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cloudproduct"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct/vm"
)

type VmApiHandler struct {
	VmService vm.IVmService
}

func BuildVmApiHandler() *VmApiHandler {
	vmService := vm.NewVmService()
	return &VmApiHandler{
		VmService: vmService,
	}
}

func (s *VmApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/cloud/vm").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)

	tagCloudProduct := []string{"cloud product vm"}
	ws.Route(ws.POST("/overview").To(s.Overview).Doc("Get overview of cloud host").
		Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
		Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		//Param(ws.BodyParameter("lab", "机房").Required(false)).
		Returns(200, "OK", vmmodel.OverViewSuccess{}))

	//POST /metrics/v1/cloud/vm/overviewTopK 云资源监控 / 云产品监控 / 云主机
	ws.Route(ws.POST("/overviewTopK").To(s.OverviewTop).Doc("Get overview of vm topK").
		Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
		Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		//Param(ws.BodyParameter("lab", "机房").Required(false)).
		Param(ws.BodyParameter("name", "The name of TopK,eg:cpu/mem/disk/net").Required(false)).
		//Param(ws.BodyParameter("subName","The subName of TopK").Required(false)).
		Param(ws.BodyParameter("topK", "The K of TopK").Required(false)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(200, "OK", vmmodel.OverViewTopSuccess{}))
	ws.Route(ws.POST("/list").To(s.PostListVM).
		Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
		Doc("Get all vm server").
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("region", "Region of physical server").Required(false).DataType("string")).
		Param(ws.BodyParameter("az", "可用区").Required(false).DataType("[]string")).
		Param(ws.BodyParameter("searchKey", "The key of search.eg:`name`;`tenantId`;`physicalHost`;`innerIp`;`outerIp`;`pool`").Required(false).DataType("string")).
		Param(ws.BodyParameter("searchValue", "The value of search.eg:`127.0.0.1`").Required(false).DataType("string")).
		Param(ws.BodyParameter("runList", "The list of run state.eg:active/willoverdue/overdued//error").Required(false)).
		//Param(ws.BodyParameter("name", "Name of physical server")).
		//Param(ws.BodyParameter("tenantId", "租户id")).
		//Param(ws.BodyParameter("innerIp", "内网ip")).
		//Param(ws.BodyParameter("outerIp", "外网ip")).
		//Param(ws.BodyParameter("physicalHost", "所属服务器")).
		//Param(ws.BodyParameter("pool", "所属资源池")).
		Returns(http.StatusOK, "OK", vmmodel.MonitorVmsSuccess{}))
	ws.Route(ws.POST("/metrics/{id}/query").To(s.GetVMMetrics).
		Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
		Doc("Get alert detail from alertmanager by severity level").
		Param(ws.PathParameter("id", "The id of monitor vm server").Required(true).DataType("string")).
		Param(ws.BodyParameter("list", "The list of query string").Required(true).DataType("array")).
		Param(ws.QueryParameter("start", "The start time of range query")).
		Param(ws.QueryParameter("end", "The end time of range query")).
		Returns(200, "ok", vmmodel.MetricSuccess{}))

	return ws
}

func (s *VmApiHandler) Overview(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	t := new(vmmodel.TopQuery)
	request.ReadEntity(t)
	ms, err := s.VmService.GetVmOverview(t)
	rst := new(vmmodel.OverViewSuccess)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {

		rst.Code = 200
		rst.Message = "success"
		rst.Data = ms
		response.WriteAsJson(rst)
		return
	}
}

//OverviewTop 云资源监控 / 云产品监控 / 云主机
func (s *VmApiHandler) OverviewTop(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	t := new(vmmodel.TopQuery)
	request.ReadEntity(t)
	ms, err := s.VmService.GetVmTop(t)
	rst := new(vmmodel.OverViewTopSuccess)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = ms
		response.WriteAsJson(rst)
		return
	}
}

func (s *VmApiHandler) PostListVM(request *restful.Request, response *restful.Response) {

	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(vmmodel.MonitorVmsSuccess)
	t := new(vmmodel.VmListQuery)
	request.ReadEntity(t)

	if t.SearchKey != "" && t.SearchValue != "" {
		switch t.SearchKey {
		case "name":
			t.Name = t.SearchValue
		case "tenantId":
			t.TenantId = t.SearchValue
		case "physicalHost":
			t.PhysicalHost = t.SearchValue
		case "innerIp":
			t.InnerIp = t.SearchValue
		case "outerIp":
			t.OuterIp = t.SearchValue
		case "pool":
			t.Pool = t.SearchValue
		}
	}
	if t.PageNo == 0 {
		rst.Code = 500
		rst.Message = "pageNo false"
		response.WriteAsJson(rst)
		return
	}
	if t.PageSize == 0 {
		rst.Code = 500
		rst.Message = "pageSize false"
		response.WriteAsJson(rst)
		return
	}

	var ms vmmodel.MonitorVms
	var err error

	//go func() {
	//	_, err = s.VmService.GetVmList1(t)
	//}()

	ms, err = s.VmService.GetVmList(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = ms
		response.WriteAsJson(rst)
		return
	}
}

func (s *VmApiHandler) GetVMMetrics(request *restful.Request, response *restful.Response) {

	response.AddHeader("Access-Control-Allow-Origin", "*")
	t := new(QueryList)
	request.ReadEntity(t)
	id := request.PathParameter("id")
	start := request.QueryParameter("start")
	end := request.QueryParameter("end")
	step := request.QueryParameter("step")
	if start != "" && end == "" {
		end = strconv.FormatFloat(float64(time.Now().Unix()), 'f', -1, 64)
	}
	result := kts.QueryVmMetric(id, start, end, t.List)
	if start != "" {
		start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
		end1, _ := strconv.ParseFloat(end, 64)
		step = services.TimeToStepForTSDBKNew111(end1 - start1) //降采样
		ss := MakeTimeStamp(start, end, step)
		tt := TimeResult{
			TimeStamp: ss,
			Result:    result,
		}
		success := Result{Code: 200, Message: "success", Data: tt}
		response.WriteAsJson(success)
	} else {
		//获取网卡出/入口流量(24h)
		endTime := time.Now().Unix()
		startTime := endTime - 86400
		netEnd := strconv.FormatInt(endTime, 10)
		netStart := strconv.FormatInt(startTime, 10)
		net := kts.QueryVmMetric(id, netStart, netEnd, []string{"NetInAvg", "NetOutAvg"})

		for k, v := range net {
			if v.Name == "NetInAvg" {
				net[k].Name = "NetIn"
			}
			if v.Name == "NetOutAvg" {
				net[k].Name = "NetOut"
			}
			net[k].Value = v.Avg
		}

		result = append(result, net...)
		success := Result{Code: 200, Message: "success", Data: result}
		response.WriteAsJson(success)
	}
}

func MakeTimeStamp(start, end, step string) []string {
	sl := make([]string, 0)
	start1, _ := strconv.ParseFloat(start, 64)
	end1, _ := strconv.ParseFloat(end, 64)
	step1, _ := strconv.ParseFloat(step, 64)
	for {
		ss := strconv.FormatFloat(start1, 'f', -1, 64)
		sl = append(sl, ss)
		start1 += step1
		if start1 > end1 {
			break
		}
	}

	return sl
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/vm/util.go
```golang
package vm

import (
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"sort"
	"strconv"
	//"github.com/jmoiron/sqlx"
	//_ "github.com/go-sql-driver/mysql"
)

func ValueOrder(in []CmdbTopVm, code string) []CmdbTopVm {
	results := alert.Bucket{}
	for i := 0; i < len(in); i++ {
		results.Slice = append(results.Slice, in[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	switch code {
	case "asc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(CmdbTopVm).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(CmdbTopVm).Value), 64)
			return aa < bb
		}
	case "desc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(CmdbTopVm).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(CmdbTopVm).Value), 64)
			return aa > bb
		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(in); i++ {
		in[i] = results.Slice[i].(CmdbTopVm)
	}
	return in
}

//func makeMysqlClient() *sqlx.DB {
//	db, err := sqlx.Open("mysql", "root:Kingsoft123@tcp(10.178.224.65:8306)/luban?charset=utf8")
//	if err != nil {
//		panic("failed to connect database,err:" + err.Error())
//	}
//	return db
//}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/vm/model.go
```golang
package vm

//overview

type AlertLevels struct {
	P0 int `json:"p0"`
	P1 int `json:"p1"`
	P2 int `json:"p2"`
	P3 int `json:"p3"`
}

//OverviewTop

type ValueType struct {
	Value      interface{} `json:"value"`
	Name       string      `json:"name"`
	Timestamep string      `json:"timestamep"`
	SubName    string      `json:"subName"`
	VmId       string      `json:"vmId"`
}

type CMDBTopResult struct {
	Code    int        `json:"code"`
	Message string     `json:"message"`
	Data    CmdbTopVms `json:"data"`
}

type CmdbTopVms struct {
	PageStruct
	DataList []CmdbTopVm `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type CmdbTopVm struct {
	ID     string      `json:"id"`
	Name   string      `json:"name"`
	Value  interface{} `json:"value"`
	Status string      `json:"status"`
}

//other
type Result struct {
	Code    int         `json:"code"`
	Message string      `json:"messgae"`
	Data    interface{} `json:"data"`
}

type CMDBResult struct {
	Code    int     `json:"code"`
	Message string  `json:"message"`
	Data    CmdbVms `json:"data"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

type ListQuery struct {
	PageNo       int      `json:"pageNo"`
	PageSize     int      `json:"pageSize"`
	Region       string   `json:"region"`
	Az           string   `json:"az"`
	Name         string   `json:"name"`
	Pool         string   `json:"pool"`
	Lab          string   `json:"lab"`
	TenantId     string   `json:"tenantId"`
	InnerIp      string   `json:"innerIp"`
	OuterIp      string   `json:"outerIp"`
	Label        string   `json:"label"`
	State        string   `json:"state"`
	PhysicalHost string   `json:"physicalHost"`
	SearchKey    string   `json:"searchKey"`
	SearchValue  string   `json:"searchValue"`
	RunList      []string `json:"runList"`
	Metrics      []string `json:"metrics"`
	Start        string   `json:"start"`
	End          string   `json:"end"`
	TopK         string   `json:"topk"`
}



type CmdbVms struct {
	PageStruct
	DataList []CmdbVm `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type CmdbVm struct {
	ID   string `json:"id"`
	Name string `json:"name"`
	//Flavor     interface{} `json:"flavor"`
	Flavor     string `json:"flavor"`
	Status     string `json:"status"`
	Aggregate  string `json:"aggregate"`
	Region     string `json:"region"`
	RegionCode string `json:"regionCode"`
	Az         string `json:"az"`
	AzCode     string `json:"azCode"`
	TenantId   string `json:"tenantId"`
	TenantName string `json:"tenantName"`
	Hypervisor string `json:"hypervisor"`
	InnerIP    string `json:"innerIp"`
	PublicIP   string `json:"publicIp"`
	//CreateTime time.Time `json:"createTime"`
	CreateTime string `json:"createTime"`
}


type VmTop struct {
	Id   string `json:"id"`
	Name string `json:"name"`
}

type MetricResult struct {
	Name    interface{} `json:"name"`
	Current interface{} `json:"current"`
	Avg     interface{} `json:"avg"`
	Max     interface{} `json:"max"`
	Min     interface{} `json:"min"`
	Value   interface{} `json:"value"`
}

type ResponseMetric struct {
	Metric     string      `json:"metric"`
	Value      interface{} `json:"value"`
	CPUModeAvg interface{} `json:"cpuModeAvg"`
	Curren     interface{} `json:"curren"`
	Min        interface{} `json:"min"`
	Max        interface{} `json:"max"`
	Avg        interface{} `json:"avg"`
}

//
//type TSDBQueryRangeBody struct {
//	Start   string       `json:"start"`
//	End     string       `json:"end"`
//	Queries []RangeQuery `json:"queries"`
//}
//
//type QueryResult struct {
//	Metric    string      `json:"metric"`
//	Timestamp interface{} `json:"timestamp"`
//	Value     string      `json:"value"`
//	Tsuid     string      `json:"tsuid"`
//}
//
//type TSDBQueryBody struct {
//	ResolveNames bool        `json:"resolveNames"`
//	BackScan     int         `json:"backScan"`
//	Queries      []LastQuery `json:"queries"`
//}
//
//type QueryRangeResult struct {
//	Metric string      `json:"metric"`
//	Dps    interface{} `json:"dps"`
//}
//
//type RangeQuery struct {
//	Aggregator string            `json:"aggregator"`
//	Metric     string            `json:"metric"`
//	Tags       map[string]string `json:"tags"`
//}
//

type LastQuery struct {
	Metric string            `json:"metric"`
	Tags   map[string]string `json:"tags"`
}

type QueryList struct {
	List []string `json:"list"`
}

type TimeResult struct {
	TimeStamp interface{} `json:"timeStamp"`
	Result    interface{} `json:"result"`
}

type VmListPost struct {
	PageNo   int      `json:"pageNo"`
	PageSize int      `json:"pageSize"`
	Region   string   `json:"region"`
	Az       []string `json:"az"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/load/handler.go
```golang
package load

import (
	restfulspec "github.com/emicklei/go-restful-openapi/v2"
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	loadmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/load"
	loadservice "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct/load"
	"k8s.io/klog/v2"
	"net/http"
)

type LoadApiHandler struct {
	LoadService loadservice.ILoadService
}

func BuildLoadApiHandler() *LoadApiHandler {
	loadService := loadservice.NewLoadService()
	return &LoadApiHandler{
		LoadService: loadService,
	}
}

func (l *LoadApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/cloud/load").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)
	tag := []string{"cloud product load"}

	ws.Route(ws.POST("/overview").To(l.overview).Doc("负载均衡概览页").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", loadmodel.LoadOverviewResponse{}))
	ws.Route(ws.POST("/overviewTop").To(l.overviewTop).Doc("负载均衡概览页top").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "的监控项名称,eg:slbBps:负载均衡流量/slbPps:负载均衡每秒收发包次数/slbCps:每秒新建连接数/slbActiveconn:链接数/eipBps:弹性IP带宽/eipPps:弹性IP每秒收发包次数/bandWidth:带宽使用百分比").Required(false).DataType("[]string")).
		Param(ws.BodyParameter("topK", "topk的k").DataType("int").Required(false)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Param(ws.BodyParameter("flowType", "flowType 0/全部 1/公网").Required(true)).
		Returns(http.StatusOK, "Get Overview Success", loadmodel.LoadOverviewTopResponse{}))
	ws.Route(ws.POST("/list").To(l.MonitorList).Doc("负载均衡监控列表").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("region", "区域编码 eg:`cn-shanghai-2`").DataType("string").Required(false)).
		Param(ws.BodyParameter("resourcePoolName", "网络资源池名称").DataType("string").Required(false)).
		Param(ws.BodyParameter("state", "状态：开启 已停止 [active]").DataType("string").Required(false)).
		Param(ws.BodyParameter("instanceType", "实例类型：经典型 应用型 ['default', 'application']").DataType("string").Required(false)).
		Param(ws.BodyParameter("lineType", "线路类型 [bgp,private]").DataType("string").Required(false)).
		Param(ws.BodyParameter("netType", "网络类型: 公网 私网 [public,private]").DataType("string").Required(false)).
		Param(ws.BodyParameter("poolList", "资源池列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("tenantIdList", "租户id列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("tenantNameList", "租户名称列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("projectNameList", "所属项目名称: 默认项目").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("searchKey", "搜索的Key").Required(false)).
		Param(ws.BodyParameter("searchValue", "搜索的value").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`cpuUsedPercent`;`memoryUsedPercent`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升 asc;降 desc").Required(false)).
		Returns(200, "OK", loadmodel.MonitorPage{}))
	ws.Route(ws.POST("/metricLine").To(l.MetricLine).Doc("负载均衡监控指标详情").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.PathParameter("id", "The id of lb").Required(true)).
		Param(ws.BodyParameter("name", "The name of metric,eg:dropbps/droppps/bps/pps/cps/conn/reqrate").Required(true)).
		Param(ws.BodyParameter("start", "The start time of line").Required(true)).
		Param(ws.BodyParameter("end", "The end time of line").Required(true)).
		Returns(200, "OK", loadmodel.LoadMetricRsp{}))
	return ws
}

func (l *LoadApiHandler) overview(request *restful.Request, response *restful.Response) {
	klog.Infof("get load overview")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	param := &loadmodel.OverviewQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := l.LoadService.Overview(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

func (l *LoadApiHandler) overviewTop(request *restful.Request, response *restful.Response) {
	klog.Infof("get load overview top")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	param := &loadmodel.OverviewTopQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := l.LoadService.OverviewTopK(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

func (s *LoadApiHandler) MonitorList(request *restful.Request, response *restful.Response) {
	klog.Infof("get load balance  MonitorList")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	q := &loadmodel.ListQuery{PageNo: 1, PageSize: 10}
	err := request.ReadEntity(q)
	if err != nil {
		klog.Errorf("request readEntity error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}

	res, err := s.LoadService.GetLBList(q)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

func (s *LoadApiHandler) MetricLine(request *restful.Request, response *restful.Response) {
	klog.Infof("get lb metricLine")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	q := &loadmodel.LoadMetricQuery{}

	if err := request.ReadEntity(q); err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		_ = response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}

	responseMetric, err := s.LoadService.GetMetricLine(q)
	if err == nil {
		_ = response.WriteEntity(models.NewSuccessResponse().SetData(responseMetric))
		return
	}

	_ = response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/bucket/handler.go
```golang
package bucket

import (
	"encoding/json"
	"fmt"
	"strings"
	"time"

	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	objectmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/object"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/esmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	"k8s.io/klog/v2"

	"strconv"

	restfulspec "github.com/emicklei/go-restful-openapi"

	"io"
	"net/http"

	"github.com/emicklei/go-restful/v3"
	"github.com/pkg/errors"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct/object"
)

type ObjectApiHandler struct {
	ObjectService object.IObjectService
}

func BuildObjectApiHandler() *ObjectApiHandler {
	objectService := object.NewObjectService()
	return &ObjectApiHandler{
		ObjectService: objectService,
	}
}

func (s *ObjectApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/cloud/object").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)

	tagCloudProduct := []string{"cloud product object"}
	ws.Route(ws.POST("/Overview").To(s.Overview).
		Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
		Doc("Overview of object storage").
		Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		//Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("storageType", "存储类型,eg:STANDARD:标准存储/ARCHIVE:归档存储/STANDARD_IA:低频存储").Required(false)).
		Returns(http.StatusOK, "OK", objectmodel.OverviewSuccess{}))
	ws.Route(ws.POST("/OverviewTop").To(s.OverviewTop).
		Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
		Doc("Overview of TopK for object storage").
		Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		Param(ws.BodyParameter("storageType", "存储类型,eg:STANDARD:标准存储/ARCHIVE:归档存储/STANDARD_IA:低频存储").Required(false)).
		Param(ws.BodyParameter("name", "The name of TopK,eg:总流量监控totalFlow:cdn/out/in;总请求监控totalRequest:cdn/out/in;空间容量capacity;空间异常capacityErr;存储空间成功率capacitySuccess").Required(false)).
		Param(ws.BodyParameter("topK", "The K of TopK").Required(false)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(http.StatusOK, "OK", objectmodel.OverviewTopSuccess{}))
	ws.Route(ws.POST("/list").To(s.PostListBucket).
		Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
		Doc("Get all object storage").
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		//Param(ws.BodyParameter("name", "Name of physical server")).
		Param(ws.BodyParameter("searchKey", "The key of search.eg:`name`").Required(false).DataType("string")).
		Param(ws.BodyParameter("searchValue", "The value of search.").Required(false).DataType("string")).
		//Param(ws.QueryParameter("tenantId", "租户id")).
		//Param(ws.QueryParameter("pool", "服务器所属资源池")).
		Param(ws.BodyParameter("storageType", "存储类型,eg:STANDARD:标准存储/ARCHIVE:归档存储/STANDARD_IA:低频存储").Required(false)).
		Param(ws.BodyParameter("monitorStatus", "监控状态,eg:monitor/error").Required(false)).
		Returns(http.StatusOK, "OK", objectmodel.MonitorBucketsSuccess{}))
	ws.Route(ws.POST("/{id}/query").To(s.Metric).
		Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
		Doc("metric of object storage").
		Param(ws.PathParameter("id", "The id of bucket").Required(false)).
		//Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		//Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		//Param(ws.BodyParameter("storageType", "存储类型,eg:standard:标准存储/archive:归档存储/standard_ia:低频存储").Required(false)).
		Returns(http.StatusOK, "OK", objectmodel.MetricSuccess{}))
	ws.Route(ws.POST("/{id}/queryLine").To(s.MetricLine).
		Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
		Doc("metric line of object storage").
		//Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		//Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		//Param(ws.BodyParameter("storageType", "存储类型,eg:standard:标准存储/archive:归档存储/standard_ia:低频存储").Required(false)).
		Param(ws.PathParameter("id", "The id of bucket").Required(false)).
		Param(ws.BodyParameter("name", "The name of metric,eg:存储空间capacity;空间流量flow:isp;带宽band;请求数返回requestReturn:isp;API请求延时apiDelay;返回码returnCode:qs/isp;读写成功R/WSuccess").Required(false)).
		Param(ws.BodyParameter("subName", "The subName of metric，eg:空间流量flow:isp;请求数返回requestReturn:isp;返回码returnCode:qs/isp;").Required(false)).
		//Param(ws.BodyParameter("topK","The K of TopK").Required(false)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(http.StatusOK, "OK", objectmodel.MetricLineSuccess{}))
	//ws.Route(ws.POST("data/cloud/bucket/{id}/query").To(phy.GetPhysicalHostMonitorByIp).
	//	Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
	//	Doc("Get alert detail from alertmanager by severity level").
	//	Param(ws.PathParameter("id", "The ip of monitor physical server").Required(true).DataType("string")).
	//	Param(ws.BodyParameter("list", "The list of query string").Required(true).DataType("array")).
	//	Param(ws.QueryParameter("start", "The start time of range query")).
	//	Param(ws.QueryParameter("end", "The end time of range query")).
	//	Returns(200, "ok", phy.ListResult{}))
	return ws
}

func (s *ObjectApiHandler) PostListBucket(request *restful.Request, response *restful.Response) {

	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(objectmodel.MonitorBucketsSuccess)
	t := new(objectmodel.ListQuery)
	request.ReadEntity(t)
	if t.SearchKey != "" && t.SearchValue != "" {
		switch t.SearchKey {
		case "name":
			t.Name = t.SearchValue
			//case "tenantId":
			//	t.TenantId = t.SearchValue
			//case "pool":
			//	t.Pool = t.SearchValue
		}
	}

	if t.PageNo == 0 {
		rst.Code = 500
		rst.Message = "pageNo false"
		response.WriteAsJson(rst)
		return
	}

	if t.PageSize == 0 {
		rst.Code = 500
		rst.Message = "pageSize false"
		response.WriteAsJson(rst)
		return
	}

	//if t.Region == "" || t.Region == "all" {
	//	t.Region = "all"
	//}
	//
	//if t.Az == "" || t.Az == "all" {
	//	t.Az = "all"
	//} else {
	//	t.Az = config.RegionMap[t.Az]
	//}

	ms, err := s.ObjectService.GetObjectList(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = ms
		response.WriteAsJson(rst)
		return
	}

}
func (s *ObjectApiHandler) Overview(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	q := new(objectmodel.BucketQuery)
	request.ReadEntity(q)
	ms, err := s.ObjectService.GetObjectOverview(q)
	rst := new(objectmodel.OverviewSuccess)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = ms
		response.WriteAsJson(rst)
		return
	}

}

func GetBucketOverviewList(bq *objectmodel.BucketQuery) (objectmodel.OverviewBucket, error) {
	klog.Infof("GetBucketOverview BucketQuery:%+v", bq)
	c := http.Client{}
	var storageType []string
	if bq.StorageType != "" {
		storageType = append(storageType, bq.StorageType)
	}
	//查询对象存储总条数
	bucketCount := services.QueryTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/bucket", bq.Region, "", "post", storageType)
	//查询对象存储数据
	hostUrlPost := cmdbmodel.HostUrlPost{
		PageNo:      1,
		PageSize:    bucketCount,
		Region:      bq.Region,
		StorageType: storageType,
	}
	bucketQueryInput, _ := json.Marshal(hostUrlPost)
	bucketQueryJson := strings.NewReader(string(bucketQueryInput))

	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/bucket", "application/json", bucketQueryJson)
	rst := objectmodel.OverviewBucket{}
	if err != nil {
		klog.Errorf("GetBucketOverview querybucket error:%+v", bq)
		return rst, err
	}
	b, _ := io.ReadAll(resp.Body)
	bucketResult := objectmodel.CMDBResult{Data: objectmodel.CmdbBucks{DataList: make([]objectmodel.CmdbBucket, 0, bucketCount)}}
	err = json.Unmarshal(b, &bucketResult)
	if err != nil {
		return rst, err
	}
	if bucketResult.Code != 200 {
		klog.Errorf("GetBucketOverview querybucket code!=200:%+v", bq)
		return rst, errors.Errorf("GetBucketOverview querybucket error!")
	}
	var bucketIds []string
	for _, bucketInfo := range bucketResult.Data.DataList {
		bucketIds = append(bucketIds, bucketInfo.ID)
	}

	return rst, nil
}

func PrometheusResultToValue(r interface{}) interface{} {
	var s interface{}
	valu := r.(map[string]interface{})
	if resultData, ok := valu["result"]; ok {
		result := resultData.([]interface{})
		if len(result) > 0 {
			resultForValue := result[0].(map[string]interface{})
			if valueData, ok := resultForValue["values"]; ok {
				return valueData
			}
			if valueData, ok := resultForValue["value"]; ok {
				return valueData
			}
		}
	}

	return s
}

func (s *ObjectApiHandler) OverviewTop(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	q := new(objectmodel.BucketQuery)
	request.ReadEntity(q)
	ms, err := s.ObjectService.GetObjectOverviewTop(q)
	rst := new(objectmodel.OverviewTopSuccess)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = ms
		response.WriteAsJson(rst)
		return
	}
}

var MetricMap = map[string]func(id, start, end, step string) (*objectmodel.MetricBucketType, error){
	//bucket
	"capacity":       QueryStorageCapacityMonitoring,                //存储容量监控
	"traffic":        QueryStorageTrafficAnalysis,                   //存储流量分析
	"trafficISP":     QueryStorageTrafficAnalysisISP,                //存储流量分析
	"band":           QueryBandwidthUploadAndDownloadVolumeAnalysis, //带宽上传下载量分析
	"reqNum":         QueryNumberOfRequestsReturn,                   //请求数返回总计
	"reqNumISP":      QueryNumberOfRequestsReturnISP,                //请求数返回总计
	"delay":          QueryApiRequestDelay,                          //API请求延时
	"retCode":        QueryRequestReturnCodeStatistics,              //请求返回码统计
	"retCodePercent": QueryRWPercent,                                //请求返回码统计饼图
	"retCodeISP":     QueryRequestReturnCodeStatisticsISP,           //请求返回码统计ISP
	"rwOk":           QueryRWOkRate,                                 //读写成功率

}

func (s *ObjectApiHandler) Metric(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	id := request.PathParameter("id")
	responseMetric, err := s.ObjectService.GetObjectMetric(id)
	if err != nil {
		fail := objectmodel.ResponseObject{Code: 500, Message: err.Error(), Data: nil}
		response.WriteAsJson(fail)
		return
	}
	success := objectmodel.ResponseObject{Code: 200, Message: "success", Data: responseMetric}
	err = response.WriteAsJson(success)
	if err != nil {
		klog.Error(err)
	}

}

func (s *ObjectApiHandler) MetricLine(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	t := new(objectmodel.QueryList)
	err := request.ReadEntity(t)
	var effectiveParameters []string
	for s, _ := range MetricMap {
		effectiveParameters = append(effectiveParameters, s)
	}
	if err != nil {
		fail := objectmodel.ResponseObject{Code: 500, Message: "参数错误" + err.Error() + ". 有效参数列表:" + strings.Join(effectiveParameters, `,`), Data: nil}
		response.WriteAsJson(fail)
		return
	}
	if len(t.List) == 0 {
		fail := objectmodel.ResponseObject{Code: 500, Message: "参数错误list长度不能为0." + " 有效参数列表:" + strings.Join(effectiveParameters, `,`), Data: nil}
		response.WriteAsJson(fail)
		return
	}
	id := request.PathParameter("id")
	start := request.QueryParameter("start")
	if start == "" {
		start = t.Start
	}
	end := request.QueryParameter("end")
	if end == "" {
		end = t.End
	}
	step := request.QueryParameter("step")
	if step == "" {
		step = t.Step
	}
	//前端是13位的
	startT, _ := strconv.ParseFloat(start, 64)
	start = fmt.Sprintf("%f", startT/1000)
	endT, _ := strconv.ParseFloat(end, 64)
	end = fmt.Sprintf("%f", endT/1000)
	if start == "" && end == "" {
		start = strconv.FormatInt(time.Now().Unix()-(60*30), 64)
		end = strconv.FormatInt(time.Now().Unix(), 64)
	}
	if step == "" {
		startTime, _ := strconv.ParseFloat(start, 64)
		endTime, _ := strconv.ParseFloat(end, 64)
		interval := endTime - startTime
		step = services.TimeToStep(interval)
	}
	var responseMetric []*objectmodel.MetricBucketType
	for _, opName := range t.List {
		if op, ok := MetricMap[opName]; ok {
			result, errOp := op(id, start, end, step)
			if errOp != nil {
				klog.Error(errOp)
				continue
			}
			responseMetric = append(responseMetric, result)
		}
	}
	if start != "" && end != "" && step != "" {
		tt := objectmodel.TimeResult{
			Result: responseMetric,
		}
		success := objectmodel.ResponseObject{Code: 200, Message: "success", Data: tt}
		err := response.WriteAsJson(success)
		if err != nil {
			klog.Error(err)
			return
		}
	} else {
		success := objectmodel.ResponseObject{Code: 200, Message: "success", Data: responseMetric}
		err := response.WriteAsJson(success)
		if err != nil {
			klog.Error(err)
			return
		}
	}
}

// QueryCloudBucketMetric metric

// QueryStorageCapacityMonitoring 存储容量监控
func QueryStorageCapacityMonitoring(id, start, end, step string) (*objectmodel.MetricBucketType, error) {
	metricBucket := &objectmodel.MetricBucketType{}
	metricBucket.ID = id
	metricBucket.Start = start
	metricBucket.End = end
	metricBucket.Name = "capacity"
	rr, err := esmanager.Get30StoreLineById(id)
	if err != nil {
		klog.Info(err)
		return metricBucket, err
	}
	metricBucket.Echarts = append(metricBucket.Echarts, rr...)

	return metricBucket, nil
}

// QueryStorageTrafficAnalysis 存储流量分析
func QueryStorageTrafficAnalysis(id, start, end, step string) (*objectmodel.MetricBucketType, error) {
	metricBucket := &objectmodel.MetricBucketType{}
	metricBucket.ID = id
	metricBucket.Start = start
	metricBucket.End = end
	metricBucket.Name = "traffic"

	rr, err := esmanager.Get30FlowLineById(id)
	if err != nil {
		klog.Info(err)
		return metricBucket, err
	}
	metricBucket.Echarts = append(metricBucket.Echarts, rr...)

	return metricBucket, nil
}

// QueryStorageTrafficAnalysisISP 存储流量分析ISP todo 没有isp信息
func QueryStorageTrafficAnalysisISP(id, start, end, step string) (*objectmodel.MetricBucketType, error) {
	metricBucket := &objectmodel.MetricBucketType{}
	metricBucket.ID = id
	metricBucket.Start = start
	metricBucket.End = end
	metricBucket.Name = "trafficISP"

	//rangIf := false
	//if start != "" || end != "" {
	//	rangIf = true
	//}
	return metricBucket, nil
}

// QueryBandwidthUploadAndDownloadVolumeAnalysis 上传下载带宽分析 todo 目前没有数据
func QueryBandwidthUploadAndDownloadVolumeAnalysis(id, start, end, step string) (*objectmodel.MetricBucketType, error) {
	metricBucket := &objectmodel.MetricBucketType{}
	metricBucket.ID = id
	metricBucket.Start = start
	metricBucket.End = end
	metricBucket.Name = "band"

	rr, err := esmanager.Get30BandLineById(id)
	if err != nil {
		klog.Info(err)
		return metricBucket, err
	}
	metricBucket.Echarts = append(metricBucket.Echarts, rr...)

	return metricBucket, nil
}

// QueryNumberOfRequestsReturn 请求数监控
func QueryNumberOfRequestsReturn(id, start, end, step string) (*objectmodel.MetricBucketType, error) {
	metricBucket := &objectmodel.MetricBucketType{}
	metricBucket.ID = id
	metricBucket.Start = start
	metricBucket.End = end
	metricBucket.Name = "reqNum"

	rr, err := esmanager.Get30ApiNumLineById(id)
	if err != nil {
		klog.Info(err)
		return metricBucket, err
	}
	metricBucket.Echarts = append(metricBucket.Echarts, rr...)

	return metricBucket, nil
}

// QueryNumberOfRequestsReturnISP 请求数监控
func QueryNumberOfRequestsReturnISP(id, start, end, step string) (*objectmodel.MetricBucketType, error) {
	metricBucket := &objectmodel.MetricBucketType{}
	metricBucket.ID = id
	metricBucket.Start = start
	metricBucket.End = end
	metricBucket.Name = "reqNumISP"
	return metricBucket, nil
}

// QueryApiRequestDelay API请求延时 //todo 没有数据
func QueryApiRequestDelay(id, start, end, step string) (*objectmodel.MetricBucketType, error) {
	metricBucket := &objectmodel.MetricBucketType{}
	metricBucket.ID = id
	metricBucket.Start = start
	metricBucket.End = end
	metricBucket.Name = "delay"
	return metricBucket, nil
}

// QueryRequestReturnCodeStatistics 请求返回码统计
func QueryRequestReturnCodeStatistics(id, start, end, step string) (*objectmodel.MetricBucketType, error) {
	metricBucket := &objectmodel.MetricBucketType{}
	metricBucket.ID = id
	metricBucket.Start = start
	metricBucket.End = end
	metricBucket.Name = "retCode"

	rr, err := esmanager.Get30CodeLineById(id)
	if err != nil {
		klog.Info(err)
		return metricBucket, err
	}
	metricBucket.Echarts = append(metricBucket.Echarts, rr...)

	return metricBucket, nil
}

const (
	//存储类型
	STORAGETYPE_STANDARD    = "STANDARD"    //标准存储
	STORAGETYPE_ARCHIVE     = "ARCHIVE"     //归档存储
	STORAGETYPE_STANDARD_IA = "STANDARD_IA" //低频存储

	//单位类型 storage:存储的、percent:百分比的、number:数值的

	UNIT_TYPE_STORAGE = "storage"
	UNIT_TYPE_PERCENT = "percent"
	UNIT_TYPE_NUMBER  = "number"
)

// QueryRWPercent 请求返回码统计百分比
func QueryRWPercent(id, start, end, step string) (*objectmodel.MetricBucketType, error) {
	metricBucket := &objectmodel.MetricBucketType{}
	metricBucket.ID = id
	metricBucket.Start = start
	metricBucket.End = end
	metricBucket.Name = "retCodePercent"

	codeMap := esmanager.GetBucketCodeById(id)
	var codeTotalCount float64
	for _, v := range codeMap {
		codeTotalCount += v

	}
	echart := resourcepoolmodel.EchartType{}
	echart.Info.Unit = "次"
	echart.Info.UnitType = UNIT_TYPE_NUMBER
	echart.Info.Value = codeTotalCount
	for k, v := range codeMap {
		var percent float64
		if codeTotalCount > 0 {
			percent = v / codeTotalCount
		}

		rrr := services.ValueType{Name: k, Value: v, Percent: prometheusmanager.FormPercent(percent)}

		echart.Values = append(echart.Values, rrr)
	}
	metricBucket.Echarts = append(metricBucket.Echarts, echart)

	// for k, v := range codeMap {
	// 	m := resourcepoolmodel.EchartType{}
	// 	m.Info.UnitType = UNIT_TYPE_NUMBER
	// 	m.Info.Unit = "次"
	// 	value := services.ValueType{Value: v,Name: k}
	// 	m.Values = append(m.Values, value)
	// 	metricBucket.Echarts = append(metricBucket.Echarts, m)
	// }

	// rangIf := false
	// if start != "" || end != "" {
	// 	rangIf = true
	// }
	// //sum(bucket_wide_times{code=~"2.*"})
	// bucketApiRequests2xx, _ := prometheusmanager.PrometheusQuery2(rangIf, start, end, step, `sum(bucket_wide_times{bucketid="`+id+`",code=~"2.*"})`)
	// bucketApiRequests3xx, _ := prometheusmanager.PrometheusQuery2(rangIf, start, end, step, `sum(bucket_wide_times{bucketid="`+id+`",code=~"3.*"})`)
	// bucketApiRequests4xx, _ := prometheusmanager.PrometheusQuery2(rangIf, start, end, step, `sum(bucket_wide_times{bucketid="`+id+`",code=~"4.*"})`)
	// bucketApiRequests5xx, _ := prometheusmanager.PrometheusQuery2(rangIf, start, end, step, `sum(bucket_wide_times{bucketid="`+id+`",code=~"5.*"})`)

	// if bucketApiRequests2xx == nil || len(bucketApiRequests2xx) == 0 {
	// 	klog.Error(fmt.Errorf("bucketApiRequests2xx ret nil"))
	// } else {
	// 	bucketApiRequests2xxEcharts := proDataConvEchartPercent("2xx", id, start, end, bucketApiRequests2xx)
	// 	bucketApiRequests2xxEcharts.Info.UnitType = UNIT_TYPE_NUMBER
	// 	bucketApiRequests2xxEcharts.Info.Unit = "次"
	// 	metricBucket.Echarts = append(metricBucket.Echarts, bucketApiRequests2xxEcharts)
	// }
	// if bucketApiRequests3xx == nil || len(bucketApiRequests3xx) == 0 {
	// 	klog.Error(fmt.Errorf("bucketApiRequests3xx ret nil"))
	// } else {
	// 	bucketApiRequests3xxEcharts := proDataConvEchartPercent("3xx", id, start, end, bucketApiRequests3xx)
	// 	bucketApiRequests3xxEcharts.Info.UnitType = UNIT_TYPE_NUMBER
	// 	bucketApiRequests3xxEcharts.Info.Unit = "次"
	// 	metricBucket.Echarts = append(metricBucket.Echarts, bucketApiRequests3xxEcharts)
	// }
	// if bucketApiRequests4xx == nil || len(bucketApiRequests4xx) == 0 {
	// 	klog.Error(fmt.Errorf("bucketApiRequestsGet ret nil"))
	// } else {
	// 	bucketApiRequests4xxEcharts := proDataConvEchartPercent("4xx", id, start, end, bucketApiRequests4xx)
	// 	bucketApiRequests4xxEcharts.Info.UnitType = UNIT_TYPE_NUMBER
	// 	bucketApiRequests4xxEcharts.Info.Unit = "次"
	// 	metricBucket.Echarts = append(metricBucket.Echarts, bucketApiRequests4xxEcharts)
	// }
	// if bucketApiRequests5xx == nil || len(bucketApiRequests5xx) == 0 {
	// 	klog.Error(fmt.Errorf("bucketApiRequestsGet ret nil"))
	// } else {
	// 	bucketApiRequests5xxEcharts := proDataConvEchartPercent("5xx", id, start, end, bucketApiRequests5xx)
	// 	bucketApiRequests5xxEcharts.Info.UnitType = UNIT_TYPE_NUMBER
	// 	bucketApiRequests5xxEcharts.Info.Unit = "次"
	// 	metricBucket.Echarts = append(metricBucket.Echarts, bucketApiRequests5xxEcharts)
	// }
	return metricBucket, nil
}

// QueryRequestReturnCodeStatisticsISP 请求返回码统计ISP
func QueryRequestReturnCodeStatisticsISP(id, start, end, step string) (*objectmodel.MetricBucketType, error) {
	metricBucket := &objectmodel.MetricBucketType{}
	metricBucket.ID = id
	metricBucket.Start = start
	metricBucket.End = end
	metricBucket.Name = "retCodeISP"
	return metricBucket, nil
}

// QueryRWOkRate 读写成功率
func QueryRWOkRate(id, start, end, step string) (*objectmodel.MetricBucketType, error) {
	//sum(bucket_wide_times{bucketid="`+id+`",code=~"2.*",operation=~".*GET.*"})/sum(bucket_wide_times{bucketid="`+id+`",code=~"2.*",operation=~".*GET.*"})/100
	metricBucket := &objectmodel.MetricBucketType{}
	metricBucket.ID = id
	metricBucket.Start = start
	metricBucket.End = end
	metricBucket.Name = "rwOk"
	rr, err := esmanager.Get30RWOKLineById(id)
	if err != nil {
		klog.Info(err)
		return metricBucket, err
	}
	metricBucket.Echarts = append(metricBucket.Echarts, rr...)

	// rangIf := false
	// if start != "" || end != "" {
	// 	rangIf = true
	// }
	// //sum(bucket_wide_times{code=~"2.*"})
	// rOkRate, _ := prometheusmanager.PrometheusQuery2(rangIf, start, end, step, `sum(bucket_wide_times{bucketid="`+id+`",code=~"2.*",operation=~".*GET.*"})/sum(bucket_wide_times{bucketid="`+id+`",operation=~".*GET.*"})*100`)
	// wOkRate, _ := prometheusmanager.PrometheusQuery2(rangIf, start, end, step, `sum(bucket_wide_times{bucketid="`+id+`",code=~"2.*",operation=~".*PUT.*"})/sum(bucket_wide_times{bucketid="`+id+`",operation=~".*PUT.*"})*100`)
	// if rOkRate == nil || len(rOkRate) == 0 {
	// 	klog.Error(fmt.Errorf("bucketApiRequestsGet ret nil"))
	// } else {
	// 	rOkRateEcharts := proDataConvEchart("读成功率", id, start, end, rOkRate)
	// 	rOkRateEcharts.Info.UnitType = UNIT_TYPE_PERCENT
	// 	rOkRateEcharts.Info.Unit = "%"
	// 	metricBucket.Echarts = append(metricBucket.Echarts, rOkRateEcharts)
	// }
	// if wOkRate == nil || len(wOkRate) == 0 {
	// 	klog.Error(fmt.Errorf("bucketApiRequestsGet ret nil"))
	// } else {
	// 	wOkRateEcharts := proDataConvEchart("写成功率", id, start, end, wOkRate)
	// 	wOkRateEcharts.Info.UnitType = UNIT_TYPE_PERCENT
	// 	wOkRateEcharts.Info.Unit = "%"
	// 	metricBucket.Echarts = append(metricBucket.Echarts, wOkRateEcharts)
	// }
	return metricBucket, nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/bucket/util.go
```golang
package bucket


```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/bucket/model.go
```golang
package bucket


```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/mysql/handler.go
```golang
package mysql

import (
	"fmt"
	restfulspec "github.com/emicklei/go-restful-openapi/v2"
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	mysqlmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/mysql"
	mysqlservice "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct/mysql"
	"k8s.io/klog/v2"
	"net/http"
)

type MysqlApiHandler struct {
	MysqlService mysqlservice.IMysqlService
}

func BuildMysqlApiHandler() *MysqlApiHandler {
	mysqlService := mysqlservice.NewMysqlService()
	return &MysqlApiHandler{
		MysqlService: mysqlService,
	}
}

func (s *MysqlApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/cloud/mysql").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)
	tag := []string{"cloud product mysql"}

	ws.Route(ws.POST("/list").To(s.MonitorList).Doc("Mysql监控列表").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("region", "区域编码 eg:`cn-shanghai-2`").DataType("string").Required(false)).
		Param(ws.BodyParameter("id", "id`").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "名称`").DataType("string").Required(false)).
		Param(ws.BodyParameter("ip", "ip地址").DataType("string").Required(false)).
		Param(ws.BodyParameter("tenantId", "租户id").DataType("string").Required(false)).
		Param(ws.BodyParameter("tenantName", "租户名称").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("tenantIdList", "租户id列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("tenantNameList", "租户名称列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("poolName", "资源池列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("status", "状态列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("searchKey", "搜索的Key").Required(false)).
		Param(ws.BodyParameter("searchValue", "搜索的value").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`cpuUsedPercent`;`memoryUsedPercent`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升 asc;降 desc").Required(false)).
		Returns(200, "OK", mysqlmodel.MonitorMysqlPage{}))
	ws.Route(ws.GET("/items").To(s.Items).Doc("Mysql监控列表筛选").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("dbType", "数据库类型 eg:mysql/redis").Required(false)).
		Param(ws.BodyParameter("region", "区域编码 eg:`cn-shanghai-2`").DataType("string").Required(false)).
		Returns(200, "OK", mysqlmodel.Filter{}))
	ws.Route(ws.POST("overview").To(s.Overview).Doc("Mysql监控概览").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域编码 eg:`cn-shanghai-2`").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Returns(200, "OK", mysqlmodel.OverViewSuccess{}))
	ws.Route(ws.POST("overviewTop").To(s.OverviewTop).Doc("Mysql监控概览top").
		Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "The name of TopK,eg:cpu/mem/iops/link/input/output/ops/tps").Required(false)).
		Param(ws.BodyParameter("topK", "The K of TopK").Required(false)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(200, "OK", mysqlmodel.OverViewTopSuccess{}))
	ws.Route(ws.POST("metricLine").To(s.MetricLine).Doc("Mysql监控指标").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.PathParameter("id", "The id of mysql").Required(true)).
		Param(ws.BodyParameter("indexType", "The name of indexType,eg:DataAccess;ResourceLoad;QueryCache;InnoDB;MyISAM").Required(false)).
		Param(ws.BodyParameter("name", "The name of TopK,eg:cpu/mem/iops/link/input/output/ops/tps").Required(false)).
		Param(ws.BodyParameter("start", "The start time of line").Required(false)).
		Param(ws.BodyParameter("end", "The end time of line").Required(false)).
		Returns(200, "OK", mysqlmodel.MetricLineSuccess{}))
	ws.Route(ws.POST("/logsList").To(s.LogsList).Doc("Mysql日志列表").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("id", "实例id`").DataType("string").Required(true)).
		Param(ws.BodyParameter("name", "实例名称`").DataType("string").Required(true)).
		Param(ws.BodyParameter("dbLogType", "日志类型 ErrorLog /SlowLog /BinLog`").DataType("string").Required(true)).
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(200, "OK", mysqlmodel.LogsListSuccess{}))
	ws.Route(ws.GET("logsDownload").To(s.LogsDownload).Doc("Mysql日志下载").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		//Param(ws.PathParameter("id", "The id of mysql").Required(true)).
		Returns(200, "OK", nil))
	return ws
}

// 监控概览
func (s *MysqlApiHandler) Overview(request *restful.Request, response *restful.Response) {

	response.AddHeader("Access-Control-Allow-Origin", "*")
	klog.Info("cloud_mysql_metric_line")
	param := new(mysqlmodel.OverviewQuery)
	request.ReadEntity(param)
	responseMetric, err := s.MysqlService.GetVmOverview(param)
	if err != nil {
		fail := mysqlmodel.OverViewSuccess{Code: 500, Message: err.Error(), Data: mysqlmodel.OverView{}}
		response.WriteAsJson(fail)
		return
	}
	success := mysqlmodel.OverViewSuccess{Code: 200, Message: "success", Data: responseMetric}
	response.WriteAsJson(success)

}

// 监控概览Top
func (s *MysqlApiHandler) OverviewTop(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	klog.Info("cloud_mysql_metric_line")
	param := new(mysqlmodel.TopQuery)
	request.ReadEntity(param)

	responseMetric, err := s.MysqlService.GetOverviewTopK(param)
	if err != nil {
		fail := mysqlmodel.OverViewTopSuccess{Code: 500, Message: err.Error(), Data: nil}
		response.WriteAsJson(fail)
		return
	}
	success := mysqlmodel.OverViewTopSuccessNew{Code: 200, Message: "success", Data: responseMetric}
	response.WriteAsJson(success)
}

// 监控指标
func (s *MysqlApiHandler) MetricLine(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	klog.Info("cloud_mysql_metric_line")
	param := new(mysqlmodel.MetricQuery)
	request.ReadEntity(param)
	responseMetric, err := s.MysqlService.GetBlockMetricLine(param)
	if err != nil {
		fail := mysqlmodel.MetricLineSuccess{Code: 500, Message: err.Error(), Data: nil}
		response.WriteAsJson(fail)
		return
	}
	success := mysqlmodel.MetricLineSuccess{Code: 200, Message: "success", Data: responseMetric}
	response.WriteAsJson(success)
}

//获取mysql监控列表
func (s *MysqlApiHandler) MonitorList(request *restful.Request, response *restful.Response) {
	klog.Infof("get mysql  MonitorList")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	q := &mysqlmodel.ListQuery{PageNo: 1, PageSize: 10}
	err := request.ReadEntity(q)
	if err != nil {
		klog.Errorf("request readEntity error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}

	res, err := s.MysqlService.GetMysqlListNew(q)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}


//获取mysql监控列表
func (s *MysqlApiHandler) MonitorLists(request *restful.Request, response *restful.Response) {
	klog.Infof("get mysql  MonitorList")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	q := &mysqlmodel.ListQuery{PageNo: 1, PageSize: 10}
	err := request.ReadEntity(q)
	if err != nil {
		klog.Errorf("request readEntity error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}

	res, err := s.MysqlService.GetMysqlListDisorder(q)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

//监控列表筛选项列表
func (s *MysqlApiHandler) Items(request *restful.Request, response *restful.Response) {
	klog.Infof("get mysql  monitorList filters")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	region := request.QueryParameter("region")
	dbType := request.QueryParameter("dbType")
	poolId := request.QueryParameter("poolId")
	res, err := s.MysqlService.GetItems(region, dbType, poolId)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

//获取mysql日志列表
func (s *MysqlApiHandler) LogsList(request *restful.Request, response *restful.Response) {
	klog.Infof("get mysql LogsList")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	q := &mysqlmodel.LogsListMetricQuery{PageNo: 1, PageSize: 10}
	err := request.ReadEntity(q)
	if err != nil {
		klog.Errorf("request readEntity error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}

	res, err := s.MysqlService.GetBlockMetricLogsList(q)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

// 监控日志下载
func (s *MysqlApiHandler) LogsDownload(request *restful.Request, response *restful.Response) {
	klog.Info("cloud_mysql_metric_logs")

	response.AddHeader("Access-Control-Allow-Origin", "*")
	response.AddHeader("Content-type", "application/octet-stream")
	response.AddHeader("Content-Disposition", fmt.Sprintf("attachment; filename=%s", "sss.gz"))

	param := new(mysqlmodel.MetricQuery)
	request.ReadEntity(param)
	responseMetric, _ := s.MysqlService.GetBlockMetricLogs(param)

	//aa := bytes.Buffer{
	//}
	//a
	//_,err = io.Copy(response.ResponseWriter,)

	//_,err = io.Copy(response.ResponseWriter, responseMetric)
	//
	////files[0].File.Close()
	//if err != nil {
	//	response.BadRequest(c, validate.Translate(err))
	//	return
	//}

	response.Write(responseMetric)

	//if err != nil {
	//	fail := mysqlmodel.MetricLineSuccess{Code: 500, Message: err.Error(), Data: nil}
	//	response.WriteAsJson(fail)
	//	return
	//}
	//success := mysqlmodel.MetricLineSuccess{Code: 200, Message: "success"}
	//response.WriteAsJson(success)
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/eip/handler.go
```golang
package eip

import (
	"encoding/json"
	"fmt"
	restfulspec "github.com/emicklei/go-restful-openapi"
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	eipmodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/eip"
	mysqlmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/mysql"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/eip"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"k8s.io/klog/v2"
	"net/http"
)

type EipApiHandler struct {
	EipService eip.IEip
}

func BuildEipApiHandler() *EipApiHandler {
	eipService := eip.NewEipService()
	return &EipApiHandler{EipService: eipService}
}

func (e *EipApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/eip").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)
	tag := []string{"eip"}

	ws.Route(ws.POST("/overview").To(e.overviewHandler).Doc("弹性ip产品概览页").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", eipmodels.EipOverviewResponse{}))

	// 监控告警 / 云资源监控 / 云产品监控 / 弹性IP
	ws.Route(ws.POST("/overviewTop").To(e.overviewTopNewHandler).Doc("弹性ip产品概览页的top").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "的监控项名称,eg:outBandRate:出向带宽使用百分比/inBandRate:入向带宽使用百分比/outFlow:出网流量/inFlow:入网流量/outPackages:每秒流出包数/inPackages:每秒流入包数").Required(false).DataType("[]string")).
		Param(ws.BodyParameter("topK", "topk的k").DataType("int").Required(false)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", eipmodels.OverviewTopResponse{}))
	ws.Route(ws.POST("/list").To(e.listHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Doc("弹性ip列表").
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("ip", "ip地址").Required(false)).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("state", "状态").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("netSegment", "网段").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("lineType", "线路类型").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("searchKey", "搜索的K.eg:`ip`").Required(false)).
		Param(ws.BodyParameter("searchValue", "搜索的value. eg:`127.0.0.1`").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`netSegment`;`ipAvailRate`;`ipUsedRate`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升：asc;降：desc").Required(false)).
		Returns(http.StatusOK, "OK", eipmodels.EipListResp{}))
	ws.Route(ws.GET("/items").To(e.Items).Doc("Eip监控列表筛选").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域编码 eg:`cn-shanghai-2`").DataType("string").Required(false)).
		Returns(200, "OK", mysqlmodel.Filter{}))
	ws.Route(ws.POST("/line").To(e.metricLineHandler).Doc("弹性ip监控指标变化曲线").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("eip", "ip地址").DataType("string").Required(false)).
		Param(ws.BodyParameter("id", "弹性ip绑定的hostId").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "的监控项名称,eg:outBandRant:出向带宽利用率/inBandRate:入向带宽利用率/outFlow:出网流量/inFlow:入网流量/outPackages:每秒流出包数/inPackages:每秒流入包数").Required(false).DataType("[]string")).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", eipmodels.EipResponse{}))
	return ws
}

func (s *EipApiHandler) overviewHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get switch overview")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &eipmodels.EipOverviewQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.EipService.GetEipOverview(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}


// 缓存框架
func (s *EipApiHandler) overviewTopNewHandler(request *restful.Request, response *restful.Response) {

	klog.Infof("get eip metric top")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &eipmodels.EipOverviewLineQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.EipService.GetEipTopNew(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *EipApiHandler) overviewTopHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get eip overview top")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &eipmodels.EipOverviewLineQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}

	getFromCache := true
	var res []eipmodels.OverviewLineData
	if getFromCache {
		//临时缓存处理，忽略时间区间做缓存
		queryKey := fmt.Sprintf("metrics/v1/eip/overviewTop/%s/%s/%s/%s", para.Region, para.Az, para.Name, para.TopK)
		apiCache := utils.NewApiCache()
		var result []byte
		result, err = apiCache.Get(queryKey, func() (interface{}, error) {
			return s.EipService.GetEipOverviewLine(para)
		})

		if err != nil {
			response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		}
		err = json.Unmarshal(result, &res)
	} else {
		res, err = s.EipService.GetEipOverviewLine(para)
	}

	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}
func (s *EipApiHandler) listHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get eip list")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &eipmodels.EipListQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}

	getFromCache := false
	if para.SearchKey != "" && para.SearchValue != "" {
		getFromCache = false
	}

	var ms eipmodels.EipListResult
	if getFromCache {
		//临时缓存处理 start
		queryKey := fmt.Sprintf("metrics/v1/eip/list/%s/%d/%d", para.Region, para.PageNo, para.PageSize)
		apiCache := utils.NewApiCache()
		var result []byte
		result, err = apiCache.Get(queryKey, func() (interface{}, error) {
			return s.EipService.GetEipList(para)
		})
		if err != nil {
			response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		}
		err = json.Unmarshal(result, &ms)
		//临时缓存处理 end
	} else {
		ms, err = s.EipService.GetEipList(para)
	}

	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(ms))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *EipApiHandler) metricLineHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get eip metric line")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &eipmodels.EipMetricLineQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.EipService.GetEipMetricLine(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *EipApiHandler) Items(request *restful.Request, response *restful.Response) {
	klog.Infof("get eip metric Items")
	response.AddHeader("Access-Control-Allow-Origin", "*")

	res, err := s.EipService.GetEiprEsourcesList()
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/block/handler.go
```golang
package block

import (
	"bytes"
	"encoding/json"
	"fmt"
	restfulspec "github.com/emicklei/go-restful-openapi"
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/block"
	blockmodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/block"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	blockserver "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct/block"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	resourcepoolservice "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/resourcepool"
	"io/ioutil"
	"k8s.io/klog/v2"
	"net/http"
	"strconv"
	"time"
)

type BlockApiHandler struct {
	BlockService blockserver.IBlockService
}

func BuildBlockApiHandler() *BlockApiHandler {
	blockService := blockserver.NewBlockService()
	return &BlockApiHandler{
		BlockService: blockService,
	}
}

func (s *BlockApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/cloud/block").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)

	tagCloudProduct := []string{"cloud product block"}
	ws.Route(ws.POST("/overview").
		To(s.Overview).
		Doc("Get overview of block storage").
		Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
		Reads(block.OverViewParameter{}, `
			az: string 可用区code
			region: string 区域code
			diskType: string 云盘类型，必传，可用值：SSD3.0，SSD2.0，SATA2.0，EHDD
		`).
		Returns(200, "OK", block.OverViewSuccess{}))

	//POST /metrics/v1/cloud/block/overviewTopK 云资源监控 / 云产品监控 / 块存储 概览
	ws.Route(ws.POST("/overviewTopK").To(s.overviewTopNewHandler).Doc("Get overview topK of block storage").
		Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
		Param(ws.BodyParameter("region", "Region of block storage").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		//Param(ws.BodyParameter("lab", "机房").Required(false)).
		Param(ws.BodyParameter("name", "The name of TopK,eg:band/io").Required(false)).
		//Param(ws.BodyParameter("subName","The subName of TopK").Required(false)).
		Param(ws.BodyParameter("diskType", "云硬盘类型：eg:SSD3.0/SSD2.0/SATA2.0/EHDD").Required(false)).
		Param(ws.BodyParameter("topK", "The K of TopK").Required(false)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(200, "OK", block.OverViewTopSuccess{}))
	ws.Route(ws.POST("/list").To(s.PostListBlocks).
		Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
		Doc("Get all cloud blocks").
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("region", "Region of physical server").Required(false).DataType("string")).
		Param(ws.BodyParameter("az", "可用区").Required(false).DataType("[]string")).
		Param(ws.BodyParameter("searchKey", "The key of search.eg:`name`").Required(false).DataType("string")).
		Param(ws.BodyParameter("searchValue", "The value of search.").Required(false).DataType("string")).
		//Param(ws.BodyParameter("name", "Name of physical server")).
		//Param(ws.BodyParameter("tenantId", "租户id")).
		//Param(ws.BodyParameter("pool", "服务器所属资源池")).
		Param(ws.BodyParameter("storageType", "存储类型,eg:SSD3.0/SSD2.0/SATA2.0/EHDD").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`usePercent`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升：asc;降：desc").Required(false)).
		Param(ws.BodyParameter("useStatus", "使用状态,eg:in-use").Required(false)).
		Param(ws.BodyParameter("runningStatus", "健康状态,eg:normal/degrade/offline").Required(false)).
		Returns(http.StatusOK, "OK", block.MonitorBlocksSuccess{}))
	ws.Route(ws.GET("/{id}/query").To(s.Metric).
		Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
		Doc("metric of block storage").
		Param(ws.PathParameter("id", "The id of block").Required(false)).
		//Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		//Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		//Param(ws.BodyParameter("storageType", "存储类型,eg:standard:标准存储/archive:归档存储/standard_ia:低频存储").Required(false)).
		Returns(http.StatusOK, "OK", block.MetricSuccess{}))
	ws.Route(ws.POST("/{id}/queryLine").To(s.MetricLine).
		Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
		Doc("metric line of block storage").
		//Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		//Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		//Param(ws.BodyParameter("storageType", "存储类型,eg:standard:标准存储/archive:归档存储/standard_ia:低频存储").Required(false)).
		Param(ws.PathParameter("id", "The id of block").Required(false)).
		Param(ws.BodyParameter("name", "The name of metric,eg:存储容量capacity;带宽band;IOPS监控iops;IO延时:ioDelay").Required(false)).
		//Param(ws.BodyParameter("topK","The K of TopK").Required(false)).
		Param(ws.BodyParameter("start", "The start time of line").Required(false)).
		Param(ws.BodyParameter("end", "The end time of line").Required(false)).
		Returns(http.StatusOK, "OK", block.MetricLineSuccess{}))
	//ws.Route(ws.POST("data/cloud/blockMetric/{id}/query").To(phy.GetPhysicalHostMonitorByIp).
	//	Metadata(restfulspec.KeyOpenAPITags, tagCloudProduct).
	//	Doc("Get alert detail from alertmanager by severity level").
	//	Param(ws.PathParameter("ip", "The ip of monitor physical server").Required(true).DataType("string")).
	//	Param(ws.BodyParameter("list", "The list of query string").Required(true).DataType("array")).
	//	Param(ws.QueryParameter("start", "The start time of range query")).
	//	Param(ws.QueryParameter("end", "The end time of range query")).
	//	Returns(200, "ok", block.MonitorBlocksSuccess{}))

	return ws
}

type commonPageQuery struct {
	PageNo     int      `json:"pageNo,omitempty"`
	PageSize   int      `json:"pageSize,omitempty"`
	AzCode     []string `json:"az,omitempty"`
	RegionCode string   `json:"region,omitempty"`
}

type cloudDiskListQueryParameter struct {
	PageNo           int      `json:"pageNo,omitempty"`
	PageSize         int      `json:"pageSize,omitempty"`
	AzCode           []string `json:"az,omitempty"`
	RegionCode       string   `json:"region,omitempty"`
	DiskType         []string `json:"diskType,omitempty"`
	ResourcePoolType []string `json:"resourcePoolType"`
}

func queryLastFloatValueFromPrometheus(query string) (float64, error) {
	klog.Infof("query %s", query)
	resp, err := prometheusmanager.PrometheusQuery(false, "", "", "", query)
	if err != nil {
		return 0, fmt.Errorf("query prometheus failed")
	}
	if resp == nil {
		return 0, nil
	} else {
		sizeValues := prometheusmanager.PrometheusResultToValue(resp)
		if sizeValues == nil {
			return 0, nil
		}
		arr := sizeValues.([]interface{})
		if len(arr) > 0 {
			sizeStr := arr[len(arr)-1].([]interface{})[1]
			value, err := strconv.ParseFloat(sizeStr.(string), 64)
			if err != nil {
				return 0, fmt.Errorf("invalid prometheus value %s", sizeStr)
			}
			return value, nil
		}
		return 0, nil
	}

}

func floatGbToByte(size float64) int64 {
	return int64(size * 1024 * 1024 * 1024)
}

func (s *BlockApiHandler) Overview(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	parameter := block.OverViewParameter{}
	err := request.ReadEntity(&parameter)
	if err != nil {
		response.WriteAsJson(block.MonitorBlocksSuccess{
			Code:    500,
			Message: "can't get request entity",
		})
		return
	}
	if parameter.RegionCode == "" {
		parameter.RegionCode = "all"
	}
	az := []string{}
	if parameter.AzCode == "all" || parameter.AzCode == "" {
		az = []string{}
	} else {
		az = append(az, parameter.AzCode)
	}
	diskType := parameter.DiskType

	// 告警
	pppp := make([]resourcepoolmodel.AlertType, 0, 4)
	p0 := resourcepoolmodel.AlertType{Label: "紧急告警", Level: "p0", Kind: "error", Number: 0, Unit: "个"}
	pppp = append(pppp, p0)
	p1 := resourcepoolmodel.AlertType{Label: "重要告警", Level: "p1", Kind: "warn", Number: 0, Unit: "个"}
	pppp = append(pppp, p1)
	p2 := resourcepoolmodel.AlertType{Label: "次要告警", Level: "p2", Kind: "minor", Number: 0, Unit: "个"}
	pppp = append(pppp, p2)
	p3 := resourcepoolmodel.AlertType{Label: "提醒告警", Level: "p3", Kind: "info", Number: 0, Unit: "个"}
	pppp = append(pppp, p3)

	// todo 存储使用概览
	var totalDiskSize float64
	var usedDiskSize float64 // 已使用
	var avaDiskSize float64  // 可使用
	//capacity
	t := resourcepoolmodel.CMDBOverViewQuery{Region: parameter.RegionCode, Az: parameter.AzCode, DiskType: diskType}
	cmdbOverview, err := resourcepoolservice.GetBlockStorageOverView(t)

	if err != nil {
		response.WriteAsJson(block.MonitorBlocksSuccess{
			Code:    500,
			Message: "query cmdb failed",
		})
		return
	}

	for _, v := range cmdbOverview.TotalStorageOverview {
		totalDiskSize += services.FormatFloat64(v.Value)
		for _, vv := range v.Distributed {
			if vv.Code == "used" {
				usedDiskSize += services.FormatFloat64(vv.Value)
			}
			if vv.Code == "avilable" {
				avaDiskSize += services.FormatFloat64(vv.Value)
			}
		}
	}

	//todo 块存储概览
	totalDiskCount := 0   //块存储总数
	usedDiskCount := 0    // 使用中
	unmountDiskCount := 0 // 待挂载
	otherDiskCount := 0

	queryParam := cloudDiskListQueryParameter{
		PageNo:           1,
		PageSize:         1,
		AzCode:           az,
		RegionCode:       parameter.RegionCode,
		ResourcePoolType: []string{diskType},
	}

	// 获取云硬盘列表数量
	cloudDiskCount, err := queryCloudDiskList(queryParam)
	if err != nil {
		response.WriteAsJson(block.MonitorBlocksSuccess{
			Code:    500,
			Message: "query cmdb failed",
		})
		return
	}
	//获取云硬盘列表列表
	queryParam.PageSize = cloudDiskCount.Data.TotalCount
	res, err := queryCloudDiskList(queryParam)
	if err != nil {
		response.WriteAsJson(block.MonitorBlocksSuccess{
			Code:    500,
			Message: "query cmdb failed",
		})
		return
	}
	dataList := res.Data.DataList
	for _, item := range dataList {
		totalDiskCount += 1
		switch item.UseStatus {
		case "in-use":
			usedDiskCount += 1
		case "available":
			unmountDiskCount += 1
		default:
			otherDiskCount += 1
		}
	}

	view := block.OverViewSuccess{
		Code:    200,
		Message: "success",
		Data: block.OverView{
			Alerts: pppp,
			Echarts: []block.EchartType{
				{
					Name: "storageUse",
					Data: []block.ChartInfo{
						{
							Info: block.InfoType{
								Name:  "存储使用概览",
								Total: floatGbToByte(totalDiskSize),
								Value: floatGbToByte(totalDiskSize),
							},
							Values: []block.ValueType{
								{
									Name:  "已使用",
									Value: floatGbToByte(usedDiskSize),
								},
								{
									Name:  "可使用",
									Value: floatGbToByte(avaDiskSize),
								},
							},
						},
					},
				},
				{
					Name: "diskCount",
					Data: []block.ChartInfo{
						{
							Info: block.InfoType{
								Name:     "云硬盘使用概览",
								Value:    totalDiskCount,
								Total:    totalDiskCount,
								UnitType: "number",
								Unit:     "个",
							},
							Values: []block.ValueType{
								{
									Name:  "使用中",
									Value: usedDiskCount,
								},
								{
									Name:  "待挂载",
									Value: unmountDiskCount,
								},
							},
						},
					},
				},
				{
					Name: "diskHealthy",
					Data: []block.ChartInfo{
						{
							Info: block.InfoType{
								Name:  "云硬盘健康占比使用率",
								Total: 0,
								Value: 0,
							},
							Values: []block.ValueType{
								{
									Name:  "正常",
									Value: 0,
								},
								{
									Name:  "降级",
									Value: 0,
								},
								{
									Name:  "离线",
									Value: 0,
								},
								{
									Name:  "其他",
									Value: 0,
								},
							},
						},
					},
				},
			},
		},
	}
	response.WriteAsJson(view)
}
func (s *BlockApiHandler) OverviewTop(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	t := new(block.TopQuery)
	request.ReadEntity(t)
	ms, err := s.BlockService.GetBlockOverviewTop(t)
	rst := new(block.OverViewTopSuccess)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = ms
		response.WriteAsJson(rst)
		return
	}
}

func (s *BlockApiHandler) overviewTopNewHandler(request *restful.Request, response *restful.Response) {

	klog.Infof("get block metric top")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &blockmodels.BlockOverviewLineQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.BlockService.GetBlockTopNew(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

func (s *BlockApiHandler) Metric(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	klog.Info("cloud_block_metric")
	id := request.PathParameter("id")

	////临时缓存处理 start
	//var responseMetric []block.MetricInfo
	//var err error
	//key := "metrics/v1/cloud/block/" + id + "/query"
	//ir, err := utils.ApiCache.Get(key)
	//if err != nil {
	//	responseMetric, err = s.BlockService.GetBlockMetric(id)
	//	if err != nil {
	//		klog.Error("GetBlockMetric error: %v", err)
	//		return
	//	} else {
	//		utils.ApiCache.Set(key, responseMetric)
	//		return
	//	}
	//} else {
	//	responseMetric, _ = ir.([]block.MetricInfo)
	//}
	//
	////update cache
	//go func() {
	//	responseMetric, err := s.BlockService.GetBlockMetric(id)
	//	if err != nil {
	//		klog.Error("GetBlockMetric error: %v", err)
	//		return
	//	} else {
	//		utils.ApiCache.Set(key, responseMetric)
	//	}
	//}()
	////临时缓存处理 end

	responseMetric, err := s.BlockService.GetBlockMetric(id)
	if err != nil {
		fail := block.MetricSuccess{Code: 500, Message: err.Error(), Data: nil}
		response.WriteAsJson(fail)
		return
	}
	success := block.MetricSuccess{Code: 200, Message: "success", Data: responseMetric}
	response.WriteAsJson(success)
}
func (s *BlockApiHandler) MetricLine(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	klog.Info("cloud_block_metric_line")
	t := new(block.MetricQuery)
	request.ReadEntity(t)
	id := request.PathParameter("id")

	responseMetric, err := s.BlockService.GetBlockMetricLine(id, t)
	if err != nil {
		fail := block.MetricLineSuccess{Code: 500, Message: err.Error(), Data: nil}
		response.WriteAsJson(fail)
		return
	}
	success := block.MetricLineSuccess{Code: 200, Message: "success", Data: responseMetric}
	response.WriteAsJson(success)
}

func (s *BlockApiHandler) PostListBlocks(request *restful.Request, response *restful.Response) {

	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(block.MonitorBlocksSuccess)
	t := new(block.ListQuery)
	request.ReadEntity(t)
	if t.SearchKey != "" && t.SearchValue != "" {
		switch t.SearchKey {
		case "name":
			t.Name = t.SearchValue
		case "pool":
			t.Pool = t.SearchValue
		case "tenantId":
			t.TenantId = t.SearchValue
		}
	}
	if t.PageNo == 0 {
		rst.Code = 500
		rst.Message = "pageNo false"
		response.WriteAsJson(rst)
		return
	}
	if t.PageSize == 0 {
		rst.Code = 500
		rst.Message = "pageSize false"
		response.WriteAsJson(rst)
		return
	}

	var ms block.MonitorBlocks
	var err error
	ms, err = s.BlockService.GetBlockList(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = ms
		response.WriteAsJson(rst)
		return
	}

}
func GetVMMetrics(request *restful.Request, response *restful.Response) {

	//se := GetAllPhysicals("physical_server")
	//ips := strings.Join(getTopIpSlice(se.Host), ":9100|")
	//ips = ips + ":9100"
}

var blockMap = map[string]string{
	"cn-shanghai-2": "上海二区",       //上海2区(VPC)
	"cn-beijing-6":  "TJWQRegion", //北京6区
}

type CloudDiskPageResult struct {
	Code    int             `json:"code,omitempty"`
	Message string          `json:"message"`
	Data    CloudDiskResult `json:"data"`
}
type CommonListPagination struct {
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
	TotalCount int `json:"totalCount"`
}

type CloudDiskResult struct {
	CommonListPagination
	DataList []cmdbmodel.CloudDiskData `json:"dataList"`
}

func queryCloudDiskList(parameter cloudDiskListQueryParameter) (*CloudDiskPageResult, error) {
	res := &CloudDiskPageResult{}
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/clouddisk"
	err := PostUrl(url, parameter, res)
	if err != nil {
		return nil, err
	}
	return res, nil
}

func PostUrl(url string, data interface{}, result interface{}) error {
	jsonStr, _ := json.Marshal(data)
	req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonStr))
	req.Header.Add("content-type", "application/json")
	if err != nil {
		panic(err)
	}
	defer req.Body.Close()
	client := &http.Client{Timeout: 300 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()
	respBytes, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		return err
	}
	err = json.Unmarshal(respBytes, result)
	if err != nil {
		return err
	}
	return nil
}

////云产品块存储列表
//func GetCMDBBytes() ([]byte, error) {
//	cmdbCount := services.GetTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "post")
//	//ms := MonitorBlocks{DataList: make([]MonitorBlock, 0, cmdbCount)}
//	//cmdb := CMDBResult{Data: CmdbBlocks{DataList: make([]CloudDiskData, 0, cmdbCount)}}
//	var b []byte
//	c := http.Client{}
//	hostUrlPost := cmdbmodel.HostUrlPost{
//		PageNo:   1,
//		PageSize: cmdbCount,
//		Region:   "all",
//		Az:       "all",
//
//		//cmdb.Data.TotalCount = services.GetTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "post")
//	}
//	jsons, _ := json.Marshal(hostUrlPost)
//	result := string(jsons)
//	jsoninfo := strings.NewReader(result)
//
//	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "application/json", jsoninfo)
//
//	if err != nil {
//		return b, err
//	}
//
//	b, _ = io.ReadAll(resp.Body)
//	return b,nil
//
//}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/block/util.go
```golang
package block




```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cloudproduct/block/model.go
```golang
package block



//overview

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cmdbservice/models.go
```golang
package cmdbservice

type Result struct {
	Code    int         `json:"code"`
	Message string      `json:"message"`
	Data    interface{} `json:"data"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/cmdbservice/handler.go
```golang
package cmdbservice

import (
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/servicemonitor"
)

func ServiceInstanceListHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")

	res := &Result{
		Code:    200,
		Message: "success",
		Data:    nil,
	}
	params := cmdbmanager.QueryServiceInstanceListParams{}

	err := request.ReadEntity(&params)
	if err != nil {
		res.Code = 500
		res.Message = "参数解析错误"
		return
	}
	data, err := servicemonitor.ServiceInstanceList(params)
	if err != nil {
		res.Code = 500
		res.Message = err.Error()
		return
	}
	res.Data = data
	response.WriteAsJson(res)
	return

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/physicalServer/models.go
```golang
package physicalServer

type ListQuery struct {
	PageNo   int `json:"pageNo"`
	PageSize int `json:"pageSize"`
	//Count    bool   `json:"count"`
	Region    string `json:"region"`
	Az        string `json:"az"`
	Lab       string `json:"lab"`
	Name      string `json:"name"`
	Sn        string `json:"sn"`
	Ip        string `json:"ip"`
	Label     string `json:"label"`
	State     string `json:"state"`
	OrderCode string `json:"orderCode"`
	OrderType string `json:"orderType"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

type ResourceT struct {
	Rate    string `json:"rate"`
	Use     string `json:"use"`
	Surplus string `json:"surplus"`
}

//overview
type OverViewSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverView struct {
	Region string      `json:"region"`
	Az     string      `json:"az"`
	Lab    string      `json:"lab"`
	Alerts []AlertType `json:"alerts"`
	State  []StateType `json:"state"`
	//AllTopK       []prometheusmanager.RateTopResult
}

type AlertType struct {
	Prefix string `json:"prefix"`
	Level  string `json:"level"`
	Unit   string `json:"unit"`
	Number int    `json:"number"`
	Name   string `json:"name"`
	Kind   string `json:"kind"`
	Type   string `json:"type"`
}
type StateType struct {
	Prefix string `json:"prefix"`
	Unit   string `json:"unit"`
	Number int    `json:"number"`
	Name   string `json:"name"`
	Kind   string `json:"kind"`
	Type   string `json:"type"`
}

type OverViewTopSuccess struct {
	Code    int               `json:"code"`
	Message string            `json:"message"`
	Data    []OverviewTopType `json:"data"`
}

type OverviewTopType struct {
	Region string `json:"region"`
	Az     string `json:"az"`
	Lab    string `json:"lab"`
	Name   string `json:"name"`
	Unit   string `json:"unit"`
	//Alert  AlertLevels `json:"alert"`
	Echarts []EchartType `json:"echarts"`
}

type EchartType struct {
	Info   InfoType    `json:"info"`
	Values []ValueType `json:"values"`
}

type InfoType struct {
	Unit     string `json:"unit"`
	Name     string `json:"name"`
	UnitType string `json:"unitType"`
}

type ValueType struct {
	Value   interface{} `json:"value"`
	Name    string      `json:"name"`
	Ip      string      `json:"ip"`
	SubName string      `json:"subName"`
}

type PhysicalServer struct {
	Name        string  `json:"name"`
	State       string  `json:"state"`
	Pool        string  `json:"pool"`
	Region      string  `json:"region"`
	Az          string  `json:"zone"`
	Lab         string  `json:"lab"`
	Sn          string  `json:"sn"`
	IP          string  `json:"ip"`
	Os          string  `json:"os"`
	CpuLoad     float64 `json:"cpuLoad"`
	MemLoad     float64 `json:"memLoad"`
	DiskLoad    float64 `json:"diskLoad"`
	AlertNumber int     `json:"alertNumber"`
	Label       string  `json:"label"`
}

//type MetricSuccess struct {
//	Code    int        `json:"code"`
//	Message string     `json:"message"`
//	Data    ListResult `json:"data"`
//}

type ListResult struct {
	PageStruct
	DataList []PhysicalServer `json:"dataList"`
}

type AlertDetail struct {
	Id        string `json:"id"`
	Name      string `json:"name"`
	Level     string `json:"level"`
	State     string `json:"state"`
	Rule      string `json:"rule"`
	Threshold string `json:"threshold"`
	LastTime  string `json:"lastTime"`
	RangeTime string `json:"rangeTime"`
	Handler   string `json:"handler"`
}

type AlertDetailSuccess struct {
	Code    int           `json:"code"`
	Message string        `json:"message"`
	Data    []AlertDetail `json:"data"`
}

type Success struct {
	Code    int        `json:"code"`
	Message string     `json:"message"`
	Data    ListResult `json:"data"`
}

//type TopKSuccess struct {
//	Code    int                               `json:"code"`
//	Message string                            `json:"message"`
//	Data    []prometheusmanager.RateTopResult `json:"data"`
//}

type ResponseMetric struct {
	TimeStamp  []string    `json:"timeStamp"`
	Metric     string      `json:"metric"`
	Value      interface{} `json:"value"`
	CPUModeAvg interface{} `json:"cpuModeAvg"`
	Curren     interface{} `json:"curren"`
	Min        interface{} `json:"min"`
	Max        interface{} `json:"max"`
}

type ResultT struct {
	Metric MetricType    `json:"metric"`
	Value  []interface{} `json:"value"`
}

type Lab struct {
	LabCode string `json:"labCode"`
	LabName string `json:"labName"`
}

type Az struct {
	AzCode          string `json:"azCode"`
	AzName          string `json:"azName"`
	AzCodeAggregate string `json:"azCodeAggregate"`
	ContainLabs     []Lab  `json:"az_labs"`
}

type RegionSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    []Region `json:"data"`
}
type Region struct {
	RegionCode          string `json:"regionCode"`
	RegionName          string `json:"regionName"`
	RegionCodeAggregate string `json:"regionCodeAggregate"`
	ContainAzs          []Az   `json:"region_azs"`
}

type RegionData struct {
	DataList []Region `json:"dataList"`
}

type ResponseObject struct {
	Code    int         `json:"code"`
	Message string      `json:"message"`
	Data    interface{} `json:"data"`
}

type TimeResult struct {
	TimeStamp interface{} `json:"timeStamp"`
	Result    interface{} `json:"result"`
}

type DgraphCount struct {
	Host []HostCount `json:"host"`
}

type HostCount struct {
	Count          int    `json:"count"`
	Label          string `json:"label"`
	Ip             string `json:"ip"`
	HostName       string `json:"hostname"`
	HostRegionName string `json:"hostRegionName"`
	HostLabName    string `json:"hostLabName"`
	HostAzName     string `json:"hostAzName"`
	Sn             string `json:"sn"`
	RunStatus      string `json:"runstatus"`
	Os             string `json:"system"`
	ServiceType    string `json:"serviceType"`
}

type QueryList struct {
	List []string `json:"list"`
}
type TopKQueryList struct {
	Region string   `json:"region"`
	Az     string   `json:"az"`
	Lab    string   `json:"lab"`
	Name   []string `json:"name"`
	Start  string   `json:"start"`
	End    string   `json:"end"`
	Step   string   `json:"step"`
	TopK   string   `json:"topk"`
}

//prometheus

type MetricType struct {
	MountPoint string `json:"mountpoint"`
}

type MetricSuccess struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    []MetricResult `json:"data"`
}

type MetricResult struct {
	Type       interface{} `json:"type"`
	MountPoint interface{} `json:"mountpoint"`
	Name       interface{} `json:"name"`
	Current    interface{} `json:"current"`
	Avg        interface{} `json:"avg"`
	Max        interface{} `json:"max"`
	Min        interface{} `json:"min"`
	Value      interface{} `json:"value"`
}

//dashboard
type RegionCurrentStates struct {
	Region               string `json:"region"`
	PhysicalRunningCount int    `json:"physicalRunningCount"`
	PhysicalErrorCount   int    `json:"physicalErrorCount"`
}

type AlertLevels struct {
	P0 int `json:"p0"`
	P1 int `json:"p1"`
	P2 int `json:"p2"`
	P3 int `json:"p3"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/physicalServer/util.go
```golang
package physicalServer

import (
	"fmt"
	cmdb "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	prom "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	"strconv"
)

func MakeTimeStamp(start, end, step string) []string {
	sl := make([]string, 0)
	start1, _ := strconv.ParseFloat(start, 64)
	end1, _ := strconv.ParseFloat(end, 64)
	step1, _ := strconv.ParseFloat(step, 64)
	for {
		ss := strconv.FormatFloat(start1, 'f', -1, 64)
		sl = append(sl, ss)
		start1 += step1
		if start1 > end1 {
			break
		}
	}

	return sl
}

//func GetStateByIp(ip string) (string, error) {
//	c := http.Client{}
//	prome := new(Prometheus)
//	resp, err := c.Get("http://" + config.GetDefaultUrl(config.PrometheusService) + "/api/v1/targets")
//	if err != nil {
//		return "", err
//	}
//
//	b, _ := io.ReadAll(resp.Body)
//	json.Unmarshal(b, prome)
//
//	state := ""
//	for i := 0; i < len(prome.Data.ActiveTargets); i++ {
//		fmt.Printf("instance= %s\n", prome.Data.ActiveTargets[i].Labels.Instance)
//		if pp := strings.Split(prome.Data.ActiveTargets[i].Labels.Instance, ":"); pp[0] == ip {
//			fmt.Printf("%s, health: %s", pp[0], prome.Data.ActiveTargets[i].Health)
//			state = strings.ToUpper(prome.Data.ActiveTargets[i].Health)
//			break
//		} else {
//			state = "DOWN"
//		}
//	}
//	return state, nil
//}

func rTOs(s string, l interface{}) ResponseMetric {
	r := ResponseMetric{}
	r.Metric = s
	ll := prom.PrometheusResultToValue2(l)

	r.Value = ll
	return r
}

func getIpSlice(hosts []cmdb.PhysicalHostData) []string {
	s := []string{}
	for i := 0; i < len(hosts); i++ {
		s = append(s, hosts[i].ManagementIP)
	}

	return s
}

func getMax(vals []float64) float64 {
	var max = vals[0]
	for _, val := range vals {
		if val > max {
			max = val
		}
	}
	return max
}

func getMin(vals []float64) float64 {
	var min = vals[0]
	for _, val := range vals {
		if val < min {
			min = val
		}
	}
	return min
}

func getAvg(vals []float64) float64 {
	l := len(vals)
	sum := 0.0
	for _, val := range vals {
		sum += val / float64(l)
	}
	return sum
}

func getSlice(r interface{}) []float64 {
	var result []float64

	valu := r.(map[string]interface{})
	if Data, o := valu["values"]; o {
		value := Data.([]interface{})
		for i := 0; i < len(value); i++ {
			v := value[i].([]interface{})
			switch v[1].(type) {
			case string:
				vv, _ := strconv.ParseFloat(v[1].(string), 64)
				//ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", vv), 64)
				//sss := services.FormatSize(ss)
				//v[1] = sss
				result = append(result, vv)
			case float64:
				ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", v[1].(float64)), 64)
				//sss := services.FormatSize(ss)
				//v[1] = sss
				result = append(result, ss)
			}
		}
		//result = res.(string)
	}

	return result
}

//func getMetric (l []interface{}) []MetricResult {
//	responseMetric := []MetricResult{}
//	for j := 0; j < len(l); j++ {
//		r := MetricResult{}
//
//		ll := l[j].(map[string]interface{})
//		lll := ll["metric"].(map[string]interface{})
//
//		s := getSlice(l[j])
//
//
//		r.Name = "r:" + lll["device"].(string)
//
//		r.Min = services.FormatSize(getMin(s))
//		r.Avg = services.FormatSize(getAvg(s))
//		r.Max = services.FormatSize(getMax(s))
//		llll := prom.PrometheusResultToValueForSize(l)
//		r.Value = llll[j]
//		responseMetric = append(responseMetric, r)
//	}
//	return responseMetric
//}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/physicalServer/physicalServer.go
```golang
package physicalServer

import (
	"net/http"

	restfulspec "github.com/emicklei/go-restful-openapi"
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	servermodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/physicalServer"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/physicalServer"
	"k8s.io/klog/v2"
)

type PhysicalServerApiHandler struct {
	ServerService physicalServer.IPhysicalServer
}

func BuildPhysicalServerApiHandler() *PhysicalServerApiHandler {
	serverService := physicalServer.NewPhysicalServerService()
	return &PhysicalServerApiHandler{
		ServerService: serverService,
	}
}

func (s *PhysicalServerApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/data/physical").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)

	tags := []string{"physicalServer"}

	//todo switch overview
	ws.Route(ws.POST("/overview").To(s.overviewHandler).Doc("概览页").
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("lab", "机房").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", servermodels.OverViewSuccess{}))
	ws.Route(ws.POST("/overviewTopK").To(s.overviewTopHandler).Doc("概览页的topK").
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "topK的监控项名称,eg:dropRateIn/dropRateOut/errRateIn/errRateOut/bandRateIn/bandRateOut/cpuRate/memRate").Required(false).DataType("[]string")).
		//Param(ws.BodyParameter("subName","The subName of TopK").Required(false)).
		Param(ws.BodyParameter("topK", "topk的k").DataType("int").Required(false)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", servermodels.OverViewTopSuccess{}))
	ws.Route(ws.POST("/server").To(s.listHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("服务器列表").
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		//Param(ws.BodyParameter("contentSelector", "要返回的字段，默认返回所有字段.").Required(false)).
		//Param(ws.BodyParameter("count", "是否统计实例数量，默认值true").Required(true).DataType("bool")).
		// Param(ws.BodyParameter("lab", "机房").DataType("[]string").Required(false)).
		// Param(ws.BodyParameter("Pool", "服务器所属资源池").Required(false)).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("searchKey", "搜索的K.eg:`name`;`sn`;`pool`").Required(false)).
		Param(ws.BodyParameter("searchValue", "搜索的value. eg:`127.0.0.1`").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`cpuLoad`;`memLoad`;`disLoad`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升：asc;降：desc").Required(false)).
		Param(ws.BodyParameter("runState", "运行状态,eg:`up`;`down`").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("pool", "资源池名称,eg:`ebs3.0`").DataType("string").Required(false)).
		Param(ws.BodyParameter("poolType", "资源池类型,eg:`ebs3.0`").DataType("[]string").Required(false)).
		//Param(ws.BodyParameter("cpuErrNum", "cpu硬件故障的筛选,eg:`zero/nonzero`").DataType("string").Required(false)).
		//Param(ws.BodyParameter("memErrNum", "内存硬件故障的筛选,eg:`zero/nonzero`").DataType("string").Required(false)).
		//Param(ws.BodyParameter("diskErrNum", "硬盘硬件故障筛选,eg:`zero/nonzero`").DataType("string").Required(false)).
		Param(ws.BodyParameter("cpuErrNum", "cpu故障数").DataType("string").Required(false)).
		Param(ws.BodyParameter("memErrNum", "mem故障数").DataType("string").Required(false)).
		Param(ws.BodyParameter("diskErrNum", "硬盘硬件故障筛选").DataType("string").Required(false)).
		Param(ws.BodyParameter("isAggragate", "是否是计算资源池,eg:`poolComputer`").DataType("int").Required(false)).
		Returns(http.StatusOK, "OK", servermodels.Success{}))
	ws.Route(ws.POST("/server/{ip}/query").To(s.metricHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("取得服务器的监控").
		Param(ws.PathParameter("ip", "The ip of monitor physical server").Required(true).DataType("string")).
		Param(ws.BodyParameter("list", "The list of query string").Required(true).DataType("array")).
		Param(ws.QueryParameter("start", "The start time of range query")).
		Param(ws.QueryParameter("end", "The end time of range query")).
		Param(ws.QueryParameter("step", "The step time of range query")).
		Param(ws.QueryParameter("workName", "The workName of query string")).
		Returns(200, "ok", servermodels.MetricSuccess{}))
	ws.Route(ws.GET("/server/{ip}/workDropDownList").To(s.metricWorkDropDownListHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("网卡下拉列表").
		Param(ws.PathParameter("ip", "The ip of monitor physical server").Required(true).DataType("string")).
		Returns(200, "ok", servermodels.MetricSuccess{}))
	ws.Route(ws.GET("/server/{ip}/boundOutQuery").To(s.hardwareHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("取得服务器的硬件监控").
		Param(ws.PathParameter("ip", "The ip of monitor physical server").Required(true).DataType("string")).
		// Param(ws.BodyParameter("list", "The list of query string").Required(true).DataType("array")).
		// Param(ws.QueryParameter("start", "The start time of range query")).
		// Param(ws.QueryParameter("end", "The end time of range query")).
		// Param(ws.QueryParameter("step", "The step time of range query")).
		Returns(200, "ok", servermodels.HardwareResponse{}))
	// ws.Route(ws.POST("/{sn}/queryLine").To(s.metricLineHandler).
	// 	Metadata(restfulspec.KeyOpenAPITags, tags).
	// 	Doc("取得交换机的监控变化曲线").
	// 	Param(ws.PathParameter("sn", "交换机的sn号").Required(true).DataType("string")).
	// 	Param(ws.BodyParameter("list", "交换机的查询监控项列表,eg:`cpu`;`mem`;`power`").Required(true).DataType("[]string")).
	// 	Param(ws.BodyParameter("start", "The start time of range query")).
	// 	Param(ws.BodyParameter("end", "查询的结束时间")).
	// 	//Param(ws.QueryParameter("step", "查询的开始时间")).
	// 	Returns(200, "ok", switchmodels.SwitchMetricLineResponse{}))
	// ws.Route(ws.POST("/server/alert").To(s.alertListHandler).
	// 	Metadata(restfulspec.KeyOpenAPITags, tags).
	// 	Doc("交换机的告警列表").
	// 	Param(ws.QueryParameter("pageNo", "页码，默认值：`1`")).
	// 	Param(ws.QueryParameter("pageSize", "页大小，默认值：`10`")).
	// 	Param(ws.PathParameter("sn", "交换机的sn号")).
	// 	Param(ws.QueryParameter("pLevel", "告警等级, 默认是 `p0`")).
	// 	Param(ws.QueryParameter("alertState", "告警状态")).
	// 	Param(ws.QueryParameter("alertId", "告警id")).
	// 	Param(ws.QueryParameter("alertInstance", "告警实例")).
	// 	Returns(200, "OK", servermodels.AlertDetailSuccess{}))
	//todo swtich cpu usage rate (begin end step)

	return ws
}

func (s *PhysicalServerApiHandler) overviewHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get server overview")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &servermodels.ListQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.ServerService.GetServerOverview(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *PhysicalServerApiHandler) overviewTopHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get switch overview")
	para := &servermodels.TopKQueryList{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.ServerService.GetServerOverviewTop(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *PhysicalServerApiHandler) listHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get server List")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &servermodels.PhyListQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.ServerService.GetServerList(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *PhysicalServerApiHandler) metricHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get server metric")

	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &servermodels.QueryList{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}

	para.Ip = request.PathParameter("ip")
	para.Start = request.QueryParameter("start")
	para.End = request.QueryParameter("end")

	res, err := s.ServerService.GetServerMetric(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *PhysicalServerApiHandler) metricWorkDropDownListHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")

	ip := request.PathParameter("ip")

	res, err := s.ServerService.GetServerMetricWorkDropDownList(ip)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *PhysicalServerApiHandler) hardwareHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get server metric")

	response.AddHeader("Access-Control-Allow-Origin", "*")

	ip := request.PathParameter("ip")

	res, err := s.ServerService.GetServerHardwareMetric(ip)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/resourcepool/database/handler.go
```golang
package database

import (
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	"net/http"
	"time"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"

	restfulspec "github.com/emicklei/go-restful-openapi/v2"
	"github.com/emicklei/go-restful/v3"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	resourcepoolservice "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/resourcepool"
	"k8s.io/klog/v2"
)

type DatabaseApiHandler struct {
	DatabaseService resourcepoolservice.DatabaseServer
}

func BuildDatabaseApiHandler() *DatabaseApiHandler {
	databaseService := resourcepoolservice.NewDatabaseServerService()
	return &DatabaseApiHandler{
		DatabaseService: databaseService,
	}
}

func (s *DatabaseApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/database").
		Consumes(restful.MIME_JSON).
		Produces(restful.MIME_JSON)

	tag := []string{"Database Resource Pool"}

	ws.Route(ws.POST("/overview").To(s.Overview).Doc("数据库监控概览").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("lab", "机房").Required(false)).
		Returns(200, "OK", resourcepoolmodel.OverviewSuccess{}))
	ws.Route(ws.POST("/overviewline").To(s.OverviewLine).Doc("数据库监控概览").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "line的监控项名称,eg:disk/cpuRate/memRate").Required(false).DataType("[]string")).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(200, "OK", resourcepoolmodel.DatabaseOverviewLineSuccess{}))
	ws.Route(ws.POST("/databaseList").To(s.DatabaseList).Doc("数据库监控列表").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("region", "区域编码 eg:`cn-shanghai-2`").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("name", "资源池名称").DataType("string").Required(false)).
		Param(ws.BodyParameter("searchKey", "搜索的K.eg:`name`;`region`").Required(false)).
		Param(ws.BodyParameter("searchValue", "搜索的value. eg:`127.0.0.1`").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`cpuUsedPercent`;`memoryUsedPercent`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升 asc;降 desc").Required(false)).
		Param(ws.BodyParameter("dbType", "数据库类型名称").DataType("[]string").Required(false)).
		Returns(200, "OK", resourcepoolmodel.DatabaseListSuccess{}))

	ws.Route(ws.POST("/serverList").To(s.ServerList).Doc("数据库服务器列表").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("region", "区域编码 eg:`cn-shanghai-2`").DataType("string").Required(false)).
		Param(ws.BodyParameter("id", "资源池的id").Required(false)).
		Param(ws.BodyParameter("runState", "运行状态：up，down").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("lab", "所属机房").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("searchKey", "搜索的K.eg:`name`;`ip`;`sn`").Required(false)).
		Param(ws.BodyParameter("searchValue", "搜索的value. eg:`127.0.0.1`").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`cpuUsedPercent`;`memoryUsedPercent`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升 asc;降 desc").Required(false)).
		Returns(200, "OK", resourcepoolmodel.ServerListSuccess{}))

	ws.Route(ws.POST("/instanceList").To(s.InstanceList).Doc("数据库实例列表").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("region", "区域编码 eg:`cn-shanghai-2`").DataType("string").Required(false)).
		Param(ws.BodyParameter("id", "资源池的id").Required(false)).
		Param(ws.BodyParameter("runState", "运行状态：up，down").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("tenantIdList", "租户id列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("tenantNameList", "租户名称列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("searchKey", "搜索的K.eg:`name`;`ip`;`sn`").Required(false)).
		Param(ws.BodyParameter("searchValue", "搜索的value. eg:`127.0.0.1`").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`cpuUsedPercent`;`memoryUsedPercent`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升 asc;降 desc").Required(false)).
		Returns(200, "OK", resourcepoolmodel.InstanceListSuccess{}))

	ws.Route(ws.POST("/dbTypeList").To(s.DbTypeList).Doc("数据库类型列表").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Returns(200, "OK", models.Response{}))
	ws.Route(ws.POST("/monitor").To(s.monitor).
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Doc("数据库监控详情").
		Param(ws.BodyParameter("id", "database resource pool id").DataType("string").Required(true)).
		Param(ws.BodyParameter("metric", "The monitor metric query").DataType("string").Required(true)).
		Param(ws.BodyParameter("start", "The start timestamp of range query").DataType("string").Required(false)).
		Param(ws.BodyParameter("end", "The end timestamp of range query").Required(false)).
		Param(ws.BodyParameter("step", "The step time of range query").DataType("int").Required(false).DefaultValue("120")).
		Returns(http.StatusOK, "ok", resourcepoolmodel.DatabaseMonitorLine{}),
	)

	return ws
}

//获取数据库监控概览
func (s *DatabaseApiHandler) Overview(request *restful.Request, response *restful.Response) {
	klog.Infof("get database overview")
	param := &resourcepoolmodel.DatabaseOverviewQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.DatabaseService.Overview(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

//获取数据库监控概览
func (s *DatabaseApiHandler) OverviewLine(request *restful.Request, response *restful.Response) {
	klog.Infof("get database overviewline")
	param := &resourcepoolmodel.DatabaseOverviewLineQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.DatabaseService.OverviewLine(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

//获取数据库监控列表
func (s *DatabaseApiHandler) DatabaseList(request *restful.Request, response *restful.Response) {
	klog.Infof("get database DatabaseList")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	param := &resourcepoolmodel.DatabaseListQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}

	if param.PageNo == 0 {
		param.PageNo = 1
	}
	if param.PageSize == 0 {
		param.PageSize = 10
	}
	//if param.Region == "" {
	//	param.Region = "all"
	//}

	res, err := s.DatabaseService.DatabaseList(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

//获取数据库全部类型
func (s *DatabaseApiHandler) DbTypeList(request *restful.Request, response *restful.Response) {
	klog.Infof("get database DatabaseList")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	res, err := s.DatabaseService.DbTypeList()
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

// 数据库监控详情
func (s *DatabaseApiHandler) monitor(request *restful.Request, response *restful.Response) {
	//defaultStep := 120
	monitorQuery := resourcepoolmodel.DatabaseMonitorQuery{}
	if err := request.ReadEntity(&monitorQuery); err != nil {
		klog.Errorln(err)
		if err = response.WriteAsJson(models.NewBadRequestError(err)); err != nil {
			klog.Errorln(err)
		}
		return
	}

	if monitorQuery.End == 0 {
		monitorQuery.End = time.Now().Unix()
	}
	if monitorQuery.Start == 0 {
		monitorQuery.Start = time.Unix(monitorQuery.End, 0).Add(-30 * time.Minute).Unix()
	}

	//maximumPoints := 11000
	//monitorQuery.Step = int(monitorQuery.End-monitorQuery.Start)/maximumPoints + 1
	//if monitorQuery.Step < defaultStep {
	//	monitorQuery.Step = defaultStep
	//}
	monitorQuery.Step = services.TimeToStepForInt(monitorQuery.End - monitorQuery.Start)
	klog.Infof("get resource pool monitor, query param: %+v", monitorQuery)
	monitorLine, err := s.DatabaseService.Monitor(&monitorQuery)
	if err != nil {
		klog.Errorln(err)
		if err = response.WriteAsJson(models.NewServerError(err)); err != nil {
			klog.Errorln(err)
		}
		return
	}
	response.WriteEntity(monitorLine)
}

//获取数据库服务器列表
func (s *DatabaseApiHandler) ServerList(request *restful.Request, response *restful.Response) {
	klog.Infof("get database server list")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	param := &resourcepoolmodel.ServerListQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}

	if param.PageNo == 0 {
		param.PageNo = 1
	}
	if param.PageSize == 0 {
		param.PageSize = 10
	}

	res, err := s.DatabaseService.ServerList(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

//获取数据库实例列表
func (s *DatabaseApiHandler) InstanceList(request *restful.Request, response *restful.Response) {
	klog.Infof("get database instance list")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	param := &resourcepoolmodel.InstanceListQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	if param.Id == "" {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage("id 不能为空"))
		return
	}

	if param.PageNo == 0 {
		param.PageNo = 1
	}
	if param.PageSize == 0 {
		param.PageSize = 10
	}

	res, err := s.DatabaseService.InstanceList(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/resourcepool/objectstorage/handler.go
```golang
package objectstorage

import (
	"context"
	"encoding/json"
	"fmt"
	"net/http"
	"strconv"

	"k8s.io/klog/v2"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/dgraphmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"

	restfulspec "github.com/emicklei/go-restful-openapi"
	"github.com/emicklei/go-restful/v3"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	resourcepoolservice "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/resourcepool"
)

type ObjectPoolApiHandler struct {
	ObjectPoolService resourcepoolservice.IObjectPoolService
}

func BuildObjectPoolApiHandler() *ObjectPoolApiHandler {
	objectPoolService := resourcepoolservice.NewObjectPoolService()
	return &ObjectPoolApiHandler{
		ObjectPoolService: objectPoolService,
	}
}

func (s *ObjectPoolApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/objectStorage").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)

	tag3 := []string{"object Reasource Pool Monitor"}
	ws.Route(ws.POST("/overview").To(s.Overview).Doc("Get overview of object pool").
		Metadata(restfulspec.KeyOpenAPITags, tag3).
		Param(ws.BodyParameter("region", "Region of object pool").DataType("string").Required(false)).
		//Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		//Param(ws.BodyParameter("lab", "机房").Required(false)).
		Param(ws.BodyParameter("pool", "资源池").Required(false)).
		Returns(200, "OK", resourcepoolmodel.ObjectOverViewSuccess{}))
	ws.Route(ws.POST("/overviewLine").To(s.OverviewLine).Doc("Get overview of object pool line").
		Metadata(restfulspec.KeyOpenAPITags, tag3).
		Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		//Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		//Param(ws.BodyParameter("lab", "机房").Required(false)).Param(ws.BodyParameter("name","The name of TopK").Required(false)).
		Param(ws.BodyParameter("name", "The Name of metric,eg:stockCapacity/bucket/qs/api/requestNum/connectNum/band/flow").Required(false)).
		//Param(ws.BodyParameter("subName","The subName of TopK").Required(false)).
		//Param(ws.BodyParameter("topK","The K of TopK").Required(false)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(200, "OK", resourcepoolmodel.ObjectOverViewLineSuccess{}))
	ws.Route(ws.POST("/list").To(s.ListObjectPoolHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag3).
		Doc("list all object Reasource Pool/").
		Param(ws.BodyParameter("pageNo", "eg:1,页码，默认值1。").DataType("int32").Required(true).DefaultValue("1")).
		Param(ws.BodyParameter("pageSize", "eg:10, 页大小，默认值10。").DataType("int32").Required(true).DefaultValue("10")).
		Param(ws.BodyParameter("region", "区域;默认值：全部").DataType("string").Required(false).DefaultValue("全部")).
		Param(ws.BodyParameter("az", "可用区;默认值：全部").DataType("string").Required(false).DefaultValue("全部")).
		//Param(ws.BodyParameter("name", "实例名称").DataType("string").Required(false)).
		Param(ws.BodyParameter("searchKey", "The key of search.eg:`name`").Required(false).DataType("string")).
		Param(ws.BodyParameter("searchValue", "The value of search.eg:`127.0.0.1`").Required(false).DataType("string")).
		Param(ws.BodyParameter("storageType", "The list of type storage.eg:active/willoverdue/overdued//error").Required(false)).
		Param(ws.BodyParameter("state", "The list of type storage.eg:active/willoverdue/overdued//error").Required(false)).
		Returns(http.StatusOK, "ok", resourcepoolmodel.ObjectStoragePoolSuccess{}))
	ws.Route(ws.GET("/{id}/query").To(s.ObjectPoolMetricHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag3).
		Doc("metric of object pool").
		Param(ws.PathParameter("id", "The id of pool").Required(false)).
		//Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		//Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		//Param(ws.BodyParameter("storageType", "存储类型,eg:standard:标准存储/archive:归档存储/standard_ia:低频存储").Required(false)).
		Returns(http.StatusOK, "OK", resourcepoolmodel.BucketPoolMetricResponse{}))
	ws.Route(ws.GET("/usage").To(s.ListObjectStorageUsageHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag3).
		Doc("list all object Reasource Pool usage/获取对象存储资源池-库存列表").
		Param(ws.QueryParameter("name", "实例名称").DataType("string").Required(false)).
		Param(ws.QueryParameter("region", "区域;默认值：all").DataType("string").Required(false).DefaultValue("all")).
		Param(ws.QueryParameter("pageNo", "eg:1,页码，默认值1。").DataType("int32").Required(true).DefaultValue("1")).
		Param(ws.QueryParameter("pageSize", "eg:10, 页大小，默认值10。").DataType("int32").Required(true).DefaultValue("10")).
		Param(ws.QueryParameter("orderCode", "The orderCode of order.eg:capacityUsedRate").Required(false)).
		Param(ws.QueryParameter("orderType", "The orderType of order.eg:升：asc;降：desc").Required(false)).
		Returns(http.StatusOK, "ok", resourcepoolmodel.ObjectStoragePoolUsageResult{}))

	ws.Route(ws.GET("/test").To(s.TestHandler).
		Returns(http.StatusOK, "ok", resourcepoolmodel.ObjectStoragePoolUsageResult{}))

	return ws
}

func (s *ObjectPoolApiHandler) Overview(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	klog.Info("object_overview")
	rst := new(Result)
	t := new(resourcepoolmodel.ObjectOverviewLineQuery)
	request.ReadEntity(t)
	AggregateDataResult, err := s.ObjectPoolService.GetObjectPoolOverview(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = AggregateDataResult
		response.WriteAsJson(rst)
		return
	}
}
func (s *ObjectPoolApiHandler) OverviewLine(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(resourcepoolmodel.OverviewLineQuery)
	request.ReadEntity(t)
	//do
	computerPool, err := s.ObjectPoolService.GetObjectPoolOverviewLine(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = computerPool
		response.WriteAsJson(rst)
		return
	}
}

// 云资源监控/资源池监控/对象存储-列表页
func (s *ObjectPoolApiHandler) ListObjectPoolHandler(request *restful.Request, response *restful.Response) {

	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(resourcepoolmodel.ObjectStoragePoolSuccess)
	t := new(resourcepoolmodel.ListQuery)
	request.ReadEntity(t)
	if t.SearchKey != "" && t.SearchValue != "" {
		switch t.SearchKey {
		case "name":
			t.Name = t.SearchValue
		}
	}
	if t.PageNo == 0 {
		rst.Code = 500
		rst.Message = "pageNo false"
		response.WriteAsJson(rst)
		return
	}

	if t.PageSize == 0 {
		rst.Code = 500
		rst.Message = "pageSize false"
		response.WriteAsJson(rst)
		return
	}

	BlockStorageDataResult, err := s.ObjectPoolService.GetObjectPoolList(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = BlockStorageDataResult
		response.WriteAsJson(rst)
		return
	}

}

func (s *ObjectPoolApiHandler) ObjectPoolMetricHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	id := request.PathParameter("id")

	if id == "" {
		rst.Code = 500
		rst.Message = "id false"
		response.WriteAsJson(rst)
		return
	}

	responseMetric := s.ObjectPoolService.GetObjectPoolMetric(id)

	rst.Code = 200
	rst.Message = "success"
	rst.Data = responseMetric
	response.WriteAsJson(rst)
	return

}

// 资源池管理/对象存储资源池/库存-列表页
func (s *ObjectPoolApiHandler) ListObjectStorageUsageHandler(request *restful.Request, response *restful.Response) {

	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	var objectStoragesResult resourcepoolmodel.ObjectStoragePoolUsageResult
	t := new(resourcepoolmodel.ObjectStorageUsageQuery)
	t.Name = request.QueryParameter("name")
	// if t.Name == "" {
	// 	rst.Code = 500
	// 	rst.Message = "name false"
	// 	rst.Data = objectStoragesResult
	// 	response.WriteAsJson(rst)
	// 	return
	// }
	pageNo, err := strconv.Atoi(request.QueryParameter("pageNo"))
	if err != nil {
		rst.Code = 500
		rst.Message = "pageNo false"
		rst.Data = objectStoragesResult
		response.WriteAsJson(rst)
		return
	}
	t.PageNo = pageNo
	pageSize, eer := strconv.Atoi(request.QueryParameter("pageSize"))
	if eer != nil {
		rst.Code = 500
		rst.Message = "pageSize false"
		rst.Data = objectStoragesResult
		response.WriteAsJson(rst)
		return
	}
	t.PageSize = pageSize
	t.Region = request.QueryParameter("region")
	if t.Region == "" {
		t.Region = "all"
	}
	orderCode := request.QueryParameter("orderCode")
	orderType := request.QueryParameter("orderType")
	t.OrderCode = orderCode
	t.OrderType = orderType
	BlockStorageDataResult, err := s.ObjectPoolService.GetObjectPoolUsageList(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		rst.Data = objectStoragesResult
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = BlockStorageDataResult
		response.WriteAsJson(rst)
		return
	}

}

func (s *ObjectPoolApiHandler) TestHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	mail := s.ObjectPoolService.Test()
	rst.Code = 200
	rst.Message = "success"
	rst.Data = mail
	response.WriteAsJson(rst)
}

// pool server list
func GetPoolServerListHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(ListQuery)
	pageNo := request.QueryParameter("pageNo")
	if pageNo == "" {
		rst.Code = 500
		rst.Message = "pageNo false"
		response.WriteAsJson(rst)
		return
	}
	pageSize := request.QueryParameter("pageSize")
	if pageSize == "" {
		rst.Code = 500
		rst.Message = "pageSize false"
		response.WriteAsJson(rst)
		return
	}
	//region := request.QueryParameter("region")
	//if region == "" || region == "all" {
	//	region = "all"
	//}
	//
	//az := request.QueryParameter("az")
	//if az == "" {
	//	az = "all"
	//}

	t.PageNo = pageNo
	t.PageSize = pageSize
	//t.Count = count
	//t.Region = region
	//t.Az = az
	t.Id = request.PathParameter("id")
	//t.TenantId = request.QueryParameter("tenantId")
	//t.InnerIp = request.QueryParameter("innerIp")
	//t.OuterIp = request.QueryParameter("outerIp")
	//t.PhysicalHost = request.QueryParameter("physicalHost")
	//t.Pool = request.QueryParameter("pool")
	//t.State = request.QueryParameter("state")

	ms, err := GetComputerPoolServerList(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = ms
		response.WriteAsJson(rst)
		return
	}

}

func GetComputerPoolServerList(l *ListQuery) (MonitorHosts, error) {
	ms := MonitorHosts{}
	//cs := CmdbVms{}
	//cmdb := CMDBResult{}

	cmdb, err := cmdbmanager.GetHostListByResourcePool(l.Id)

	if err != nil {
		fmt.Println("err" + err.Error())
		return ms, err
	}

	for i := 0; i < len(cmdb.Data.DataList); i++ {

		j := cmdb.Data.DataList[i]

		q := fmt.Sprintf(`{
		host(func:has(sn)) @filter(eq(sn, %s)) {
		  sn
		  ip
		  label
		}}`, j.SN)
		resp, er := dgraphmanager.NewDgraphClient().NewTxn().Query(context.Background(), q)
		if er != nil {
			return ms, er
		}
		var se DgraphCount
		e := json.Unmarshal(resp.Json, &se)
		if e != nil {
			return ms, e
		}

		m := MonitorHost{
			Id:           j.Id,
			Name:         j.Name,
			State:        j.Status,
			ResourcePool: j.ResourcePool,
			Region:       j.Region,
			Az:           j.Az,
			SN:           j.SN,
			Ip:           se.Host[0].Ip,
			Lable:        se.Host[0].Label,
		}

		state, _ := prometheusmanager.GetStateByIp(se.Host[i].Ip)
		m.State = state

		c, _ := prometheusmanager.PrometheusQuery2(false, "", "", "", `1-avg(irate(node_cpu_seconds_total{mode="idle",instance="`+se.Host[i].Ip+`:9100"`+`}[5m]))`)
		m.CpuUesd = prometheusmanager.PrometheusResultToValue2(c)

		mem, _ := prometheusmanager.PrometheusQuery2(false, "", "", "", `1-node_memory_MemAvailable_bytes{instance=~"`+se.Host[i].Ip+`:9100"`+`}/node_memory_MemTotal_bytes{instance=~"`+se.Host[i].Ip+`:9100"`+`}`)
		m.MemUsed = prometheusmanager.PrometheusResultToValue2(mem)

		alerts, _ := alertmanager.GetAlertsByFilter(se.Host[i].Ip + ":9100")
		m.AlertNumber = len(alerts)
		ms.DataList = append(ms.DataList, m)
	}

	ms.PageNo = cmdb.Data.PageNo
	ms.PageSize = cmdb.Data.PageSize
	ms.TotalCount = cmdb.Data.TotalCount

	return ms, nil
}

// 资源池管理/块存储资源池/概览
func GetCMDBObjectStorageOverViewHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(cmdbmodel.BucketRequest)

	region := request.QueryParameter("region")
	if region == "" || region == "all" {
		region = "all"
	}
	// az := request.QueryParameter("az")
	// if az == "" || az == "all" {
	// 	az = "all"
	// }

	//t.Count = count
	t.Region = region
	//t.Az = az
	//request.ReadEntity(t)

	responseMetric, err := resourcepoolservice.GetCMDBObjectStorageOverView(*t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = responseMetric
		response.WriteAsJson(rst)
		return
	}

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/resourcepool/objectstorage/result.go
```golang
package objectstorage

//overview
type OverViewSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverView struct {
	StorageType  string      `json:"storageType"`
	ResourcePool string      `json:"resourcePool"`
	Region       string      `json:"region"`
	Az           string      `json:"az"`
	Lab          string      `json:"lab"`
	Alerts       AlertLevels `json:"alerts"`
	Echarts      []Chart     `json:"echarts"`
	//State  RegionCurrentStates `json:"state"`
	//AllTopK       []prometheusmanager.RateTopResult
}
type AlertLevels struct {
	P0 int `json:"p0"`
	P1 int `json:"p1"`
	P2 int `json:"p2"`
	P3 int `json:"p3"`
}

type Chart struct {
	Info   OverInfo    `json:"info"`
	Values []ValueType `json:"values"`
}
type OverInfo struct {
	Region       string `json:"region"`
	Az           string `json:"az"`
	StorageType  string `json:"storageType"`
	ResourcePool string `json:"resourcePool"`
	Name         string `json:"name"`
	SubName      string `json:"subName"`
	Total        string `json:"total"`
}

//OverviewLine
type OverViewLineSuccess struct {
	Code    int          `json:"code"`
	Message string       `json:"message"`
	Data    OverViewLine `json:"data"`
}

type OverViewLine struct {
	StorageType  string `json:"storageType"`
	ResourcePool string `json:"resourcePool"`
	Region       string `json:"region"`
	Az           string `json:"az"`
	Lab          string `json:"lab"`
	//Alert  AlertLevels `json:"alert"`
	Echarts []EchartType `json:"echarts"`
}

type EchartType struct {
	Info   InfoType    `json:"info"`
	Values []ValueType `json:"values"`
}

type ValueType struct {
	Value     string `json:"value"`
	Name      string `json:"name"`
	Timestamp string `json:"timestamp"`
}

type InfoType struct {
	StorageType  string `json:"storageType"`
	ResourcePool string `json:"resourcePool"`
	Region       string `json:"region"`
	Az           string `json:"az"`
	Lab          string `json:"lab"`
	Name         string `json:"name"`
	SubName      string `json:"subName"`
	Total        string `json:"total"`
	TopK         int    `json:"topk"`
	Start        string `json:"start"`
	End          string `json:"end"`
}

//other
type Result struct {
	Code    int         `json:"code"`
	Message string      `json:"messgae"`
	Data    interface{} `json:"data"`
}

type ListQuery struct {
	PageNo   string `json:"pageNo"`
	PageSize string `json:"pageSize"`
	Id       string `json:"id"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

type MonitorHosts struct {
	PageStruct
	DataList []MonitorHost `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type MonitorHost struct {
	Id               string      `json:"id"`
	Name             string      `json:"name"`
	AssignmentStatus string      `json:"assignmentStatus"`
	ResourcePoolType string      `json:"resourcePoolType"`
	ResourcePool     string      `json:"resourcePool"`
	Region           string      `json:"region"`
	Az               string      `json:"az"`
	SN               string      `json:"sn"`
	Ip               string      `json:"ip"`
	State            string      `json:"state"`
	CpuUesd          interface{} `json:"cpuUesd"`
	MemUsed          interface{} `json:"memUsed"`
	AlertNumber      int         `json:"alertNumber"`
	Lable            string      `json:"lable"`
}

type DgraphCount struct {
	Host []HostCount `json:"host"`
}

type HostCount struct {
	Count          int    `json:"count"`
	Label          string `json:"label"`
	Ip             string `json:"ip"`
	HostName       string `json:"hostname"`
	HostRegionName string `json:"hostRegionName"`
	HostLabName    string `json:"hostLabName"`
	HostAzName     string `json:"hostAzName"`
	Sn             string `json:"sn"`
	RunStatus      string `json:"runstatus"`
	Os             string `json:"system"`
	ServiceType    string `json:"serviceType"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/resourcepool/blockstorage/handler.go
```golang
package blockstorage

import (
	"context"
	"encoding/json"
	"fmt"
	"net/http"
	"strings"

	restfulspec "github.com/emicklei/go-restful-openapi"
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/handler/resourcepool/aggragate"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/dgraphmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	resourcepoolservice "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/resourcepool"
	"k8s.io/klog/v2"
)

type BlockPoolApiHandler struct {
	BlockPoolService resourcepoolservice.IBlockPoolService
}

func BuildBlockPoolApiHandler() *BlockPoolApiHandler {
	blockPoolService := resourcepoolservice.NewBlockPoolService()
	return &BlockPoolApiHandler{
		BlockPoolService: blockPoolService,
	}
}

func (s *BlockPoolApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/blockStorage").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)

	tag2 := []string{"block Reasource Pool Monitor"}
	ws.Route(ws.POST("/overview").To(s.Overview).Doc("Get overview of block storage").
		Metadata(restfulspec.KeyOpenAPITags, tag2).
		Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		//Param(ws.BodyParameter("lab", "机房").Required(false)).
		Param(ws.BodyParameter("diskType", "云硬盘类型：eg:SSD3.0/SSD2.0/SATA2.0/EHDD").Required(false)).
		Param(ws.BodyParameter("pool", "资源池").Required(false)).
		Returns(200, "OK", resourcepoolmodel.BlockPoolOverViewSuccess{}))
	ws.Route(ws.POST("/overviewLine").To(s.OverviewLineCharts).Doc("Get overview of block storage pool").
		Metadata(restfulspec.KeyOpenAPITags, tag2).
		Reads(resourcepoolmodel.OverviewLineChartsParameter{}, `
				az: string 						可用区code，支持：all
				region: string   				区域code，支持：all
				diskType: string 				存储类型，必传，可选值：SSD3.0,SSD2.0,EHDD
				pool: string 					资源池名称
				name: string数组					需要获取的图表的名称，支持的chart：stockCapacity（存储容量库存），total（云硬盘总数），unMount（待挂载云硬盘），ioNum（IO读写吞吐），ioDelay（IO读写延时），band（读写带宽）,health（云硬盘健康状态）
				start: int                      查询开始的时间戳，必传，单位毫秒
				end: int						查询结束的时间戳，必传，单位毫秒
			`).
		//Param(ws.BodyParameter("region", "Region of pool").DataType("string").Required(false)).
		//Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		////Param(ws.BodyParameter("lab", "机房").Required(false)).
		//Param(ws.BodyParameter("diskType", "云硬盘类型：eg:SSD3.0/SSD2.0/SATA2.0/EHDD").Required(false)).
		//Param(ws.BodyParameter("pool", "资源池").Required(false)).
		//Param(ws.BodyParameter("name", "The name of metric line,eg:stockCapacity/total/unMount/health/ioNum/ioDelay/band").Required(false)).
		////Param(ws.BodyParameter("subName","The subName of TopK").Required(false)).
		////Param(ws.BodyParameter("topK","The K of TopK").Required(false)).
		//Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		//Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(200, "OK", resourcepoolmodel.OverviewLineChartsResponse{}))
	ws.Route(ws.POST("/list").To(s.ListBlockStorageHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag2).
		Doc("list all block Reasource Pool/").
		Param(ws.BodyParameter("pageNo", "eg:1,页码，默认值1。").DataType("int32").Required(true).DefaultValue("1")).
		Param(ws.BodyParameter("pageSize", "eg:10, 页大小，默认值10。").DataType("int32").Required(true).DefaultValue("10")).
		Param(ws.BodyParameter("region", "区域;默认值：全部").DataType("string").Required(false).DefaultValue("全部")).
		Param(ws.BodyParameter("az", "可用区;默认值：全部").DataType("[]string").Required(false).DefaultValue("全部")).
		//Param(ws.BodyParameter("name", "实例名称").DataType("string").Required(false)).
		Param(ws.BodyParameter("searchKey", "The key of search.eg:`name`").Required(false).DataType("string")).
		Param(ws.BodyParameter("searchValue", "The value of search.").Required(false).DataType("string")).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:capacityUsedRate").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升：asc;降：desc").Required(false)).
		Param(ws.BodyParameter("storageType", "存储类型,eg:SSD3.0/SSD2.0/SATA2.0/EHDD").Required(false)).
		Param(ws.BodyParameter("monitorStatus", "监控状态,eg:in-use").Required(false)).
		Returns(http.StatusOK, "ok", resourcepoolmodel.BlockStorageSuccess{}))
	ws.Route(ws.POST("/usage").To(s.ListBlockStorageUsageHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag2).
		Doc("list all block Reasource Pool usage/获取块存储资源池-库存列表").
		Reads(resourcepoolmodel.BlockStorageUseageQuery{}, resourcepoolmodel.BlockStorageUseageQueryDoc).
		// Param(ws.PathParameter("name", "实例名称").DataType("string").Required(false)).
		// Param(ws.BodyParameter("region", "区域;默认值：all").DataType("string").Required(false).DefaultValue("all")).
		// Param(ws.BodyParameter("az", "可用区;默认值：all").DataType("string").Required(false).DefaultValue("all")).
		// Param(ws.BodyParameter("storageType", "存储类型,eg:ssd3.0/ssd2.0/ehdd").Required(false)).
		// Param(ws.QueryParameter("pageNo", "eg:1,页码，默认值1。").DataType("int32").Required(true).DefaultValue("1")).
		// Param(ws.QueryParameter("pageSize", "eg:10, 页大小，默认值10。").DataType("int32").Required(true).DefaultValue("10")).
		// Param(ws.QueryParameter("orderCode", "The orderCode of order.eg:capacityUsedRate").Required(false)).
		// Param(ws.QueryParameter("orderType", "The orderType of order.eg:升：asc;降：desc").Required(false)).
		Returns(http.StatusOK, "ok", resourcepoolmodel.BlockStoragesUseageResult{}))
	ws.Route(ws.GET("/{id}/hosts").To(aggragate.GetPoolServerListHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag2).
		Doc("list all aggregates").
		Param(ws.QueryParameter("pageNo", "eg:1,页码，默认值1。").DataType("int32").Required(false).DefaultValue("1")).
		Param(ws.QueryParameter("pageSize", "eg:10, 页大小，默认值10。").DataType("int32").Required(false).DefaultValue("10")).
		Param(ws.PathParameter("id", "pool id")).
		Returns(http.StatusOK, "ok", resourcepoolmodel.AggregateMonitorSuccess{}))
	// ws.Route(ws.POST("/storage/monitorMetrics").To(blockstorage.StorageMonitorTargetHandler).
	// 	Metadata(restfulspec.KeyOpenAPITags, tag2).
	// 	Doc("get monitor metrics line/").
	// 	//Param(ws.QueryParameter("query", "The monitor metric query eg:块存储资源池总量：CapTotal;资源池用量趋势：CapRate;IO读取：DiskIoReadsCompletedTota;IO写：DiskIoWritesCompletedTotal;IO读延迟：DiskIoReadtimeTotal;IO写延迟：DiskIoWritetimeTotal")).
	// 	Param(ws.BodyParameter("list", "The list of query string IO读取：DiskIoReadsCompletedTotal;IO写：DiskIoWritesCompletedTotal;IO读延迟：DiskIoReadtimeTotal;IO写延迟：DiskIoWritetimeTotal").Required(true).DataType("array")).
	// 	Param(ws.QueryParameter("start", "The start time of range query")).
	// 	Param(ws.QueryParameter("end", "The end time of range query")).
	// 	Param(ws.QueryParameter("step", "The step time of range query")).
	// 	Param(ws.QueryParameter("region", "区域;默认值：全部").DataType("string").Required(false).DefaultValue("all")).
	// 	Param(ws.QueryParameter("name", "实例名称").DataType("string").Required(false)).
	// 	Returns(http.StatusOK, "ok", resourcepoolmodel.StorageLineDataSuccess{}))
	ws.Route(ws.GET("/{id}/query").To(s.BlockPoolMetricHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag2).
		Doc("metric of block pool").
		Param(ws.PathParameter("id", "The id of pool").Required(false)).
		//Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		//Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		//Param(ws.BodyParameter("storageType", "存储类型,eg:standard:标准存储/archive:归档存储/standard_ia:低频存储").Required(false)).
		Returns(http.StatusOK, "OK", resourcepoolmodel.BlockPoolMetricResponse{}))
	// ws.Route(ws.POST("/storage/storagePoolMonitor").To(blockstorage.StoragePoolMonitorTargetHandler).
	// 	Metadata(restfulspec.KeyOpenAPITags, tag2).
	// 	Doc("get storage monitor metrics line/").
	// 	//Param(ws.QueryParameter("query", "The monitor metric query eg:块存储资源池总量：CapTotal;资源池用量趋势：CapRate;IO读取：DiskIoReadsCompletedTota;IO写：DiskIoWritesCompletedTotal;IO读延迟：DiskIoReadtimeTotal;IO写延迟：DiskIoWritetimeTotal")).
	// 	Param(ws.BodyParameter("list", "The list of query string eg:块存储资源池总量：CapTotal;资源池用量趋势：CapRate").Required(true).DataType("array")).
	// 	Param(ws.QueryParameter("start", "The start time of range query")).
	// 	Param(ws.QueryParameter("end", "The end time of range query")).
	// 	Param(ws.QueryParameter("step", "The step time of range query")).
	// 	Param(ws.QueryParameter("region", "区域;默认值：全部").DataType("string").Required(false).DefaultValue("all")).
	// 	Param(ws.QueryParameter("name", "实例名称").DataType("string").Required(false)).
	// 	Returns(http.StatusOK, "ok", resourcepoolmodel.StorageLineDataSuccess{}))
	//todo swtich cpu usage rate (begin end step)

	return ws
}

func (s *BlockPoolApiHandler) Overview(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(resourcepoolmodel.BlockPoolOverviewQuery)
	request.ReadEntity(t)
	blockResult, err := s.BlockPoolService.GetBlockPoolOverview(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = blockResult
		response.WriteAsJson(rst)
		return
	}
}
func (s *BlockPoolApiHandler) OverviewLine(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(resourcepoolmodel.OverviewLineQuery)
	request.ReadEntity(t)
	//do
	computerPool, err := s.BlockPoolService.GetBlockPoolOverviewLine(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = computerPool
		response.WriteAsJson(rst)
		return
	}
}

func (s *BlockPoolApiHandler) OverviewLineCharts(request *restful.Request, response *restful.Response) {
	klog.Info("block pool overview line")
	parameter := OverviewLineChartsParameter{}
	err := request.ReadEntity(&parameter)
	klog.Infof("para : %v", parameter)
	if err != nil {
		response.WriteAsJson(Result{
			Code:    500,
			Message: "can't read parameter from request",
		})
		return
	}
	if parameter.StartTime == 0 || parameter.EndTime == 0 {
		response.WriteAsJson(Result{
			Code:    500,
			Message: "start and end can't be empty",
		})
		return
	}
	switch strings.ToUpper(parameter.StorageType) {
	case ST_SSD3, ST_SSD2, ST_EHDD:
	default:
		response.WriteAsJson(Result{
			Code:    500,
			Message: "invalid storage type",
		})
		return
	}
	parameter.StorageType = strings.ToLower(parameter.StorageType)
	totalCharts := make(map[string][]ChartData)
	var queryFun func(OverviewLineChartsParameter) ([]ChartData, error)
	for _, name := range parameter.ChartNames {
		switch name {
		case "stockCapacity":
			queryFun = queryStorageCapacityChart
		case "total":
			queryFun = queryTotalCloudDiskCountChart
		case "unMount":
			queryFun = queryUnmountCloudDiskPercentChart
		case "ioNum":
			queryFun = queryIoQpsChart
		case "ioDelay":
			queryFun = queryIoLatencyChart
		case "band":
			queryFun = queryBwQpsChart
		case "health":
			queryFun = queryHealthChart
		default:
			continue
		}
		chartData, err := queryFun(parameter)
		if err != nil {
			response.WriteAsJson(Result{
				Code:    500,
				Message: fmt.Sprintf("query %s chart failed", name),
			})
			return
		}
		totalCharts[name] = chartData
	}
	response.WriteAsJson(Result{
		Code:    200,
		Message: "success",
		Data:    totalCharts,
	})
}

// 云资源监控/资源池监控/块存储-列表页
func (s *BlockPoolApiHandler) ListBlockStorageHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(resourcepoolmodel.BlockStorageSuccess)
	t := new(resourcepoolmodel.BlockPoolListQuery)
	request.ReadEntity(t)
	if t.SearchKey != "" && t.SearchValue != "" {
		switch t.SearchKey {
		case "name":
			t.Name = t.SearchValue
		}
	}
	if t.PageNo == 0 {
		rst.Code = 500
		rst.Message = "pageNo false"
		response.WriteAsJson(rst)
		return
	}

	if t.PageSize == 0 {
		rst.Code = 500
		rst.Message = "pageSize false"
		response.WriteAsJson(rst)
		return
	}

	BlockStorageDataResult, err := s.BlockPoolService.GetBlockPoolList(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = BlockStorageDataResult
		response.WriteAsJson(rst)
		return
	}

}

// 获取资源池管理-库存list
func (s *BlockPoolApiHandler) ListBlockStorageUsageHandler(request *restful.Request, response *restful.Response) {

	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	var blockStoragesResult resourcepoolmodel.BlockStoragesUseageResult
	t := new(resourcepoolmodel.BlockStorageUseageQuery)
	err := request.ReadEntity(&t)
	if t.Region == "" {
		t.Region = "all"
	}
	BlockStorageDataResult, err := s.BlockPoolService.GetBlockPoolUsageList(*t)
	klog.Infof("getstock6 %+v, %+v", BlockStorageDataResult, err)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		rst.Data = blockStoragesResult
		err = response.WriteAsJson(rst)
		klog.Infof("getstock7 %+v, %+v", response, err)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = BlockStorageDataResult
		err = response.WriteAsJson(rst)
		klog.Infof("getstock8 %+v, %+v", response, err)
		return
	}
}

func (s *BlockPoolApiHandler) BlockPoolMetricHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	id := request.PathParameter("id")

	if id == "" {
		rst.Code = 500
		rst.Message = "id false"
		response.WriteAsJson(rst)
		return
	}

	responseMetric := s.BlockPoolService.GetBlockPoolMetric(id)

	rst.Code = 200
	rst.Message = "success"
	rst.Data = responseMetric
	response.WriteAsJson(rst)
	return

}

// 云资源监控/资源池监控/详情页-监控指标 针对prometheus原有的指标
func StorageMonitorTargetHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(resourcepoolmodel.StorageMonitorTargetQuery)

	name := request.QueryParameter("name")
	if name == "" {
		rst.Code = 500
		rst.Message = "name false"
		response.WriteAsJson(rst)
		return
	}
	t.Name = name
	region := request.QueryParameter("region")
	if region == "" {
		rst.Code = 500
		rst.Message = "region false"
		response.WriteAsJson(rst)
		return
	}
	t.Region = region
	t.Start = request.QueryParameter("start")
	t.End = request.QueryParameter("end")
	t.Step = request.QueryParameter("step")
	tQ := new(resourcepoolmodel.QueryList)

	request.ReadEntity(tQ)
	if len(tQ.List) < 1 {
		rst.Code = 500
		rst.Message = "list is must"
		response.WriteAsJson(rst)
		return
	}
	t.List = tQ.List
	//request.ReadEntity(t)

	responseMetric := resourcepoolservice.GetMonitorTargetLineListForStorage(*t)

	rst.Code = 200
	rst.Message = "success"
	rst.Data = responseMetric
	response.WriteAsJson(rst)
	return

}

// 云资源监控/资源池监控/详情页-监控指标 针对新上报的存储
func StoragePoolMonitorTargetHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(resourcepoolmodel.StorageMonitorTargetQuery)

	name := request.QueryParameter("name")
	if name == "" {
		rst.Code = 500
		rst.Message = "name false"
		response.WriteAsJson(rst)
		return
	}
	t.Name = name
	region := request.QueryParameter("region")
	if region == "" {
		rst.Code = 500
		rst.Message = "region false"
		response.WriteAsJson(rst)
		return
	}
	t.Region = region
	t.Az = request.QueryParameter("az")
	if t.Az == "" {
		t.Az = "cn-shanghai-2a"
	}
	t.Start = request.QueryParameter("start")
	t.End = request.QueryParameter("end")
	t.Step = request.QueryParameter("step")
	//request.ReadEntity(t)
	tQ := new(resourcepoolmodel.QueryList)

	request.ReadEntity(tQ)
	if len(tQ.List) < 1 {
		rst.Code = 500
		rst.Message = "list is must"
		response.WriteAsJson(rst)
		return
	}
	t.List = tQ.List
	//request.ReadEntity(t)

	responseMetric := resourcepoolservice.GetStoragePoolMonitorTargetLineList(*t)

	rst.Code = 200
	rst.Message = "success"
	rst.Data = responseMetric
	response.WriteAsJson(rst)
	return

}

// pool server list
func GetPoolServerListHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(ListQuery)
	pageNo := request.QueryParameter("pageNo")
	if pageNo == "" {
		rst.Code = 500
		rst.Message = "pageNo false"
		response.WriteAsJson(rst)
		return
	}
	pageSize := request.QueryParameter("pageSize")
	if pageSize == "" {
		rst.Code = 500
		rst.Message = "pageSize false"
		response.WriteAsJson(rst)
		return
	}
	//region := request.QueryParameter("region")
	//if region == "" || region == "all" {
	//	region = "all"
	//}
	//
	//az := request.QueryParameter("az")
	//if az == "" {
	//	az = "all"
	//}

	t.PageNo = pageNo
	t.PageSize = pageSize
	//t.Count = count
	//t.Region = region
	//t.Az = az
	t.Id = request.PathParameter("id")
	//t.TenantId = request.QueryParameter("tenantId")
	//t.InnerIp = request.QueryParameter("innerIp")
	//t.OuterIp = request.QueryParameter("outerIp")
	//t.PhysicalHost = request.QueryParameter("physicalHost")
	//t.Pool = request.QueryParameter("pool")
	//t.State = request.QueryParameter("state")

	ms, err := GetComputerPoolServerList(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = ms
		response.WriteAsJson(rst)
		return
	}

}

func GetComputerPoolServerList(l *ListQuery) (MonitorHosts, error) {
	ms := MonitorHosts{}
	//cs := CmdbVms{}
	//cmdb := CMDBResult{}

	cmdb, err := cmdbmanager.GetHostListByResourcePool(l.Id)

	if err != nil {
		fmt.Println("err" + err.Error())
		return ms, err
	}

	for i := 0; i < len(cmdb.Data.DataList); i++ {

		j := cmdb.Data.DataList[i]

		q := fmt.Sprintf(`{
		host(func:has(sn)) @filter(eq(sn, %s)) {
		  sn
		  ip
		  label
		}}`, j.SN)
		resp, er := dgraphmanager.NewDgraphClient().NewTxn().Query(context.Background(), q)
		if er != nil {
			return ms, er
		}
		var se DgraphCount
		e := json.Unmarshal(resp.Json, &se)
		if e != nil {
			return ms, e
		}

		m := MonitorHost{
			Id:           j.Id,
			Name:         j.Name,
			State:        j.Status,
			ResourcePool: j.ResourcePool,
			Region:       j.Region,
			Az:           j.Az,
			SN:           j.SN,
			Ip:           se.Host[0].Ip,
			Lable:        se.Host[0].Label,
		}

		state, _ := prometheusmanager.GetStateByIp(se.Host[i].Ip)
		m.State = state

		c, _ := prometheusmanager.PrometheusQuery2(false, "", "", "", `1-avg(irate(node_cpu_seconds_total{mode="idle",instance="`+se.Host[i].Ip+`:9100"`+`}[5m]))`)
		m.CpuUesd = prometheusmanager.PrometheusResultToValue2(c)

		mem, _ := prometheusmanager.PrometheusQuery2(false, "", "", "", `1-node_memory_MemAvailable_bytes{instance=~"`+se.Host[i].Ip+`:9100"`+`}/node_memory_MemTotal_bytes{instance=~"`+se.Host[i].Ip+`:9100"`+`}`)
		m.MemUsed = prometheusmanager.PrometheusResultToValue2(mem)

		alerts, _ := alertmanager.GetAlertsByFilter(se.Host[i].Ip + ":9100")
		m.AlertNumber = len(alerts)
		ms.DataList = append(ms.DataList, m)
	}

	ms.PageNo = cmdb.Data.PageNo
	ms.PageSize = cmdb.Data.PageSize
	ms.TotalCount = cmdb.Data.TotalCount

	return ms, nil
}

// 资源池管理/块存储资源池/概览
func GetCMDBBlockStorageOverViewHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(resourcepoolmodel.CMDBOverViewQuery)

	region := request.QueryParameter("region")
	if region == "" || region == "all" {
		region = "all"
	}
	az := request.QueryParameter("az")
	if az == "" || az == "all" {
		az = "all"
	}

	//t.Count = count
	t.Region = region
	t.Az = az
	//request.ReadEntity(t)

	responseMetric, err := resourcepoolservice.GetBlockStorageOverView(*t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = responseMetric
		response.WriteAsJson(rst)
		return
	}

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/resourcepool/blockstorage/result.go
```golang
package blockstorage

//overview
type OverViewSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverView struct {
	StorageType  string      `json:"storageType"`
	ResourcePool string      `json:"resourcePool"`
	Region       string      `json:"region"`
	Az           string      `json:"az"`
	Lab          string      `json:"lab"`
	Alerts       AlertLevels `json:"alerts"`
	Echarts      []Chart     `json:"echarts"`
	//State  RegionCurrentStates `json:"state"`
	//AllTopK       []prometheusmanager.RateTopResult
}
type AlertLevels struct {
	P0 int `json:"p0"`
	P1 int `json:"p1"`
	P2 int `json:"p2"`
	P3 int `json:"p3"`
}

type Chart struct {
	Info   OverInfo    `json:"info"`
	Values []ValueType `json:"values"`
}
type OverInfo struct {
	Region       string `json:"region"`
	Az           string `json:"az"`
	StorageType  string `json:"storageType"`
	ResourcePool string `json:"resourcePool"`
	Name         string `json:"name"`
	SubName      string `json:"subName"`
	Total        string `json:"total"`
}

//type RegionCurrentStates struct {
//	Region               string `json:"region"`
//	PhysicalRunningCount int    `json:"physicalRunningCount"`
//	PhysicalErrorCount   int    `json:"physicalErrorCount"`
//}

//OverviewLine
type OverViewLineSuccess struct {
	Code    int          `json:"code"`
	Message string       `json:"message"`
	Data    OverViewLine `json:"data"`
}

type OverViewLine struct {
	Region string `json:"region"`
	Az     string `json:"az"`
	Lab    string `json:"lab"`
	//Alert  AlertLevels `json:"alert"`
	Echarts []EchartType `json:"echarts"`
}

type EchartType struct {
	Info   InfoType    `json:"info"`
	Values []ValueType `json:"values"`
}

type ValueType struct {
	Value     string `json:"value"`
	Name      string `json:"name"`
	Timestamp string `json:"timestamp"`
}

type InfoType struct {
	Region       string `json:"region"`
	Az           string `json:"az"`
	Lab          string `json:"lab"`
	Name         string `json:"name"`
	SubName      string `json:"subName"`
	StorageType  string `json:"storageType"`
	ResourcePool string `json:"resourcePool"`
	Total        string `json:"total"`
	TopK         int    `json:"topk"`
	Start        string `json:"start"`
	End          string `json:"end"`
}

//other
type Result struct {
	Code    int         `json:"code"`
	Message string      `json:"messgae"`
	Data    interface{} `json:"data"`
}

type ListQuery struct {
	PageNo   string `json:"pageNo"`
	PageSize string `json:"pageSize"`
	Id       string `json:"id"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

type MonitorHosts struct {
	PageStruct
	DataList []MonitorHost `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type MonitorHost struct {
	Id               string      `json:"id"`
	Name             string      `json:"name"`
	AssignmentStatus string      `json:"assignmentStatus"`
	ResourcePoolType string      `json:"resourcePoolType"`
	ResourcePool     string      `json:"resourcePool"`
	Region           string      `json:"region"`
	Az               string      `json:"az"`
	SN               string      `json:"sn"`
	Ip               string      `json:"ip"`
	State            string      `json:"state"`
	CpuUesd          interface{} `json:"cpuUesd"`
	MemUsed          interface{} `json:"memUsed"`
	AlertNumber      int         `json:"alertNumber"`
	Lable            string      `json:"lable"`
}

type DgraphCount struct {
	Host []HostCount `json:"host"`
}

type HostCount struct {
	Count          int    `json:"count"`
	Label          string `json:"label"`
	Ip             string `json:"ip"`
	HostName       string `json:"hostname"`
	HostRegionName string `json:"hostRegionName"`
	HostLabName    string `json:"hostLabName"`
	HostAzName     string `json:"hostAzName"`
	Sn             string `json:"sn"`
	RunStatus      string `json:"runstatus"`
	Os             string `json:"system"`
	ServiceType    string `json:"serviceType"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/resourcepool/blockstorage/newhandler.go
```golang
package blockstorage

import (
	"fmt"
	"sort"
	"strconv"
	"strings"
	"time"

	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	"k8s.io/klog/v2"
)

const (
	ST_SSD3 = "SSD3.0"
	ST_SSD2 = "SSD2.0"
	ST_EHDD = "EHDD"

	UNIT_TYPE_NUMBER  = "number"
	UNIT_TYPE_PERCENT = "percent"
	UNIT_TYPE_STORAGE = "storage"
)

type ChartInfoType struct {
	Name  string      `json:"name"`
	Value interface{} `json:"value"`
	Unit  string      `json:"unit"`
	//storage:存储的、percent:百分比的、number:数值的
	UnitType string `json:"unitType"`
}

type ChartValueItem struct {
	Value interface{} `json:"value"`
	Name  interface{} `json:"name"`
	Unit  string      `json:"unit"`
	//storage:存储的、percent:百分比的、number:数值的
	UnitType string `json:"unitType"`
}

type ChartData struct {
	Info   ChartInfoType    `json:"info"`
	Values []ChartValueItem `json:"values"`
}

type OverviewParameter struct {
	AzCode      string `json:"az"`
	RegionCode  string `json:"region"`
	StorageType string `json:"diskType"`
	PoolName    string `json:"pool"`
}

type OverviewLineChartsParameter struct {
	OverviewParameter
	ChartNames []string `json:"name"`
	StartTime  int64    `json:"start"`
	EndTime    int64    `json:"end"`
}

type OverviewLineChartsResponse struct {
	Code    int                    `json:"code"`
	Message string                 `json:"message"`
	Data    map[string][]ChartData `json:"data"`
}

type PromValueItem struct {
	Timestamp float64
	Value     string
}

type TimeValuePair struct {
	Timestamp float64
	Value     interface{}
}

type PromResult struct {
	Metric map[string]interface{}
	Values []PromValueItem
}

func resolveProResult(resultValues []interface{}) ([]PromResult, error) {
	var data []PromResult
	for _, item := range resultValues {
		itemMap := item.(map[string]interface{})
		v := PromResult{
			Metric: itemMap["metric"].(map[string]interface{}),
		}
		for _, vItem := range itemMap["values"].([]interface{}) {
			vPair := vItem.([]interface{})
			v.Values = append(v.Values, PromValueItem{
				Timestamp: vPair[0].(float64),
				Value:     vPair[1].(string),
			})
		}
		data = append(data, v)
	}
	return data, nil
}

func queryRangeData(query string, startTime time.Time, endTime time.Time) ([]PromResult, error) {
	return queryRangeDataFromProm(query, startTime, endTime, services.CalculatePromStep(startTime, endTime))
}

func queryRangeDataFromProm(query string, startTime time.Time, endTime time.Time, step string) ([]PromResult, error) {
	res, err := prometheusmanager.PrometheusQuery(true,
		strconv.FormatInt(startTime.Unix(), 10),
		strconv.FormatInt(endTime.Unix(), 10),
		step,
		query)
	if err != nil {
		return nil, fmt.Errorf("query prometheus failed")
	}
	if res == nil {
		return nil, nil
	}
	arr := res.(map[string]interface{})["result"].([]interface{})
	return resolveProResult(arr)
}

func combinePromResultByTime(arrData []PromResult,
	valueConverter func(string) (interface{}, error),
	combFunc func(v1 interface{}, v2 interface{}) (interface{}, error)) []TimeValuePair {
	var arr []TimeValuePair
	storeMap := make(map[float64]interface{})
	for _, item := range arrData {
		for _, vItem := range item.Values {
			t := vItem.Timestamp
			newValue, err := valueConverter(vItem.Value)
			if err != nil {
				continue
			}
			if _, ok := storeMap[t]; !ok {
				storeMap[t] = newValue
			} else {
				combValue, err := combFunc(storeMap[t], newValue)
				if err != nil {
					continue
				}
				storeMap[t] = combValue
			}
		}
	}
	for k, v := range storeMap {
		arr = append(arr, TimeValuePair{
			Timestamp: k,
			Value:     v,
		})
	}
	sort.Slice(arr, func(i, j int) bool {
		return arr[i].Timestamp < arr[j].Timestamp
	})
	return arr
}

func OverviewLineCharts(request *restful.Request, response *restful.Response) {
	klog.Info("block pool overview line")
	parameter := OverviewLineChartsParameter{}
	err := request.ReadEntity(&parameter)
	klog.Infof("para : %v", parameter)
	if err != nil {
		response.WriteAsJson(Result{
			Code:    500,
			Message: "can't read parameter from request",
		})
		return
	}
	if parameter.StartTime == 0 || parameter.EndTime == 0 {
		response.WriteAsJson(Result{
			Code:    500,
			Message: "start and end can't be empty",
		})
		return
	}
	switch strings.ToUpper(parameter.StorageType) {
	case ST_SSD3, ST_SSD2, ST_EHDD:
	default:
		response.WriteAsJson(Result{
			Code:    500,
			Message: "invalid storage type",
		})
		return
	}
	parameter.StorageType = strings.ToLower(parameter.StorageType)
	totalCharts := make(map[string][]ChartData)
	var queryFun func(OverviewLineChartsParameter) ([]ChartData, error)
	for _, name := range parameter.ChartNames {
		switch name {
		case "stockCapacity":
			queryFun = queryStorageCapacityChart
		case "total":
			queryFun = queryTotalCloudDiskCountChart
		case "unMount":
			queryFun = queryUnmountCloudDiskPercentChart
		case "ioNum":
			queryFun = queryIoQpsChart
		case "ioDelay":
			queryFun = queryIoLatencyChart
		case "band":
			queryFun = queryBwQpsChart
		case "health":
			queryFun = queryHealthChart
		default:
			continue
		}
		chartData, err := queryFun(parameter)
		if err != nil {
			response.WriteAsJson(Result{
				Code:    500,
				Message: fmt.Sprintf("query %s chart failed", name),
			})
			return
		}
		totalCharts[name] = chartData
	}
	response.WriteAsJson(Result{
		Code:    200,
		Message: "success",
		Data:    totalCharts,
	})
}

func buildCommonCondition(parameter OverviewLineChartsParameter, extConditions ...string) string {
	var conditions []string
	if len(extConditions) > 0 {
		conditions = append(conditions, extConditions...)
	}
	if parameter.AzCode != "" && parameter.AzCode != "all" {
		conditions = append(conditions, "az=\""+parameter.AzCode+"\"")
	}
	if parameter.RegionCode != "" && parameter.RegionCode != "all" {
		conditions = append(conditions, "region=\""+parameter.RegionCode+"\"")
	}
	if parameter.PoolName != "" && parameter.PoolName != "all" {
		conditions = append(conditions, "resourcePoolName=\""+parameter.PoolName+"\"")
	}
	if parameter.StorageType != "" {
		conditions = append(conditions, "resourcePool=\""+parameter.StorageType+"\"")
	}
	var conditionStr string
	if len(conditions) > 0 {
		conditionStr = strings.Join(conditions, ",")
	}
	return conditionStr
}

func queryRangeTimeLineChartDataWithTimeInt(query string, startTime time.Time, endTime time.Time) ([]ChartValueItem, error) {
	return queryRangeTimeLineChartDataWithTime(query, startTime, endTime, func(value string) (interface{}, error) {
		return strconv.ParseInt(value, 10, 64)
	}, func(v1 interface{}, v2 interface{}) (interface{}, error) {
		return v1.(int64) + v2.(int64), nil
	})
}

func queryRangeTimeLineChartDataWithTimeFloat(query string, startTime time.Time, endTime time.Time) ([]ChartValueItem, error) {
	return queryRangeTimeLineChartDataWithTime(query, startTime, endTime, func(value string) (interface{}, error) {
		return strconv.ParseFloat(value, 64)
	}, func(v1 interface{}, v2 interface{}) (interface{}, error) {
		return v1.(float64) + v2.(float64), nil
	})
}

func queryRangeTimeLineChartDataWithTime(
	query string,
	startTime time.Time,
	endTime time.Time,
	valueConverter func(string) (interface{}, error),
	combFunc func(v1 interface{}, v2 interface{}) (interface{}, error)) ([]ChartValueItem, error) {
	res, err := queryRangeData(query, startTime, endTime)
	if err != nil {
		return nil, fmt.Errorf("query prom failed")
	}
	var lineValues []ChartValueItem
	for _, item := range combinePromResultByTime(res, valueConverter, combFunc) {
		lineValues = append(lineValues, ChartValueItem{
			Name:  int64(float64(item.Timestamp) * 1000),
			Value: item.Value,
		})
	}
	if lineValues == nil {
		lineValues = []ChartValueItem{}
	}
	return lineValues, nil
}

func queryCommonFloatValueChart(collectType string, parameter OverviewLineChartsParameter) (*ChartData, error) {
	query := `%s{%s}`
	condition := buildCommonCondition(parameter)
	query = fmt.Sprintf(query, collectType, condition)
	start := time.Unix(parameter.StartTime/1000, 0)
	end := time.Unix(parameter.EndTime/1000, 0)
	values, err := queryRangeTimeLineChartDataWithTimeFloat(query, start, end)
	if err != nil {
		return nil, err
	}
	return &ChartData{
		Values: values,
		Info: ChartInfoType{
			Name:     "",
			Value:    "",
			Unit:     "",
			UnitType: UNIT_TYPE_NUMBER,
		},
	}, nil
}

func queryCommonIntValueChart(collectType string, parameter OverviewLineChartsParameter) (*ChartData, error) {
	query := `%s{%s}`
	condition := buildCommonCondition(parameter)
	query = fmt.Sprintf(query, collectType, condition)
	start := time.Unix(parameter.StartTime/1000, 0)
	end := time.Unix(parameter.EndTime/1000, 0)
	values, err := queryRangeTimeLineChartDataWithTimeInt(query, start, end)
	if err != nil {
		return nil, err
	}
	return &ChartData{
		Values: values,
		Info: ChartInfoType{
			Name:     "",
			Value:    "",
			Unit:     "",
			UnitType: UNIT_TYPE_NUMBER,
		},
	}, nil
}

func queryHealthChart(parameter OverviewLineChartsParameter) ([]ChartData, error) {
	return []ChartData{
		{
			Info: ChartInfoType{
				Name:     "云硬盘健康状态",
				Value:    "",
				Unit:     "%",
				UnitType: UNIT_TYPE_PERCENT,
			},
			Values: []ChartValueItem{},
		},
	}, nil
}

func queryStorageCapacityChart(parameter OverviewLineChartsParameter) ([]ChartData, error) {
	query := "1024*1024*1024*(storage_resource_pool_total{%v}-storage_resource_pool_usage{%v})"

	start := time.Unix(parameter.StartTime/1000, 0)
	end := time.Unix(parameter.EndTime/1000, 0)
	//parameter.StorageType = ""
	conditionStr := buildCommonCondition(parameter)
	//conditionStr := "resourcePool=\"" + parameter.StorageType + "\""
	query = fmt.Sprintf(query, conditionStr, conditionStr)
	values, err := queryRangeTimeLineChartDataWithTimeInt(query, start, end)
	if err != nil {
		return nil, err
	}

	return []ChartData{
		{
			Values: values,
			Info: ChartInfoType{
				Name:     "存储容量库存",
				Value:    "",
				Unit:     "Byte",
				UnitType: UNIT_TYPE_STORAGE,
			},
		},
	}, nil
}

func queryTotalCloudDiskCountChart(parameter OverviewLineChartsParameter) ([]ChartData, error) {
	chart, err := queryCommonIntValueChart("cloud_disk_count", parameter)
	if err != nil {
		return nil, err
	}
	chart.Info.Name = "块存储总数"
	chart.Info.Unit = "个"
	return []ChartData{
		*chart,
	}, nil
}

func queryUnmountCloudDiskPercentChart(parameter OverviewLineChartsParameter) ([]ChartData, error) {
	query := `sum(cloud_disk_count{%s})/sum(cloud_disk_count{%s})`
	condition := buildCommonCondition(parameter)
	availableCondition := "status=\"available\""
	if condition != "" {
		availableCondition = availableCondition + "," + condition
	}
	query = fmt.Sprintf(query, availableCondition, condition)
	start := time.Unix(parameter.StartTime/1000, 0)
	end := time.Unix(parameter.EndTime/1000, 0)
	values, err := queryRangeTimeLineChartDataWithTimeFloat(query, start, end)
	if err != nil {
		return nil, err
	}
	return []ChartData{
		{
			Values: values,
			Info: ChartInfoType{
				Name:     "待挂载块存储占比",
				Value:    "",
				Unit:     "%",
				UnitType: UNIT_TYPE_PERCENT,
			},
		},
	}, nil
}

func queryIoQpsChart(parameter OverviewLineChartsParameter) ([]ChartData, error) {
	readChart, err := queryCommonFloatValueChart("xuanwu_read_qps", parameter)
	if err != nil {
		return nil, err
	}
	//readChart.Info.Name = "IO读吞吐"
	readChart.Info.Name = "读"
	readChart.Info.Unit = "次/秒"
	writeChart, err := queryCommonFloatValueChart("xuanwu_write_qps", parameter)
	if err != nil {
		return nil, err
	}
	writeChart.Info.Name = "写"
	writeChart.Info.Unit = "次/秒"

	if len(readChart.Values) == 0 {
		readChart.Values = mockChartData(parameter.StartTime, parameter.EndTime)
	}
	if len(writeChart.Values) == 0 {
		writeChart.Values = mockChartData(parameter.StartTime, parameter.EndTime)
	}

	return []ChartData{
		*readChart,
		*writeChart,
	}, nil
}

func queryIoLatencyChart(parameter OverviewLineChartsParameter) ([]ChartData, error) {
	readChart, err := queryCommonFloatValueChart("xuanwu_read_avg_latency", parameter)
	if err != nil {
		return nil, err
	}
	readChart.Info.Name = "读延时"
	readChart.Info.Unit = "毫秒"
	for i, item := range readChart.Values {
		floatValue := item.Value.(float64)
		if floatValue > 0 {
			readChart.Values[i].Value = floatValue / 1000
		}
	}
	writeChart, err := queryCommonFloatValueChart("xuanwu_write_avg_latency", parameter)
	if err != nil {
		return nil, err
	}
	for i, item := range writeChart.Values {
		floatValue := item.Value.(float64)
		if floatValue > 0 {
			writeChart.Values[i].Value = floatValue / 1000
		}
	}
	writeChart.Info.Name = "写延时"
	writeChart.Info.Unit = "毫秒"

	if len(readChart.Values) == 0 {
		readChart.Values = mockChartData(parameter.StartTime, parameter.EndTime)
	}
	if len(writeChart.Values) == 0 {
		writeChart.Values = mockChartData(parameter.StartTime, parameter.EndTime)
	}

	return []ChartData{
		*readChart,
		*writeChart,
	}, nil
}

func queryBwQpsChart(parameter OverviewLineChartsParameter) ([]ChartData, error) {
	readChart, err := queryCommonFloatValueChart("xuanwu_read_bw", parameter)
	if err != nil {
		return nil, err
	}
	readChart.Info.Name = "读带宽"
	readChart.Info.Unit = "Mb/s"
	for i, item := range readChart.Values {
		floatValue := item.Value.(float64)
		if floatValue > 0 {
			readChart.Values[i].Value = floatValue / 1024 / 1024
		}
	}
	writeChart, err := queryCommonFloatValueChart("xuanwu_write_bw", parameter)
	if err != nil {
		return nil, err
	}
	writeChart.Info.Name = "写带宽"
	writeChart.Info.Unit = "Mb/s"
	for i, item := range writeChart.Values {
		floatValue := item.Value.(float64)
		if floatValue > 0 {
			writeChart.Values[i].Value = floatValue / 1024 / 1024
		}
	}

	if len(readChart.Values) == 0 {
		readChart.Values = mockChartData(parameter.StartTime, parameter.EndTime)
	}
	if len(writeChart.Values) == 0 {
		writeChart.Values = mockChartData(parameter.StartTime, parameter.EndTime)
	}

	return []ChartData{
		*readChart,
		*writeChart,
	}, nil
}

func mockChartData(startTime, endTime int64) []ChartValueItem {
	values := make([]ChartValueItem, 0)
	start := time.Unix(startTime/1000, 0)
	end := time.Unix(endTime/1000, 0)
	h := end.Sub(start).Hours()
	step := int64(24 * 3600 * 1000)
	if h <= 24*2 {
		step = 60 * 1000
	} else if h <= 24*7 {
		step = 3600 * 1000
	}
	for ; startTime < endTime; startTime += step {
		values = append(values, ChartValueItem{
			Value: 0,
			Name:  startTime,
		})
	}
	return values
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/resourcepool/network/handler.go
```golang
package network

import (
	"github.com/asaskevich/govalidator"
	"net/http"

	restfulspec "github.com/emicklei/go-restful-openapi"
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	resourcepoolservice "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/resourcepool"
	"k8s.io/klog/v2"
)

type NetworkApiHandler struct {
	NetworkPoolService resourcepoolservice.INetworkPoolService
}

func BuildNetworkApiHandler() *NetworkApiHandler {
	networkPoolService := resourcepoolservice.NewNetworkPoolService()
	return &NetworkApiHandler{
		NetworkPoolService: networkPoolService,
	}
}

func (s *NetworkApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/network").
		Consumes(restful.MIME_JSON).
		Produces(restful.MIME_JSON)

	tag := []string{"Network Resource Pool Monitor"}
	ws.Route(ws.POST("/overview").To(s.Overview).Doc("网络资源池监控概览告警及服务器状态").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Returns(200, "OK", resourcepoolmodel.NetPoolOverViewSuccess{}))

	ws.Route(ws.POST("/overviewline").To(s.OverviewLine).Doc("网络资源池监控概览主要监控项").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("poolType", "poolType 资源池类型").Required(false).DataType("string")).
		Param(ws.BodyParameter("name", "line的监控项名称,eg:diskRate/cpuRate/memRate").Required(false).DataType("[]string")).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(200, "OK", resourcepoolmodel.NetOverviewLineSuccess{}))

	ws.Route(ws.POST("/networkList").To(s.NetworkList).Doc("网络资源池监控列表").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("indexType", "indexType LB：负载均衡，EIP：弹性IP，NAT：NAT，BM：裸金属，SL：专线").Required(true).DataType("string")).
		Param(ws.BodyParameter("poolType", "poolType 资源池类型").Required(false).DataType("[]string")).
		Param(ws.BodyParameter("poolName", "搜索资源池名称").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`createAt`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升 ascending;降 descending").Required(false)).
		Returns(200, "OK", resourcepoolmodel.NetworkListSuccess{}))

	ws.Route(ws.POST("/usage").To(s.NetworkUsage).Doc("网络资源池库存").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Returns(200, "OK", resourcepoolmodel.NetPoolUsageSuccess{}))

	ws.Route(ws.POST("/instanceList/lb").To(s.InstanceListLB).Doc("负载均衡实例列表").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("region", "区域编码 eg:`cn-shanghai-2`").DataType("string").Required(false)).
		Param(ws.BodyParameter("id", "资源池的id").Required(false)).
		Param(ws.BodyParameter("runState", "运行状态：up，down").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("tenantIdList", "租户id列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("tenantNameList", "租户名称列表").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("searchKey", "搜索的K.eg:`name`;`ip`;`sn`").Required(false)).
		Param(ws.BodyParameter("searchValue", "搜索的value. eg:`127.0.0.1`").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`cpuUsedPercent`;`memoryUsedPercent`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升 asc;降 desc").Required(false)).
		Returns(200, "OK", resourcepoolmodel.InstanceListSuccess{}))

	ws.Route(ws.POST("/networkDetail").To(s.NetworkDetail).Doc("网络资源池监控指标详情").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("poolName", "资源池名称").Required(true).DataType("string")).
		Param(ws.BodyParameter("poolType", "资源池类型").Required(true).DataType("string")).
		Param(ws.BodyParameter("region", "区域, 填 regionCode").Required(true).DataType("string")).
		Param(ws.BodyParameter("metricName", "监控项名称, eg: clusterConn/conn/pps/bps/cpuRate/memoryUsage/memoryRate/diskUsage/diskRate").Required(true).DataType("string")).
		Param(ws.BodyParameter("start", "开始时间戳").Required(true).DataType("int")).
		Param(ws.BodyParameter("end", "结束时间戳").Required(true).DataType("int")).
		Returns(200, "OK", resourcepoolmodel.NetworkDetailSuccess{}))

	ws.Route(ws.POST("/networkDetailSort").To(s.NetworkDetailSort).Doc("网络资源池节点监控指标详情排序").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("poolName", "资源池名称").Required(true).DataType("string")).
		Param(ws.BodyParameter("poolType", "资源池类型").Required(true).DataType("string")).
		Param(ws.BodyParameter("region", "区域, 填 regionCode").Required(true).DataType("string")).
		Param(ws.BodyParameter("hostname", "主机名称").Required(true).DataType("string")).
		Param(ws.BodyParameter("topK", "传正整数, 例: top5 传数字5").Required(true).DataType("int")).
		Param(ws.BodyParameter("metricName", "排序监控项名称, eg:\nXGW、KGW: slbConnsTopK/slbTrafficTopK/eipTrafficTopK\nNAT: natTrafficTopK\nTengine: tengineSlbConnsTopK/tengineSlbTrafficTopK\nSGW: sgwTrafficTopK/sgwDropPacketRateTopK").Required(true).DataType("string")).
		Param(ws.BodyParameter("start", "开始时间戳").Required(true).DataType("int")).
		Param(ws.BodyParameter("end", "结束时间戳").Required(true).DataType("int")).
		Returns(200, "OK", resourcepoolmodel.NetworkDetailSuccess{}))

	ws.Route(ws.POST("/networkTopLine").To(s.NetworkTopLine).Doc("网络资源池监控指标top折线图").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("poolName", "资源池名称").Required(true).DataType("string")).
		Param(ws.BodyParameter("poolType", "资源池类型").Required(true).DataType("string")).
		Param(ws.BodyParameter("region", "区域, 填 regionCode").Required(true).DataType("string")).
		Param(ws.BodyParameter("metricName", "监控项名称, eg: tgwLpeerBytesInTopK/tgwLpeerBytesOutTopK/tgwDcytesInTopK/tgwDcBytesOutTopK/tgwVpnBytesInTopK/tgwVpnBytesOutTopK").Required(true).DataType("string")).
		Param(ws.BodyParameter("topK", "传正整数, 例: top5 传数字5").Required(true).DataType("int")).
		Param(ws.BodyParameter("start", "开始时间戳").Required(true).DataType("int")).
		Param(ws.BodyParameter("end", "结束时间戳").Required(true).DataType("int")).
		Returns(200, "OK", resourcepoolmodel.NetworkDetailSuccess{}))

	return ws
}

//获取网络资源池监控概览
func (s *NetworkApiHandler) Overview(request *restful.Request, response *restful.Response) {
	klog.Infof("get network pool overview")
	param := &resourcepoolmodel.NetworkOverviewQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.NetworkPoolService.Overview(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

//获取网络资源池监控概览Line
func (s *NetworkApiHandler) OverviewLine(request *restful.Request, response *restful.Response) {
	klog.Infof("get network pool overview line")
	param := &resourcepoolmodel.NetworkOverviewLineQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.NetworkPoolService.OverviewLine(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

// 获取网络资源池监控列表
func (s *NetworkApiHandler) NetworkList(request *restful.Request, response *restful.Response) {
	klog.Infof("get network pool list")
	param := &resourcepoolmodel.NetworkListQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.NetworkPoolService.NetworkList(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

// 获取网络资源池库存
func (s *NetworkApiHandler) NetworkUsage(request *restful.Request, response *restful.Response) {
	klog.Infof("get network pool usage")
	param := &resourcepoolmodel.NetWorkUsageQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.NetworkPoolService.NetworkUsage(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

// 负载均衡实例列表
func (s *NetworkApiHandler) InstanceListLB(request *restful.Request, response *restful.Response) {
	klog.Infof("get network pool list")
	param := &resourcepoolmodel.NetworkListQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.NetworkPoolService.NetworkList(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

// 获取网络资源池监控指标详情
func (s *NetworkApiHandler) NetworkDetail(request *restful.Request, response *restful.Response) {
	klog.Infof("get network pool detail")
	param := &resourcepoolmodel.NetworkDetailQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.NetworkPoolService.NetworkMetricDetail(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

// 获取网络资源池监控指标详情排序
func (s *NetworkApiHandler) NetworkDetailSort(request *restful.Request, response *restful.Response) {
	klog.Infof("get network pool detail sort")
	param := &resourcepoolmodel.NetworkDetailQuery{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.NetworkPoolService.NetworkMetricDetailSort(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

// 获取网络资源池监控指标详情
func (s *NetworkApiHandler) NetworkTopLine(request *restful.Request, response *restful.Response) {
	klog.Infof("get network pool networkTopLine")
	param := &resourcepoolmodel.NetworkDetailQuery{}
	err :=request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	// 参数校验
	result, err := govalidator.ValidateStruct(param)
	if err != nil || result == false{
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.NetworkPoolService.NetworkMetricTopLine(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}
```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/resourcepool/aggragate/handler.go
```golang
package aggragate

import (
	"encoding/json"
	"fmt"
	"net/http"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/dgraphmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	"k8s.io/klog/v2"

	"context"
	"strconv"

	restfulspec "github.com/emicklei/go-restful-openapi"

	"github.com/emicklei/go-restful/v3"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	resourcepoolservice "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/resourcepool"
)

type ComputerPoolApiHandler struct {
	ComputerPoolService resourcepoolservice.IComputerPoolService
}

func BuildComputerPoolApiHandler() *ComputerPoolApiHandler {
	computerPoolService := resourcepoolservice.NewComputerPoolService()
	return &ComputerPoolApiHandler{
		ComputerPoolService: computerPoolService,
	}
}

func (s *ComputerPoolApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/computerPool").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)

	tag := []string{"computer pool"}
	ws.Route(ws.POST("/overview").To(s.Overview).Doc("Get overview of computer pool").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "Region of pool").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("pool", "资源池").Required(false)).
		Returns(200, "OK", resourcepoolmodel.OverViewSuccess{}))
	ws.Route(ws.POST("/overviewLine").To(s.OverviewLine).Doc("Get overview of computer pool topK").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "Region of physical server").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("pool", "资源池").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "The name of metric line,eg:cpuStock/memStock/cpuPercent/memPercent").Required(false)).
		//Param(ws.BodyParameter("subName","The subName of TopK").Required(false)).
		//Param(ws.BodyParameter("topK","The K of TopK").Required(false)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(200, "OK", resourcepoolmodel.OverViewLineSuccess{}))
	ws.Route(ws.POST("/list").To(s.ListAggregatesHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Doc("list all aggregates").
		Param(ws.BodyParameter("pageNo", "eg:1,页码，默认值1。").DataType("int32").Required(true).DefaultValue("1")).
		Param(ws.BodyParameter("pageSize", "eg:10, 页大小，默认值10。").DataType("int32").Required(true).DefaultValue("10")).
		Param(ws.BodyParameter("region", "区域;all").DataType("string").Required(false).DefaultValue("all")).
		Param(ws.BodyParameter("az", "可用区;默认值：all").DataType("[]string").Required(false).DefaultValue("all")).
		Param(ws.BodyParameter("searchKey", "搜索的key").DataType("string").Required(false)).
		Param(ws.BodyParameter("searchValue", "搜索的value").DataType("string").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:vcpuUtilizationRate;memUtilizationRate")).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升：asc;降：desc")).
		Returns(http.StatusOK, "ok", resourcepoolmodel.AggregateMonitorSuccess{}))
	// ws.Route(ws.GET("/computePool/{id}/hosts").To(s.GetPoolServerListHandler).
	// 	Metadata(restfulspec.KeyOpenAPITags, tag1).
	// 	Doc("list all aggregates").
	// 	Param(ws.QueryParameter("pageNo", "eg:1,页码，默认值1。").DataType("int32").Required(false).DefaultValue("1")).
	// 	Param(ws.QueryParameter("pageSize", "eg:10, 页大小，默认值10。").DataType("int32").Required(false).DefaultValue("10")).
	// 	Param(ws.PathParameter("id", "pool id")).
	// 	Returns(http.StatusOK, "ok", phy.Success{}))
	//ws.Route(ws.GET("/computePool/{id}/vms").To(aggragate.GetPoolVmListHandler).
	//	Metadata(restfulspec.KeyOpenAPITags, tag1).
	//	Doc("list all aggregates").
	//	Param(ws.QueryParameter("pageNo", "eg:1,页码，默认值1。").DataType("int32").Required(false).DefaultValue("1")).
	//	Param(ws.QueryParameter("pageSize", "eg:10, 页大小，默认值10。").DataType("int32").Required(false).DefaultValue("10")).
	//	Param(ws.PathParameter("id", "pool id")).
	//	Returns(http.StatusOK, "ok", resourcepoolmodel.AggregateMonitorsResult{}))
	ws.Route(ws.GET("/use").To(s.CpuUsedHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Doc("get cpu use").
		Param(ws.QueryParameter("id", "计算资源池id").DataType("int").Required(true)).
		//Param(ws.PathParameter("ip", "The ip of monitor physical server").Required(true).DataType("string")).
		Param(ws.QueryParameter("query", "The monitor metric query eg:CPU使用率：CPUUseRate;CPU使用量:CPUUsed; 内存使用率:MemoryUse;  内存使用量:MemoryUsed;磁盘使用率:DiskUseRate;磁盘使用量:DiskUsed")).
		Param(ws.QueryParameter("start", "The start time of range query")).
		Param(ws.QueryParameter("end", "The end time of range query")).
		Param(ws.QueryParameter("step", "The step time of range query")).
		Returns(http.StatusOK, "ok", resourcepoolmodel.LineDataResultSuccess{}))
	//todo swtich cpu usage rate (begin end step)

	return ws
}

func (s *ComputerPoolApiHandler) Overview(request *restful.Request, response *restful.Response) {
	// 可以去掉
	response.AddHeader("Access-Control-Allow-Origin", "*")
	klog.Info("computer pool overview")

	// 写入model
	rst := new(Result)
	t := new(resourcepoolmodel.ListQuery)
	request.ReadEntity(t)
	AggregateDataResult, err := s.ComputerPoolService.GetComputerPoolOverview(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = AggregateDataResult
		response.WriteAsJson(rst)
		return
	}
}
func (s *ComputerPoolApiHandler) OverviewLine(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(resourcepoolmodel.OverviewLineQuery)
	request.ReadEntity(t)
	//do
	computerPool, err := s.ComputerPoolService.GetComputerPoolOverviewLine(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = computerPool
		response.WriteAsJson(rst)
		return
	}
}

// 云资源监控/资源池监控/计算-列表页
func (s *ComputerPoolApiHandler) ListAggregatesHandler(request *restful.Request, response *restful.Response) {

	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(resourcepoolmodel.ComputerPoolListQuery)
	request.ReadEntity(t)
	if t.PageNo == 0 {
		rst.Code = 500
		rst.Message = "pageNo false"
		response.WriteAsJson(rst)
		return
	}
	if t.PageSize == 0 {
		rst.Code = 500
		rst.Message = "pageSize false"
		response.WriteAsJson(rst)
		return
	}

	if t.Region == "" || t.Region == "all" {
		t.Region = "all"
	}

	// if t.Az == "" || az == "all" {
	// 	t.Az = []string{}
	// }

	//request.ReadEntity(t)
	AggregateDataResult, err := s.ComputerPoolService.GetComputerPoolList(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = AggregateDataResult
		response.WriteAsJson(rst)
		return
	}

}

// 云资源监控/资源池监控/详情页-监控指标
func (s *ComputerPoolApiHandler) CpuUsedHandler(request *restful.Request, response *restful.Response) {
	klog.Info("---computer_pool_metric---")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(resourcepoolmodel.MonitorTargetListQuery)

	id, err := strconv.Atoi(request.QueryParameter("id"))
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	}
	if id < 1 {
		rst.Code = 500
		rst.Message = "id false" + request.QueryParameter("id")
		response.WriteAsJson(rst)
		return
	}
	t.Id = id
	t.Start = request.QueryParameter("start")
	t.End = request.QueryParameter("end")
	t.Step = request.QueryParameter("step")
	t.Query = request.QueryParameter("query")
	if t.Query == "" {
		rst.Code = 500
		rst.Message = "query is must"
		response.WriteAsJson(rst)
		return
	}
	t.Qs = append(t.Qs, t.Query)
	//request.ReadEntity(t)

	responseMetric, err := s.ComputerPoolService.GetComputerPoolMetric(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = responseMetric
		response.WriteAsJson(rst)
		return
	}

}

// 资源池管理/计算资源池/概览
func GetCMDBOverViewHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(resourcepoolmodel.CMDBOverViewQuery)

	region := request.QueryParameter("region")
	if region == "" || region == "all" {
		region = "all"
	}
	az := request.QueryParameter("az")
	if az == "" || az == "all" {
		az = "all"
	}

	//t.Count = count
	t.Region = region
	t.Az = az
	//request.ReadEntity(t)

	responseMetric, err := resourcepoolservice.GetCMDBOverView(*t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = responseMetric
		response.WriteAsJson(rst)
		return
	}

}

// pool server list
func GetPoolServerListHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(ListQuery)
	pageNo := request.QueryParameter("pageNo")
	if pageNo == "" {
		rst.Code = 500
		rst.Message = "pageNo false"
		response.WriteAsJson(rst)
		return
	}
	pageSize := request.QueryParameter("pageSize")
	if pageSize == "" {
		rst.Code = 500
		rst.Message = "pageSize false"
		response.WriteAsJson(rst)
		return
	}
	//region := request.QueryParameter("region")
	//if region == "" || region == "all" {
	//	region = "all"
	//}
	//
	//az := request.QueryParameter("az")
	//if az == "" {
	//	az = "all"
	//}

	t.PageNo = pageNo
	t.PageSize = pageSize
	//t.Count = count
	//t.Region = region
	//t.Az = az
	t.Id = request.PathParameter("id")
	//t.TenantId = request.QueryParameter("tenantId")
	//t.InnerIp = request.QueryParameter("innerIp")
	//t.OuterIp = request.QueryParameter("outerIp")
	//t.PhysicalHost = request.QueryParameter("physicalHost")
	//t.Pool = request.QueryParameter("pool")
	//t.State = request.QueryParameter("state")

	ms, err := GetComputerPoolServerList(t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = ms
		response.WriteAsJson(rst)
		return
	}

}

func GetComputerPoolServerList(l *ListQuery) (MonitorHosts, error) {
	ms := MonitorHosts{}
	//cs := CmdbVms{}
	//cmdb := CMDBResult{}

	cmdb, err := cmdbmanager.GetHostListByResourcePool(l.Id)

	if err != nil {
		fmt.Println("err" + err.Error())
		return ms, err
	}

	for i := 0; i < len(cmdb.Data.DataList); i++ {

		j := cmdb.Data.DataList[i]

		q := fmt.Sprintf(`{
		host(func:has(sn)) @filter(eq(sn, %s)) {
		  sn
		  ip
		  label
		}}`, j.SN)
		resp, er := dgraphmanager.NewDgraphClient().NewTxn().Query(context.Background(), q)
		if er != nil {
			return ms, er
		}
		var se DgraphCount
		e := json.Unmarshal(resp.Json, &se)
		if e != nil {
			return ms, e
		}

		m := MonitorHost{
			Id:           j.Id,
			Name:         j.Name,
			State:        j.Status,
			ResourcePool: j.ResourcePool,
			Region:       j.Region,
			Az:           j.Az,
			SN:           j.SN,
			Ip:           j.IP,
		}

		state, _ := prometheusmanager.GetStateByIp(j.IP)
		m.State = state

		c, _ := prometheusmanager.PrometheusQuery2(false, "", "", "", `1-avg(irate(node_cpu_seconds_total{mode="idle",instance="`+j.IP+`:9100"`+`}[5m]))`)
		m.CpuUesd = prometheusmanager.PrometheusResultToValue2(c)

		mem, _ := prometheusmanager.PrometheusQuery2(false, "", "", "", `1-node_memory_MemAvailable_bytes{instance=~"`+j.IP+`:9100"`+`}/node_memory_MemTotal_bytes{instance=~"`+j.IP+`:9100"`+`}`)
		m.MemUsed = prometheusmanager.PrometheusResultToValue2(mem)

		alerts, _ := alertmanager.GetAlertsByFilter(j.IP + ":9100")
		m.AlertNumber = len(alerts)
		ms.DataList = append(ms.DataList, m)
	}

	ms.PageNo = cmdb.Data.PageNo
	ms.PageSize = cmdb.Data.PageSize
	ms.TotalCount = cmdb.Data.TotalCount

	return ms, nil
}

// pool server list
func GetPoolVmListHandler(request *restful.Request, response *restful.Response) {
	//	response.AddHeader("Access-Control-Allow-Origin", "*")
	//	rst := new(Result)
	//	t := new(ListQuery)
	//	pageNo := request.QueryParameter("pageNo")
	//	if pageNo == "" {
	//		rst.Code = 500
	//		rst.Message = "pageNo false"
	//		response.WriteAsJson(rst)
	//		return
	//	}
	//	pageSize := request.QueryParameter("pageSize")
	//	if pageSize == "" {
	//		rst.Code = 500
	//		rst.Message = "pageSize false"
	//		response.WriteAsJson(rst)
	//		return
	//	}
	//	//region := request.QueryParameter("region")
	//	//if region == "" || region == "all" {
	//	//	region = "all"
	//	//}
	//	//
	//	//az := request.QueryParameter("az")
	//	//if az == "" {
	//	//	az = "all"
	//	//}
	//
	//	t.PageNo = pageNo
	//	t.PageSize = pageSize
	//	//t.Count = count
	//	//t.Region = region
	//	//t.Az = az
	//	t.Id = request.PathParameter("id")
	//	//t.TenantId = request.QueryParameter("tenantId")
	//	//t.InnerIp = request.QueryParameter("innerIp")
	//	//t.OuterIp = request.QueryParameter("outerIp")
	//	//t.PhysicalHost = request.QueryParameter("physicalHost")
	//	//t.Pool = request.QueryParameter("pool")
	//	//t.State = request.QueryParameter("state")
	//
	//	ms, err := GetComputerPoolVmList(t)
	//	if err != nil {
	//		rst.Code = 500
	//		rst.Message = err.Error()
	//		response.WriteAsJson(rst)
	//		return
	//	} else {
	//		rst.Code = 200
	//		rst.Message = "success"
	//		rst.Data = ms
	//		response.WriteAsJson(rst)
	//		return
	//	}

}

//func GetComputerPoolVmList(l *ListQuery) (MonitorHosts, error) {
//	ms := MonitorHosts{}
//	//cs := CmdbVms{}
//	//cmdb := CMDBResult{}
//
//	cmdb, err := cmdbmanager.GetVmListByResourcePool(l.Id)
//
//	if err != nil {
//		fmt.Println("err" + err.Error())
//		return ms, err
//	}
//
//	for i := 0; i < len(cmdb.Data.DataList); i++ {
//
//		j := cmdb.Data.DataList[i]
//
//		//q := fmt.Sprintf(`{
//		//host(func:has(sn)) @filter(eq(sn, %s)) {
//		//  sn
//		//  ip
//		//  label
//		//}}`,j.SN)
//		//resp, er := dgraphmanager.NewDgraphClient().NewTxn().Query(context.Background(), q)
//		//if er != nil {
//		//	return ms,er
//		//}
//		//var se DgraphCount
//		//e := json.Unmarshal(resp.Json, &se)
//		//if e != nil {
//		//	return ms,e
//		//}
//
//		m := MonitorVm{
//			ID:           j.ID,
//			Name:         j.Name,
//			VmType:       j.Aggregate,
//			ComputePool:  j.Aggregate,
//			Region:       j.Region,
//			Az:           j.Az,
//			TenantId:     j.TenantId,
//			PhysicalHost: j.Hypervisor,
//			InnerIP:      j.InnerIP,
//			OuterIP:      j.PublicIP,
//			CreateTime:   j.CreateTime,
//		}
//
//		//state, _ := prometheusmanager.GetStateByIp(j.InnerIP)
//		//m.State = state
//		//
//		//c, _ := prometheusmanager.PrometheusQuery2(false, "", "", "", `1-avg(irate(node_cpu_seconds_total{mode="idle",instance="`+j.IP+`:9100"`+`}[5m]))`)
//		//m.CpuUesd = prometheusmanager.PrometheusResultToValue2(c)
//		//
//		//mem, _ := prometheusmanager.PrometheusQuery2(false, "", "", "", `1-node_memory_MemAvailable_bytes{instance=~"`+j.IP+`:9100"`+`}/node_memory_MemTotal_bytes{instance=~"`+j.IP+`:9100"`+`}`)
//		//m.MemUsed = prometheusmanager.PrometheusResultToValue2(mem)
//		//
//		//alerts, _ := alertmanager.GetAlertsByFilter(j. + ":9100")
//		//m.AlertNumber = len(alerts)
//		ms.DataList = append(ms.DataList, m)
//	}
//
//	ms.PageNo = cmdb.Data.PageNo
//	ms.PageSize = cmdb.Data.PageSize
//	ms.TotalCount = cmdb.Data.TotalCount
//
//	return ms, nil
//}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/resourcepool/aggragate/util.go
```golang
package aggragate

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/resourcepool/aggragate/result.go
```golang
package aggragate

//overview
type OverViewSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverView struct {
	Region string              `json:"region"`
	Az     string              `json:"az"`
	Lab    string              `json:"lab"`
	Alerts AlertLevels         `json:"alerts"`
	State  RegionCurrentStates `json:"state"`
	//AllTopK       []prometheusmanager.RateTopResult
}
type AlertLevels struct {
	P0 int `json:"p0"`
	P1 int `json:"p1"`
	P2 int `json:"p2"`
	P3 int `json:"p3"`
}

type RegionCurrentStates struct {
	Region               string `json:"region"`
	PhysicalRunningCount int    `json:"physicalRunningCount"`
	PhysicalErrorCount   int    `json:"physicalErrorCount"`
}

//OverviewLine
type OverViewLineSuccess struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    []OverViewLine `json:"data"`
}

type OverViewLine struct {
	Region string `json:"region"`
	Az     string `json:"az"`
	Lab    string `json:"lab"`
	//Alert  AlertLevels `json:"alert"`
	Echarts []EchartType `json:"echarts"`
}

type EchartType struct {
	Info   InfoType    `json:"info"`
	Values []ValueType `json:"values"`
}

type ValueType struct {
	Value string `json:"value"`
	Name  string `json:"name"`
}

type InfoType struct {
	Region  string `json:"region"`
	Az      string `json:"az"`
	Lab     string `json:"lab"`
	Name    string `json:"name"`
	SubName string `json:"subName"`
	Total   string `json:"total"`
	TopK    int    `json:"topk"`
	Start   string `json:"start"`
	End     string `json:"end"`
}

//other
type Result struct {
	Code    int         `json:"code"`
	Message string      `json:"messgae"`
	Data    interface{} `json:"data"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

type ListQuery struct {
	PageNo   string `json:"pageNo"`
	PageSize string `json:"pageSize"`
	Id       string `json:"id"`
}

type MonitorHosts struct {
	PageStruct
	DataList []MonitorHost `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type MonitorHost struct {
	Id               string      `json:"id"`
	Name             string      `json:"name"`
	AssignmentStatus string      `json:"assignmentStatus"`
	ResourcePoolType string      `json:"resourcePoolType"`
	ResourcePool     string      `json:"resourcePool"`
	Region           string      `json:"region"`
	Az               string      `json:"az"`
	SN               string      `json:"sn"`
	Ip               string      `json:"ip"`
	State            string      `json:"state"`
	CpuUesd          interface{} `json:"cpuUesd"`
	MemUsed          interface{} `json:"memUsed"`
	AlertNumber      int         `json:"alertNumber"`
	Lable            string      `json:"lable"`
}

type MonitorVms struct {
	PageStruct
	DataList []MonitorVm `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type MonitorVm struct {
	ID           string `json:"id"`
	Name         string `json:"name"`
	VmType       string `json:"vmType"`
	Status       string `json:"status"`
	ComputePool  string `json:"computePool"`
	Region       string `json:"region"`
	Az           string `json:"az"`
	TenantId     string `json:"tenantId"`
	PhysicalHost string `json:"physicalHost"`
	InnerIP      string `json:"innerIp"`
	OuterIP      string `json:"outerIp"`
	CreateTime   string `json:"createTime"`
	CPUTotal     string `json:"cpuTotal"`
	CPUUse       string `json:"cpuUse"`
	MemoryTotal  string `json:"memoryTotal"`
	MemoryUse    string `json:"memoryUse"`
	AlertAmount  int    `json:"alertAmount"`
}

type AggregatesHosts struct {
	DataList   []AggregatesHost `json:"dataList" description:"paging data"`
	PageStruct                  //int              `json:"totalCount" description:"total count"`
}

type AggregatesHost struct {
	Id               string `json:"id"`
	Name             string `json:"name"`
	Status           string `json:"status"`
	AssignmentStatus string `json:"assignmentStatus"`
	ResourcePoolType string `json:"resourcePoolType"`
	ResourcePool     string `json:"resourcePool"`
	Service          string `json:"service"`
	Region           string `json:"region"`
	Az               string `json:"az"`
	Room             string `json:"room"`
	Rack             string `json:"rack"`
	RackPosition     string `json:"rackPosition"`
	SN               string `json:"sn"`
	Ip               string `json:"ip"`
}

type DgraphCount struct {
	Host []HostCount `json:"host"`
}

type HostCount struct {
	Count          int    `json:"count"`
	Label          string `json:"label"`
	Ip             string `json:"ip"`
	HostName       string `json:"hostname"`
	HostRegionName string `json:"hostRegionName"`
	HostLabName    string `json:"hostLabName"`
	HostAzName     string `json:"hostAzName"`
	Sn             string `json:"sn"`
	RunStatus      string `json:"runstatus"`
	Os             string `json:"system"`
	ServiceType    string `json:"serviceType"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/resourcepool/eipPool/handler.go
```golang
package eipPool

import (
	"net/http"

	restfulspec "github.com/emicklei/go-restful-openapi"
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	eipmodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/eip"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/eip"
	"k8s.io/klog/v2"
)

type EipPoolApiHandler struct {
	EipService eip.IEipPool
}

func BuildEipPoolApiHandler() *EipPoolApiHandler {
	eipService := eip.NewEipPoolService()
	return &EipPoolApiHandler{EipService: eipService}
}

func (e *EipPoolApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/eipPool").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)
	tag := []string{"eipPool"}

	ws.Route(ws.POST("/overview").To(e.overviewHandler).Doc("弹性ip概览页").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", eipmodels.EipPoolOverviewResponse{}))
	ws.Route(ws.POST("/overviewLine").To(e.overviewLineHandler).Doc("弹性ip概览页的变化曲线").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "的监控项名称,eg:used:使用趋势图/outFlow:出网流量/inFlow:入网流量/outPackages:每秒流出包数/inPackages:每秒流入包数").Required(false).DataType("[]string")).
		//Param(ws.BodyParameter("subName","The subName of TopK").Required(false)).
		//Param(ws.BodyParameter("topK", "topk的k").DataType("int").Required(false)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", eipmodels.OverviewLineResponse{}))
	ws.Route(ws.POST("/list").To(e.listHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Doc("弹性ip资源池列表").
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("Pool", "服务器所属资源池").Required(false)).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("searchKey", "搜索的K.eg:`pool`").Required(false)).
		Param(ws.BodyParameter("searchValue", "搜索的value. eg:`127.0.0.1`").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`netSegment`;`ipAvailRate`;`ipUsedRate`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升：asc;降：desc").Required(false)).
		Returns(http.StatusOK, "OK", eipmodels.EipPoolListResp{}))
	ws.Route(ws.POST("/line").To(e.metricLineHandler).Doc("弹性ip资源池监控指标变化曲线").
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Param(ws.BodyParameter("netSegment", "资源池名称（网段）").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "的监控项名称,eg:outFlow:出网流量/inFlow:入网流量/outPackages:每秒流出包数/inPackages:每秒流入包数").Required(false).DataType("[]string")).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", eipmodels.NetSegmentResponse{}))
	ws.Route(ws.POST("/usage").To(e.usageHandler).
		Metadata(restfulspec.KeyOpenAPITags, tag).
		Doc("list all eip Pool usage/获取弹性ip资源池-库存列表").
		Param(ws.QueryParameter("region", "区域;默认值：").DataType("string").Required(false).DefaultValue("")).
		Param(ws.QueryParameter("pageNo", "eg:1,页码，默认值1。").DataType("int32").Required(true).DefaultValue("1")).
		Param(ws.QueryParameter("pageSize", "eg:10, 页大小，默认值10。").DataType("int32").Required(true).DefaultValue("10")).
		Param(ws.QueryParameter("orderCode", "The orderCode of order.eg:capacityUsedRate").Required(false)).
		Param(ws.QueryParameter("orderType", "The orderType of order.eg:升：asc;降：desc").Required(false)).
		Returns(http.StatusOK, "ok", eipmodels.EipPoolUsageResponse{}))
	return ws
}

func (s *EipPoolApiHandler) overviewHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get eipPool overview")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &eipmodels.EipPoolOverviewQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.EipService.GetEipPoolOverview(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *EipPoolApiHandler) overviewLineHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get eipPool overview line")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &eipmodels.EipPoolOverviewLineQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	
	res, err := s.EipService.GetEipPoolOverviewLine(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}
func (s *EipPoolApiHandler) listHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get eipPool list")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &eipmodels.EipPoolListQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.EipService.GetEipPoolList(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *EipPoolApiHandler) metricLineHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get eipPool metric line")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &eipmodels.EipPoolMetricLineQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.EipService.GetEipPoolMetricLine(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *EipPoolApiHandler) usageHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get eipPool usage")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &eipmodels.EipPoolListQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.EipService.GetEipPoolUsage(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/servicemonitor/handler.go
```golang
package servicemonitor

import (
	"github.com/emicklei/go-restful/v3"
	servicemodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/servicemonitor"
	servicemonitor "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/servicemonitor"
)

func Overview(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)

	region := request.QueryParameter("region")
	//
	//fmt.Println(&t)
	////request.ReadEntity(t)
	overViewDataResult, err := servicemonitor.GetServiceOverView(region)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = overViewDataResult
		response.WriteAsJson(rst)
		return
	}
}

//服务监控/服务监控-列表页
func ListServiceHandler(request *restful.Request, response *restful.Response) {

	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(servicemodel.ListQuery)
	request.ReadEntity(t)
	if t.SearchKey != "" && t.SearchValue != "" {
		switch t.SearchKey {
		case "name":
			t.Name = t.SearchValue
		}
	}

	if t.PageNo == 0 {
		rst.Code = 500
		rst.Message = "pageNo false"
		response.WriteAsJson(rst)
		return
	}

	if t.PageSize == 0 {
		rst.Code = 500
		rst.Message = "pageSize false"
		response.WriteAsJson(rst)
		return
	}

	//t.PageNo = pageNo
	//t.PageSize = pageSize
	////t.Count = count
	//t.Name = request.QueryParameter("name")
	//t.OrderCode = request.QueryParameter("orderCode")
	//t.OrderType = request.QueryParameter("orderType")
	//
	//fmt.Println(&t)
	////request.ReadEntity(t)
	BlockStorageDataResult, err := servicemonitor.GetServiceList(*t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = BlockStorageDataResult
		response.WriteAsJson(rst)
		return
	}

}

//服务监控/详情页-进程列表
func ListProcessHandler(request *restful.Request, response *restful.Response) {

	response.AddHeader("Access-Control-Allow-Origin", "*")
	rst := new(Result)
	t := new(servicemodel.ProcessListQuery)
	request.ReadEntity(&t)
	//pageNo, err := strconv.Atoi(request.QueryParameter("pageNo"))
	if t.PageNo == 0 {
		rst.Code = 500
		rst.Message = "pageNo false"
		response.WriteAsJson(rst)
		return
	}

	if t.PageSize == 0 {
		rst.Code = 500
		rst.Message = "pageSize false"
		response.WriteAsJson(rst)
		return
	}

	//t.PageNo = pageNo
	//t.PageSize = pageSize
	////t.Count = count
	//t.Name = request.QueryParameter("name")
	//t.Cmdline = request.QueryParameter("cmdline")
	//t.Ip = request.QueryParameter("ip")
	//fmt.Println(&t)
	//request.ReadEntity(t)
	BlockStorageDataResult, err := servicemonitor.GetProcessList(*t)
	if err != nil {
		rst.Code = 500
		rst.Message = err.Error()
		response.WriteAsJson(rst)
		return
	} else {
		rst.Code = 200
		rst.Message = "success"
		rst.Data = BlockStorageDataResult
		response.WriteAsJson(rst)
		return
	}

}
func GetBusinessServiceInstanceListHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/servicemonitor/result.go
```golang
package servicemonitor

type Result struct {
	Code    int         `json:"code"`
	Message string      `json:"messgae"`
	Data    interface{} `json:"data"`
}

//overview
type OverViewSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverView struct {
	Region string      `json:"region"`
	Alerts []AlertType `json:"alerts"`
	State  []StateType `json:"state"`
	//AllTopK       []prometheusmanager.RateTopResult
}

type AlertType struct {
	Prefix string `json:"prefix"`
	Level  string `json:"level"`
	Unit   string `json:"unit"`
	Number int    `json:"number"`
	Name   string `json:"name"`
	Kind   string `json:"kind"`
	Type   string `json:"type"`
}
type StateType struct {
	Prefix string `json:"prefix"`
	Unit   string `json:"unit"`
	Number int    `json:"number"`
	Name   string `json:"name"`
	Kind   string `json:"kind"`
	Type   string `json:"type"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/handler/physicalSwitch/switch-handler.go
```golang
package physicalSwitch

import (
	"net/http"

	restfulspec "github.com/emicklei/go-restful-openapi"
	"github.com/emicklei/go-restful/v3"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	switchmodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/physicalSwitch"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/physicalSwitch"
	"k8s.io/klog/v2"
)

type PhysicalSwitchApiHandler struct {
	SwitchService physicalSwitch.IPhysicalSwitch
}

func BuildPhysicalSwitchApiHandler() *PhysicalSwitchApiHandler {
	switchService := physicalSwitch.NewPhysicalSwitchService()
	return &PhysicalSwitchApiHandler{
		SwitchService: switchService,
	}
}

func (s *PhysicalSwitchApiHandler) New() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/metrics/v1/switch").
		Consumes(restful.MIME_JSON, restful.MIME_XML).
		Produces(restful.MIME_JSON, restful.MIME_XML)

	tags := []string{"switch"}

	//todo switch overview
	ws.Route(ws.POST("/overview").To(s.overviewHandler).Doc("概览页").
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", switchmodels.SwitchOverviewResponse{}))
	ws.Route(ws.POST("/overviewTopK").To(s.overviewTopHandler).Doc("概览页的topK").
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("string").Required(false)).
		Param(ws.BodyParameter("name", "topK的监控项名称,eg:dropRateIn/dropRateOut/errRateIn/errRateOut/bandRateIn/bandRateOut/cpuRate/memRate").Required(false).DataType("[]string")).
		//Param(ws.BodyParameter("subName","The subName of TopK").Required(false)).
		Param(ws.BodyParameter("topK", "topk的k").DataType("int").Required(false)).
		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).
		Returns(http.StatusOK, "Get Overview Success", switchmodels.SwitchOverviewTopResponse{}))
	ws.Route(ws.POST("/list").To(s.listHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("交换机列表").
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		//Param(ws.BodyParameter("contentSelector", "要返回的字段，默认返回所有字段.").Required(false)).
		//Param(ws.BodyParameter("count", "是否统计实例数量，默认值true").Required(true).DataType("bool")).
		// Param(ws.BodyParameter("lab", "机房").DataType("[]string").Required(false)).
		// Param(ws.BodyParameter("Pool", "服务器所属资源池").Required(false)).
		Param(ws.BodyParameter("region", "区域").DataType("string").Required(false)).
		Param(ws.BodyParameter("cpuErrNum", "cpu故障数").DataType("string").Required(false)).
		Param(ws.BodyParameter("memErrNum", "mem故障数").DataType("string").Required(false)).
		Param(ws.BodyParameter("az", "可用区").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("searchKey", "搜索的K.eg:`name`;`sn`").Required(false)).
		Param(ws.BodyParameter("searchValue", "搜索的value. eg:`127.0.0.1`").Required(false)).
		Param(ws.BodyParameter("orderCode", "The orderCode of order.eg:`cpuLoad`;`memLoad`;`disLoad`").Required(false)).
		Param(ws.BodyParameter("orderType", "The orderType of order.eg:升：asc;降：desc").Required(false)).
		Param(ws.BodyParameter("runState", "运行状态,eg:`up`;`down`").DataType("[]string").Required(false)).
		Param(ws.BodyParameter("snmpState", "snmp服务的状态,eg:`up`;`down`").DataType("[]string").Required(false)).
		Returns(http.StatusOK, "OK", switchmodels.SwitchListResponse{}))
	ws.Route(ws.POST("/ifdetail").To(s.ifDetailHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("交换机接口详情").
		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
		Param(ws.BodyParameter("sn", "交换机序列号").Required(true)).
		Param(ws.BodyParameter("name", "交换机接口名").Required(false)).
		Param(ws.BodyParameter("runState", "运行状态,eg:`up`;`down`").DataType("[]string").Required(false)).
		//Returns(http.StatusOK, "OK", switchmodels.InterfaceListSuccess{}))
		Returns(http.StatusOK, "OK", switchmodels.InterfaceDetail{}))
	ws.Route(ws.GET("/{sn}/query").To(s.metricHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("取得交换机的监控").
		Param(ws.PathParameter("sn", "The ip of monitor physical server").Required(true).DataType("string")).
		// Param(ws.BodyParameter("list", "The list of query string").Required(true).DataType("array")).
		// Param(ws.QueryParameter("start", "The start time of range query")).
		// Param(ws.QueryParameter("end", "The end time of range query")).
		// Param(ws.QueryParameter("step", "The step time of range query")).
		Returns(200, "ok", switchmodels.SwitchMetricSuccess{}))
	ws.Route(ws.GET("/{sn}/boundOutQuery").To(s.hardwareHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("取得交换机的硬件监控").
		Param(ws.PathParameter("sn", "The ip of monitor physical server").Required(true).DataType("string")).
		// Param(ws.BodyParameter("list", "The list of query string").Required(true).DataType("array")).
		// Param(ws.QueryParameter("start", "The start time of range query")).
		// Param(ws.QueryParameter("end", "The end time of range query")).
		// Param(ws.QueryParameter("step", "The step time of range query")).
		Returns(200, "ok", switchmodels.HardwareResponse{}))
	ws.Route(ws.POST("/{sn}/queryLine").To(s.metricLineHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("取得交换机的监控变化曲线").
		Param(ws.PathParameter("sn", "交换机的sn号").Required(true).DataType("string")).
		Param(ws.BodyParameter("list", "交换机的查询监控项列表,eg:`cpu`;`mem`;`power`").Required(true).DataType("[]string")).
		Param(ws.BodyParameter("start", "The start time of range query")).
		Param(ws.BodyParameter("end", "查询的结束时间")).
		//Param(ws.QueryParameter("step", "查询的开始时间")).
		Returns(200, "ok", switchmodels.SwitchMetricLineResponse{}))
	ws.Route(ws.POST("/{sn}/{interfaceIndex}/singleLine").To(s.interfaceSingleLineHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("取得交换机的接口变化曲线").
		Param(ws.QueryParameter("start", "开始时间").DataType("int64").Required(true)).
		Param(ws.QueryParameter("end", "结束时间").DataType("int64").Required(true)).
		Param(ws.PathParameter("sn", "交换机的sn号").DataType("string").Required(true)).
		Param(ws.PathParameter("interfaceIndex", "接口序号,  `1`").DataType("int").Required(true)).
		Param(ws.QueryParameter("name", `监控项名称,eg:inFlow:接收速率/outFlow:发送速率/inBandRate:接收带宽利用率/outBandRate:发送带宽利用率/inPacketRate:接收包速率/outPacketRate:发送包速率/
		inDropPacketRate:接收丢包速率/outDropPacketRate:发送丢包速率/inErrPacketRate:接收错包速率/outErrPacketRate:发送错包速率/inDropRate:接收丢包率/outDropRate:接收丢包率/inErrRate:接收错包率/outErrRate:发送错包率`).DataType("string").Required(true)).
		Returns(200, "OK", switchmodels.IfMetricSingleLineResponse{}))
	ws.Route(ws.POST("/{sn}/{interfaceIndex}/line").To(s.interfaceLineHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("取得交换机的接口变化曲线").
		Param(ws.QueryParameter("start", "开始时间").DataType("int64").Required(true)).
		Param(ws.QueryParameter("end", "结束时间").DataType("int64").Required(true)).
		Param(ws.PathParameter("sn", "交换机的sn号").DataType("string").Required(true)).
		Param(ws.PathParameter("interfaceIndex", "接口序号,  `1`").DataType("int").Required(true)).
		Param(ws.QueryParameter("name", `监控项名称,eg:inFlow:接收速率/outFlow:发送速率/inBandRate:接收带宽利用率/outBandRate:发送带宽利用率/inPacketRate:接收包速率/outPacketRate:发送包速率/
		inDropPacketRate:接收丢包速率/outDropPacketRate:发送丢包速率/inErrPacketRate:接收错包速率/outErrPacketRate:发送错包速率/inDropRate:接收丢包率/outDropRate:接收丢包率/inErrRate:接收错包率/outErrRate:发送错包率`).DataType("string").Required(true)).
		Returns(200, "OK", switchmodels.IfMetricLineResponse{}))
	ws.Route(ws.GET("/{sn}/{interfaceIndex}/info").To(s.interfaceHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("取得交换机的即时监控信息").
		Param(ws.PathParameter("sn", "交换机的sn号").DataType("string").Required(true)).
		Param(ws.PathParameter("interfaceIndex", "接口序号,  `1`").DataType("int").Required(true)).
		// Param(ws.QueryParameter("name", "监控项名称,eg:inFlow/outFlow/inPacketRate/outPacketRate/errPacketNum").DataType("string").Required(true)).
		Returns(200, "OK", switchmodels.MetricSuccess{}))
	ws.Route(ws.GET("/{sn}/ifNameArray").To(s.ifIndexNameHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("取得交换机的接口名数组,下标就是index,对应的string就是接口名").
		Param(ws.PathParameter("sn", "交换机的sn号").DataType("string").Required(true)).
		Returns(200, "OK", switchmodels.SwitchIfNameSuccess{}))
	ws.Route(ws.POST("/{sn}/interfaceList").To(s.interfaceListHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("交换机的接口列表").
		Param(ws.QueryParameter("pageNo", "页码，默认值：`1`")).
		Param(ws.QueryParameter("pageSize", "页大小，默认值：`10`")).
		Param(ws.PathParameter("sn", "交换机的sn号")).
		Param(ws.QueryParameter("name", "接口的名称")).
		Param(ws.BodyParameter("runList", "接口状态").DataType("[]string")).
		Returns(200, "OK", switchmodels.InterfaceListSuccess{}))
	ws.Route(ws.POST("/{sn}/alertList").To(s.alertListHandler).
		Metadata(restfulspec.KeyOpenAPITags, tags).
		Doc("交换机的告警列表").
		Param(ws.QueryParameter("pageNo", "页码，默认值：`1`")).
		Param(ws.QueryParameter("pageSize", "页大小，默认值：`10`")).
		Param(ws.PathParameter("sn", "交换机的sn号")).
		Param(ws.QueryParameter("pLevel", "告警等级, 默认是 `p0`")).
		Param(ws.QueryParameter("alertState", "告警状态")).
		Param(ws.QueryParameter("alertId", "告警id")).
		Param(ws.QueryParameter("alertInstance", "告警实例")).
		Returns(200, "OK", switchmodels.AlertDetailSuccess{}))
	//todo swtich cpu usage rate (begin end step)

	return ws
}

func (s *PhysicalSwitchApiHandler) overviewHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get switch overview")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &switchmodels.SwitchOverviewQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.SwitchService.GetSwitchOverview(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *PhysicalSwitchApiHandler) overviewTopHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	klog.Infof("get switch overview")
	para := &switchmodels.SwitchOverviewTopQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.SwitchService.GetSwitchOverviewTop(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *PhysicalSwitchApiHandler) listHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get switch List")
	response.AddHeader("Access-Control-Allow-Origin", "*")
	para := &switchmodels.SwitchListQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.SwitchService.GetSwitchList(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *PhysicalSwitchApiHandler) metricHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get switch overview")
	sn := request.PathParameter("sn")

	res, err := s.SwitchService.GetSwitchMetric(sn)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}
func (s *PhysicalSwitchApiHandler) hardwareHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get switch overview")

	sn := request.PathParameter("sn")
	res, err := s.SwitchService.GetSwitchHardwareMetric(sn)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *PhysicalSwitchApiHandler) metricLineHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get switch overview")

	para := &switchmodels.SwitchMetricLineQuery{}
	err := request.ReadEntity(para)
	para.Sn = request.PathParameter("sn")

	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.SwitchService.GetSwitchMetricLine(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *PhysicalSwitchApiHandler) interfaceHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get switch overview")
	para := &switchmodels.InterfaceQuery{}

	para.Sn = request.PathParameter("sn")
	para.Index = request.PathParameter("interfaceIndex")
	res, err := s.SwitchService.GetSwitchIfInfo(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *PhysicalSwitchApiHandler) interfaceLineHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	klog.Infof("get switch interface line")

	para := &switchmodels.SwitchInterfaceLineQuery{}

	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	para.Sn = request.PathParameter("sn")
	para.Index = request.PathParameter("interfaceIndex")
	para.Name = append(para.Name[:0], "inFlow", "outFlow", "inBandRate", "outBandRate", "inErrRate", "outErrRate", "inDropRate", "outDropRate", "inPackageRate", "outPackageRate", "inErrNum", "outErrNum", "inDropNum", "outDropNum")

	res, err := s.SwitchService.GetSwitchInterfaceLine(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *PhysicalSwitchApiHandler) interfaceListHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get switch overview")
	sn := request.PathParameter("sn")
	para := &switchmodels.SwitchInterfaceListQuery{Sn: sn}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.SwitchService.GetSwitchInterfaceList(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}
func (s *PhysicalSwitchApiHandler) interfaceSingleLineHandler(request *restful.Request, response *restful.Response) {
	response.AddHeader("Access-Control-Allow-Origin", "*")
	klog.Infof("get switch interface line")

	para := &switchmodels.SwitchInterfaceLineQuery{}

	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	para.Sn = request.PathParameter("sn")
	para.Index = request.PathParameter("interfaceIndex")
	if len(para.Name) == 0 {
		para.Name = append(para.Name, "outFlow", "inFlow")
	}
	res, err := s.SwitchService.GetSwitchInterfaceSigleLine(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *PhysicalSwitchApiHandler) alertListHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get switch overview")
	para := &switchmodels.SwitchOverviewQuery{}
	err := request.ReadEntity(para)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.SwitchService.GetSwitchOverview(para)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

func (s *PhysicalSwitchApiHandler) ifDetailHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get switch interface detail list")
	param := &switchmodels.SwitchIfDetailParams{}
	err := request.ReadEntity(param)
	if err != nil {
		klog.Errorf("json Unmarshal error : %s", err.Error())
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
		return
	}
	res, err := s.SwitchService.GetSwitchIfDetail(param)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}
}

func (s *PhysicalSwitchApiHandler) ifIndexNameHandler(request *restful.Request, response *restful.Response) {
	klog.Infof("get switch interface index to name")
	sn := request.PathParameter("sn")
	// para := &switchmodels.SwitchOverviewQuery{}
	// err := request.ReadEntity(para)
	// if err != nil {
	// 	klog.Errorf("json Unmarshal error : %s", err.Error())
	// 	response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	// 	return
	// }
	res, err := s.SwitchService.GetIfNameArray(sn)
	if err == nil {
		response.WriteEntity(models.NewSuccessResponse().SetData(res))
	} else {
		response.WriteEntity(models.NewResponse().SetCode(http.StatusInternalServerError).SetMessage(err.Error()))
	}

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/filters/k8s-filter.go
```golang
package filters

import (
	"crypto/tls"
	"fmt"

	"github.com/emicklei/go-restful/v3"
	client2 "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"io/ioutil"
	"net/http"
	"strings"
)

func ForwardKubernetes(request *restful.Request, response *restful.Response, chain *restful.FilterChain) {
	fmt.Println("filter k8s...")
	path := request.Request.URL.Path
	verb := request.Request.Method

	startsWith := strings.HasPrefix(path, "/k8s/")
	if !startsWith {
		chain.ProcessFilter(request, response)
		return
	}

	path = strings.TrimLeft(path, "/k8s/")
	url := "https://kubernetes.default/" + path

	limit := request.QueryParameter("limit")
	if limit != "" {
		url = url + "?limit=" + limit
	}

	tr := &http.Transport{TLSClientConfig: &tls.Config{InsecureSkipVerify: true}, DisableCompression: true}
	req, _ := http.NewRequest(verb, url, nil)
	fmt.Println(url)

	token := "Bearer " + client2.GetToken()
	fmt.Println(client2.GetToken())
	req.Header.Set("Authorization", token)

	client := http.Client{Transport: tr}
	resp, _ := client.Do(req)

	defer resp.Body.Close()
	body, _ := ioutil.ReadAll(resp.Body)
	response.Write(body)
	response.WriteHeader(resp.StatusCode)
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/tasks/tasks.go
```golang
package tasks

import (
	"context"
	"fmt"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	resourcepoolservice "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/tasks/cloudTask"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/tasks/poolTask"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"k8s.io/klog/v2"
	"strconv"
	"sync"
	"time"
)

// func InitTasks 异步任务脚本
func InitTasks() {
	klog.Infoln("自动任务开始")
	utils.GoSafe(GetBlockStoragePoolList)  // 获取资源池库存
	utils.GoSafe(cloudTask.GetBucketInfo)  //bucket
	utils.GoSafe(poolTask.GetDiskCapacity) //ks3 磁盘容量
	var wg sync.WaitGroup
	wg.Add(7)
	utils.GoSafe(func() { cloudTask.GetVmTop(&wg) })
	utils.GoSafe(func() { cloudTask.GetBlockTop(&wg) })
	utils.GoSafe(func() { cloudTask.GetEipTop(&wg) })
	utils.GoSafe(func() { cloudTask.GetMysqlTop(&wg) })
	utils.GoSafe(func() { cloudTask.GetRedisTop(&wg) })
	utils.GoSafe(func() { cloudTask.GetNatTop(&wg) })
	utils.GoSafe(func() { cloudTask.GetLoadTop(&wg) })
	wg.Wait()
	klog.Infoln("自动任务结束")
}

// func GetBlockStoragePoolList 同步资源池数据
func GetBlockStoragePoolList() {
	for {
		klog.Infof("获取资源池库存开始")
		param := []string{}
		blockStoragePoolResult, err := cmdbmanager.GetBlockStorageResourcePoolList("all", "", param, param)
		if err != nil {
			klog.Errorf("GetBlockStoragePoolList err", err)
		}
		blockStorageList := blockStoragePoolResult.Data.DataList
		klog.Infof("getstock len blockStorageList", blockStorageList)
		for _, blockRe := range blockStorageList {
			var stock cmdbmodel.GetPoolStock
			var clusters cmdbmodel.GetPoolClusters
			if blockRe.Name == "ssd3.0" {
				blockRe.Name = "ssd3"
			}
			ctx, cefl := context.WithTimeout(context.Background(), 10*time.Minute)
			defer cefl()
			azIdStr := "az" + strconv.Itoa(blockRe.AzId)
			stockKey := fmt.Sprintf("block_storage_name_%s_%s", azIdStr, blockRe.Name)
			klog.Infof("stockKey", stockKey)
			klog.Infof("blockRe.StockUrl", blockRe.StockUrl)
			klog.Infof("blockRe.MetricUrl", blockRe.MetricUrl)
			stock, stockErr := cmdbmanager.GetBlockStock(blockRe.StockUrl)
			if stockErr != nil {
				klog.Errorf("Failed to get_GetBlockStock_information:", stockErr)
				continue
			}
			resourcepoolservice.HsetStockRedis(ctx, stockKey, "getStock", stock)
			clusters, clustersErr := cmdbmanager.GetBlockClusters(blockRe.MetricUrl)
			if clustersErr != nil {
				klog.Errorf("Failed to get GetBlockClusters information:", clustersErr)
				continue
			}
			resourcepoolservice.HsetClustersRedis(ctx, stockKey, "getClusters", clusters)
		}
		time.Sleep(time.Minute * 20)
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/tasks/cloudTask/mysql_job.go
```golang
package cloudTask

import (
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"k8s.io/klog/v2"
	"strconv"
	"sync"
	"time"
)

// GetMysqlTop mysql top Job
func GetMysqlTop(wg *sync.WaitGroup) {
	defer wg.Done()
	wg.Add(4)
	utils.GoSafe(func() { mysqlFiveMinutesJob(wg) })// 5m点  0.5h/1h
	utils.GoSafe(func() { mysqlTenMinutesJob(wg) })// 10m点 3h
	utils.GoSafe(func() { mysqlHourOneJob(wg) }) // 1h点  12h 1d 7d
	utils.GoSafe(func() { mysqlDayOneJob(wg) })// 1d  30d
}

//cpu,mem,inRatio,outRatio,connectionRatio,hitRate,slowlogLen

// fiveMinutesJob 0.5小时/1小时同步数据脚本
func mysqlFiveMinutesJob(wg *sync.WaitGroup) { // 0.5h/1h
	klog.Infof("Start_of_script_execution_in_5_minutes_%s_%d", config.CloudMysqlResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{6, 12} //tsdb 0.5h/1h 所取点数
		endTime := time.Now().Unix()
		startTime := endTime - 3600
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudMysqlResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(10)
			go SetFiveMinutes(wg, param, config.CloudMysqlResource, "MysqlCpuRate")       // mysqlCpu使用率
			go SetFiveMinutes(wg, param, config.CloudMysqlResource, "MysqlMemRate")       // mysql内存使用率
			go SetFiveMinutes(wg, param, config.CloudMysqlResource, "MysqlIopsRead")      // 每秒io输出量
			go SetFiveMinutes(wg, param, config.CloudMysqlResource, "MysqlIopsWrite")     // 每秒io输入量
			go SetFiveMinutes(wg, param, config.CloudMysqlResource, "MysqlLinkRunning")   // 当前活跃连接数
			go SetFiveMinutes(wg, param, config.CloudMysqlResource, "MysqlLinkConnected") // 当前连接数
			go SetFiveMinutes(wg, param, config.CloudMysqlResource, "MysqlBytesReceived") // 网络输入吞吐量
			go SetFiveMinutes(wg, param, config.CloudMysqlResource, "MysqlBytesSent")     // 网络输出吞吐量
			go SetFiveMinutes(wg, param, config.CloudMysqlResource, "MysqlOps")           // MysqlOps
			go SetFiveMinutes(wg, param, config.CloudMysqlResource, "MysqlTps")           // MysqlTps
		}
		time.Sleep(time.Minute * 5)
	}
}

//tenMinutesJob 3h同步数据脚本
func mysqlTenMinutesJob(wg *sync.WaitGroup) { //3h
	klog.Infof("Start_of_script_execution_in_3_hour_%s_%d", config.CloudMysqlResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{18}        // 3 小时 10m 取一次 取18个点
		endTime := time.Now().Unix() // 当前时间
		startTime := endTime - 10800
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudMysqlResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(10)
			go SetTenMinutes(wg, param, config.CloudMysqlResource, "MysqlCpuRate")
			go SetTenMinutes(wg, param, config.CloudMysqlResource, "MysqlMemRate")
			go SetTenMinutes(wg, param, config.CloudMysqlResource, "MysqlIopsRead")
			go SetTenMinutes(wg, param, config.CloudMysqlResource, "MysqlIopsWrite")
			go SetTenMinutes(wg, param, config.CloudMysqlResource, "MysqlLinkRunning")
			go SetTenMinutes(wg, param, config.CloudMysqlResource, "MysqlLinkConnected")
			go SetTenMinutes(wg, param, config.CloudMysqlResource, "MysqlBytesReceived")
			go SetTenMinutes(wg, param, config.CloudMysqlResource, "MysqlBytesSent")
			go SetTenMinutes(wg, param, config.CloudMysqlResource, "MysqlOps")
			go SetTenMinutes(wg, param, config.CloudMysqlResource, "MysqlTps")
		}
		time.Sleep(time.Minute * 10)
	}
}

//hourOneJob 同步数据脚本12h/ 1d /7d
func mysqlHourOneJob(wg *sync.WaitGroup) { // 12h/ 1d /7d
	klog.Infof("Start_of_script_execution_in_12_hour_%s_%d", config.CloudMysqlResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{12, 24, 168} // 12,24,168 取点数量
		endTime := time.Now().Unix()   // 当前时间
		startTime := endTime - 604800  // 7天前时间
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudMysqlResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(10)
			go SetOneHour(wg, param, config.CloudMysqlResource, "MysqlCpuRate")
			go SetOneHour(wg, param, config.CloudMysqlResource, "MysqlMemRate")
			go SetOneHour(wg, param, config.CloudMysqlResource, "MysqlIopsRead")
			go SetOneHour(wg, param, config.CloudMysqlResource, "MysqlIopsWrite")
			go SetOneHour(wg, param, config.CloudMysqlResource, "MysqlLinkRunning")
			go SetOneHour(wg, param, config.CloudMysqlResource, "MysqlLinkConnected")
			go SetOneHour(wg, param, config.CloudMysqlResource, "MysqlBytesReceived")
			go SetOneHour(wg, param, config.CloudMysqlResource, "MysqlBytesSent")
			go SetOneHour(wg, param, config.CloudMysqlResource, "MysqlOps")
			go SetOneHour(wg, param, config.CloudMysqlResource, "MysqlTps")
		}
		time.Sleep(time.Minute * 60)
	}
}

// dayOneJob 30d同步数据脚本
func mysqlDayOneJob(wg *sync.WaitGroup) { // 30d
	klog.Infof("Start_of_script_execution_in_30_day_%s_%d", config.CloudMysqlResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{30}          //取点数量
		endTime := time.Now().Unix()   // 当前时间
		startTime := endTime - 2592000 // 7天前时间
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudMysqlResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(10)
			go SetOneDay(wg, param, config.CloudMysqlResource, "MysqlCpuRate")
			go SetOneDay(wg, param, config.CloudMysqlResource, "MysqlMemRate")
			go SetOneDay(wg, param, config.CloudMysqlResource, "MysqlIopsRead")
			go SetOneDay(wg, param, config.CloudMysqlResource, "MysqlIopsWrite")
			go SetOneDay(wg, param, config.CloudMysqlResource, "MysqlLinkRunning")
			go SetOneDay(wg, param, config.CloudMysqlResource, "MysqlLinkConnected")
			go SetOneDay(wg, param, config.CloudMysqlResource, "MysqlBytesReceived")
			go SetOneDay(wg, param, config.CloudMysqlResource, "MysqlBytesSent")
			go SetOneDay(wg, param, config.CloudMysqlResource, "MysqlOps")
			go SetOneDay(wg, param, config.CloudMysqlResource, "MysqlTps")
		}
		time.Sleep(time.Hour * 24)
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/tasks/cloudTask/eip_job.go
```golang
package cloudTask

import (
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"k8s.io/klog/v2"
	"strconv"
	"sync"
	"time"
)

func GetEipTop(wg *sync.WaitGroup) {
	defer wg.Done()
	wg.Add(4)
	utils.GoSafe(func() { EipFiveMinutesJob(wg) })// 5m点  0.5h/1h
	utils.GoSafe(func() { EipTenMinutesJob(wg) })// 10m点 3h
	utils.GoSafe(func() { EipHourOneJob(wg) }) // 1h点  12h 1d 7d
	utils.GoSafe(func() { EipDayOneJob(wg) })// 1d  30d

}
// EipFiveMinutesJob 0.5小时/1小时同步数据脚本
func EipFiveMinutesJob(wg *sync.WaitGroup) { // 0.5h/1h
	klog.Infof("Start_of_script_execution_in_5_minutes_%s_%d",config.CloudEipResource,time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{6, 12} //tsdb 0.5h/1h 所取点数
		endTime := time.Now().Unix()
		startTime := endTime - 3600
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudEipResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(6)
			go SetFiveMinutes(wg, param, config.CloudEipResource, "EipUtilizationOut") // 出向带宽使用百分比
			go SetFiveMinutes(wg, param, config.CloudEipResource, "EipUtilizationIn")  // 入向带宽使用百分比
			go SetFiveMinutes(wg, param, config.CloudEipResource, "EipPpsOut")         // 出网流量
			go SetFiveMinutes(wg, param, config.CloudEipResource, "EipPpsIn")          //入网流量
			go SetFiveMinutes(wg, param, config.CloudEipResource, "EipBpsOut")         //每秒流出包数
			go SetFiveMinutes(wg, param, config.CloudEipResource, "EipBpsIn")          //每秒流入包数
		}
		time.Sleep(time.Minute * 5)
	}
}

//EipTenMinutesJob 3h同步数据脚本
func EipTenMinutesJob(wg *sync.WaitGroup) { //3h
	klog.Infof("Start_of_script_execution_in_3_hour_%s_%d",config.CloudEipResource,time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{18} // 3 小时 10m 取一次 取18个点
		endTime := time.Now().Unix() // 当前时间
		startTime := endTime - 10800
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudEipResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(6)
			go SetTenMinutes(wg, param, config.CloudEipResource, "EipUtilizationOut") // 出向带宽使用百分比
			go SetTenMinutes(wg, param, config.CloudEipResource, "EipUtilizationIn")  // 入向带宽使用百分比
			go SetTenMinutes(wg, param, config.CloudEipResource, "EipPpsOut")         // 出网流量
			go SetTenMinutes(wg, param, config.CloudEipResource, "EipPpsIn")          //入网流量
			go SetTenMinutes(wg, param, config.CloudEipResource, "EipBpsOut")         //每秒流出包数
			go SetTenMinutes(wg, param, config.CloudEipResource, "EipBpsIn")          //每秒流入包数
		}
		time.Sleep(time.Minute * 10)
	}
}
//EipTenMinutesJob 同步数据脚本12h/ 1d /7d
func EipHourOneJob(wg *sync.WaitGroup) { // 12h/ 1d /7d
	klog.Infof("Start_of_script_execution_in_12_hour_%s_%d",config.CloudEipResource,time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{12, 24, 168} // 12,24,168 取点数量
		endTime := time.Now().Unix()  // 当前时间
		startTime := endTime - 604800 // 7天前时间
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudEipResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(6)
			go SetOneHour(wg, param, config.CloudEipResource, "EipUtilizationOut") // 出向带宽使用百分比
			go SetOneHour(wg, param, config.CloudEipResource, "EipUtilizationIn")  // 入向带宽使用百分比
			go SetOneHour(wg, param, config.CloudEipResource, "EipPpsOut")         // 出网流量
			go SetOneHour(wg, param, config.CloudEipResource, "EipPpsIn")          //入网流量
			go SetOneHour(wg, param, config.CloudEipResource, "EipBpsOut")         //每秒流出包数
			go SetOneHour(wg, param, config.CloudEipResource, "EipBpsIn")          //每秒流入包数
		}
		time.Sleep(time.Minute * 60)
	}
}
// EipDayOneJob 30d同步数据脚本
func EipDayOneJob(wg *sync.WaitGroup) { // 30d
	klog.Infof("Start_of_script_execution_in_30_day_%s_%d",config.CloudEipResource,time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{30} //取点数量
		endTime := time.Now().Unix()   // 当前时间
		startTime := endTime - 2592000 // 7天前时间
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudEipResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(6)
			go SetOneDay(wg, param, config.CloudEipResource, "EipUtilizationOut") // 出向带宽使用百分比
			go SetOneDay(wg, param, config.CloudEipResource, "EipUtilizationIn")  // 入向带宽使用百分比
			go SetOneDay(wg, param, config.CloudEipResource, "EipPpsOut")         // 出网流量
			go SetOneDay(wg, param, config.CloudEipResource, "EipPpsIn")          //入网流量
			go SetOneDay(wg, param, config.CloudEipResource, "EipBpsOut")         //每秒流出包数
			go SetOneDay(wg, param, config.CloudEipResource, "EipBpsIn")          //每秒流入包数
		}
		time.Sleep(time.Hour * 24)
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/tasks/cloudTask/bucket_job.go
```golang
package cloudTask

import (
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct/object"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"k8s.io/klog/v2"
	"time"
)

func GetBucketInfo() {
	utils.GoSafe(BucketEightHourOneJob) // 1d  30d
}

// 每8小时执行一次
func BucketEightHourOneJob() {
	klog.Infof("Start_of_script_execution_%s_%d", "BUCKET", time.Now().Unix())
	for {
		object.GetTopBuckets("CDNTrafficUp")
		object.GetTopBuckets("CDNTrafficDown")
		object.GetTopBuckets("outNetTrafficUp")
		object.GetTopBuckets("outNetTrafficDown")
		object.GetTopBuckets("innerNetTrafficUp")
		object.GetTopBuckets("innerNetTrafficDown")
		object.GetTopBuckets("PUT")
		object.GetTopBuckets("GET")
		object.GetTopBuckets("rok")
		object.GetTopBuckets("wok")
		object.GetTopBuckets("codeErr")

		time.Sleep(time.Hour * 8)
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/tasks/cloudTask/nat_job.go
```golang
package cloudTask

import (
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"strconv"
	"sync"
	"time"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"k8s.io/klog/v2"
)

func GetNatTop(wg *sync.WaitGroup) {
	defer wg.Done()
	wg.Add(4)
	utils.GoSafe(func() { NatFiveMinutesJob(wg) }) // 5m点  0.5h/1h
	utils.GoSafe(func() { NatTenMinutesJob(wg) })  // 10m点 3h
	utils.GoSafe(func() { NatHourOneJob(wg) })     // 1h点  12h 1d 7d
	utils.GoSafe(func() { NatDayOneJob(wg) })      // 1d  30d
}

// Nat 同步0.5小时/1小时同步数据脚本
func NatFiveMinutesJob(wg *sync.WaitGroup) {
	klog.Infof("Start_of_script_execution_in_5_minutes_%s_%d", config.CloudNatResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{6, 12} //tsdb 0.5h/1h 所取点数
		endTime := time.Now().Unix()
		startTime := endTime - 3600
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//// 获取所有region Az数据
		paramList := SplicingCloudJobParam(config.CloudNatResource, start, end, interval)
		klog.Infof("Start_of_script_execution_in_5_minutes_%s: paramList %+v", config.CloudNatResource, paramList)
		// 执行异步脚本
		for _, param := range paramList {
			wg.Add(8)
			go SetFiveMinutes(wg, param, config.CloudNatResource, "NatBpsIn")        // nat带宽 入
			go SetFiveMinutes(wg, param, config.CloudNatResource, "NatBpsOut")       // nat带宽 出
			go SetFiveMinutes(wg, param, config.CloudNatResource, "NatPpsIn")        // nat每秒收发包次数  入
			go SetFiveMinutes(wg, param, config.CloudNatResource, "NatPpsOut")       // nat每秒收发包次数  出
			go SetFiveMinutes(wg, param, config.CloudNatResource, "NatBpsInPublic")  // nat带宽(公网)  入
			go SetFiveMinutes(wg, param, config.CloudNatResource, "NatBpsOutPublic") // nat带宽(公网)  出
			go SetFiveMinutes(wg, param, config.CloudNatResource, "NatPpsInPublic")  // nat每秒收发包次数(公网)  入
			go SetFiveMinutes(wg, param, config.CloudNatResource, "NatPpsOutPublic") // nat每秒收发包次数(公网)  出
		}
		time.Sleep(time.Minute * 5)
	}

}

func NatTenMinutesJob(wg *sync.WaitGroup) {
	klog.Infof("Start_of_script_execution_in_3_hour_%s_%d", config.CloudNatResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{18}        // 3 小时 10m 取一次 取18个点
		endTime := time.Now().Unix() // 当前时间
		startTime := endTime - 10800
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudNatResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(8)
			go SetTenMinutes(wg, param, config.CloudNatResource, "NatBpsIn")        // nat带宽 入
			go SetTenMinutes(wg, param, config.CloudNatResource, "NatBpsOut")       // nat带宽 出
			go SetTenMinutes(wg, param, config.CloudNatResource, "NatPpsIn")        // nat每秒收发包次数  入
			go SetTenMinutes(wg, param, config.CloudNatResource, "NatPpsOut")       // nat每秒收发包次数  出
			go SetTenMinutes(wg, param, config.CloudNatResource, "NatBpsInPublic")  // nat带宽(公网)  入
			go SetTenMinutes(wg, param, config.CloudNatResource, "NatBpsOutPublic") // nat带宽(公网)  出
			go SetTenMinutes(wg, param, config.CloudNatResource, "NatPpsInPublic")  // nat每秒收发包次数(公网)  入
			go SetTenMinutes(wg, param, config.CloudNatResource, "NatPpsOutPublic") // nat每秒收发包次数(公网)  出
		}
		time.Sleep(time.Minute * 10)
	}
}

func NatHourOneJob(wg *sync.WaitGroup) {
	klog.Infof("Start_of_script_execution_in_12_hour_%s_%d", config.CloudNatResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{12, 24, 168} // 12,24,168 取点数量
		endTime := time.Now().Unix()   // 当前时间
		startTime := endTime - 604800  // 7天前时间
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudNatResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(8)
			go SetOneHour(wg, param, config.CloudNatResource, "NatBpsIn")        // nat带宽 入
			go SetOneHour(wg, param, config.CloudNatResource, "NatBpsOut")       // nat带宽 出
			go SetOneHour(wg, param, config.CloudNatResource, "NatPpsIn")        // nat每秒收发包次数  入
			go SetOneHour(wg, param, config.CloudNatResource, "NatPpsOut")       // nat每秒收发包次数  出
			go SetOneHour(wg, param, config.CloudNatResource, "NatBpsInPublic")  // nat带宽(公网)  入
			go SetOneHour(wg, param, config.CloudNatResource, "NatBpsOutPublic") // nat带宽(公网)  出
			go SetOneHour(wg, param, config.CloudNatResource, "NatPpsInPublic")  // nat每秒收发包次数(公网)  入
			go SetOneHour(wg, param, config.CloudNatResource, "NatPpsOutPublic") // nat每秒收发包次数(公网)  出
		}
		time.Sleep(time.Minute * 60)
	}
}

func NatDayOneJob(wg *sync.WaitGroup) { // 30d
	klog.Infof("Start_of_script_execution_in_30_day_%s_%d", config.CloudNatResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{30}          //取点数量
		endTime := time.Now().Unix()   // 当前时间
		startTime := endTime - 2592000 // 7天前时间
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudNatResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(8)
			go SetOneDay(wg, param, config.CloudNatResource, "NatBpsIn")        // nat带宽 入
			go SetOneDay(wg, param, config.CloudNatResource, "NatBpsOut")       // nat带宽 出
			go SetOneDay(wg, param, config.CloudNatResource, "NatPpsIn")        // nat每秒收发包次数  入
			go SetOneDay(wg, param, config.CloudNatResource, "NatPpsOut")       // nat每秒收发包次数  出
			go SetOneDay(wg, param, config.CloudNatResource, "NatBpsInPublic")  // nat带宽(公网)  入
			go SetOneDay(wg, param, config.CloudNatResource, "NatBpsOutPublic") // nat带宽(公网)  出
			go SetOneDay(wg, param, config.CloudNatResource, "NatPpsInPublic")  // nat每秒收发包次数(公网)  入
			go SetOneDay(wg, param, config.CloudNatResource, "NatPpsOutPublic") // nat每秒收发包次数(公网)  出
		}
		time.Sleep(time.Hour * 24)
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/tasks/cloudTask/block_job.go
```golang
package cloudTask

import (
	"strconv"
	"sync"
	"time"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"k8s.io/klog/v2"
)

func GetBlockTop(wg *sync.WaitGroup) {
	defer wg.Done()
	wg.Add(4)
	utils.GoSafe(func() { BlockFiveMinutesJob(wg) })// 5m点  0.5h/1h
	utils.GoSafe(func() { BlockTenMinutesJob(wg) })// 10m点 3h
	utils.GoSafe(func() { BlockHourOneJob(wg) }) // 1h点  12h 1d 7d
	utils.GoSafe(func() { BlockDayOneJob(wg) })// 1d  30d
}

// 块存储 同步0.5小时/1小时同步数据脚本
func BlockFiveMinutesJob(wg *sync.WaitGroup) {
	klog.Infof("Start_of_script_execution_in_5_minutes_%s_%d", config.CloudBlockResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{6, 12} //tsdb 0.5h/1h 所取点数
		endTime := time.Now().Unix()
		startTime := endTime - 3600
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		// 获取所有region Az数据
		paramList := SplicingCloudJobParam(config.CloudBlockResource, start, end, interval)
		// 执行异步脚本
		for _, param := range paramList {
			wg.Add(4)
			go SetFiveMinutes(wg, param, config.CloudBlockResource, "BwInAvg")  // 带宽速率 写
			go SetFiveMinutes(wg, param, config.CloudBlockResource, "BwOutAvg") // 带宽速率 读
			go SetFiveMinutes(wg, param, config.CloudBlockResource, "IOIn")     // IO吞吐  写
			go SetFiveMinutes(wg, param, config.CloudBlockResource, "IOOut")    // IO吞吐  读
		}
		time.Sleep(time.Minute * 5)
	}
}

func BlockTenMinutesJob(wg *sync.WaitGroup) {
	klog.Infof("Start_of_script_execution_in_3_hour_%s_%d", config.CloudBlockResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{18}        // 3 小时 10m 取一次 取18个点
		endTime := time.Now().Unix() // 当前时间
		startTime := endTime - 10800
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudBlockResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(4)
			go SetTenMinutes(wg, param, config.CloudBlockResource, "BwInAvg")  // 带宽速率 写
			go SetTenMinutes(wg, param, config.CloudBlockResource, "BwOutAvg") // 带宽速率 读
			go SetTenMinutes(wg, param, config.CloudBlockResource, "IOIn")     // IO吞吐  写
			go SetTenMinutes(wg, param, config.CloudBlockResource, "IOOut")    // IO吞吐  读
		}
		time.Sleep(time.Minute * 10)
	}
}

func BlockHourOneJob(wg *sync.WaitGroup) {
	klog.Infof("Start_of_script_execution_in_12_hour_%s_%d", config.CloudBlockResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{12, 24, 168} // 12,24,168 取点数量
		endTime := time.Now().Unix()   // 当前时间
		startTime := endTime - 604800  // 7天前时间
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudBlockResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(4)
			go SetOneHour(wg, param, config.CloudBlockResource, "BwInAvg")  // 带宽速率 写
			go SetOneHour(wg, param, config.CloudBlockResource, "BwOutAvg") // 带宽速率 读
			go SetOneHour(wg, param, config.CloudBlockResource, "IOIn")     // IO吞吐  写
			go SetOneHour(wg, param, config.CloudBlockResource, "IOOut")    // IO吞吐  读
		}
		time.Sleep(time.Minute * 60)
	}
}

func BlockDayOneJob(wg *sync.WaitGroup) {
	klog.Infof("Start_of_script_execution_in_30_day_%s_%d", config.CloudBlockResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{30}          //取点数量
		endTime := time.Now().Unix()   // 当前时间
		startTime := endTime - 2592000 // 7天前时间
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudBlockResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(4)
			go SetOneDay(wg, param, config.CloudBlockResource, "BwInAvg")  // 带宽速率 写
			go SetOneDay(wg, param, config.CloudBlockResource, "BwOutAvg") // 带宽速率 读
			go SetOneDay(wg, param, config.CloudBlockResource, "IOIn")     // IO吞吐  写
			go SetOneDay(wg, param, config.CloudBlockResource, "IOOut")    // IO吞吐  读
		}
		time.Sleep(time.Hour * 24)

	}

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/tasks/cloudTask/redis_job.go
```golang
package cloudTask

import (
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"k8s.io/klog/v2"
	"strconv"
	"sync"
	"time"
)

// GetRedisTop Redis top Job
func GetRedisTop(wg *sync.WaitGroup) {
	defer wg.Done()
	wg.Add(4)
	utils.GoSafe(func() { fiveMinutesJob(wg) })// 5m点  0.5h/1h
	utils.GoSafe(func() { tenMinutesJob(wg) })// 10m点 3h
	utils.GoSafe(func() { hourOneJob(wg) }) // 1h点  12h 1d 7d
	utils.GoSafe(func() { dayOneJob(wg) })// 1d  30d
}

// fiveMinutesJob 0.5小时/1小时同步数据脚本
func fiveMinutesJob(wg *sync.WaitGroup) { // 0.5h/1h
	klog.Infof("Start_of_script_execution_in_5_minutes_%s_%d", config.CloudRedisResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{6, 12} //tsdb 0.5h/1h 所取点数
		endTime := time.Now().Unix()
		startTime := endTime - 3600
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudRedisResource, start, end, interval)
		klog.Infof("DEBUG  -- paramList: %v", len(paramList))
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(8)
			utils.GoSafe(func() { SetFiveMinutes(wg, param, config.CloudRedisResource, "RedisCpuLoad") })          // cpu使用率
			utils.GoSafe(func() { SetFiveMinutes(wg, param, config.CloudRedisResource, "RedisMemoryLoad") })       // 内存使用量
			utils.GoSafe(func() { SetFiveMinutes(wg, param, config.CloudRedisResource, "DiskUsedRange") })         //缺-磁盘使用量
			utils.GoSafe(func() { SetFiveMinutes(wg, param, config.CloudRedisResource, "RedisIntranetInRatio") })  //网卡流量 入
			utils.GoSafe(func() { SetFiveMinutes(wg, param, config.CloudRedisResource, "RedisIntranetOutRatio") }) //网卡流量 出
			utils.GoSafe(func() { SetFiveMinutes(wg, param, config.CloudRedisResource, "RedisConnectionUsage") })  //连接数
			utils.GoSafe(func() { SetFiveMinutes(wg, param, config.CloudRedisResource, "RedisHitRate") })          //缓存命中率
			utils.GoSafe(func() { SetFiveMinutes(wg, param, config.CloudRedisResource, "RedisSlowlogLen") })       //慢查询数量
		}
		time.Sleep(time.Minute * 5)
	}
}

//tenMinutesJob 3h同步数据脚本
func tenMinutesJob(wg *sync.WaitGroup) { //3h
	klog.Infof("Start_of_script_execution_in_3_hour_%s_%d", config.CloudRedisResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{18}        // 3 小时 10m 取一次 取18个点
		endTime := time.Now().Unix() // 当前时间
		startTime := endTime - 10800
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudRedisResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(8)
			//go SetTenMinutes(wg, param, config.CloudRedisResource, "RedisCpuLoad")
			//go SetTenMinutes(wg, param, config.CloudRedisResource, "RedisMemoryLoad")
			//go SetTenMinutes(wg, param, config.CloudRedisResource, "DiskUsedRange")
			utils.GoSafe(func() { SetTenMinutes(wg, param, config.CloudRedisResource, "RedisCpuLoad") })          // cpu使用率
			utils.GoSafe(func() { SetTenMinutes(wg, param, config.CloudRedisResource, "RedisMemoryLoad") })       // 内存使用量
			utils.GoSafe(func() { SetTenMinutes(wg, param, config.CloudRedisResource, "DiskUsedRange") })         //缺-磁盘使用量
			utils.GoSafe(func() { SetTenMinutes(wg, param, config.CloudRedisResource, "RedisIntranetInRatio") })  //网卡流量 入
			utils.GoSafe(func() { SetTenMinutes(wg, param, config.CloudRedisResource, "RedisIntranetOutRatio") }) //网卡流量 出
			utils.GoSafe(func() { SetTenMinutes(wg, param, config.CloudRedisResource, "RedisConnectionUsage") })  //连接数
			utils.GoSafe(func() { SetTenMinutes(wg, param, config.CloudRedisResource, "RedisHitRate") })          //缓存命中率
			utils.GoSafe(func() { SetTenMinutes(wg, param, config.CloudRedisResource, "RedisSlowlogLen") })       //慢查询数量
		}
		time.Sleep(time.Minute * 10)
	}
}

//hourOneJob 同步数据脚本12h/ 1d /7d
func hourOneJob(wg *sync.WaitGroup) { // 12h/ 1d /7d
	klog.Infof("Start_of_script_execution_in_12_hour_%s_%d", config.CloudRedisResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{12, 24, 168} // 12,24,168 取点数量
		endTime := time.Now().Unix()   // 当前时间
		startTime := endTime - 604800  // 7天前时间
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudRedisResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(8)
			utils.GoSafe(func() { SetOneHour(wg, param, config.CloudRedisResource, "RedisCpuLoad") })          // cpu使用率
			utils.GoSafe(func() { SetOneHour(wg, param, config.CloudRedisResource, "RedisMemoryLoad") })       // 内存使用量
			utils.GoSafe(func() { SetOneHour(wg, param, config.CloudRedisResource, "DiskUsedRange") })         //缺-磁盘使用量
			utils.GoSafe(func() { SetOneHour(wg, param, config.CloudRedisResource, "RedisIntranetInRatio") })  //网卡流量 入
			utils.GoSafe(func() { SetOneHour(wg, param, config.CloudRedisResource, "RedisIntranetOutRatio") }) //网卡流量 出
			utils.GoSafe(func() { SetOneHour(wg, param, config.CloudRedisResource, "RedisConnectionUsage") })  //连接数
			utils.GoSafe(func() { SetOneHour(wg, param, config.CloudRedisResource, "RedisHitRate") })          //缓存命中率
			utils.GoSafe(func() { SetOneHour(wg, param, config.CloudRedisResource, "RedisSlowlogLen") })       //慢查询数量
		}
		time.Sleep(time.Minute * 60)
	}
}

// dayOneJob 30d同步数据脚本
func dayOneJob(wg *sync.WaitGroup) { // 30d
	klog.Infof("Start_of_script_execution_in_30_day_%s_%d", config.CloudRedisResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{30}          //取点数量
		endTime := time.Now().Unix()   // 当前时间
		startTime := endTime - 2592000 // 7天前时间
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudRedisResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(8)
			utils.GoSafe(func() { SetOneDay(wg, param, config.CloudRedisResource, "RedisCpuLoad") })          // cpu使用率
			utils.GoSafe(func() { SetOneDay(wg, param, config.CloudRedisResource, "RedisMemoryLoad") })       // 内存使用量
			utils.GoSafe(func() { SetOneDay(wg, param, config.CloudRedisResource, "DiskUsedRange") })         //缺-磁盘使用量
			utils.GoSafe(func() { SetOneDay(wg, param, config.CloudRedisResource, "RedisIntranetInRatio") })  //网卡流量 入
			utils.GoSafe(func() { SetOneDay(wg, param, config.CloudRedisResource, "RedisIntranetOutRatio") }) //网卡流量 出
			utils.GoSafe(func() { SetOneDay(wg, param, config.CloudRedisResource, "RedisConnectionUsage") })  //连接数
			utils.GoSafe(func() { SetOneDay(wg, param, config.CloudRedisResource, "RedisHitRate") })          //缓存命中率
			utils.GoSafe(func() { SetOneDay(wg, param, config.CloudRedisResource, "RedisSlowlogLen") })       //慢查询数量
		}
		time.Sleep(time.Hour * 24)
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/tasks/cloudTask/task_model.go
```golang
package cloudTask

type JobParam struct {
	Region   string
	Az       string
	List     string //[]cmdbmodel.CmdbVm
	Start    string
	End      string
	Interval []int
}

//请求资源列表参数
type HostUrlPost struct {
	PageNo     int      `json:"pageNo"`
	PageSize   int      `json:"pageSize"`
	Region     string   `json:"region"`
	Az         []string `json:"az"`
	AzCodeList []string `json:"azCodeList"`// mysql redis 获取数据时参数不是az
}

//云主机
type VmValueType struct {
	Value      interface{} `json:"value"` //值
	Name       string      `json:"name"`  // 名称
	Timestamep string      `json:"timestamep"`
	SubName    string      `json:"subName"`    //子名称
	Id         string      `json:"Id"`         // 实例id
	RegionCode string      `json:"regionCode"` // region
	Az         string      `json:"azCode"`     //Az
	Status     string      `json:"status"`     // 筛选运行状态
}

// 块存储
type BlockValueType struct {
	Value       interface{} `json:"value"` //值
	Name        string      `json:"name"`  // 名称
	Timestamep  string      `json:"timestamep"`
	SubName     string      `json:"subName"`          //子名称
	Id          string      `json:"instanceId"`       // 实例id
	RegionCode  string      `json:"regionCode"`       // region
	Az          string      `json:"azCode"`           //Az
	Status      string      `json:"useStatus"`        // 筛选使用状态
	StorageType string      `json:"resourcePoolType"` // 存储类型
	VmId        string      `json:"vmId"`
}

//Redis
type RdValueType struct {
	Value      interface{} `json:"value"` //值
	Name       string      `json:"name"`  // 名称
	Timestamep string      `json:"timestamep"`
	SubName    string      `json:"subName"`    //子名称
	Id         string      `json:"Id"`         // 实例id
	RegionCode string      `json:"regionCode"` // region
	Az         string      `json:"azCode"`     //Az
	Status     string      `json:"status"`     // 筛选运行状态
}

//// MySQL
//type MysqlValueType struct {
//	Value      interface{} `json:"value"` //值
//	Name       string      `json:"name"`  // 名称
//	Timestamep string      `json:"timestamep"`
//	SubName    string      `json:"subName"`    //子名称
//	Id         string      `json:"id"`         // 实例id
//	RegionCode string      `json:"regionCode"` // region
//	Az         string      `json:"azCode"`     //Az
//	Status     string      `json:"status"`     // 筛选运行状态
//}

//load
type LoadValueType struct {
	Value      interface{} `json:"value"` //值
	Name       string      `json:"name"`  // 名称
	Timestamep string      `json:"timestamep"`
	SubName    string      `json:"subName"` //子名称
	Id         string      `json:"id"`      // 实例id
	RegionCode string      `json:"region"`  // region
	Az         string      `json:"azCode"`  //Az
	Eip        string      `json:"eip"`
	Status     string      `json:"status"`
}

// NAT
type NatValueType struct {
	Value        interface{} `json:"value"` //值
	InstanceName string      `json:"instanceName"`
	Name         string      `json:"name"` // 名称
	Timestamep   string      `json:"timestamep"`
	SubName      string      `json:"subName"` //子名称
	Id           string      `json:"Id"`      // 实例id
	InstanceId   string      `json:"instanceId"`
	VmId         string      `json:"vmId"`
	RegionCode   string      `json:"regionCode"` // region
	Az           string      `json:"azCode"`     //Az
	VpcName      string      `json:"vpcName"`    //所属VPC
	Scope        string      `json:"scope"`      //作用范围
	NatType      string      `json:"natType"`    //类型
	TenantId     string      `json:"tenantId"`   //租户ID
	TenantName   string      `json:"tenantName"` //租户名称

}

type CmdbVm struct {
	ID   string `json:"id"`
	Name string `json:"name"`
	//Flavor     interface{} `json:"flavor"`
	Flavor     string `json:"flavor"`
	Status     string `json:"status"`
	Aggregate  string `json:"aggregate"`
	Region     string `json:"region"`
	RegionCode string `json:"regionCode"`
	Az         string `json:"az"`
	AzCode     string `json:"azCode"`
	TenantId   string `json:"tenantId"`
	TenantName string `json:"tenantName"`
	Hypervisor string `json:"hypervisor"`
	InnerIP    string `json:"innerIp"`
	PublicIP   string `json:"publicIp"`
	//CreateTime time.Time `json:"createTime"`
	CreateTime int         `json:"createTime"`
	Value      interface{} `json:"value"`
	MetricDir  []string    `json:"metricDir"`
}

//Eip
type EipValueType struct {
	Value      interface{} `json:"value"` //值
	Name       string      `json:"name"`  // 名称
	Timestamep string      `json:"timestamep"`
	SubName    string      `json:"subName"`    //子名称
	Id         string      `json:"Id"`         // 实例id
	RegionCode string      `json:"regionCode"` // region
	Az         string      `json:"azCode"`     //Az
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/tasks/cloudTask/load_job.go
```golang
package cloudTask

import (
	"fmt"
	"strconv"
	"sync"
	"time"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"k8s.io/klog/v2"
)

func GetLoadTop(wg *sync.WaitGroup) {
	defer wg.Done()
	wg.Add(4)
	utils.GoSafe(func() { LoadFiveMinutesJob(wg) })// 5m点  0.5h/1h
	utils.GoSafe(func() { LoadTenMinutesJob(wg) })// 10m点 3h
	utils.GoSafe(func() { LoadHourOneJob(wg) }) // 1h点  12h 1d 7d
	utils.GoSafe(func() { LoadDayOneJob(wg) })// 1d  30d
}

// FiveMinutesJob 0.5小时/1小时同步数据脚本
func LoadFiveMinutesJob(wg *sync.WaitGroup) { // 0.5h/1h
	klog.Infof("Start_of_script_execution_in_5_minutes_%s_%d", config.CloudLoadResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{6, 12} //tsdb 0.5h/1h 所取点数
		endTime := time.Now().Unix()
		startTime := endTime - 3600
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudLoadResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(14)
			go SetFiveMinutes(wg, param, config.CloudLoadResource, "SlbBpsIn")          // 入网带宽
			go SetFiveMinutes(wg, param, config.CloudLoadResource, "SlbBpsOut")         // 出网带宽
			go SetFiveMinutes(wg, param, config.CloudLoadResource, "SlbPpsIn")          // 每秒流入包数
			go SetFiveMinutes(wg, param, config.CloudLoadResource, "SlbPpsOut")         //每秒流出包数
			go SetFiveMinutes(wg, param, config.CloudLoadResource, "SlbCps")            // 每秒新建连接数
			go SetFiveMinutes(wg, param, config.CloudLoadResource, "SlbActiveconn")     // 活跃连接数
			go SetFiveMinutes(wg, param, config.CloudLoadResource, "SlbConcurrentconn") //并发连接数
			go SetFiveMinutes(wg, param, config.CloudLoadResource, "SlbInactiveconn")   // 不活跃连接数
			go SetFiveMinutes(wg, param, config.CloudLoadResource, "EipBpsIn")          //入网带宽
			go SetFiveMinutes(wg, param, config.CloudLoadResource, "EipBpsOut")         //出网带宽
			go SetFiveMinutes(wg, param, config.CloudLoadResource, "EipPpsIn")          //每秒流入包数
			go SetFiveMinutes(wg, param, config.CloudLoadResource, "EipPpsOut")         //每秒流出包数
			go SetFiveMinutes(wg, param, config.CloudLoadResource, "EipUtilizationIn")  //入带宽百分比
			go SetFiveMinutes(wg, param, config.CloudLoadResource, "EipUtilizationOut") //出带宽百分比
		}
		time.Sleep(time.Minute * 5)
	}
}

//TenMinutesJob 3h同步数据脚本
func LoadTenMinutesJob(wg *sync.WaitGroup) { //3h
	klog.Infof("Start_of_script_execution_in_3_hour_%s_%d", config.CloudLoadResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{18}        // 3 小时 10m 取一次 取18个点
		endTime := time.Now().Unix() // 当前时间
		startTime := endTime - 10800
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudLoadResource, start, end, interval)
		fmt.Println(paramList,len(paramList))
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(14)
			go SetTenMinutes(wg, param, config.CloudLoadResource, "SlbBpsIn")          // 入网带宽
			go SetTenMinutes(wg, param, config.CloudLoadResource, "SlbBpsOut")         // 出网带宽
			go SetTenMinutes(wg, param, config.CloudLoadResource, "SlbPpsIn")          // 每秒流入包数
			go SetTenMinutes(wg, param, config.CloudLoadResource, "SlbPpsOut")         //每秒流出包数
			go SetTenMinutes(wg, param, config.CloudLoadResource, "SlbCps")            // 每秒新建连接数
			go SetTenMinutes(wg, param, config.CloudLoadResource, "SlbActiveconn")     // 活跃连接数
			go SetTenMinutes(wg, param, config.CloudLoadResource, "SlbConcurrentconn") //并发连接数
			go SetTenMinutes(wg, param, config.CloudLoadResource, "SlbInactiveconn")   // 不活跃连接数
			go SetTenMinutes(wg, param, config.CloudLoadResource, "EipBpsIn")          //入网带宽（公网）
			go SetTenMinutes(wg, param, config.CloudLoadResource, "EipBpsOut")         //出网带宽（公网）
			go SetTenMinutes(wg, param, config.CloudLoadResource, "EipPpsIn")          //每秒流入包数（公网）
			go SetTenMinutes(wg, param, config.CloudLoadResource, "EipPpsOut")         //每秒流出包数（公网）
			go SetTenMinutes(wg, param, config.CloudLoadResource, "EipUtilizationIn")  //入带宽百分比（公网）
			go SetTenMinutes(wg, param, config.CloudLoadResource, "EipUtilizationOut") //出带宽百分比（公网）
		}
		time.Sleep(time.Minute * 10)
	}
}

//HourOneJob 同步数据脚本12h/ 1d /7d
func LoadHourOneJob(wg *sync.WaitGroup) { // 12h/ 1d /7d
	klog.Infof("Start_of_script_execution_in_12_hour_%s_%d", config.CloudLoadResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{12, 24, 168} // 12,24,168 取点数量
		endTime := time.Now().Unix()   // 当前时间
		startTime := endTime - 604800  // 7天前时间
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudLoadResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(14)
			go SetOneHour(wg, param, config.CloudLoadResource, "SlbBpsIn")          // 入网带宽
			go SetOneHour(wg, param, config.CloudLoadResource, "SlbBpsOut")         // 出网带宽
			go SetOneHour(wg, param, config.CloudLoadResource, "SlbPpsIn")          // 每秒流入包数
			go SetOneHour(wg, param, config.CloudLoadResource, "SlbPpsOut")         //每秒流出包数
			go SetOneHour(wg, param, config.CloudLoadResource, "SlbCps")            // 每秒新建连接数
			go SetOneHour(wg, param, config.CloudLoadResource, "SlbActiveconn")     // 活跃连接数
			go SetOneHour(wg, param, config.CloudLoadResource, "SlbConcurrentconn") //并发连接数
			go SetOneHour(wg, param, config.CloudLoadResource, "SlbInactiveconn")   // 不活跃连接数
			go SetOneHour(wg, param, config.CloudLoadResource, "EipBpsIn")          //入网带宽
			go SetOneHour(wg, param, config.CloudLoadResource, "EipBpsOut")         //出网带宽
			go SetOneHour(wg, param, config.CloudLoadResource, "EipPpsIn")          //每秒流入包数
			go SetOneHour(wg, param, config.CloudLoadResource, "EipPpsOut")         //每秒流出包数
			go SetOneHour(wg, param, config.CloudLoadResource, "EipUtilizationIn")  //入带宽百分比
			go SetOneHour(wg, param, config.CloudLoadResource, "EipUtilizationOut") //出带宽百分比
		}
		time.Sleep(time.Minute * 60)
	}
}

// DayOneJob 30d同步数据脚本
func LoadDayOneJob(wg *sync.WaitGroup) { // 30d
	klog.Infof("Start_of_script_execution_in_30_day_%s_%d", config.CloudLoadResource, time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{30}          //取点数量
		endTime := time.Now().Unix()   // 当前时间
		startTime := endTime - 2592000 // 7天前时间
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudLoadResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(14)
			go SetOneDay(wg, param, config.CloudLoadResource, "SlbBpsIn")          // 入网带宽
			go SetOneDay(wg, param, config.CloudLoadResource, "SlbBpsOut")         // 出网带宽
			go SetOneDay(wg, param, config.CloudLoadResource, "SlbPpsIn")          // 每秒流入包数
			go SetOneDay(wg, param, config.CloudLoadResource, "SlbPpsOut")         //每秒流出包数
			go SetOneDay(wg, param, config.CloudLoadResource, "SlbCps")            // 每秒新建连接数
			go SetOneDay(wg, param, config.CloudLoadResource, "SlbActiveconn")     // 活跃连接数
			go SetOneDay(wg, param, config.CloudLoadResource, "SlbConcurrentconn") //并发连接数
			go SetOneDay(wg, param, config.CloudLoadResource, "SlbInactiveconn")   // 不活跃连接数
			go SetOneDay(wg, param, config.CloudLoadResource, "EipBpsIn")          //入网带宽
			go SetOneDay(wg, param, config.CloudLoadResource, "EipBpsOut")         //出网带宽
			go SetOneDay(wg, param, config.CloudLoadResource, "EipPpsIn")          //每秒流入包数
			go SetOneDay(wg, param, config.CloudLoadResource, "EipPpsOut")         //每秒流出包数
			go SetOneDay(wg, param, config.CloudLoadResource, "EipUtilizationIn")  //入带宽百分比
			go SetOneDay(wg, param, config.CloudLoadResource, "EipUtilizationOut") //出带宽百分比
		}
		time.Sleep(time.Hour * 24)
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/tasks/cloudTask/task_common.go
```golang
package cloudTask

import (
	"context"
	"encoding/json"
	vmmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cloudproduct"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/dbmsservice"
	"sync"
	"time"

	eipmodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/eip"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/dbmsmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/eip"

	redisclient "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	kts "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/ktsmanager"

	"k8s.io/klog/v2"
)

// 拼接所有rediskey条件
func SplicingCloudJobParam(resourcesType, start, end string, interval []int) []JobParam {
	paramList := []JobParam{}
	// 获取region列表
	regionList, err := cmdbmanager.ReadRegionFromCMDB()
	if err != nil {
		klog.Error("get_getRegions_fail", err)
	}
	//BLOCK 有region 有az
	//vm 有region 部分无az
	//MYSQL/REDIS 部分无region 无az
	for _, regin := range regionList.Data {
		// 循环拼接Az 组成redisKey集合
		if resourcesType == "VM" || resourcesType == "BLOCK" || resourcesType == "MYSQL" || resourcesType == "REDIS" { // 有Az筛选条件
			for _, az := range regin.ContainAzs {
				hostUrlPost := HostUrlPost{
					PageNo: 1,
					Region: regin.RegionCode,
					Az:     []string{az.AzCode},
				}
				// mysql redis 获取数据时参数不是az
				if resourcesType == "MYSQL" || resourcesType == "REDIS" {
					hostUrlPost.AzCodeList = []string{az.AzCode}
				}
				psram, _ := json.Marshal(hostUrlPost)
				// GetList 获取az下列表
				list := GetList(resourcesType, string(psram))
				if len(list) == 0 {
					continue
				}
				param := JobParam{
					Region:   regin.RegionCode,
					Az:       az.AzCode,
					List:     list,
					Start:    start,
					End:      end,
					Interval: interval,
				}
				paramList = append(paramList, param)
			}
		}
		// 无Az筛选条件 (部分VM数据无az)
		if resourcesType == "EIP" || resourcesType == "LOAD" || resourcesType == "NAT" || resourcesType == "Bm" || (resourcesType == "VM" && len(paramList) == 0) {
			hostUrlPost := HostUrlPost{
				PageNo: 1,
				Region: regin.RegionCode,
			}
			//EIP region 需要特殊处理
			if resourcesType == "EIP" {
				hostUrlPost.Region = regin.RegionCodeAggregate
			}
			psram, _ := json.Marshal(hostUrlPost)
			// GetList 获取region 下列表
			list := GetList(resourcesType, string(psram))
			//klog.Infof("RegionList_%s_Region_%s_%d", resourcesType, regin, len(paramList))
			if len(list) == 0 {
				continue
			}
			param := JobParam{
				Region:   regin.RegionCode,
				List:     list,
				Start:    start,
				End:      end,
				Interval: interval,
			}
			paramList = append(paramList, param)
		}
	}
	//mysql/redis 无region与az的
	if resourcesType == "MYSQL" || resourcesType == "REDIS" {
		psram, _ := json.Marshal(HostUrlPost{PageNo: 1})
		getList := GetList(resourcesType, string(psram))
		var rdList []vmmodel.CmdbTopVm
		err := json.Unmarshal([]byte(getList), &rdList)
		if err != nil {
			klog.Error("Parsing_RD_JSON_failed:", err)
		}
		var rdIds []vmmodel.CmdbTopVm
		for j := 0; j < len(rdList); j++ {
			instanceInfo := rdList[j]
			if instanceInfo.Region != "" {
				continue
			}
			rdIdsInfo := vmmodel.CmdbTopVm{
				ID:     instanceInfo.ID,
				Name:   instanceInfo.Name,
				Region: instanceInfo.Region,
				Az:     instanceInfo.Az,
			}
			rdIds = append(rdIds, rdIdsInfo)
		}
		if len(rdIds) > 0 {
			list1, _ := json.Marshal(rdIds)
			param := JobParam{
				List:     string(list1),
				Start:    start,
				End:      end,
				Interval: interval,
			}
			paramList = append(paramList, param)
		}

	}

	return paramList
}

// region=""获取所有数据的情况使用
func SplicingCloudJobParam2(resourcesType, start, end string, interval []int) []JobParam {
	paramList := []JobParam{}
	// 获取region列表
	regionList, err := cmdbmanager.ReadRegionFromCMDB()
	if err != nil {
		klog.Error("get_getRegions_fail", err)
	}

	regionList.Data = append(regionList.Data, cmdbmodel.Region{RegionCode: ""}) // 部分数据无region,添加空region确保数据可以获取到

	for _, regin := range regionList.Data {
		// 循环拼接Az 组成redisKey集合
		for _, az := range regin.ContainAzs {
			hostUrlPost := HostUrlPost{
				PageNo: 1,
				Region: regin.RegionCode,
				Az:     []string{az.AzCode},
			}
			psram, _ := json.Marshal(hostUrlPost)
			// GetList 获取az下列表
			list := GetList(resourcesType, string(psram))
			if len(list) == 0 {
				continue
			}
			param := JobParam{
				Region:   regin.RegionCode,
				Az:       az.AzCode,
				List:     list,
				Start:    start,
				End:      end,
				Interval: interval,
			}
			paramList = append(paramList, param)
		}

		if regin.RegionCode != "" {
			//Az下无数据 redisKey集合只包括region
			if len(paramList) == 0 {
				hostUrlPost := HostUrlPost{
					PageNo: 1,
					//PageSize: 10,
					Region: regin.RegionCode,
				}
				psram, _ := json.Marshal(hostUrlPost)
				// GetList 获取region 下列表
				list := GetList(resourcesType, string(psram))
				if len(list) == 0 {
					continue
				}
				param := JobParam{
					Region:   regin.RegionCode,
					List:     list,
					Start:    start,
					End:      end,
					Interval: interval,
				}
				paramList = append(paramList, param)
			}
		} else {
			hostUrlPost := HostUrlPost{
				PageNo: 1,
				//PageSize: 10,
				Region: regin.RegionCode,
			}
			psram, _ := json.Marshal(hostUrlPost)
			// GetList 获取region 下列表
			list := GetList(resourcesType, string(psram))
			if len(list) == 0 {
				continue
			}
			param := JobParam{
				Region:   regin.RegionCode,
				List:     list,
				Start:    start,
				End:      end,
				Interval: interval,
			}
			paramList = append(paramList, param)
		}

	}
	return paramList
}

// 获取资源列表
func GetList(resourcesType, hostUrlPost string) string {
	var listStr string
	switch resourcesType {
	case config.CloudVmResource: // 获取云主机列表
		var vmParam cmdbmodel.VmListPost
		// 解析云主机参数
		err := json.Unmarshal([]byte(hostUrlPost), &vmParam)
		if err != nil {
			klog.Error("Parsing_JSON_failed_", resourcesType)
		}
		// 获取云主机列表
		vmList, err := cmdbmanager.GetCMDBVmList(vmParam)
		klog.Infof("Vm_Param_vmList_len %s,%s ", vmParam, len(vmList.Data.DataList))
		if err != nil {
			klog.Error("get_vmList_failed_", resourcesType)
			return ""
		}
		list := vmList.Data.DataList
		if len(list) == 0 {
			return ""
		}
		list1, _ := json.Marshal(list)
		listStr = string(list1)
	case config.CloudBlockResource: //获取块存储列表
		var blockParam cmdbmodel.BlockListPost
		// 解析块存储参数
		err := json.Unmarshal([]byte(hostUrlPost), &blockParam)
		if err != nil {
			klog.Error("Parsing_JSON_failed_", resourcesType)
		}
		// 获取块存储列表
		blocklist, err := cmdbmanager.GetCMDBBlockList(blockParam)
		klog.Infof("Block_Param_blocklist_len %s,%s ", blockParam, len(blocklist.Data.DataList))
		// 过滤InstanceId为空的字段
		filterList := make([]cmdbmodel.CloudDiskData, 0)
		for _, v := range blocklist.Data.DataList {
			if v.VmId != "" {
				filterList = append(filterList, v)
			} else {
				continue
			}
		}
		blocklist.Data.DataList = filterList
		filterList = []cmdbmodel.CloudDiskData{}
		for _, v := range blocklist.Data.DataList {
			if v.UseStatus == "in-use" {
				filterList = append(filterList, v)
			} else {
				continue
			}
		}
		blocklist.Data.DataList = filterList
		filterList = []cmdbmodel.CloudDiskData{}
		for _, v := range blocklist.Data.DataList {
			if v.ResourcePoolType != "" {
				filterList = append(filterList, v)
			} else {
				continue
			}
		}
		blocklist.Data.DataList = filterList
		if err != nil {
			klog.Error("get_blockList_failed_", resourcesType)
			return ""
		}
		list := blocklist.Data.DataList
		if len(list) == 0 {
			return ""
		}
		list1, _ := json.Marshal(list)
		listStr = string(list1)
	case config.CloudEipResource: //获取Eip列表
		var eipParam eipmodels.EipListQuery
		// 解析块存储参数
		err := json.Unmarshal([]byte(hostUrlPost), &eipParam)
		if err != nil {
			klog.Error("Parsing_JSON_failed_", resourcesType)
		}
		eipParam.BoundState = []int{3} // 只获取以绑定以分配的
		eipParam.Region = ""
		cmdbEip, err := eip.GetCmdbEipList(eipParam)
		klog.Infof("Eip_Param_cmdbEip_len %s,%s ", eipParam, len(cmdbEip.Data.DataList))
		if err != nil {
			klog.Error("get_EipList_failed_", resourcesType, err)
			return ""
		}
		list := cmdbEip.Data.DataList
		if len(list) == 0 {
			return ""
		}
		var eipList []eipmodels.EipTop
		for _, v := range list {
			if v.IpAddr != "" && v.Id != "" {
				eipInfo := eipmodels.EipTop{}
				eipInfo.ID = "ksceip--" + v.Id
				eipInfo.Name = v.IpAddr
				eipList = append(eipList, eipInfo)
			}
		}
		list1, _ := json.Marshal(eipList)
		listStr = string(list1)
	case config.CloudLoadResource: // 获取负载均衡列表
		var loadParam cmdbmodel.GetLoadListParam
		// 解析负载均衡参数
		err := json.Unmarshal([]byte(hostUrlPost), &loadParam)
		if err != nil {
			klog.Error("Parsing_JSON_failed_", resourcesType)
		}
		// 获取负载均衡列表
		loadlist, err := cmdbmanager.GetLbList(loadParam)
		klog.Infof("Load_Param_loadlist_len %+v,%d ", loadParam, len(loadlist.Data.DataList))
		if err != nil {
			klog.Error("get_loadList_failed_", resourcesType)
			return ""
		}
		list := loadlist.Data.DataList
		var lodaIds []vmmodel.CmdbTopLoad
		for j := 0; j < len(list); j++ {
			instanceInfo := list[j]
			lodaIds = append(lodaIds, vmmodel.CmdbTopLoad{
				ID:     instanceInfo.InstanceID,
				Name:   instanceInfo.InstanceName,
				Region: instanceInfo.Region,
				Eip:    instanceInfo.Eip,
				Status: instanceInfo.State,
			})
		}
		list1, _ := json.Marshal(lodaIds)
		listStr = string(list1)
	case config.CloudMysqlResource:
		var mysqlParam dbmsservice.MysqlRequestParam
		err := json.Unmarshal([]byte(hostUrlPost), &mysqlParam)
		if err != nil {
			klog.Error("Parsing_JSON_failed_", resourcesType)
		}
		mysqlRes, err := dbmsmanager.GetDbMysqlList(mysqlParam)
		klog.Infof("Mysql_Param_mysqlRes_len %v,%d ", mysqlParam, len(mysqlRes.Data.DataList))
		if err != nil {
			klog.Error("get_mysqlRes_failed_", resourcesType)
			return ""
		}
		list := mysqlRes.Data.DataList
		if len(list) == 0 {
			return ""
		}
		var mysqlIds []vmmodel.CmdbTopVm
		for j := 0; j < len(list); j++ {
			instanceInfo := list[j]
			mysqlIds = append(mysqlIds, vmmodel.CmdbTopVm{
				ID:     instanceInfo.ID,
				Name:   instanceInfo.Name,
				Region: instanceInfo.RegionName,
				Az:     instanceInfo.AzName,
			})
		}
		list1, _ := json.Marshal(mysqlIds)
		listStr = string(list1)
	case config.CloudRedisResource: //获取Redis列表
		var redisParam dbmsservice.RedisRequestParam
		err := json.Unmarshal([]byte(hostUrlPost), &redisParam)
		if err != nil {
			klog.Error("Parsing_JSON_failed_", resourcesType)
		}
		redisRes, err := dbmsmanager.GetDbRedisList(redisParam)
		klog.Infof("Redis_Param_redisRes_len %v,%d ", redisParam, len(redisRes.Data.InstanceList))
		if err != nil {
			klog.Error("get_redisRes_failed_", resourcesType)
			return ""
		}
		list := redisRes.Data.InstanceList
		if len(list) == 0 {
			return ""
		}
		var redisIds []vmmodel.CmdbTopVm
		for j := 0; j < len(list); j++ {
			instanceInfo := list[j]
			redisIds = append(redisIds, vmmodel.CmdbTopVm{
				ID:     instanceInfo.ID,
				Name:   instanceInfo.Name,
				Region: instanceInfo.RegionName,
				Az:     instanceInfo.AzName,
			})
		}
		list1, _ := json.Marshal(redisIds)
		listStr = string(list1)
	case config.CloudNatResource: // 获取NAT列表
		var natParam cmdbmodel.GetNatListParam
		// 解析NAT参数
		err := json.Unmarshal([]byte(hostUrlPost), &natParam)
		if err != nil {
			klog.Error("Parsing_JSON_failed_", resourcesType)
		}
		natList, err := cmdbmanager.GetNatList(natParam)
		klog.Infof("Nat_Param_natList_len %+v,%d ", natParam, len(natList.Data.DataList))
		// 过滤字段
		// filterList := make([]cmdbmodel.NatInfo, 0)
		// for _, v := range natList.Data.DataList {
		// 	if v.InstanceId != "" {
		// 		filterList = append(filterList, v)
		// 	} else {
		// 		continue
		// 	}
		// }
		// natList.Data.DataList = filterList
		if err != nil {
			klog.Error("get_natList_failed_", resourcesType)
			return ""
		}
		list := natList.Data.DataList
		if len(list) == 0 {
			return ""
		}
		list1, _ := json.Marshal(list)
		listStr = string(list1)
	}
	return listStr
}

// 5m数据脚本
func SetFiveMinutes(wg *sync.WaitGroup, param JobParam, resourceType, metric string) {
	klog.Infof("Execution_Start_%s_%s_5m_%s_%s", resourceType, metric, param.Region, param.Az)
	//wg.Add(1)
	defer wg.Done()

	var (
		tirtyList   []interface{}
		scoresTirty []float64
		sixtyList   []interface{}
		scoresSixty []float64
	)

	switch resourceType {
	case config.CloudVmResource: // 云主机
		var vmList []VmValueType
		err := json.Unmarshal([]byte(param.List), &vmList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		tirtyList = make([]interface{}, len(vmList)) // 0.5h 列表
		scoresTirty = make([]float64, len(vmList))   //  0.5h scores
		sixtyList = make([]interface{}, len(vmList)) // 1h 列表
		scoresSixty = make([]float64, len(vmList))   // 1h scores

		for i, val := range vmList {
			scoresTirty[i] = 0
			scoresSixty[i] = 0
			var valueTirty VmValueType
			valueTirty.Name = val.Name
			valueTirty.Id = val.Id
			valueTirty.RegionCode = val.RegionCode
			valueTirty.Az = val.Az
			valueTirty.Status = val.Status
			valueTirty.Value = 0

			var valueSixty VmValueType
			valueSixty.Name = val.Name
			valueSixty.Id = val.Id
			valueSixty.RegionCode = val.RegionCode
			valueSixty.Az = val.Az
			valueSixty.Status = val.Status
			valueSixty.Value = 0
			//获取当前metric 对应redis key
			cpuLoad := []string{metric}
			//获取tsdb数据
			oo := kts.QueryVmMetricTop(val.Id, param.Start, param.End, cpuLoad, param.Interval)
			klog.Infof("Vm_Metric_VM", metric, oo)
			if len(oo) > 0 {
				// 获取数据平均值
				values := oo[0].Avg
				scoresTirty[i] = values[6]
				valueTirty.Value = values[6]
				scoresSixty[i] = values[12]
				valueSixty.Value = values[12]
			}
			vmtTirtyListByte, _ := json.Marshal(valueTirty)
			tirtyList[i] = vmtTirtyListByte
			vmSixtyListByte, _ := json.Marshal(valueSixty)
			sixtyList[i] = vmSixtyListByte
		}
	case config.CloudBlockResource:
		var blockList []BlockValueType
		err := json.Unmarshal([]byte(param.List), &blockList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		tirtyList = make([]interface{}, len(blockList)) // 0.5h 列表
		scoresTirty = make([]float64, len(blockList))   //  0.5h scores
		sixtyList = make([]interface{}, len(blockList)) // 1h 列表
		scoresSixty = make([]float64, len(blockList))   // 1h scores

		for i, val := range blockList {
			scoresTirty[i] = 0
			scoresSixty[i] = 0
			var valueTirty BlockValueType
			valueTirty.Name = val.Name
			valueTirty.Id = val.Id
			valueTirty.RegionCode = val.RegionCode
			valueTirty.Az = val.Az
			valueTirty.Status = val.Status
			valueTirty.Value = 0
			valueTirty.VmId = val.VmId
			valueTirty.StorageType = val.StorageType

			var valueSixty BlockValueType
			valueSixty.Name = val.Name
			valueSixty.Id = val.Id
			valueSixty.RegionCode = val.RegionCode
			valueSixty.Az = val.Az
			valueSixty.Status = val.Status
			valueSixty.Value = 0
			valueSixty.StorageType = val.StorageType
			valueTirty.VmId = val.VmId

			//获取当前metric 对应redis key
			DiskUsed := []string{metric}
			//获取tsdb数据
			oo := kts.QueryBlockMetricTop(val.VmId, param.Start, param.End, DiskUsed, param.Interval) // 此处修改
			if len(oo) > 0 {
				// 获取数据平均值
				values := oo[0].Avg
				scoresTirty[i] = values[6]
				valueTirty.Value = values[6]
				scoresSixty[i] = values[12]
				valueSixty.Value = values[12]
			}
			blockTirtyListByte, _ := json.Marshal(valueTirty)
			tirtyList[i] = blockTirtyListByte
			blockSixtyListByte, _ := json.Marshal(valueSixty)
			sixtyList[i] = blockSixtyListByte
		}
	case config.CloudEipResource:
		var eipList []EipValueType
		err := json.Unmarshal([]byte(param.List), &eipList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		tirtyList = make([]interface{}, len(eipList)) // 0.5h 列表
		scoresTirty = make([]float64, len(eipList))   //  0.5h scores
		sixtyList = make([]interface{}, len(eipList)) // 1h 列表
		scoresSixty = make([]float64, len(eipList))   // 1h scores

		for i, val := range eipList {
			scoresTirty[i] = 0
			scoresSixty[i] = 0
			var valueTirty EipValueType
			valueTirty.Name = val.Name
			valueTirty.Id = val.Id
			valueTirty.RegionCode = val.RegionCode
			valueTirty.Az = val.Az
			valueTirty.Value = 0

			var valueSixty EipValueType
			valueSixty.Name = val.Name
			valueSixty.Id = val.Id
			valueSixty.RegionCode = val.RegionCode
			valueSixty.Az = val.Az
			valueSixty.Value = 0
			//获取当前metric 对应redis key
			metrics := []string{metric}
			//获取tsdb数据
			oo := kts.QueryEipMetricTop(val.Id, param.Start, param.End, metrics, param.Interval)
			if len(oo) > 0 {
				// 获取数据平均值
				values := oo[0].Avg
				scoresTirty[i] = values[6]
				valueTirty.Value = values[6]
				scoresSixty[i] = values[12]
				valueSixty.Value = values[12]
			}
			vmtTirtyListByte, _ := json.Marshal(valueTirty)
			tirtyList[i] = vmtTirtyListByte
			vmSixtyListByte, _ := json.Marshal(valueSixty)
			sixtyList[i] = vmSixtyListByte
		}
	case config.CloudRedisResource:
		var redisList []RdValueType
		err := json.Unmarshal([]byte(param.List), &redisList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		tirtyList = make([]interface{}, len(redisList)) // 0.5h 列表
		scoresTirty = make([]float64, len(redisList))   //  0.5h scores
		sixtyList = make([]interface{}, len(redisList)) // 1h 列表
		scoresSixty = make([]float64, len(redisList))   // 1h scores

		for i, val := range redisList {
			scoresTirty[i] = 0
			scoresSixty[i] = 0
			var valueTirty RdValueType
			valueTirty.Name = val.Name
			valueTirty.Id = val.Id
			valueTirty.RegionCode = val.RegionCode
			valueTirty.Az = val.Az
			valueTirty.Status = val.Status
			valueTirty.Value = 0

			var valueSixty RdValueType
			valueSixty.Name = val.Name
			valueSixty.Id = val.Id
			valueSixty.RegionCode = val.RegionCode
			valueSixty.Az = val.Az
			valueSixty.Status = val.Status
			valueSixty.Value = 0
			//获取当前metric 对应redis key
			cpuLoad := []string{metric}
			//获取tsdb数据
			oo := kts.QueryRedisMetricTop(val.Id, param.Start, param.End, cpuLoad, param.Interval)
			if len(oo) > 0 {
				// 获取数据平均值
				values := oo[0].Avg
				scoresTirty[i] = values[6]
				valueTirty.Value = values[6]
				scoresSixty[i] = values[12]
				valueSixty.Value = values[12]
			}
			tirtyListByte, _ := json.Marshal(valueTirty)
			tirtyList[i] = tirtyListByte
			sixtyListByte, _ := json.Marshal(valueSixty)
			sixtyList[i] = sixtyListByte
		}
	case config.CloudMysqlResource:
		var mysqlList []RdValueType
		err := json.Unmarshal([]byte(param.List), &mysqlList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}

		tirtyList = make([]interface{}, len(mysqlList)) // 0.5h 列表
		scoresTirty = make([]float64, len(mysqlList))   //  0.5h scores
		sixtyList = make([]interface{}, len(mysqlList)) // 1h 列表
		scoresSixty = make([]float64, len(mysqlList))   // 1h scores

		for i, val := range mysqlList {
			scoresTirty[i] = 0
			scoresSixty[i] = 0
			var valueTirty RdValueType
			valueTirty.Name = val.Name
			valueTirty.Id = val.Id
			valueTirty.RegionCode = val.RegionCode
			valueTirty.Az = val.Az
			valueTirty.Status = val.Status
			valueTirty.Value = 0

			var valueSixty RdValueType
			valueSixty.Name = val.Name
			valueSixty.Id = val.Id
			valueSixty.RegionCode = val.RegionCode
			valueSixty.Az = val.Az
			valueSixty.Status = val.Status
			valueSixty.Value = 0
			//获取当前metric 对应redis key
			metrics := []string{metric}
			//获取tsdb数据
			oo := kts.QueryMysqlMetricTop(val.Id, param.Start, param.End, metrics, param.Interval)

			if len(oo) > 0 {
				// 获取数据平均值
				values := oo[0].Avg
				scoresTirty[i] = values[6]
				valueTirty.Value = values[6]
				scoresSixty[i] = values[12]
				valueSixty.Value = values[12]
			}
			mysqlTirtyListByte, _ := json.Marshal(valueTirty)
			tirtyList[i] = mysqlTirtyListByte
			mysqlSixtyListByte, _ := json.Marshal(valueSixty)
			sixtyList[i] = mysqlSixtyListByte
		}
	case config.CloudLoadResource:
		var loadList []LoadValueType
		err := json.Unmarshal([]byte(param.List), &loadList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		tirtyList = make([]interface{}, len(loadList)) // 0.5h 列表
		scoresTirty = make([]float64, len(loadList))   //  0.5h scores
		sixtyList = make([]interface{}, len(loadList)) // 1h 列表
		scoresSixty = make([]float64, len(loadList))   // 1h scores

		loadPublicList, err := LoadPublicList(metric, loadList)
		klog.Infof("loadPublicList", len(loadPublicList))
		if err != nil {
			klog.Error("get_load_loadPublicList_failed :", err)
		}
		if len(loadPublicList) > 0 {
			loadList = loadPublicList
		}
		klog.Infof("loadList", len(loadList))

		for i, val := range loadList {
			scoresTirty[i] = 0
			scoresSixty[i] = 0
			var valueTirty LoadValueType
			valueTirty.Name = val.Name
			valueTirty.Id = val.Id
			valueTirty.RegionCode = val.RegionCode
			valueTirty.Az = val.Az
			// valueTirty.Status = val.Status
			valueTirty.Value = 0

			var valueSixty LoadValueType
			valueSixty.Name = val.Name
			valueSixty.Id = val.Id
			valueSixty.RegionCode = val.RegionCode
			valueSixty.Az = val.Az
			// valueSixty.Status = val.Status
			valueSixty.Value = 0
			//获取当前metric 对应redis key
			cpuLoad := []string{metric}
			//获取tsdb数据
			oo := kts.QueryLoadMetricTop(val.Id, param.Start, param.End, cpuLoad, param.Interval)
			if len(oo) > 0 {
				// 获取数据平均值
				values := oo[0].Avg
				scoresTirty[i] = values[6]
				valueTirty.Value = values[6]
				scoresSixty[i] = values[12]
				valueSixty.Value = values[12]
			}
			loadTirtyListByte, _ := json.Marshal(valueTirty)
			tirtyList[i] = loadTirtyListByte
			loadSixtyListByte, _ := json.Marshal(valueSixty)
			sixtyList[i] = loadSixtyListByte
		}
	case config.CloudNatResource:
		var natList []NatValueType
		err := json.Unmarshal([]byte(param.List), &natList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		tirtyList = make([]interface{}, len(natList)) // 0.5h 列表
		scoresTirty = make([]float64, len(natList))   //  0.5h scores
		sixtyList = make([]interface{}, len(natList)) // 1h 列表
		scoresSixty = make([]float64, len(natList))   // 1h scores

		for i, val := range natList {
			scoresTirty[i] = 0
			scoresSixty[i] = 0
			var valueTirty NatValueType
			valueTirty.Value = 0
			valueTirty.InstanceName = val.InstanceName
			valueTirty.SubName = valueTirty.InstanceName
			valueTirty.Name = valueTirty.InstanceName
			valueTirty.InstanceId = val.InstanceId
			valueTirty.Id = valueTirty.InstanceId
			valueTirty.RegionCode = val.RegionCode
			valueTirty.Az = val.Az
			valueTirty.VpcName = val.VpcName
			valueTirty.Scope = val.Scope
			valueTirty.NatType = val.NatType
			valueTirty.TenantId = val.TenantId
			valueTirty.TenantName = val.TenantName
			valueTirty.VmId = "kscnat--" + valueTirty.InstanceId

			var valueSixty NatValueType
			valueSixty.Value = 0
			valueSixty.InstanceName = val.InstanceName
			valueSixty.SubName = valueSixty.InstanceName
			valueSixty.Name = valueSixty.InstanceName
			valueSixty.InstanceId = val.InstanceId
			valueSixty.Id = valueSixty.InstanceId
			valueSixty.RegionCode = val.RegionCode
			valueSixty.Az = val.Az
			valueSixty.VpcName = val.VpcName
			valueSixty.Scope = val.Scope
			valueSixty.NatType = val.NatType
			valueSixty.TenantId = val.TenantId
			valueSixty.TenantName = val.TenantName
			valueSixty.VmId = "kscnat---" + valueSixty.InstanceId

			//获取当前metric 对应redis key
			Nat := []string{metric}
			//获取tsdb数据
			oo := kts.QueryNatMetricTop(val.InstanceId, param.Start, param.End, Nat, param.Interval) // 此处修改
			if len(oo) > 0 {
				// 获取数据平均值
				values := oo[0].Avg
				scoresTirty[i] = values[6]
				valueTirty.Value = values[6]
				scoresSixty[i] = values[12]
				valueSixty.Value = values[12]
			}
			natTirtyListByte, _ := json.Marshal(valueTirty)
			tirtyList[i] = natTirtyListByte
			natSixtyListByte, _ := json.Marshal(valueSixty)
			sixtyList[i] = natSixtyListByte
		}
	}
	// 0.5h
	tirtyKeyCpu := config.CronjobPrefix + param.Region + param.Az + ":" + resourceType + ":" + metric + ":" + "30" // key
	//写入redis集合
	SetZAdd(tirtyKeyCpu, scoresTirty, tirtyList)
	// 1h
	sixtyKeyCpu := config.CronjobPrefix + param.Region + param.Az + ":" + resourceType + ":" + metric + ":" + "60" // key
	//写入redis集合
	SetZAdd(sixtyKeyCpu, scoresSixty, sixtyList)

	klog.Infof("Execution_End_%s_%s_5m_%s_%s", resourceType, metric, param.Region, param.Az)
}

// 10分钟数据脚本
func SetTenMinutes(wg *sync.WaitGroup, param JobParam, resourceType, metric string) {
	klog.Infof("Execution_Start_%s_%s_3h_%s_%s", resourceType, metric, param.Region, param.Az)
	//wg.Add(1)
	defer wg.Done()

	var (
		list   []interface{}
		scores []float64
	)
	switch resourceType {
	case config.CloudVmResource: // 云主机
		var vmList []VmValueType
		err := json.Unmarshal([]byte(param.List), &vmList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		list = make([]interface{}, len(vmList)) // 3h 列表
		scores = make([]float64, len(vmList))   // 3h scores
		for i, val := range vmList {
			scores[i] = 0
			var value VmValueType
			value.Name = val.Name
			value.Id = val.Id
			value.RegionCode = val.RegionCode
			value.Az = val.Az
			value.Status = val.Status
			value.Value = 0
			//获取当前metric 对应redis key
			cpuLoad := []string{metric}
			//获取tsdb数据
			oo := kts.QueryVmMetricTop(val.Id, param.Start, param.End, cpuLoad, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scores[i] = values[18]
				value.Value = values[18]
			}
			vmListByte, _ := json.Marshal(value)
			list[i] = vmListByte
		}
	case config.CloudBlockResource:
		var blockList []BlockValueType
		err := json.Unmarshal([]byte(param.List), &blockList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		list = make([]interface{}, len(blockList)) // 3h 列表
		scores = make([]float64, len(blockList))   // 3h scores
		for i, val := range blockList {
			scores[i] = 0
			var value BlockValueType
			value.Name = val.Name
			value.Id = val.Id
			value.RegionCode = val.RegionCode
			value.Az = val.Az
			value.Status = val.Status
			value.Value = 0
			value.StorageType = val.StorageType
			value.VmId = val.VmId
			//获取当前metric 对应redis key
			DiskUsed := []string{metric}
			//获取tsdb数据
			oo := kts.QueryBlockMetricTop(val.VmId, param.Start, param.End, DiskUsed, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scores[i] = values[18]
				value.Value = values[18]
			}
			blockListByte, _ := json.Marshal(value)
			list[i] = blockListByte
		}
	case config.CloudEipResource:
		var eipList []EipValueType
		err := json.Unmarshal([]byte(param.List), &eipList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		list = make([]interface{}, len(eipList)) // 3h 列表
		scores = make([]float64, len(eipList))   // 3h scores
		for i, val := range eipList {
			scores[i] = 0
			var value BlockValueType
			value.Name = val.Name
			value.Id = val.Id
			value.RegionCode = val.RegionCode
			value.Az = val.Az
			value.Value = 0
			//获取当前metric 对应redis key
			metrics := []string{metric}
			//获取tsdb数据
			oo := kts.QueryEipMetricTop(val.Id, param.Start, param.End, metrics, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scores[i] = values[18]
				value.Value = values[18]
			}
			listByte, _ := json.Marshal(value)
			list[i] = listByte
		}
	case config.CloudMysqlResource:
		var mysqlList []RdValueType
		err := json.Unmarshal([]byte(param.List), &mysqlList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		list = make([]interface{}, len(mysqlList)) // 3h 列表
		scores = make([]float64, len(mysqlList))   // 3h scores
		for i, val := range mysqlList {
			scores[i] = 0
			var value RdValueType
			value.Name = val.Name
			value.Id = val.Id
			value.RegionCode = val.RegionCode
			value.Az = val.Az
			value.Status = val.Status
			value.Value = 0
			//获取当前metric 对应redis key
			cpuLoad := []string{metric}
			//获取tsdb数据
			oo := kts.QueryMysqlMetricTop(val.Id, param.Start, param.End, cpuLoad, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scores[i] = values[18]
				value.Value = values[18]
			}
			mysqlListByte, _ := json.Marshal(value)
			list[i] = mysqlListByte
		}
	case config.CloudRedisResource:
		var redisList []RdValueType
		err := json.Unmarshal([]byte(param.List), &redisList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		list = make([]interface{}, len(redisList)) // 3h 列表
		scores = make([]float64, len(redisList))   // 3h scores
		for i, val := range redisList {
			scores[i] = 0
			var value RdValueType
			value.Name = val.Name
			value.Id = val.Id
			value.RegionCode = val.RegionCode
			value.Az = val.Az
			value.Status = val.Status
			value.Value = 0
			//获取当前metric 对应redis key
			DiskUsed := []string{metric}
			//获取tsdb数据
			oo := kts.QueryRedisMetricTop(val.Id, param.Start, param.End, DiskUsed, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scores[i] = values[18]
				value.Value = values[18]
			}
			redisListByte, _ := json.Marshal(value)
			list[i] = redisListByte
		}
	case config.CloudLoadResource:
		var loadList []LoadValueType
		err := json.Unmarshal([]byte(param.List), &loadList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		list = make([]interface{}, len(loadList)) // 3h 列表
		scores = make([]float64, len(loadList))   // 3h scores

		loadPublicList, err := LoadPublicList(metric, loadList)
		klog.Infof("loadPublicList", len(loadPublicList))
		if err != nil {
			klog.Error("get_load_loadPublicList_failed :", err)
		}
		if len(loadPublicList) > 0 {
			loadList = loadPublicList
		}
		klog.Infof("loadList", len(loadList))
		for i, val := range loadList {
			scores[i] = 0
			var value LoadValueType
			value.Name = val.Name
			value.Id = val.Id
			value.RegionCode = val.RegionCode
			value.Az = val.Az
			// value.Status = val.Status
			value.Value = 0
			//获取当前metric 对应redis key
			cpuLoad := []string{metric}
			//获取tsdb数据
			oo := kts.QueryLoadMetricTop(val.Id, param.Start, param.End, cpuLoad, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scores[i] = values[18]
				value.Value = values[18]
			}
			loadListByte, _ := json.Marshal(value)
			list[i] = loadListByte
		}
	case config.CloudNatResource:
		var natList []NatValueType
		err := json.Unmarshal([]byte(param.List), &natList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		list = make([]interface{}, len(natList)) // 3h 列表
		scores = make([]float64, len(natList))   // 3h scores
		for i, val := range natList {
			scores[i] = 0
			var value NatValueType
			value.InstanceName = val.InstanceName
			value.SubName = value.InstanceName
			value.Name = value.InstanceName
			value.InstanceId = val.InstanceId
			value.Id = value.InstanceId
			value.RegionCode = val.RegionCode
			value.Az = val.Az
			value.Value = 0
			value.VpcName = val.VpcName
			value.Scope = val.Scope
			value.NatType = val.NatType
			value.TenantId = val.TenantId
			value.TenantName = val.TenantName
			value.VmId = "kscnat--" + value.InstanceId
			//获取当前metric 对应redis key
			Nat := []string{metric}
			//获取tsdb数据
			oo := kts.QueryNatMetricTop(val.InstanceId, param.Start, param.End, Nat, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scores[i] = values[18]
				value.Value = values[18]
			}
			natListByte, _ := json.Marshal(value)
			list[i] = natListByte
		}
	}
	// 3h
	keyCpu := config.CronjobPrefix + param.Region + param.Az + ":" + resourceType + ":" + metric + ":" + "180" // key
	// 写入redis集合
	SetZAdd(keyCpu, scores, list)
	klog.Infof("Execution_End_%s_%s_3h_%s_%s", resourceType, metric, param.Region, param.Az)
}

// 12h/1d/7d数据脚本
func SetOneHour(wg *sync.WaitGroup, param JobParam, resourceType, metric string) {
	klog.Infof("Execution_Start_%s_%s_12h/1d/7d_%s_%s", resourceType, metric, param.Region, param.Az)
	//wg.Add(1)
	defer wg.Done()

	var (
		vmListTwelve   []interface{} // 12h 列表
		scoresTwelve   []float64     // 12h scores
		vmListOneDay   []interface{} // 1day 列表
		scoresOneDay   []float64     // 1day scores
		vmListSevenDay []interface{} // 72h 列表
		scoresSevenDay []float64     // 72h scores
	)

	switch resourceType {
	case config.CloudVmResource: // 云主机

		var vmList []VmValueType
		err := json.Unmarshal([]byte(param.List), &vmList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		vmListTwelve = make([]interface{}, len(vmList))   // 12h 列表
		scoresTwelve = make([]float64, len(vmList))       // 12h scores
		vmListOneDay = make([]interface{}, len(vmList))   // 1day 列表
		scoresOneDay = make([]float64, len(vmList))       // 1day scores
		vmListSevenDay = make([]interface{}, len(vmList)) // 72h 列表
		scoresSevenDay = make([]float64, len(vmList))     // 72h scores

		for i, val := range vmList {
			scoresTwelve[i] = 0
			scoresOneDay[i] = 0
			scoresSevenDay[i] = 0

			var twelveValue VmValueType
			twelveValue.Name = val.Name
			twelveValue.Id = val.Id
			twelveValue.RegionCode = val.RegionCode
			twelveValue.Az = val.Az
			twelveValue.Status = val.Status
			twelveValue.Value = 0

			var oneDayValue VmValueType
			oneDayValue.Name = val.Name
			oneDayValue.Id = val.Id
			oneDayValue.RegionCode = val.RegionCode
			oneDayValue.Az = val.Az
			oneDayValue.Status = val.Status
			oneDayValue.Value = 0

			var sevenDayValue VmValueType
			sevenDayValue.Name = val.Name
			sevenDayValue.Id = val.Id
			sevenDayValue.RegionCode = val.RegionCode
			sevenDayValue.Az = val.Az
			sevenDayValue.Status = val.Az
			sevenDayValue.Value = 0

			cpuLoad := []string{metric}
			oo := kts.QueryVmMetricTop(val.Id, param.Start, param.End, cpuLoad, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scoresTwelve[i] = values[12]
				twelveValue.Value = values[12]
				scoresOneDay[i] = values[24]
				oneDayValue.Value = values[24]
				scoresSevenDay[i] = values[168]
				sevenDayValue.Value = values[168]

			}
			vmListTwelveByte, _ := json.Marshal(twelveValue)
			vmListTwelve[i] = vmListTwelveByte
			vmListOneDayByte, _ := json.Marshal(oneDayValue)
			vmListOneDay[i] = vmListOneDayByte
			vmListSevenDayByte, _ := json.Marshal(sevenDayValue)
			vmListSevenDay[i] = vmListSevenDayByte
		}
	case config.CloudBlockResource:
		var blockList []BlockValueType
		err := json.Unmarshal([]byte(param.List), &blockList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		vmListTwelve = make([]interface{}, len(blockList))   // 12h 列表
		scoresTwelve = make([]float64, len(blockList))       // 12h scores
		vmListOneDay = make([]interface{}, len(blockList))   // 1day 列表
		scoresOneDay = make([]float64, len(blockList))       // 1day scores
		vmListSevenDay = make([]interface{}, len(blockList)) // 72h 列表
		scoresSevenDay = make([]float64, len(blockList))     // 72h scores

		for i, val := range blockList {
			scoresTwelve[i] = 0
			scoresOneDay[i] = 0
			scoresSevenDay[i] = 0

			var twelveValue BlockValueType
			twelveValue.Name = val.Name
			twelveValue.Id = val.Id
			twelveValue.RegionCode = val.RegionCode
			twelveValue.Az = val.Az
			twelveValue.Status = val.Status
			twelveValue.Value = 0
			twelveValue.StorageType = val.StorageType
			twelveValue.VmId = val.VmId

			var oneDayValue BlockValueType
			oneDayValue.Name = val.Name
			oneDayValue.Id = val.Id
			oneDayValue.RegionCode = val.RegionCode
			oneDayValue.Az = val.Az
			oneDayValue.Status = val.Status
			oneDayValue.Value = 0
			oneDayValue.StorageType = val.StorageType
			oneDayValue.VmId = val.VmId

			var sevenDayValue BlockValueType
			sevenDayValue.Name = val.Name
			sevenDayValue.Id = val.Id
			sevenDayValue.RegionCode = val.RegionCode
			sevenDayValue.Az = val.Az
			sevenDayValue.Status = val.Az
			sevenDayValue.Value = 0
			sevenDayValue.StorageType = val.StorageType
			sevenDayValue.VmId = val.VmId

			diskUsed := []string{metric}
			oo := kts.QueryBlockMetricTop(val.VmId, param.Start, param.End, diskUsed, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scoresTwelve[i] = values[12]
				twelveValue.Value = values[12]
				scoresOneDay[i] = values[24]
				oneDayValue.Value = values[24]
				scoresSevenDay[i] = values[168]
				sevenDayValue.Value = values[168]

			}
			vmListTwelveByte, _ := json.Marshal(twelveValue)
			vmListTwelve[i] = vmListTwelveByte
			vmListOneDayByte, _ := json.Marshal(oneDayValue)
			vmListOneDay[i] = vmListOneDayByte
			vmListSevenDayByte, _ := json.Marshal(sevenDayValue)
			vmListSevenDay[i] = vmListSevenDayByte
		}
	case config.CloudEipResource:
		var eipList []EipValueType
		err := json.Unmarshal([]byte(param.List), &eipList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		vmListTwelve = make([]interface{}, len(eipList))   // 12h 列表
		scoresTwelve = make([]float64, len(eipList))       // 12h scores
		vmListOneDay = make([]interface{}, len(eipList))   // 1day 列表
		scoresOneDay = make([]float64, len(eipList))       // 1day scores
		vmListSevenDay = make([]interface{}, len(eipList)) // 72h 列表
		scoresSevenDay = make([]float64, len(eipList))     // 72h scores

		for i, val := range eipList {
			scoresTwelve[i] = 0
			scoresOneDay[i] = 0
			scoresSevenDay[i] = 0

			var twelveValue EipValueType
			twelveValue.Name = val.Name
			twelveValue.Id = val.Id
			twelveValue.RegionCode = val.RegionCode
			twelveValue.Az = val.Az
			twelveValue.Value = 0

			var oneDayValue EipValueType
			oneDayValue.Name = val.Name
			oneDayValue.Id = val.Id
			oneDayValue.RegionCode = val.RegionCode
			oneDayValue.Az = val.Az
			oneDayValue.Value = 0

			var sevenDayValue EipValueType
			sevenDayValue.Name = val.Name
			sevenDayValue.Id = val.Id
			sevenDayValue.RegionCode = val.RegionCode
			sevenDayValue.Az = val.Az
			sevenDayValue.Value = 0

			cpuLoad := []string{metric}
			oo := kts.QueryEipMetricTop(val.Id, param.Start, param.End, cpuLoad, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scoresTwelve[i] = values[12]
				twelveValue.Value = values[12]
				scoresOneDay[i] = values[24]
				oneDayValue.Value = values[24]
				scoresSevenDay[i] = values[168]
				sevenDayValue.Value = values[168]

			}
			vmListTwelveByte, _ := json.Marshal(twelveValue)
			vmListTwelve[i] = vmListTwelveByte
			vmListOneDayByte, _ := json.Marshal(oneDayValue)
			vmListOneDay[i] = vmListOneDayByte
			vmListSevenDayByte, _ := json.Marshal(sevenDayValue)
			vmListSevenDay[i] = vmListSevenDayByte
		}
	case config.CloudMysqlResource:
		var mysqlList []RdValueType
		err := json.Unmarshal([]byte(param.List), &mysqlList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		vmListTwelve = make([]interface{}, len(mysqlList))   // 12h 列表
		scoresTwelve = make([]float64, len(mysqlList))       // 12h scores
		vmListOneDay = make([]interface{}, len(mysqlList))   // 1day 列表
		scoresOneDay = make([]float64, len(mysqlList))       // 1day scores
		vmListSevenDay = make([]interface{}, len(mysqlList)) // 72h 列表
		scoresSevenDay = make([]float64, len(mysqlList))     // 72h scores

		for i, val := range mysqlList {
			scoresTwelve[i] = 0
			scoresOneDay[i] = 0
			scoresSevenDay[i] = 0

			var twelveValue RdValueType
			twelveValue.Name = val.Name
			twelveValue.Id = val.Id
			twelveValue.RegionCode = val.RegionCode
			twelveValue.Az = val.Az
			twelveValue.Status = val.Status
			twelveValue.Value = 0

			var oneDayValue RdValueType
			oneDayValue.Name = val.Name
			oneDayValue.Id = val.Id
			oneDayValue.RegionCode = val.RegionCode
			oneDayValue.Az = val.Az
			oneDayValue.Status = val.Status
			oneDayValue.Value = 0

			var sevenDayValue RdValueType
			sevenDayValue.Name = val.Name
			sevenDayValue.Id = val.Id
			sevenDayValue.RegionCode = val.RegionCode
			sevenDayValue.Az = val.Az
			sevenDayValue.Status = val.Az
			sevenDayValue.Value = 0

			cpuLoad := []string{metric}
			oo := kts.QueryMysqlMetricTop(val.Id, param.Start, param.End, cpuLoad, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scoresTwelve[i] = values[12]
				twelveValue.Value = values[12]
				scoresOneDay[i] = values[24]
				oneDayValue.Value = values[24]
				scoresSevenDay[i] = values[168]
				sevenDayValue.Value = values[168]

			}
			mysqlListTwelveByte, _ := json.Marshal(twelveValue)
			vmListTwelve[i] = mysqlListTwelveByte
			mysqlListOneDayByte, _ := json.Marshal(oneDayValue)
			vmListOneDay[i] = mysqlListOneDayByte
			mysqlListSevenDayByte, _ := json.Marshal(sevenDayValue)
			vmListSevenDay[i] = mysqlListSevenDayByte
		}
	case config.CloudRedisResource:
		var redisList []RdValueType
		err := json.Unmarshal([]byte(param.List), &redisList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		vmListTwelve = make([]interface{}, len(redisList))   // 12h 列表
		scoresTwelve = make([]float64, len(redisList))       // 12h scores
		vmListOneDay = make([]interface{}, len(redisList))   // 1day 列表
		scoresOneDay = make([]float64, len(redisList))       // 1day scores
		vmListSevenDay = make([]interface{}, len(redisList)) // 72h 列表
		scoresSevenDay = make([]float64, len(redisList))     // 72h scores

		for i, val := range redisList {
			scoresTwelve[i] = 0
			scoresOneDay[i] = 0
			scoresSevenDay[i] = 0

			var twelveValue RdValueType
			twelveValue.Name = val.Name
			twelveValue.Id = val.Id
			twelveValue.RegionCode = val.RegionCode
			twelveValue.Az = val.Az
			twelveValue.Status = val.Status
			twelveValue.Value = 0

			var oneDayValue RdValueType
			oneDayValue.Name = val.Name
			oneDayValue.Id = val.Id
			oneDayValue.RegionCode = val.RegionCode
			oneDayValue.Az = val.Az
			oneDayValue.Status = val.Status
			oneDayValue.Value = 0

			var sevenDayValue RdValueType
			sevenDayValue.Name = val.Name
			sevenDayValue.Id = val.Id
			sevenDayValue.RegionCode = val.RegionCode
			sevenDayValue.Az = val.Az
			sevenDayValue.Status = val.Az
			sevenDayValue.Value = 0

			diskUsed := []string{metric}
			oo := kts.QueryRedisMetricTop(val.Id, param.Start, param.End, diskUsed, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scoresTwelve[i] = values[12]
				twelveValue.Value = values[12]
				scoresOneDay[i] = values[24]
				oneDayValue.Value = values[24]
				scoresSevenDay[i] = values[168]
				sevenDayValue.Value = values[168]

			}
			vmListTwelveByte, _ := json.Marshal(twelveValue)
			vmListTwelve[i] = vmListTwelveByte
			vmListOneDayByte, _ := json.Marshal(oneDayValue)
			vmListOneDay[i] = vmListOneDayByte
			vmListSevenDayByte, _ := json.Marshal(sevenDayValue)
			vmListSevenDay[i] = vmListSevenDayByte
		}
	case config.CloudLoadResource:
		var loadList []LoadValueType
		err := json.Unmarshal([]byte(param.List), &loadList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		vmListTwelve = make([]interface{}, len(loadList))   // 12h 列表
		scoresTwelve = make([]float64, len(loadList))       // 12h scores
		vmListOneDay = make([]interface{}, len(loadList))   // 1day 列表
		scoresOneDay = make([]float64, len(loadList))       // 1day scores
		vmListSevenDay = make([]interface{}, len(loadList)) // 72h 列表
		scoresSevenDay = make([]float64, len(loadList))     // 72h scores

		loadPublicList, err := LoadPublicList(metric, loadList)
		klog.Infof("loadPublicList", len(loadPublicList))
		if err != nil {
			klog.Error("get_load_loadPublicList_failed :", err)
		}
		if len(loadPublicList) > 0 {
			loadList = loadPublicList
		}
		klog.Infof("loadList", len(loadList))

		for i, val := range loadList {
			scoresTwelve[i] = 0
			scoresOneDay[i] = 0
			scoresSevenDay[i] = 0

			var twelveValue LoadValueType
			twelveValue.Name = val.Name
			twelveValue.Id = val.Id
			twelveValue.RegionCode = val.RegionCode
			twelveValue.Az = val.Az
			// twelveValue.Status = val.Status
			twelveValue.Value = 0

			var oneDayValue LoadValueType
			oneDayValue.Name = val.Name
			oneDayValue.Id = val.Id
			oneDayValue.RegionCode = val.RegionCode
			oneDayValue.Az = val.Az
			// oneDayValue.Status = val.Status
			oneDayValue.Value = 0

			var sevenDayValue LoadValueType
			sevenDayValue.Name = val.Name
			sevenDayValue.Id = val.Id
			sevenDayValue.RegionCode = val.RegionCode
			sevenDayValue.Az = val.Az
			// sevenDayValue.Status = val.Status
			sevenDayValue.Value = 0

			cpuLoad := []string{metric}
			oo := kts.QueryLoadMetricTop(val.Id, param.Start, param.End, cpuLoad, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scoresTwelve[i] = values[12]
				twelveValue.Value = values[12]
				scoresOneDay[i] = values[24]
				oneDayValue.Value = values[24]
				scoresSevenDay[i] = values[168]
				sevenDayValue.Value = values[168]

			}
			vmListTwelveByte, _ := json.Marshal(twelveValue)
			vmListTwelve[i] = vmListTwelveByte
			vmListOneDayByte, _ := json.Marshal(oneDayValue)
			vmListOneDay[i] = vmListOneDayByte
			vmListSevenDayByte, _ := json.Marshal(sevenDayValue)
			vmListSevenDay[i] = vmListSevenDayByte
		}
	case config.CloudNatResource:
		var natList []NatValueType
		err := json.Unmarshal([]byte(param.List), &natList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		vmListTwelve = make([]interface{}, len(natList))   // 12h 列表
		scoresTwelve = make([]float64, len(natList))       // 12h scores
		vmListOneDay = make([]interface{}, len(natList))   // 1day 列表
		scoresOneDay = make([]float64, len(natList))       // 1day scores
		vmListSevenDay = make([]interface{}, len(natList)) // 72h 列表
		scoresSevenDay = make([]float64, len(natList))     // 72h scores

		for i, val := range natList {
			scoresTwelve[i] = 0
			scoresOneDay[i] = 0
			scoresSevenDay[i] = 0

			var twelveValue NatValueType
			twelveValue.InstanceName = val.InstanceName
			twelveValue.Name = twelveValue.InstanceName
			twelveValue.SubName = twelveValue.InstanceName
			twelveValue.InstanceId = val.InstanceId
			twelveValue.Id = twelveValue.InstanceId
			twelveValue.RegionCode = val.RegionCode
			twelveValue.Az = val.Az
			twelveValue.Value = 0
			twelveValue.VpcName = val.VpcName
			twelveValue.Scope = val.Scope
			twelveValue.NatType = val.NatType
			twelveValue.TenantId = val.TenantId
			twelveValue.TenantName = val.TenantName
			twelveValue.VmId = "kscnat--" + twelveValue.Id

			var oneDayValue NatValueType
			oneDayValue.InstanceName = val.InstanceName
			oneDayValue.SubName = oneDayValue.InstanceName
			oneDayValue.Name = oneDayValue.InstanceName
			oneDayValue.InstanceId = val.InstanceId
			oneDayValue.Id = oneDayValue.InstanceId
			oneDayValue.RegionCode = val.RegionCode
			oneDayValue.Az = val.Az
			oneDayValue.Value = 0
			oneDayValue.VpcName = val.VpcName
			oneDayValue.Scope = val.Scope
			oneDayValue.NatType = val.NatType
			oneDayValue.TenantId = val.TenantId
			oneDayValue.TenantName = val.TenantName
			oneDayValue.VmId = "kscnat--" + oneDayValue.Id

			var sevenDayValue NatValueType
			sevenDayValue.InstanceName = val.InstanceName
			sevenDayValue.SubName = val.InstanceName
			sevenDayValue.Name = sevenDayValue.InstanceName
			sevenDayValue.InstanceId = val.InstanceId
			sevenDayValue.Id = sevenDayValue.InstanceId
			sevenDayValue.RegionCode = val.RegionCode
			sevenDayValue.Az = val.Az
			sevenDayValue.Value = 0
			sevenDayValue.VpcName = val.VpcName
			sevenDayValue.Scope = val.Scope
			sevenDayValue.NatType = val.NatType
			sevenDayValue.TenantId = val.TenantId
			sevenDayValue.TenantName = val.TenantName
			sevenDayValue.VmId = "kscnat--" + sevenDayValue.Id

			nat := []string{metric}
			oo := kts.QueryNatMetricTop(val.InstanceId, param.Start, param.End, nat, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scoresTwelve[i] = values[12]
				twelveValue.Value = values[12]
				scoresOneDay[i] = values[24]
				oneDayValue.Value = values[24]
				scoresSevenDay[i] = values[168]
				sevenDayValue.Value = values[168]

			}
			vmListTwelveByte, _ := json.Marshal(twelveValue)
			vmListTwelve[i] = vmListTwelveByte
			vmListOneDayByte, _ := json.Marshal(oneDayValue)
			vmListOneDay[i] = vmListOneDayByte
			vmListSevenDayByte, _ := json.Marshal(sevenDayValue)
			vmListSevenDay[i] = vmListSevenDayByte
		}
	}
	// 12h
	twelvekeyCpu := config.CronjobPrefix + param.Region + param.Az + ":" + resourceType + ":" + metric + ":" + "720" // key
	//写入redis 集合
	SetZAdd(twelvekeyCpu, scoresTwelve, vmListTwelve)
	// 1d
	oneDaykeyCpu := config.CronjobPrefix + param.Region + param.Az + ":" + resourceType + ":" + metric + ":" + "1440" // key
	//写入redis 集合
	SetZAdd(oneDaykeyCpu, scoresOneDay, vmListOneDay)
	// 7d
	sevenDaykeyCpu := config.CronjobPrefix + param.Region + param.Az + ":" + resourceType + ":" + metric + ":" + "10080" // key
	//写入redis 集合
	SetZAdd(sevenDaykeyCpu, scoresSevenDay, vmListSevenDay)
	klog.Infof("Execution_End_%s_%s_12h/1d/7d_%s_%s", resourceType, metric, param.Region, param.Az)
}

// 30d数据脚本
func SetOneDay(wg *sync.WaitGroup, param JobParam, resourceType, metric string) {
	klog.Infof("Execution_Start_%s_%s_30d_%s_%s", resourceType, metric, param.Region, param.Az)
	//wg.Add(1)
	defer wg.Done()

	var (
		list   []interface{}
		scores []float64
	)
	switch resourceType {
	case config.CloudVmResource: // 云主机
		var vmList []VmValueType
		err := json.Unmarshal([]byte(param.List), &vmList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		list = make([]interface{}, len(vmList)) // 3h 列表
		scores = make([]float64, len(vmList))   // 3h scores

		for i, val := range vmList {
			scores[i] = 0
			var value VmValueType
			value.Name = val.Name
			value.Id = val.Id
			value.RegionCode = val.RegionCode
			value.Az = val.Az
			value.Status = val.Status // 不同资源类型 写入redis 集合条件不同功能
			value.Value = 0
			cpuLoad := []string{metric}
			// 获取Tsdb数据
			oo := kts.QueryVmMetricTop(val.Id, param.Start, param.End, cpuLoad, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scores[i] = values[30]
				value.Value = values[30]
			}
			vmListByte, _ := json.Marshal(value)
			list[i] = vmListByte
		}
	case config.CloudBlockResource:
		var blockList []BlockValueType
		err := json.Unmarshal([]byte(param.List), &blockList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		list = make([]interface{}, len(blockList)) // 3h 列表
		scores = make([]float64, len(blockList))   // 3h scores

		for i, val := range blockList {
			scores[i] = 0
			var value BlockValueType
			value.Name = val.Name
			value.Id = val.Id
			value.RegionCode = val.RegionCode
			value.Az = val.Az
			value.Status = val.Status // 不同资源类型 写入redis 集合条件不同功能
			value.Value = 0
			value.StorageType = val.StorageType
			value.VmId = val.VmId
			diskUsed := []string{metric}
			// 获取Tsdb数据
			oo := kts.QueryBlockMetricTop(val.VmId, param.Start, param.End, diskUsed, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scores[i] = values[30]
				value.Value = values[30]
			}
			blockListByte, _ := json.Marshal(value)
			list[i] = blockListByte
		}
	case config.CloudEipResource:
		var eipList []EipValueType
		err := json.Unmarshal([]byte(param.List), &eipList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		list = make([]interface{}, len(eipList)) // 3h 列表
		scores = make([]float64, len(eipList))   // 3h scores

		for i, val := range eipList {
			scores[i] = 0
			var value EipValueType
			value.Name = val.Name
			value.Id = val.Id
			value.RegionCode = val.RegionCode
			value.Az = val.Az
			value.Value = 0
			cpuLoad := []string{metric}
			// 获取Tsdb数据
			oo := kts.QueryEipMetricTop(val.Id, param.Start, param.End, cpuLoad, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scores[i] = values[30]
				value.Value = values[30]
			}
			vmListByte, _ := json.Marshal(value)
			list[i] = vmListByte
		}
	case config.CloudMysqlResource:
		var mysqlList []RdValueType
		err := json.Unmarshal([]byte(param.List), &mysqlList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		list = make([]interface{}, len(mysqlList)) // 3h 列表
		scores = make([]float64, len(mysqlList))   // 3h scores

		for i, val := range mysqlList {
			scores[i] = 0
			var value RdValueType
			value.Name = val.Name
			value.Id = val.Id
			value.RegionCode = val.RegionCode
			value.Az = val.Az
			value.Status = val.Status // 不同资源类型 写入redis 集合条件不同功能
			value.Value = 0
			cpuLoad := []string{metric}
			// 获取Tsdb数据
			oo := kts.QueryMysqlMetricTop(val.Id, param.Start, param.End, cpuLoad, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scores[i] = values[30]
				value.Value = values[30]
			}
			mysqlListByte, _ := json.Marshal(value)
			list[i] = mysqlListByte
		}
	case config.CloudRedisResource:
		var redisList []RdValueType
		err := json.Unmarshal([]byte(param.List), &redisList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		list = make([]interface{}, len(redisList)) // 3h 列表
		scores = make([]float64, len(redisList))   // 3h scores

		for i, val := range redisList {
			scores[i] = 0
			var value RdValueType
			value.Name = val.Name
			value.Id = val.Id
			value.RegionCode = val.RegionCode
			value.Az = val.Az
			value.Status = val.Status // 不同资源类型 写入redis 集合条件不同功能
			value.Value = 0
			diskUsed := []string{metric}
			// 获取Tsdb数据
			oo := kts.QueryRedisMetricTop(val.Id, param.Start, param.End, diskUsed, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scores[i] = values[30]
				value.Value = values[30]
			}
			listByte, _ := json.Marshal(value)
			list[i] = listByte
		}
	case config.CloudLoadResource:
		var loadList []LoadValueType
		err := json.Unmarshal([]byte(param.List), &loadList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		list = make([]interface{}, len(loadList)) // 3h 列表
		scores = make([]float64, len(loadList))   // 3h scores

		loadPublicList, err := LoadPublicList(metric, loadList)
		klog.Infof("loadPublicList", len(loadPublicList))
		if err != nil {
			klog.Error("get_load_loadPublicList_failed :", err)
		}
		if len(loadPublicList) > 0 {
			loadList = loadPublicList
		}
		klog.Infof("loadList", len(loadList))

		for i, val := range loadList {
			scores[i] = 0
			var value LoadValueType
			value.Name = val.Name
			value.Id = val.Id
			value.RegionCode = val.RegionCode
			value.Az = val.Az
			// value.Status = val.Status // 不同资源类型 写入redis 集合条件不同功能
			value.Value = 0
			cpuLoad := []string{metric}
			// 获取Tsdb数据
			oo := kts.QueryLoadMetricTop(val.Id, param.Start, param.End, cpuLoad, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scores[i] = values[30]
				value.Value = values[30]
			}
			loadListByte, _ := json.Marshal(value)
			list[i] = loadListByte
		}
	case config.CloudNatResource:
		var natList []NatValueType
		err := json.Unmarshal([]byte(param.List), &natList)
		if err != nil {
			klog.Error("Parsing_JSON_failed:", err)
		}
		list = make([]interface{}, len(natList)) // 3h 列表
		scores = make([]float64, len(natList))   // 3h scores

		for i, val := range natList {
			scores[i] = 0
			var value NatValueType
			value.InstanceName = val.InstanceName
			value.Name = value.InstanceName
			value.InstanceId = val.InstanceId
			value.Id = value.InstanceId
			value.RegionCode = val.RegionCode
			value.Az = val.Az
			// value.Status = val.Status // 不同资源类型 写入redis 集合条件不同功能
			value.Value = 0
			value.VpcName = val.VpcName
			value.Scope = val.Scope
			value.NatType = val.NatType
			value.TenantId = val.TenantId
			value.TenantName = val.TenantName
			value.SubName = value.InstanceName
			value.VmId = "kscnat--" + value.InstanceId
			nat := []string{metric}
			// 获取Tsdb数据
			oo := kts.QueryNatMetricTop(val.InstanceId, param.Start, param.End, nat, param.Interval)
			if len(oo) > 0 {
				values := oo[0].Avg
				scores[i] = values[30]
				value.Value = values[30]
			}
			vmListByte, _ := json.Marshal(value)
			list[i] = vmListByte
		}
	}
	// 30d
	keyCpu := config.CronjobPrefix + param.Region + param.Az + ":" + resourceType + ":" + metric + ":" + "43200" // key
	// 写入redis集合
	SetZAdd(keyCpu, scores, list)
	klog.Infof("Execution_End_%s_%s_30d_%s_%s", resourceType, metric, param.Region, param.Az)
}

// 数据写入集合
func SetZAdd(rediskey string, scores []float64, list []interface{}) {
	klog.Infof("rediskey%s %v %v ", rediskey, len(scores))
	ctx, cefl := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cefl()
	//
	//_, err := redisclient.Del(ctx, rediskey)
	//if err != nil{
	//	klog.Error("delect_redis_failed:%s",rediskey,err)
	//}
	//_, err = redisclient.ZAdd(ctx, rediskey, scores, list) // 数据添加到临时key
	//if err != nil{
	//	klog.Error("write_to_redis_by_split_failed:", err)
	//}

	rediskeyTmp := rediskey + "tmp"                            // 临时key
	_, err := redisclient.ZAdd(ctx, rediskeyTmp, scores, list) // 数据添加到临时key
	if err != nil {
		klog.Error(rediskeyTmp, " write_to_redis_by_split_failed:", err)
		_, _ = redisclient.Del(ctx, rediskeyTmp)

	}
	_, err1 := redisclient.Rename(ctx, rediskeyTmp, rediskey) // 添加完临时key 更换名称
	if err1 != nil {
		klog.Error(rediskey, "data_update_failed: ", err1)
		_, _ = redisclient.Del(ctx, rediskeyTmp)
	}
}

var LoadMetricInfoMap = map[string]string{
	"EipBpsIn":          "EipBpsIn",
	"EipBpsOut":         "EipBpsOut",
	"EipPpsIn":          "EipPpsIn",
	"EipPpsOut":         "EipPpsOut",
	"EipUtilizationIn":  "EipUtilizationIn",
	"EipUtilizationOut": "EipUtilizationOut",
}

func LoadPublicList(metric string, loadList []LoadValueType) (list []LoadValueType, err error) {

	_, ok := LoadMetricInfoMap[metric] //根据metric判断是否是公共监控项
	if !ok {
		return
	}
	var loadPublicList []LoadValueType
	// 查看load instance公网流量需要有eip和状态处于开启以及有监听器这三个指标 目前数据源只有eip和state两个指标
	var ipList = map[string]LoadValueType{}
	for _, val := range loadList {
		if val.Eip != "" && val.Status == "active" {
			ipList[val.Eip] = val
		}
	}
	//获取eip 列表
	eipData, err := eip.GetCmdbEipList(eipmodels.EipListQuery{BoundType: []string{"lb"}})
	if err != nil {
		klog.Error("get eip list fail")
	}
	eipList := eipData.Data.DataList
	for _, eip := range eipList {
		loadInstance, ok := ipList[eip.IpAddr]
		if !ok {
			continue
		}
		var loadePublicInfo LoadValueType
		loadePublicInfo.Id = eip.Id
		loadePublicInfo.Name = loadInstance.Name
		loadePublicInfo.RegionCode = loadInstance.RegionCode
		loadPublicList = append(loadPublicList, loadePublicInfo)
	}

	return loadPublicList, nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/tasks/cloudTask/vm_job.go
```golang
package cloudTask

import (
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"k8s.io/klog/v2"
	"strconv"
	"sync"
	"time"
)

// GetVmTop 云主机top Job
func GetVmTop(wg *sync.WaitGroup) {
	defer wg.Done()
	wg.Add(4)
	utils.GoSafe(func() { FiveMinutesJob(wg) })// 5m点  0.5h/1h
	utils.GoSafe(func() { TenMinutesJob(wg) })// 10m点 3h
	utils.GoSafe(func() { HourOneJob(wg) }) // 1h点  12h 1d 7d
	utils.GoSafe(func() { DayOneJob(wg) })// 1d  30d
}

// FiveMinutesJob 0.5小时/1小时同步数据脚本
func FiveMinutesJob(wg *sync.WaitGroup) { // 0.5h/1h
	klog.Infof("Start_of_script_execution_in_5_minutes_%s_%d",config.CloudVmResource,time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{6, 12} //tsdb 0.5h/1h 所取点数
		endTime := time.Now().Unix()
		startTime := endTime - 3600
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudVmResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(5)
			go SetFiveMinutes(wg, param, config.CloudVmResource, "CPULoadAvg")    // cpu使用率
			go SetFiveMinutes(wg, param, config.CloudVmResource, "MemLoadAvg")    // 内存使用量
			go SetFiveMinutes(wg, param, config.CloudVmResource, "DiskUsedRange") // 磁盘使用量
			go SetFiveMinutes(wg, param, config.CloudVmResource, "NetInAvg")      //网卡流量 入
			go SetFiveMinutes(wg, param, config.CloudVmResource, "NetOutAvg")     //网卡流量 出
		}
		time.Sleep(time.Minute * 5)
	}
}
//TenMinutesJob 3h同步数据脚本
func TenMinutesJob(wg *sync.WaitGroup) { //3h
	klog.Infof("Start_of_script_execution_in_3_hour_%s_%d",config.CloudVmResource,time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{18} // 3 小时 10m 取一次 取18个点
		endTime := time.Now().Unix() // 当前时间
		startTime := endTime - 10800
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudVmResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(5)
			go SetTenMinutes(wg, param, config.CloudVmResource, "CPULoadAvg")    // cpu使用率
			go SetTenMinutes(wg, param, config.CloudVmResource, "MemLoadAvg")    // 内存使用量
			go SetTenMinutes(wg, param, config.CloudVmResource, "DiskUsedRange") // 磁盘使用量
			go SetTenMinutes(wg, param, config.CloudVmResource, "NetInAvg")      //网卡流量 入
			go SetTenMinutes(wg, param, config.CloudVmResource, "NetOutAvg")     //网卡流量 出
		}
		time.Sleep(time.Minute * 10)
	}
}
//HourOneJob 同步数据脚本12h/ 1d /7d
func HourOneJob(wg *sync.WaitGroup) { // 12h/ 1d /7d
	klog.Infof("Start_of_script_execution_in_12_hour_%s_%d",config.CloudVmResource,time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{12, 24, 168} // 12,24,168 取点数量
		endTime := time.Now().Unix()  // 当前时间
		startTime := endTime - 604800 // 7天前时间
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudVmResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(5)
			go SetOneHour(wg, param, config.CloudVmResource, "CPULoadAvg")    // cpu使用率
			go SetOneHour(wg, param, config.CloudVmResource, "MemLoadAvg")    // 内存使用量
			go SetOneHour(wg, param, config.CloudVmResource, "DiskUsedRange") // 磁盘使用量
			go SetOneHour(wg, param, config.CloudVmResource, "NetInAvg")      //网卡流量 入
			go SetOneHour(wg, param, config.CloudVmResource, "NetOutAvg")     //网卡流量 出
		}
		time.Sleep(time.Minute * 60)
	}
}
// DayOneJob 30d同步数据脚本
func DayOneJob(wg *sync.WaitGroup) { // 30d
	klog.Infof("Start_of_script_execution_in_30_day_%s_%d",config.CloudVmResource,time.Now().Unix())
	defer wg.Done()
	for {
		interval := []int{30} //取点数量
		endTime := time.Now().Unix()   // 当前时间
		startTime := endTime - 2592000 // 7天前时间
		end := strconv.FormatInt(endTime, 10)
		start := strconv.FormatInt(startTime, 10)
		//获取所有region Az 数据
		paramList := SplicingCloudJobParam(config.CloudVmResource, start, end, interval)
		//执行异步脚本
		for _, param := range paramList {
			wg.Add(5)
			go SetOneDay(wg, param, config.CloudVmResource, "CPULoadAvg")    // cpu使用率
			go SetOneDay(wg, param, config.CloudVmResource, "MemLoadAvg")    // 内存使用量
			go SetOneDay(wg, param, config.CloudVmResource, "DiskUsedRange") // 磁盘使用量
			go SetOneDay(wg, param, config.CloudVmResource, "NetInAvg")      //网卡流量 入
			go SetOneDay(wg, param, config.CloudVmResource, "NetOutAvg")     //网卡流量 出
		}
		time.Sleep(time.Hour * 24)
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/tasks/poolTask/ks3_job.go
```golang
package poolTask

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/esmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"io/ioutil"
	"k8s.io/klog/v2"
	"net/http"
	"strconv"
	"strings"
	"time"
)

func GetDiskCapacity() {
	utils.GoSafe(DayOneJob) // 1d  30d
}

// DayOneJob 30d同步数据脚本
func DayOneJob() { // 30d
	klog.Infof("Start_of_script_execution_in_30_day_%s_%d", config.PoolKs3, time.Now().Unix())
	for {
		objectStoragePoolResult, err := cmdbmanager.GetObjectStorageResourcePoolList("all", "", "", strconv.Itoa(1), strconv.Itoa(1000))
		if err != nil {
			klog.Error(err)
			time.Sleep(time.Hour * 24)
			continue
		}
		//klog.Infof("pool list result: %+v", objectStoragePoolResult)
		poolList := objectStoragePoolResult.Data.DataList
		if len(poolList) > 0 {
			for _, pool := range poolList {
				simpleHttpClient := SimpleHttpClient{}
				b, err := simpleHttpClient.SimpleHttpGet(pool.MetricUrl)
				if err != nil {
					klog.Error(err)
					continue
				}
				var capData resourcepoolmodel.Cap
				err = json.Unmarshal(b, &capData)
				if err != nil {
					klog.Error(err)
					continue
				}
				dateIndex := esmanager.GetDateIndex(0)
				ctx, _ := context.WithTimeout(context.Background(), 1*time.Minute)
				key := "objectStoragePool_disk_capacity:" + pool.RegionCode + ":" + strconv.Itoa(pool.Id)
				valueJson, _ := json.Marshal(capData)
				client.HSet(ctx, key, dateIndex, valueJson)
				esmanager.DeleteExpireFields(ctx, key)
			}
		}
		time.Sleep(time.Hour * 24)
	}
}

type SimpleHttpClient struct{}

func (s *SimpleHttpClient) SimpleHttpGet(url string) ([]byte, error) {
	klog.Infof("Simple get url: %s", url)
	c := http.Client{
		Timeout: 2 * time.Second,
	}
	resp, err := c.Get(url)
	// TODO check response code,  4xx 5xx, make error
	if err != nil {
		klog.Errorf("Error when get url: %s, %s", url, err)
		return nil, err
	}
	if strings.HasPrefix(resp.Status, "5") || strings.HasPrefix(resp.Status, "4") {
		err = errors.New(fmt.Sprintf("Error when Get url=(%s) with %s status", url, resp.Status))
		klog.Error(err)
		return nil, err
	}
	defer resp.Body.Close()
	return ioutil.ReadAll(resp.Body)
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/config/default-config.go
```golang
package config

import (
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"os"
)

const (
	ChanCacheSize          = 1
	MaxVmSearchDuration    = 10
	MaxBlockSearchDuration = 3
	MaxEipSearchDuration   = 10
	MaxLoadSearchDuration  = 10

	ConcurrencyLimit = 100
)

const (
	CronjobPrefix      = "cronjob:luban:server:" // redis集合前缀
	CloudVmResource    = "VM"
	CloudBlockResource = "BLOCK"
	CloudEipResource   = "EIP"
	CloudRedisResource = "REDIS"
	CloudLoadResource  = "LOAD"
	CloudMysqlResource = "MYSQL"
	CloudNatResource   = "NAT"
	CloudBmResource    = "Bm"
	PoolKs3            = "KS3"
)

var (
	PrometheusService    = "prometheus"
	AlarmService         = "alarm"
	AlertmanagerService  = "alertmanager"
	ElasticsearchService = "elasticsearch"
	DgraphGrpcService    = "dgraph"
	CMDBService          = "CMDB"
	ConfigService        = "Config"
	DBMSService          = "DBMS"
	PromeTimeDurtion     = "10m"

	LocalPrometheusService    = "luban.prometheus.galaxy.cloud"
	LocaltAlertmanagerService = "luban.alert.galaxy.cloud"
	LocalElasticsearchService = "luban.es.galaxy.cloud"
	LocalDgraphGrpcService    = "luban.dgraph9080.galaxy.cloud:80"
	LocalCMDBService          = "luban.cmdb.galaxy.cloud"
	LocalConfigService        = "luban.config.galaxy.cloud"
	LocalDBMSService          = "luban.dbms.galaxy.cloud"
	//TsdbServer                = "opentsdb:4243" //gms tsdb
	TsdbServer = GetTsdbHost()
	//TsdbServer                  = "10.178.80.25:4243" //测试使用
	DefaultPrometheusService    = "pm-kube-prometheus-stack-prometheus.monitoring:9090"
	DefaultAlertmanagerService  = "pm-kube-prometheus-stack-alertmanager.monitoring:9093"
	DefaultElasticsearchService = "elasticsearch-master.elastic-system:9200"
	DefaultDgraphGrpcService    = "dgraph-public-nodeport.dgraph:9080"
	DefaultCMDBService          = "cmdb.luban"
	DefaultConfigService        = "config.luban"
	DefaultDBMSService          = "dbms.luban"
	DefaultK3sEsService         = "ks3es.luban.sdns.galaxy.cloud:9200"
	//DefaultK3sEsService      = "bges.inner.sdns.cqpcloud.cn:9200"
	DefaultChargeInfoService = "ks3charge.luban.sdns.galaxy.cloud:18080"
	CloudMonitorAlertMySql   = "moniotordb.luban.sdns.galaxy.cloud:3306"

	RdsLogBucketName      = "rds-cn-shanghai-2"
	RdsLogPrefixErrlog    = "rds/errlog/"
	RdsLogPrefixSlowquery = "rds/slowquery/"

	RedisConfig = map[string]interface{}{
		"Host":       GetRedisHost(),
		"Password":   "123456",
		"Db":         10,
		"MaxRetries": 10,
	}
	PhysicalServers = "physical-nodes"
	CurrentRegion   = "CN-SHANGHAI-2" //todo get from environment
	RegionMap       = map[string]string{
		"cn-shanghai-2": "SHPBSRegionOne", //上海2区(VPC)
		"cn-beijing-6":  "TJWQRegion",     //北京6区
	}
	AzMap = map[string]string{
		"cn-shanghai-2a": "ksc_shpbs_zone1001_aggregate_raidssd_1001", //上海可用区(VPC)
	}
	// redis 云实例运行日志、满日志 ES 信息
	KCSRedisLogingElasticsearchAddress = "http://loges.kcs.luban.galaxy.cloud:9200"
	KCSRedisLogingElasticsearchIndex   = "filebeat-7.7.0-ksyun-1.0.0-1-*"
	// ReasourcePoolMap = map[string]string{
	// 	"ks3":     "ks3",       //上海2区(VPC)ks3,ebs_ssd,ebs3_ssd,ehdd_ehdd
	// 	"ssd3.0":  "ebs3_ssd",  //ebs3_ssd
	// 	"ssd2.0":  "ebs_ssd",   //ebs3_ssd
	// 	"ehdd":    "ehdd_ehdd", //ebs3_ssd
	// 	"sata2.0": "ebs2_sata", //ebs3_ssd
	// }
)

func GetTsdbHost() string {
	host := "read.tsdb.sdns.galaxy.cloud:4243"
	envHost := os.Getenv("TSDB_HOST")
	if len(envHost) > 0 {
		host = envHost
	}
	return host
}

func GetRedisHost() string {
	var rHost = "asset.luban.sdns.galaxy.cloud:9379"
	if len(os.Getenv("KUBERNETES_SERVICE_HOST")) > 0 {
		rHost = "redis-master.luban:6379"
	}
	return rHost
}

func GetDefaultUrl(name string) string {
	inCluster := true
	if client.GetClient() == nil {
		inCluster = false
	}
	if PrometheusService == name {
		if inCluster {
			return DefaultPrometheusService
		} else {
			return LocalPrometheusService
		}
	} else if AlertmanagerService == name {
		if inCluster {
			return DefaultAlertmanagerService
		} else {
			return LocaltAlertmanagerService
		}

	} else if ElasticsearchService == name {
		if inCluster {
			return DefaultElasticsearchService
		} else {
			return LocalElasticsearchService
		}

	} else if DgraphGrpcService == name {
		if inCluster {
			return DefaultDgraphGrpcService
		} else {
			return LocalDgraphGrpcService
		}
	} else if CMDBService == name {
		if inCluster {
			return DefaultCMDBService
		} else {
			return LocalCMDBService
		}
	} else if DBMSService == name {
		if inCluster {
			return DefaultDBMSService
		} else {
			return LocalDBMSService
		}
	} else if ConfigService == name {
		if inCluster {
			return DefaultConfigService
		} else {
			return LocalConfigService
		}
	} else {
		return ""
	}
}

// 获取map所有的key针对region
func GetKeys2(m map[string]string) []string {
	// 数组默认长度为map长度,后面append时,不需要重新申请内存和拷贝,效率很高
	keys := make([]string, 0, len(m))
	for k := range m {
		keys = append(keys, k)
	}
	return keys
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/common.go
```golang
package template

import (
	"bytes"
	"text/template"

	"github.com/prometheus/common/model"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/prometheus/labels"
)

type MetricsSqlTemplate struct {
	//todo test add begion end and step
	Sql  string `json:"sql"`
	Unit string `json:"unit"`
}


type MysqlMonitorTemplate struct {
	Metric []string `json:"metric"`
	Name  string `json:"name"`
	Unit string `json:"unit"`
	UnitType string `json:"unitType"`
	Copywriting string `json:"copywriting"`
}

type MysqlMonitorTemplates struct {
	IndexType string `json:"indexType"`
	List []string `json:"indexType"`
}


//type IGalaxyCloudMetrics interface {
//	//todo get prometheus  sql template sql
//	Get(key string) (*MetricsSqlTemplate,error)
//	//todo fmt print prometheus sql to string by struct field
//	ToString (key string) string
//}

type QuerySql struct {
	Name        string
	Unit        string
	SqlTemplate string
	Labels      labels.MatcherPairs
	By          model.LabelNames
}

func (qs *QuerySql) Render() (string, error) {
	sqlTemplate, err := template.New(qs.Name).Parse(qs.SqlTemplate)
	if err != nil {
		return "",err
	}
	buf := new(bytes.Buffer)
	if err = sqlTemplate.Execute(buf, qs); err != nil {
		return "",err
	}
	return buf.String(), nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/physicalServer/serverMetricTemplate.go
```golang
package physicalserver

import (
	"bytes"
	"errors"
	gotemplate "text/template"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"
	"k8s.io/klog/v2"
)

var ServerMetricsTemplateName = "server_metrics_tempalte"

type ServerMetics struct {
	IP      string
	IfIndex int
	Sub     string
}

func NewServerMetics(ip, sub string, ifIndex int) *ServerMetics {
	return &ServerMetics{
		IP:      ip,
		IfIndex: ifIndex,
		Sub:     sub,
	}
}

func (s *ServerMetics) Get(key string) (*template.MetricsSqlTemplate, error) {

	if _, ok := ServerMetricsMap[key]; ok {
		return ServerMetricsMap[key], nil
	} else {
		return nil, errors.New("server template not found")
	}

}

func (s *ServerMetics) ToString(key string) string {
	t, err := s.Get(key)
	if err != nil {
		klog.Errorf("Get server metrics template error, %s key not found", key)
		return ""
	}
	sqlTeplate, err := gotemplate.New(ServerMetricsTemplateName).Parse(t.Sql)
	if err != nil {
		klog.Errorf("go template error %s", err.Error())
		return ""
	}
	b := new(bytes.Buffer)
	err = sqlTeplate.Execute(b, s)
	if err != nil {
		klog.Errorf("go template execute %s", err.Error())
		return ""
	}
	return b.String()
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/physicalServer/map.go
```golang
package physicalserver

import "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"

var (
	Server_up                       = "server_up"
	Server_cpu_usage_rate           = "server_cpu_usage_rate"
	Server_cpu_usage_rate_new       = "server_cpu_usage_rate_new"
	Server_memory_usage_rate        = "server_memory_usage_rate"
	Server_disk_usage_rate          = "server_disk_usage_rate"
	Server_network_receive_24h      = "server_network_receive_24h"
	Server_network_transmit_24h     = "server_network_transmit_24h"
	Server_disk_avail_every         = "server_disk_avail_every"

	//ipmi
	ipmi_up                                = "ipmi_up"
	ipmi_sensor_state_cpu_overview         = "ipmi_sensor_state_cpu_overview"
	ipmi_sensor_state_memory_overview      = "ipmi_sensor_state_memory_overview"
	ipmi_sensor_state_disk_overview        = "ipmi_sensor_state_disk_overview"
	ipmi_sensor_state_cpu_by_region        = "ipmi_sensor_state_cpu_by_region"
	ipmi_sensor_state_memory_by_region     = "ipmi_sensor_state_memory_by_region"
	ipmi_sensor_state_disk_by_region       = "ipmi_sensor_state_disk_by_region"
	ipmi_sensor_state_cpu_by_az            = "ipmi_sensor_state_cpu__by_az"
	ipmi_sensor_state_memory_by_az         = "ipmi_sensor_state_memory_by_az"
	ipmi_sensor_state_disk_by_az           = "ipmi_sensor_state_disk_by_az"
	ipmi_chassis_power_state               = "ipmi_chassis_power_state" //power_chassis 1=on, 0=off
	ipmi_power_state                       = "ipmi_power_state"         //0=nominal, 1=warning, 2=critical
	ipmi_power_state_count_value           = "ipmi_power_state_count_value"
	ipmi_power_watts                       = "ipmi_power_watts"
	ipmi_fan_speed_state                   = "ipmi_fan_speed_state" //0=nominal, 1=warning, 2=critical
	ipmi_fan_speed_rpm                     = "ipmi_fan_speed_rpm"
	ipmi_sensor_state_cpu                  = "ipmi_sensor_state_cpu"
	ipmi_sensor_state_memory               = "ipmi_sensor_state_memory"
	ipmi_sensor_state_power                = "ipmi_sensor_state_power"
	ipmi_sensor_state_disk                 = "ipmi_sensor_state_disk"
	ipmi_sensor_state_fan                  = "ipmi_sensor_state_fan"
	ipmi_sensor_state_cpu_count_values     = "ipmi_sensor_state_cpu_count_values"
	ipmi_sensor_state_cpu_count_values_new = "ipmi_sensor_state_cpu_count_values_new"
	ipmi_sensor_state_memory_count_values  = "ipmi_sensor_state_memory_count_values"
	ipmi_sensor_state_power_count_values   = "ipmi_sensor_state_power_count_values"
	ipmi_sensor_state_disk_count_values    = "ipmi_sensor_state_disk_count_values"
	ipmi_sensor_state_fan_count_values     = "ipmi_sensor_state_fan_count_values"

	//computer-pool
	computer_pool_vcpu_usage_rate_stock   = "computer_pool_vcpu_usage_rate_stock"
	computer_pool_memory_usage_rate_stock = "computer_pool_memory_usage_rate_stock"
	computer_pool_cpu_usage_rate          = "computer_pool_cpu_usage_rate"
	computer_pool_memory_usage_rate       = "computer_pool_memory_usage_rate"
	//block-pool
	block_pool_storage_stock        = "block_pool_storage_stock"
	block_pool_storage_stock_region = "block_pool_storage_stock_region"
	block_pool_storage_stock_az     = "block_pool_storage_stock_az"
	// 进出风口
	ipmi_temperature_celsius_inlet         = "ipmi_temperature_celsius_inlet"
	ipmi_temperature_celsius_inlet_two     = "ipmi_temperature_celsius_inlet_two"
	ipmi_temperature_celsius_outlet        = "ipmi_temperature_celsius_outlet"
	ipmi_temperature_celsius_outlet_two    = "ipmi_temperature_celsius_outlet_two"
	ipmi_sensor_state_fan_count_values_new = "ipmi_sensor_state_fan_count_values_new"

	server_node_cpu_seconds_total = "server_node_cpu_seconds_total"
)

var ServerMetricsMap = map[string]*template.MetricsSqlTemplate{
	Server_up: &template.MetricsSqlTemplate{
		Sql:  `up{instance="{{.IP}}",namespace="monitoring"}`,
		Unit: "",
	},
	//Server_cpu_usage_rate: &template.MetricsSqlTemplate{
	//	Sql:  `1 - sum(node_cpu_seconds_total{instance="{{.IP}}",mode="idle"}) / sum(node_cpu_seconds_total{instance="{{.IP}}"})`,
	//	Unit: "",
	//},
	//上面这种计算方式可能是错的，统一使用下面这种
	Server_cpu_usage_rate: &template.MetricsSqlTemplate{
		Sql:  `1 - sum(increase(node_cpu_seconds_total{instance="{{.IP}}",mode="idle"} [10m]))/ sum(increase(node_cpu_seconds_total{instance="{{.IP}}"} [10m]))`,
		Unit: "",
	},
	Server_cpu_usage_rate_new: &template.MetricsSqlTemplate{
		Sql:  `avg(instance:cpu_use_percent:rate5m{instance="{{.IP}}"})by(instance)/100`,
		Unit: "",
	},
	Server_memory_usage_rate: &template.MetricsSqlTemplate{
		Sql:  `1 - sum(node_memory_MemAvailable_bytes{instance="{{.IP}}"})/ sum(node_memory_MemTotal_bytes{instance="{{.IP}}"} )`,
		Unit: "",
	},
	Server_disk_usage_rate: &template.MetricsSqlTemplate{
		//,mountpoint=~"/vm_data|/|/boot",fstype!="rootfs"
		Sql:  `1-(sum(node_filesystem_free_bytes{instance="{{.IP}}"})/sum(node_filesystem_size_bytes{instance="{{.IP}}" }))`,
		Unit: "",
	},
	Server_network_receive_24h: &template.MetricsSqlTemplate{
		Sql:  `sum(increase(node_network_receive_bytes_total{instance="{{.IP}}"}[24h]))`,
		Unit: "",
	},
	Server_network_transmit_24h: &template.MetricsSqlTemplate{
		Sql:  `sum(increase(node_network_transmit_bytes_total{instance="{{.IP}}"}[24h]))`,
		Unit: "",
	},
	Server_disk_avail_every: &template.MetricsSqlTemplate{
		Sql:  `node_filesystem_avail_bytes{fstype!~"(tmpfs|rootfs).*",instance="{{.IP}}"}`,
		Unit: "",
	},

	//ipmi
	ipmi_up: &template.MetricsSqlTemplate{
		Sql:  `ipmi_up{instance="{{.IP}}",namespace="monitoring",collector="bmc"}`,
		Unit: "",
	},
	ipmi_sensor_state_cpu_overview: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{service="ipmi-exporter",type="Processor"}`,
		Unit: "",
	},
	ipmi_sensor_state_memory_overview: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{service="ipmi-exporter",type="Memory"}`,
		Unit: "",
	},
	ipmi_sensor_state_disk_overview: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{service="ipmi-exporter",type="Drive Slot"}`,
		Unit: "",
	},
	ipmi_sensor_state_cpu_by_region: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{instance="{{.IP}}",service="ipmi-exporter",type="Processor"}`,
		Unit: "",
	},
	ipmi_sensor_state_memory_by_region: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Memory"}`,
		Unit: "",
	},
	ipmi_sensor_state_disk_by_region: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Drive Slot"}`,
		Unit: "",
	},
	ipmi_sensor_state_cpu_by_az: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{instance="{{.IP}}",service="ipmi-exporter",type="Processor"}`,
		Unit: "",
	},
	ipmi_sensor_state_memory_by_az: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Memory"}`,
		Unit: "",
	},
	ipmi_sensor_state_disk_by_az: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Drive Slot"}`,
		Unit: "",
	},
	ipmi_chassis_power_state: &template.MetricsSqlTemplate{
		Sql:  `ipmi_chassis_power_state{instance="{{.IP}}",service="ipmi-exporter"}`,
		Unit: "",
	},
	ipmi_power_state: &template.MetricsSqlTemplate{
		Sql:  `ipmi_power_state{instance="{{.IP}}",service="ipmi-exporter"}`,
		Unit: "",
	},
	ipmi_power_watts: &template.MetricsSqlTemplate{
		Sql:  `ipmi_power_watts{instance="{{.IP}}",service="ipmi-exporter"}`,
		Unit: "",
	},
	ipmi_fan_speed_state: &template.MetricsSqlTemplate{
		Sql:  `ipmi_fan_speed_state{instance="{{.IP}}",service="ipmi-exporter"}`,
		Unit: "",
	},
	ipmi_fan_speed_rpm: &template.MetricsSqlTemplate{
		Sql:  `ipmi_fan_speed_rpm{instance="{{.IP}}",service="ipmi-exporter"}`,
		Unit: "",
	},
	ipmi_power_state_count_value: &template.MetricsSqlTemplate{
		Sql:  `count_values("state",ipmi_power_state{instance="{{.IP}}",service="ipmi-exporter"})`,
		Unit: "",
	},
	ipmi_sensor_state_cpu: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{instance="{{.IP}}",service="ipmi-exporter",type="Processor"}`,
		Unit: "",
	},
	ipmi_sensor_state_memory: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Memory"}`,
		Unit: "",
	},
	ipmi_sensor_state_power: &template.MetricsSqlTemplate{
		//Sql:  `ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Power Unit"}`,
		Sql:  `ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Power Supply"}`,
		Unit: "",
	},
	ipmi_sensor_state_disk: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Drive Slot"}`,
		Unit: "",
	},
	ipmi_sensor_state_fan: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Drive Slot"}`,
		Unit: "",
	},
	ipmi_sensor_state_cpu_count_values: &template.MetricsSqlTemplate{
		Sql:  `count_values("state",ipmi_sensor_state{instance="{{.IP}}",name="{{.Sub}}",service="ipmi-exporter",type="Processor"})`,
		Unit: "",
	},
	ipmi_sensor_state_memory_count_values: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Memory"}`,
		Unit: "",
	},
	//ipmi_sensor_state_memory_count_values: &template.MetricsSqlTemplate{
	//	Sql:  `count_values("state",ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Memory"})`,
	//	Unit: "",
	//},
	ipmi_sensor_state_power_count_values: &template.MetricsSqlTemplate{
		Sql: `count_values("state",ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Power Supply"})`,
		//Sql:  `count_values("state",ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Power Unit"})`,
		Unit: "",
	},
	ipmi_sensor_state_disk_count_values: &template.MetricsSqlTemplate{
		Sql:  `count_values("state",ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Drive Slot"})`,
		Unit: "",
	},
	ipmi_sensor_state_fan_count_values: &template.MetricsSqlTemplate{
		Sql:  `count_values("state",ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Drive Slot"})`,
		Unit: "",
	},

	//computer-pool
	computer_pool_vcpu_usage_rate_stock: &template.MetricsSqlTemplate{
		Sql:  `1 - sum(node_cpu_seconds_total{mode="idle",az="cn-shanghai-2a",region="cn-shanghai-2",resourcePoolType="kec"}) by (resourcePool) / sum(node_cpu_seconds_total{az="cn-shanghai-2a",region="cn-shanghai-2",resourcePoolType="kec"}) by (resourcePool)`,
		Unit: "",
	},
	computer_pool_memory_usage_rate_stock: &template.MetricsSqlTemplate{
		Sql:  `1 - sum(node_memory_MemAvailable_bytes{az="cn-shanghai-2a",region="cn-shanghai-2",resourcePoolType="kec"}) by (resourcePool) / sum(node_memory_MemTotal_bytes{az="cn-shanghai-2a",region="cn-shanghai-2",resourcePoolType="kec"}) by (resourcePool)`,
		Unit: "",
	},
	computer_pool_cpu_usage_rate: &template.MetricsSqlTemplate{
		Sql:  `1 - sum(node_cpu_seconds_total{mode="idle",az="cn-shanghai-2a",region="cn-shanghai-2",resourcePoolType="kec"}) by (resourcePool) / sum(node_cpu_seconds_total{az="cn-shanghai-2a",region="cn-shanghai-2",resourcePoolType="kec"}) by (resourcePool)`,
		Unit: "",
	},
	computer_pool_memory_usage_rate: &template.MetricsSqlTemplate{
		Sql:  `1 - sum(node_memory_MemAvailable_bytes{az="cn-shanghai-2a",region="cn-shanghai-2",resourcePoolType="kec"}) by (resourcePool) / sum(node_memory_MemTotal_bytes{az="cn-shanghai-2a",region="cn-shanghai-2",resourcePoolType="kec"}) by (resourcePool)`,
		Unit: "",
	},

	//block-pool
	block_pool_storage_stock: &template.MetricsSqlTemplate{
		Sql:  `sum(ebs3_ssd_total{job="cluster-exporter"}[10m])+sum(ehdd_ehdd_total{job="cluster-exporter"}[10m])`,
		Unit: "",
	},
	block_pool_storage_stock_region: &template.MetricsSqlTemplate{
		Sql:  `sum(ebs3_ssd_total{region="{{.IP}}",job="cluster-exporter"}[10m])+sum(ehdd_ehdd_total{region="{{.IP}}",job="cluster-exporter"}[10m])`,
		Unit: "",
	},
	block_pool_storage_stock_az: &template.MetricsSqlTemplate{
		Sql:  `sum(ebs3_ssd_total{region="{{.IP}}",az="{{.Sub}}",job="cluster-exporter"}[10m])+sum(ehdd_ehdd_total{region="{{.IP}}",az="{{.Sub}}",job="cluster-exporter"}[10m])`,
		Unit: "",
	},
	computer_pool_memory_usage_rate_stock: &template.MetricsSqlTemplate{
		Sql:  `1 - sum(node_memory_MemAvailable_bytes{az="cn-shanghai-2a",region="cn-shanghai-2",resourcePoolType="kec"}) by (resourcePool) / sum(node_memory_MemTotal_bytes{az="cn-shanghai-2a",region="cn-shanghai-2",resourcePoolType="kec"}) by (resourcePool)`,
		Unit: "",
	},
	computer_pool_cpu_usage_rate: &template.MetricsSqlTemplate{
		Sql:  `1 - sum(node_cpu_seconds_total{mode="idle",az="cn-shanghai-2a",region="cn-shanghai-2",resourcePoolType="kec"}) by (resourcePool) / sum(node_cpu_seconds_total{az="cn-shanghai-2a",region="cn-shanghai-2",resourcePoolType="kec"}) by (resourcePool)`,
		Unit: "",
	},
	computer_pool_memory_usage_rate: &template.MetricsSqlTemplate{
		Sql:  `1 - sum(node_memory_MemAvailable_bytes{az="cn-shanghai-2a",region="cn-shanghai-2",resourcePoolType="kec"}) by (resourcePool) / sum(node_memory_MemTotal_bytes{az="cn-shanghai-2a",region="cn-shanghai-2",resourcePoolType="kec"}) by (resourcePool)`,
		Unit: "",
	},
	ipmi_temperature_celsius_inlet: &template.MetricsSqlTemplate{
		Sql:  `ipmi_temperature_celsius{instance="{{.IP}}", service="ipmi-exporter",name="Inlet Temp"}`,
		Unit: "",
	},
	ipmi_temperature_celsius_outlet: &template.MetricsSqlTemplate{
		Sql:  `ipmi_temperature_celsius{instance="{{.IP}}", service="ipmi-exporter",name="Outlet Temp"}`,
		Unit: "",
	},
	ipmi_temperature_celsius_inlet_two: &template.MetricsSqlTemplate{
		Sql:  `ipmi_temperature_celsius{instance="{{.IP}}", service="ipmi-exporter",name="Inlet_Temp"}`,
		Unit: "",
	},
	ipmi_temperature_celsius_outlet_two: &template.MetricsSqlTemplate{
		Sql:  `ipmi_temperature_celsius{instance="{{.IP}}", service="ipmi-exporter",name="Outlet_Temp"}`,
		Unit: "",
	},

	ipmi_sensor_state_cpu_count_values_new: &template.MetricsSqlTemplate{
		Sql:  `ipmi_sensor_state{instance="{{.IP}}", service="ipmi-exporter",type="Processor"}`,
		Unit: "",
	},

	ipmi_sensor_state_fan_count_values_new: &template.MetricsSqlTemplate{
		Sql:  `count_values("state",ipmi_fan_speed_state{instance="{{.IP}}", service="ipmi-exporter"})`,
		Unit: "",
	},

	server_node_cpu_seconds_total: &template.MetricsSqlTemplate{
		Sql:  `sum(irate(node_cpu_seconds_total{instance=~"{{.IP}}"}[5m]))by(mode)`,
		Unit: "",
	},
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/resourcePool/poolMetricsTemplate.go
```golang
package resourcepool

import (
	"bytes"
	"errors"
	gotemplate "text/template"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"
	"k8s.io/klog/v2"
)

var TemplateName = "pool_metrics_tempalte"

type PoolMetics struct {
	Label    string
	IP       string
	Duration string
}

func NewPoolMetics(label, ip, duration string) *PoolMetics {
	return &PoolMetics{
		Label:    label,
		IP:       ip,
		Duration: duration,
	}
}

func (s *PoolMetics) Get(key string) (*template.MetricsSqlTemplate, error) {

	if _, ok := poolMap[key]; ok {
		return poolMap[key], nil
	} else {
		return nil, errors.New("pool template not found")
	}

}

func (s *PoolMetics) ToString(key string) string {
	t, err := s.Get(key)
	if err != nil {
		klog.Errorf("Get pool metrics template error, %s key not found", key)
		return ""
	}
	sqlTeplate, err := gotemplate.New(TemplateName).Parse(t.Sql)
	if err != nil {
		klog.Errorf("go template error %s", err.Error())
		return ""
	}
	b := new(bytes.Buffer)
	err = sqlTeplate.Execute(b, s)
	if err != nil {
		klog.Errorf("go template execute %s", err.Error())
		return ""
	}
	return b.String()
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/resourcePool/map.go
```golang
package resourcepool

import "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"

var (

	//object
	pool_stock_capacity = "pool_stock_capacity"
	//computer-pool
	computer_pool_vcpu_stock        = "computer_pool_vcpu_stock"
	computer_pool_memory_stock      = "computer_pool_memory_stock"
	computer_pool_cpu_usage_rate    = "computer_pool_cpu_usage_rate"
	computer_pool_memory_usage_rate = "computer_pool_memory_usage_rate"
	computer_pool_cpu_rate          = "computer_pool_cpu_rate"
	computer_pool_mem_rate          = "computer_pool_mem_rate"
	computer_pool_disk_rate         = "computer_pool_disk_rate"

	//block-pool
	block_pool_storage_stock  = "block_pool_storage_stock"
	block_pool_disk_count     = "block_pool_disk_count"
	block_pool_req_count      = "block_pool_req_count"
	block_pool_io_avg_delay   = "block_pool_io_avg_delay"
	block_pool_write_band     = "block_pool_write_band"
	object_pool_storage_stock = "object_pool_storage_stock"

	object_pool_bucket_count = "object_pool_bucket_count"
)

var poolMap = map[string]*template.MetricsSqlTemplate{
	//object
	pool_stock_capacity: &template.MetricsSqlTemplate{
		Sql:  `sum(bucket_store_total{job="cluster-exporter"}[{{.Duration}}])`,
		Unit: "",
	},

	//computer-pool
	computer_pool_vcpu_stock: &template.MetricsSqlTemplate{
		//Sql:  `sum_over_time(aggregate_vcpu_remain_count{ {{.Label}} }[10m])`,
		Sql:  `aggregate_vcpu_remain_count{ {{.Label}} }`,
		Unit: "",
	},
	computer_pool_memory_stock: &template.MetricsSqlTemplate{
		Sql:  `aggregate_memory_remain_count{ {{.Label}} }`,
		Unit: "",
	},
	computer_pool_cpu_usage_rate: &template.MetricsSqlTemplate{
		Sql:  `aggregate_vcpu_used_rate{ {{.Label}} }`,
		Unit: "",
	},
	computer_pool_memory_usage_rate: &template.MetricsSqlTemplate{
		Sql:  `aggregate_memory_used_rate{ {{.Label}} }`,
		Unit: "",
	},

	//block-pool
	block_pool_storage_stock: &template.MetricsSqlTemplate{
		Sql:  `sum(ebs3_ssd_total{job="cluster-exporter",{{.Label}}}[10m])+sum(ehdd_ehdd_total{job="cluster-exporter",{{.Label}}}[10m])`,
		Unit: "",
	},
	block_pool_disk_count: &template.MetricsSqlTemplate{
		Sql:  `sum_over_time(cloud_disk_count{{{.Label}}}, service="cluster-exporter"}[10m])`,
		Unit: "",
	},
	block_pool_req_count: &template.MetricsSqlTemplate{
		Sql:  `xuanwu_req_count{job="galaxy-nodes",{{.Label}}}}`,
		Unit: "",
	},
	block_pool_io_avg_delay: &template.MetricsSqlTemplate{
		Sql:  `xuanwu_read_avg_latency{service="galaxy-nodes",{{.Label}}}`,
		Unit: "",
	},
	block_pool_write_band: &template.MetricsSqlTemplate{
		Sql:  `xuanwu_write_bw{service="galaxy-nodes",{{.Label}}}`,
		Unit: "",
	},

	//object-pool
	//object_pool_storage_stock: &template.MetricsSqlTemplate{
	//	Sql:  `sum(sum_over_time(bucket_store_total{job="cluster-exporter",{{.Label}}}[10m]))`,
	//	Unit: "",
	//},
	//上面注释的为对象存储资源池原有的概览页库存折线图计算公式
	object_pool_storage_stock: &template.MetricsSqlTemplate{
		Sql:  `floor((sum(storage_resource_pool_total{job="cluster-exporter",{{.Label}}})-sum(storage_resource_pool_usage{job="cluster-exporter",{{.Label}}})))`,
		Unit: "",
	},
	object_pool_bucket_count: &template.MetricsSqlTemplate{
		Sql:  `sum(object_pool_bucket_count{job="cluster-exporter",{{.Label}}})`,
		Unit: "",
	},
	computer_pool_cpu_rate: &template.MetricsSqlTemplate{
		Sql:  `100*(1-sum(increase(node_cpu_seconds_total{ {{.Label}},mode="idle"}[5m]))/sum(increase(node_cpu_seconds_total{ {{.Label}} }[5m])))`,
		Unit: "",
	},
	computer_pool_mem_rate: &template.MetricsSqlTemplate{
		Sql:  `100-sum(node_memory_MemAvailable_bytes{ {{.Label}} })/sum(node_memory_MemTotal_bytes{ {{.Label}} })*100`,
		Unit: "",
	},
	computer_pool_disk_rate: &template.MetricsSqlTemplate{
		Sql:  `(sum(node_filesystem_size_bytes{ {{.Label}},device=~"/dev/.*"})-sum(node_filesystem_free_bytes{ {{.Label}},device=~"/dev/.*"}))*100/(sum(node_filesystem_avail_bytes{ {{.Label}},device=~"/dev/.*"})+sum(node_filesystem_size_bytes{ {{.Label}},device=~"/dev/.*"})-sum(node_filesystem_free_bytes{ {{.Label}},device=~"/dev/.*"}))`,
		Unit: "",
	},
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/network/networkMetricTemplate.go
```golang
package network

import (
	"bytes"
	"errors"
	gotemplate "text/template"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"
	"k8s.io/klog/v2"
)

var NetworkMetricsTemplateName = "network_metrics_tempalte"

type NetworkMetics struct {
	Label    string
	TopK     int
	Duration int64
}

func NewNetworkMetics(Label string) *NetworkMetics {
	return &NetworkMetics{
		Label: Label,
	}
}

func NewNetworkMeticsSort(Label string, TopK int, Duration int64) *NetworkMetics {
	return &NetworkMetics{
		Label:    Label,
		TopK:     TopK,
		Duration: Duration,
	}
}

func (s *NetworkMetics) Get(key string) (*template.MetricsSqlTemplate, error) {

	if _, ok := networkMetricsMap[key]; ok {
		return networkMetricsMap[key], nil
	} else {
		return nil, errors.New("swtich template not found")
	}

}

func (s *NetworkMetics) ToString(key string) string {
	t, err := s.Get(key)
	if err != nil {
		klog.Errorf("Get swtich metrics template error, %s key not found", key)
		return ""
	}
	sqlTeplate, err := gotemplate.New(NetworkMetricsTemplateName).Parse(t.Sql)
	if err != nil {
		klog.Errorf("go template error %s", err.Error())
		return ""
	}
	b := new(bytes.Buffer)
	err = sqlTeplate.Execute(b, s)
	if err != nil {
		klog.Errorf("go template execute %s", err.Error())
		return ""
	}
	return b.String()
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/network/map.go
```golang
package network

import "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"

var (
	node_cpu_seconds_total                = "node_cpu_seconds_total"
	node_cpu_used_rate                    = "node_cpu_used_rate"
	node_memory_emAvailable_bytes         = "node_memory_emAvailable_bytes"
	node_memory_used_rate                 = "node_memory_used_rate"
	node_memory_used_bytes                = "node_memory_used_bytes"
	node_filesystem_free_bytes            = "node_filesystem_free_bytes"
	node_filesystem_used_rate             = "node_filesystem_used_rate"
	node_filesystem_used_bytes            = "node_filesystem_used_bytes"
	node_network_pps                      = "node_network_pps"
	node_network_bps                      = "node_network_bps"
	node_netstat_Tcp_CurrEstab            = "node_netstat_Tcp_CurrEstab"
	cluster_netstat_Tcp_CurrEstab         = "cluster_netstat_Tcp_CurrEstab"
	node_xgw_slb_conns_topK               = "node_xgw_slb_conns_topK"
	node_xgw_slb_conns                    = "node_xgw_slb_conns"
	node_xgw_slb_traffic_in_topK          = "node_xgw_slb_traffic_in_topK"
	node_xgw_slb_traffic_out_topK         = "node_xgw_slb_traffic_out_topK"
	node_xgw_slb_traffic_in               = "node_xgw_slb_traffic_in"
	node_xgw_slb_traffic_out              = "node_xgw_slb_traffic_out"
	node_xgw_eip_traffic_in_topK          = "node_xgw_eip_traffic_in_topK"
	node_xgw_eip_traffic_out_topK         = "node_xgw_eip_traffic_out_topK"
	node_xgw_eip_traffic_in               = "node_xgw_eip_traffic_in"
	node_xgw_eip_traffic_out              = "node_xgw_eip_traffic_out"
	node_nat_traffic_in_topK              = "node_nat_traffic_in_topK"
	node_nat_traffic_out_topK             = "node_nat_traffic_out_topK"
	node_nat_traffic_in                   = "node_nat_traffic_in"
	node_nat_traffic_out                  = "node_nat_traffic_out"
	node_tengine_slb_conns_topK           = "node_tengine_slb_conns_topK"
	node_tengine_slb_conns                = "node_tengine_slb_conns"
	node_tengine_slb_traffic_in_topK      = "node_tengine_slb_traffic_in_topK"
	node_tengine_slb_traffic_out_topK     = "node_tengine_slb_traffic_out_topK"
	node_tengine_slb_traffic_in           = "node_tengine_slb_traffic_in"
	node_tengine_slb_traffic_out          = "node_tengine_slb_traffic_out"
	node_sgw_public_eip_traffic_in_topK   = "node_sgw_public_eip_traffic_in_topK"
	node_sgw_public_eip_traffic_out_topK  = "node_sgw_public_eip_traffic_out_topK"
	node_sgw_public_eip_traffic_in = "node_sgw_public_eip_traffic_in"
	node_sgw_public_eip_traffic_out = "node_sgw_public_eip_traffic_out"
	node_sgw_public_eip_drop_packet_rate_in_topK = "node_sgw_public_eip_drop_packet_rate_in_topK"
	node_sgw_public_eip_drop_packet_rate_out_topK = "node_sgw_public_eip_drop_packet_rate_out_topK"
	node_sgw_public_eip_drop_packet_rate_in = "node_sgw_public_eip_drop_packet_rate_in"
	node_sgw_public_eip_drop_packet_rate_out = "node_sgw_public_eip_drop_packet_rate_out"
	//node_sgw_public_traffic_topK          = "node_sgw_public_traffic_topK"
	//node_sgw_public_drop_packet_rate_topK = "node_sgw_public_drop_packet_rate_topK"
	node_tgw_lpeer_bytes_in_topK          = "node_tgw_lpeer_bytes_in_topK"
	node_tgw_lpeer_bytes_out_topK         = "node_tgw_lpeer_bytes_out_topK"
	node_tgw_dc_bytes_in_topK             = "node_tgw_dc_bytes_in_topK"
	node_tgw_dc_bytes_out_topK            = "node_tgw_dc_bytes_out_topK"
	node_tgw_vpn_bytes_in_topK            = "node_tgw_vpn_bytes_in_topK"
	node_tgw_vpn_bytes_out_topK           = "node_tgw_vpn_bytes_out_topK"
	node_tgw_lpeer_bytes_in               = "node_tgw_lpeer_bytes_in"
	node_tgw_lpeer_bytes_out              = "node_tgw_lpeer_bytes_out"
	node_tgw_dc_bytes_in                  = "node_tgw_dc_bytes_in"
	node_tgw_dc_bytes_out                 = "node_tgw_dc_bytes_out"
	node_tgw_vpn_bytes_in                 = "node_tgw_vpn_bytes_in"
	node_tgw_vpn_bytes_out                = "node_tgw_vpn_bytes_out"
)

var networkMetricsMap = map[string]*template.MetricsSqlTemplate{
	//cpu使用率{{.Label}}
	node_cpu_seconds_total: &template.MetricsSqlTemplate{
		//Sql:  `100*(1-sum(increase(node_cpu_seconds_total{mode="idle",resourcePoolType="{{.ResourcePoolType}}",resourcePool="{{.ResourcePool}}"}[10m]))/sum(increase(node_cpu_seconds_total{resourcePoolType="{{.ResourcePoolType}}",resourcePool="{{.ResourcePool}}"}[10m])))`,
		Sql:  `100*(1-sum(increase(node_cpu_seconds_total{mode="idle",{{.Label}} }[10m]))/sum(increase(node_cpu_seconds_total{ {{.Label}} }[10m])))`,
		Unit: "",
	},
	// cpu 使用率 不乘100
	node_cpu_used_rate: &template.MetricsSqlTemplate{
		Sql:  `1-sum(increase(node_cpu_seconds_total{mode="idle",{{.Label}} }[10m]))/sum(increase(node_cpu_seconds_total{ {{.Label}} }[10m]))`,
		Unit: "",
	},
	// 内存使用率
	node_memory_emAvailable_bytes: &template.MetricsSqlTemplate{
		Sql:  `100*(1-sum(node_memory_MemAvailable_bytes{ {{.Label}} })/sum(node_memory_MemTotal_bytes{ {{.Label}} }))`,
		Unit: "",
	},
	// 内存使用率 不乘100
	node_memory_used_rate: &template.MetricsSqlTemplate{
		Sql:  `1-sum(node_memory_MemAvailable_bytes{ {{.Label}} })/sum(node_memory_MemTotal_bytes{ {{.Label}} })`,
		Unit: "",
	},
	// 内存使用量
	node_memory_used_bytes: &template.MetricsSqlTemplate{
		Sql:  `(sum(node_memory_MemTotal_bytes{ {{.Label}} })-sum(node_memory_MemAvailable_bytes{ {{.Label}} }))`,
		Unit: "byte",
	},
	// 磁盘使用率
	node_filesystem_free_bytes: &template.MetricsSqlTemplate{
		Sql:  `100*(1-(sum(node_filesystem_free_bytes{ {{.Label}} }))/sum(node_filesystem_size_bytes{ {{.Label}} }))`,
		Unit: "",
	},
	// 磁盘使用率 不乘100
	node_filesystem_used_rate: &template.MetricsSqlTemplate{
		Sql:  `1-(sum(node_filesystem_free_bytes{ {{.Label}} })/sum(node_filesystem_size_bytes{ {{.Label}} }))`,
		Unit: "",
	},
	// 磁盘使用量
	node_filesystem_used_bytes: &template.MetricsSqlTemplate{
		Sql:  `sum(node_filesystem_size_bytes{ {{.Label}} })-sum(node_filesystem_free_bytes{ {{.Label}} })`,
		Unit: "byte",
	},
	// pps
	node_network_pps: &template.MetricsSqlTemplate{
		Sql:  `sum(rate(node_network_transmit_packets_total{ {{.Label}},device=~"(?i)^(en|eth|em|x|bond|vnic).+$"}[5m]))+sum(rate(node_network_receive_packets_total{ {{.Label}},device=~"(?i)^(en|eth|em|x|bond|vnic).+$"}[5m]))`,
		Unit: "pps",
	},
	// bps
	node_network_bps: &template.MetricsSqlTemplate{
		Sql:  `sum(rate(node_network_transmit_bytes_total{ {{.Label}},device=~"(?i)^(en|eth|em|x|bond|vnic).+$" }[5m]))*8+sum(rate(node_network_receive_bytes_total{ {{.Label}},device=~"(?i)^(en|eth|em|x|bond|vnic).+$" }[5m]))*8`,
		Unit: "bps",
	},
	// 节点连接实例数
	node_netstat_Tcp_CurrEstab: &template.MetricsSqlTemplate{
		Sql:  `node_netstat_Tcp_CurrEstab{ {{.Label}} }`,
		Unit: "个",
	},
	// 总活动连接实例数
	cluster_netstat_Tcp_CurrEstab: &template.MetricsSqlTemplate{
		Sql:  `sum(node_netstat_Tcp_CurrEstab{ {{.Label}} })`,
		Unit: "个",
	},
	// xgw、kgw节点连接实例数topK
	node_xgw_slb_conns_topK: &template.MetricsSqlTemplate{
		Sql: `topK({{.TopK}},avg_over_time(xgw_lb_curr_local_conns{ {{.Label}} }[ {{.Duration}}s]))`,
		Unit: "个",
	},
	// xgw、kgw节点连接实例数折线图
	node_xgw_slb_conns: &template.MetricsSqlTemplate{
		Sql:  `sum(xgw_lb_curr_local_conns{ {{.Label}} })`,
		Unit: "个",
	},
	// xgw、kgw节点负载均衡流量topK
	node_xgw_slb_traffic_in_topK: &template.MetricsSqlTemplate{
		Sql: 	`topK({{.TopK}},avg_over_time(xgw_lb_in_traffic{ {{.Label}} }[ {{.Duration}}s]))`,
		Unit: "byte",
	},
	node_xgw_slb_traffic_out_topK: &template.MetricsSqlTemplate{
		Sql: 	`topK({{.TopK}},avg_over_time(xgw_lb_out_traffic{ {{.Label}} }[ {{.Duration}}s]))`,
		Unit: "byte",
	},
	// xgw、kgw节点负载均衡流量折线图
	node_xgw_slb_traffic_in: &template.MetricsSqlTemplate{
		Sql: `xgw_lb_in_traffic{ {{.Label}} }`,
		Unit: "byte",
	},
	node_xgw_slb_traffic_out: &template.MetricsSqlTemplate{
		Sql: `xgw_lb_out_traffic{ {{.Label}} }`,
		Unit: "byte",
	},
	// xgw、kgw节点弹性IP流量topK
	node_xgw_eip_traffic_in_topK: &template.MetricsSqlTemplate{
		Sql: `topK({{.TopK}},avg_over_time(xgw_eip_in_traffic{ {{.Label}} }[ {{.Duration}}s]))`,
		Unit: "byte",
	},
	node_xgw_eip_traffic_out_topK: &template.MetricsSqlTemplate{
		Sql: `topK({{.TopK}},avg_over_time(xgw_eip_out_traffic{ {{.Label}} }[ {{.Duration}}s]))`,
		Unit: "byte",
	},
	// xgw、kgw节点弹性IP流量line
	node_xgw_eip_traffic_in: &template.MetricsSqlTemplate{
		Sql: `xgw_eip_in_traffic{ {{.Label}} }`,
		Unit: "byte",
	},
	node_xgw_eip_traffic_out: &template.MetricsSqlTemplate{
		Sql: `xgw_eip_out_traffic{ {{.Label}} }`,
		Unit: "byte",
	},
	// 节点NAT流量入topK
	node_nat_traffic_in_topK: &template.MetricsSqlTemplate{
		Sql:  `topK({{.TopK}},avg_over_time(nat_traffic_in{ {{.Label}} }[{{.Duration}}s]))`,
		Unit: "byte",
	},
	// 节点NAT流量出topK
	node_nat_traffic_out_topK: &template.MetricsSqlTemplate{
		Sql:  `topK({{.TopK}},avg_over_time(nat_traffic_out{ {{.Label}} }[{{.Duration}}s]))`,
		Unit: "byte",
	},
	// 节点NAT流量入line
	node_nat_traffic_in: &template.MetricsSqlTemplate{
		Sql: `nat_traffic_in{ {{.Label}} }`,
		Unit: "byte",
	},
	// 节点NAT流量出line
	node_nat_traffic_out: &template.MetricsSqlTemplate{
		Sql: `nat_traffic_out{ {{.Label}} }`,
		Unit: "byte",
	},
	// Tengine节点连接实例数topK
	node_tengine_slb_conns_topK: &template.MetricsSqlTemplate{
		Sql:`topK({{.TopK}},avg_over_time(tengine_conn_total{ {{.Label}} }[ {{.Duration}}s]))`,
		Unit: "个",
	},
	//Tengine节点连接实例数line
	node_tengine_slb_conns :&template.MetricsSqlTemplate{
		Sql:`tengine_conn_total{ {{.Label}} }`,
		Unit: "个",
	},
	// Tengine节点负载均衡流量入topK
	node_tengine_slb_traffic_in_topK: &template.MetricsSqlTemplate{
		Sql:  `topK({{.TopK}},avg_over_time(tengine_traffic_in{ {{.Label}} }[ {{.Duration}}s]))`,
		Unit: "byte",
	},
	// Tengine节点负载均衡流量出topK
	node_tengine_slb_traffic_out_topK: &template.MetricsSqlTemplate{
		Sql:  `topK({{.TopK}},avg_over_time(tengine_traffic_out{ {{.Label}} }[ {{.Duration}}s]))`,
		Unit: "byte",
	},
	//Tengine节点负载均衡流量入line
	node_tengine_slb_traffic_in: &template.MetricsSqlTemplate{
		Sql:  `tengine_traffic_in{ {{.Label}} }`,
		Unit: "byte",
	},
	//Tengine节点负载均衡流量出line
	node_tengine_slb_traffic_out: &template.MetricsSqlTemplate{
		Sql:  `tengine_traffic_out{ {{.Label}} }`,
		Unit: "byte",
	},
	// sgw 公网弹性IP流量topK TODO
	//node_sgw_public_traffic_topK: &template.MetricsSqlTemplate{
	//	Sql:  `topK({{.TopK}},sum(increase(node_network_transmit_bytes_total{ {{.Label}} }[ {{.Duration}}s])+increase(node_network_receive_bytes_total{ {{.Label}} }[ {{.Duration}}s]))by(ip))`,
	//	Unit: "byte",
	//},
	//// sgw 公网弹性IP丢包率topK TODO
	//node_sgw_public_drop_packet_rate_topK: &template.MetricsSqlTemplate{
	//	Sql:  `topK({{.TopK}},sum(increase(node_network_drop_packets_total{ {{.Label}} }[ {{.Duration}}s]))by(ip)/(sum(increase(node_network_transmit_packets_total{ {{.Label}} }[ {{.Duration}}s])+increase(node_network_receive_packets_total{ {{.Label}} }[ {{.Duration}}s]))by(ip)))`,
	//	Unit: "%",
	//},

	//sgw 公网弹性IP流量topK
	node_sgw_public_eip_traffic_in_topK :&template.MetricsSqlTemplate{
		Sql:  `topK({{.TopK}},avg_over_time(sgw_eip_in_traffic{ {{.Label}} }[ {{.Duration}}s]))`,
		Unit: "byte",
	},
	node_sgw_public_eip_traffic_out_topK: &template.MetricsSqlTemplate{
		Sql:  `topK({{.TopK}},avg_over_time(sgw_eip_out_traffic{ {{.Label}} }[ {{.Duration}}s]))`,
		Unit: "byte",
	},
	//sgw 公网弹性IP流量Line
	node_sgw_public_eip_traffic_in: &template.MetricsSqlTemplate{
		Sql:  `sgw_eip_out_traffic{ {{.Label}} }`,
		Unit: "byte",
	},
	node_sgw_public_eip_traffic_out: &template.MetricsSqlTemplate{
		Sql:  `sgw_eip_in_traffic{ {{.Label}} }`,
		Unit: "byte",
	},
	//sgw 公网弹性IP丢包率topK
	node_sgw_public_eip_drop_packet_rate_in_topK: &template.MetricsSqlTemplate{
		Sql:  `topK({{.TopK}},rate(sgw_eip_in_drop_packet{ {{.Label}} }[ {{.Duration}}s]))`,
		Unit: "%",
	},
	node_sgw_public_eip_drop_packet_rate_out_topK: &template.MetricsSqlTemplate{
		Sql:  `topK({{.TopK}},rate(sgw_eip_out_drop_packet{ {{.Label}} }[ {{.Duration}}s]))`,
		Unit: "%",
	},
	node_sgw_public_eip_drop_packet_rate_in: &template.MetricsSqlTemplate{
		Sql:  `sgw_eip_in_drop_packet{ {{.Label}} }`,
		Unit: "%",
	},
	node_sgw_public_eip_drop_packet_rate_out: &template.MetricsSqlTemplate{
		Sql:  `sgw_eip_out_drop_packet{ {{.Label}} }`,
		Unit: "%",
	},
	//tgw
	node_tgw_lpeer_bytes_in_topK: &template.MetricsSqlTemplate{
		Sql: 	`topK({{.TopK}},sum(avg_over_time(tgw_bytes_in{ {{.Label}} ,tgwtype = "lpeer"}[ {{.Duration}}s]))by(vni, domain,dip, tgwtype))`,
		Unit: "byte",
	},
	node_tgw_lpeer_bytes_out_topK: &template.MetricsSqlTemplate{
		Sql: 	`topK({{.TopK}},sum(avg_over_time(tgw_bytes_out{ {{.Label}} ,tgwtype = "lpeer"}[ {{.Duration}}s]))by(vni, domain,dip, tgwtype))`,
		Unit: "byte",
	},
	node_tgw_dc_bytes_in_topK: &template.MetricsSqlTemplate{
		Sql: 	`topK({{.TopK}},sum(avg_over_time(tgw_bytes_in{ {{.Label}} ,tgwtype = "DC"}[ {{.Duration}}s]))by(vni, domain,dip, tgwtype))`,
		Unit: "byte",
	},
	node_tgw_dc_bytes_out_topK: &template.MetricsSqlTemplate{
		Sql: 	`topK({{.TopK}},sum(avg_over_time(tgw_bytes_out{ {{.Label}} ,tgwtype = "DC"}[ {{.Duration}}s]))by(vni, domain,dip, tgwtype))`,
		Unit: "byte",
	},
	node_tgw_vpn_bytes_in_topK: &template.MetricsSqlTemplate{
		Sql: 	`topK({{.TopK}},sum(avg_over_time(tgw_bytes_in{ {{.Label}} ,tgwtype = "vpn"}[ {{.Duration}}s]))by(vni, domain,dip, tgwtype))`,
		Unit: "byte",
	},
	node_tgw_vpn_bytes_out_topK: &template.MetricsSqlTemplate{
		Sql: 	`topK({{.TopK}},sum(avg_over_time(tgw_bytes_out{ {{.Label}} ,tgwtype = "vpn"}[ {{.Duration}}s]))by(vni, domain,dip, tgwtype))`,
		Unit: "byte",
	},
	node_tgw_lpeer_bytes_in: &template.MetricsSqlTemplate{
		Sql:`tgw_bytes_in{ {{.Label}} ,tgwtype = "lpeer"}`,
		Unit: "byte",
	},
	node_tgw_lpeer_bytes_out: &template.MetricsSqlTemplate{
		Sql:`tgw_bytes_out{ {{.Label}} ,tgwtype = "lpeer"}`,
		Unit: "byte",
	},
	node_tgw_dc_bytes_in: &template.MetricsSqlTemplate{
		Sql:`tgw_bytes_in{ {{.Label}} ,tgwtype = "DC"}`,
		Unit: "byte",
	},
	node_tgw_dc_bytes_out: &template.MetricsSqlTemplate{
		Sql:`tgw_bytes_out{ {{.Label}} ,tgwtype = "DC"}`,
		Unit: "byte",
	},
	node_tgw_vpn_bytes_in: &template.MetricsSqlTemplate{
		Sql:`tgw_bytes_in{ {{.Label}} ,tgwtype = "vpn"}`,
		Unit: "byte",
	},
	node_tgw_vpn_bytes_out: &template.MetricsSqlTemplate{
		Sql:`tgw_bytes_out{ {{.Label}} ,tgwtype = "vpn"}`,
		Unit: "byte",
	},
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/databaseResourcePool/databaseMetricTemplate.go
```golang
package databaseResourcePool

import (
	"bytes"
	"errors"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"
	"k8s.io/klog/v2"
	gotemplate "text/template"
)

var DatabaseMetricsTemplateName = "database_metrics_tempalte"


type DatabaseMetics struct {
	Label string
}


func NewDatabaseMetics(Label  string) *DatabaseMetics {
	return &DatabaseMetics{
		Label: Label,
	}
}

func (s *DatabaseMetics) Get(key string) (*template.MetricsSqlTemplate, error) {

	if _, ok := databaseMetricsMap[key]; ok {
		return databaseMetricsMap[key], nil
	} else {
		return nil, errors.New("swtich template not found")
	}

}

func (s *DatabaseMetics) ToString(key string) string {
	t, err := s.Get(key)
	if err != nil {
		klog.Errorf("Get swtich metrics template error, %s key not found", key)
		return ""
	}
	sqlTeplate, err := gotemplate.New(DatabaseMetricsTemplateName).Parse(t.Sql)
	if err != nil {
		klog.Errorf("go template error %s", err.Error())
		return ""
	}
	b := new(bytes.Buffer)
	err = sqlTeplate.Execute(b, s)
	if err != nil {
		klog.Errorf("go template execute %s", err.Error())
		return ""
	}
	return b.String()
}



```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/databaseResourcePool/map.go
```golang
package databaseResourcePool

import (
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"
)

var (
	node_cpu_seconds_total        = "node_cpu_seconds_total"
	node_memory_emAvailable_bytes = "node_memory_emAvailable_bytes"
	node_filesystem_free_bytes    = "node_filesystem_free_bytes"
)

var databaseMetricsMap = map[string]*template.MetricsSqlTemplate{
	//cpu使用率{{.Label}}
	node_cpu_seconds_total: &template.MetricsSqlTemplate{
		//Sql:  `100*(1-sum(increase(node_cpu_seconds_total{mode="idle",resourcePoolType="{{.ResourcePoolType}}",resourcePool="{{.ResourcePool}}"}[10m]))/sum(increase(node_cpu_seconds_total{resourcePoolType="{{.ResourcePoolType}}",resourcePool="{{.ResourcePool}}"}[10m])))`,
		Sql:  `100*(1-sum(increase(node_cpu_seconds_total{mode="idle",{{.Label}} }[10m]))/sum(increase(node_cpu_seconds_total{ {{.Label}} }[10m])))`,
		Unit: "",
	},

	//为了和服务器监控cpu使用率数据一致，采用相同的公式，将上面的注释
	//node_cpu_seconds_total: &template.MetricsSqlTemplate{
	//	//Sql:  `100*(1-sum(increase(node_cpu_seconds_total{mode="idle",resourcePoolType="{{.ResourcePoolType}}",resourcePool="{{.ResourcePool}}"}[10m]))/sum(increase(node_cpu_seconds_total{resourcePoolType="{{.ResourcePoolType}}",resourcePool="{{.ResourcePool}}"}[10m])))`,
	//	Sql:  `100*(1-sum(node_cpu_seconds_total{mode="idle",{{.Label}}}) / sum(node_cpu_seconds_total{ {{.Label}}}))`,
	//	Unit: "",
	//},

	// 内存使用率
	node_memory_emAvailable_bytes: &template.MetricsSqlTemplate{
		Sql:  `100*(1-sum(node_memory_MemAvailable_bytes{ {{.Label}} })/sum(node_memory_MemTotal_bytes{ {{.Label}} }))`,
		Unit: "",
	},
	// 磁盘使用率
	node_filesystem_free_bytes: &template.MetricsSqlTemplate{
		Sql:  `100*(1-(sum(node_filesystem_free_bytes{ {{.Label}} }))/sum(node_filesystem_size_bytes{ {{.Label}} }))`,
		Unit: "",
	},
}

type Metric string

const (
	CpuCountAmount         Metric = "cpu.count.amount"         // CPU 使用量
	CpuUtilizitionTotal    Metric = "cpu.utilizition.total"    // CPU 使用率
	MemoryUtilizitionTotal Metric = "memory.utilizition.total" // 内存使用率
	MemorySizeUsed         Metric = "memory.size.used"         // 内存使用量，单位Bytes
	MemorySizeTotal        Metric = "memory.size.total"        // 内存总量，单位Bytes
	DiskUtilizitionTotal   Metric = "disk.utilizition.total"   // 磁盘使用率
	DiskSizeUsed           Metric = "disk.size.used"           // 磁盘使用量，单位Bytes
	DiskSizeTotal          Metric = "disk.size.total"          // 磁盘总量，单位Bytes
)

var MonitorMetric = map[Metric]*template.QuerySql{
	CpuUtilizitionTotal: {
		SqlTemplate: `1-(sum(increase(node_cpu_seconds_total{mode="idle",{{.Labels}}}[10m])){{if gt .By.Len 0}} by ({{.By}}){{end}})/(sum(increase(node_cpu_seconds_total{ {{- .Labels -}} }[10m])){{if gt .By.Len 0}} by ({{.By}}){{end}})`,
		Name:        "CPU使用率",
		Unit:        "%",
	},
	CpuCountAmount: {
		SqlTemplate: `database_aggregate_vcpu_usage_count{ {{- .Labels -}} }`,
		Name:        "CPU使用量",
		Unit:        "个",
	},
	MemoryUtilizitionTotal: {
		SqlTemplate: `1-(sum(node_memory_MemAvailable_bytes{ {{- .Labels -}} }){{if gt .By.Len 0}} by ({{.By}}){{end}})/(sum(node_memory_MemTotal_bytes{ {{- .Labels -}} }){{if gt .By.Len 0}} by ({{.By}}){{end}})`,
		Name:        "内存使用率",
		Unit:        "%",
	},
	MemorySizeUsed: {
		SqlTemplate: `(sum(node_memory_MemTotal_bytes{ {{- .Labels -}} }){{if gt .By.Len 0}} by ({{.By}}){{end}}) - (sum(node_memory_MemAvailable_bytes{ {{- .Labels -}} }){{if gt .By.Len 0}} by ({{.By}}){{end}})`,
		Name:        "内存使用量",
		Unit:        "Bytes",
	},
	DiskUtilizitionTotal: {
		SqlTemplate: `1-(sum(node_filesystem_free_bytes{ {{- .Labels -}} }){{if gt .By.Len 0}} by ({{.By}}){{end}})/(sum(node_filesystem_size_bytes{ {{- .Labels -}} }){{if gt .By.Len 0}} by ({{.By}}){{end}})`,
		Name:        "磁盘使用率",
		Unit:        "%",
	},
	DiskSizeUsed: {
		SqlTemplate: `(sum(node_filesystem_size_bytes{ {{- .Labels -}} }){{if gt .By.Len 0}} by ({{.By}}){{end}}) - (sum(node_filesystem_free_bytes{ {{- .Labels -}} }){{if gt .By.Len 0}} by ({{.By}}){{end}})`,
		Name:        "磁盘使用量",
		Unit:        "Bytes",
	},
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/hardwareServer/hardwareServerTemp.go
```golang
package hardwareserver

import (
	"bytes"
	"errors"
	gotemplate "text/template"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"
	"k8s.io/klog/v2"
)

var SwitchMetricsTemplateName = "hardwar_metrics_tempalte"

type SwitchMetics struct {
	IP           string
	IfIndex      int
	IfIndexRange string
}

func NewSwitchMetics(ip string, ifIndex int) *SwitchMetics {
	return &SwitchMetics{
		IP:      ip,
		IfIndex: ifIndex,
	}
}

func (s *SwitchMetics) Get(key string) (*template.MetricsSqlTemplate, error) {

	if _, ok := HardwareMetricsMap[key]; ok {
		return HardwareMetricsMap[key], nil
	} else {
		return nil, errors.New("swtich template not found")
	}

}

func (s *SwitchMetics) ToString(key string) string {
	t, err := s.Get(key)
	if err != nil {
		klog.Errorf("Get swtich metrics template error, %s key not found", key)
		return ""
	}
	sqlTeplate, err := gotemplate.New(SwitchMetricsTemplateName).Parse(t.Sql)
	if err != nil {
		klog.Errorf("go template error %s", err.Error())
		return ""
	}
	b := new(bytes.Buffer)
	err = sqlTeplate.Execute(b, s)
	if err != nil {
		klog.Errorf("go template execute %s", err.Error())
		return ""
	}
	return b.String()
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/hardwareServer/map.go
```golang
package hardwareserver

import "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"

var (
	ipmi_chassis_power_state        = "ipmi_chassis_power_state" //power_chassis 1=on, 0=off
	ipmi_power_state                = "ipmi_power_state"         //0=nominal, 1=warning, 2=critical
	ipmi_power_state_count_value   = "ipmi_power_state_count_value"
	ipmi_power_watts                = "ipmi_power_watts"
	ipmi_fan_speed_state            = "ipmi_fan_speed_state" //0=nominal, 1=warning, 2=critical
	ipmi_fan_speed_rpm              = "ipmi_fan_speed_rpm"
	Switch_interface_admin_state    = "switch_interface_admin_state"
	Switch_interface_in_flow        = "switch_interface_in_flow"
	Switch_interface_out_flow       = "switch_interface_out_flow"
	Switch_interface_in_flowRate    = "switch_interface_in_flowRate"
	Switch_interface_out_flowRate   = "switch_interface_out_flowRate"
	Switch_interface_in_packageNum  = "switch_interface_in_packageNum"
	Switch_interface_out_packageNum = "switch_interface_out_packageNum"
	Switch_interface_in_errRate     = "switch_interface_in_errRate"
	Switch_interface_out_errRate    = "switch_interface_out_errRate"
	Switch_interface_in_dropRate    = "switch_interface_in_dropRate"
	Switch_interface_out_dropRate   = "switch_interface_out_dropRate"
	Switch_interface_in_errNum      = "switch_interface_in_errNum"
	Switch_interface_out_errNum     = "switch_interface_out_errNum"
	Switch_interface_in_dropNum     = "switch_interface_in_dropNum"
	Switch_interface_out_dropNum    = "switch_interface_out_dropNum"
	Switch_interface_errRate        = "switch_interface_errRate"
)

var HardwareMetricsMap = map[string]*template.MetricsSqlTemplate{
	ipmi_chassis_power_state: &template.MetricsSqlTemplate{
		Sql:  `ipmi_chassis_power_state{instance="{{.IP}}",service="ipmi-exporter"}`,
		Unit: "",
	},
	ipmi_power_state: &template.MetricsSqlTemplate{
		Sql:  `ipmi_power_state{instance="{{.IP}}",service="ipmi-exporter"}`,
		Unit: "",
	},
	ipmi_power_watts: &template.MetricsSqlTemplate{
		Sql:  `ipmi_power_watts{instance="{{.IP}}",service="ipmi-exporter"}`,
		Unit: "",
	},
	ipmi_fan_speed_state: &template.MetricsSqlTemplate{
		Sql:  `ipmi_fan_speed_state{instance="{{.IP}}",service="ipmi-exporter"}`,
		Unit: "",
	},
	ipmi_fan_speed_rpm: &template.MetricsSqlTemplate{
		Sql:  `ipmi_fan_speed_rpm{instance="{{.IP}}",service="ipmi-exporter"}`,
		Unit: "",
	},
	ipmi_power_state_count_value: &template.MetricsSqlTemplate{
		Sql:  `count_values("state",ipmi_power_state{instance="{{.IP}}",service="ipmi-exporter"}`,
		Unit: "",
	},
	Switch_interface_in_flow: &template.MetricsSqlTemplate{
		Sql:  `rate(ifHCInOctets{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10m])`,
		Unit: "",
	},
	Switch_interface_out_flow: &template.MetricsSqlTemplate{
		Sql:  `rate(ifHCOutOctets{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10m])`,
		Unit: "",
	},
	Switch_interface_in_flowRate: &template.MetricsSqlTemplate{
		Sql:  `rate(ifHCInOctets{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m])/ifHighSpeed{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/300/8`,
		Unit: "",
	},
	Switch_interface_out_flowRate: &template.MetricsSqlTemplate{
		Sql:  `rate(ifHCOutOctets{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m])/ifHighSpeed{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/300/8`,
		Unit: "",
	},
	Switch_interface_in_errRate: &template.MetricsSqlTemplate{
		Sql:  `ifInErrors{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/(ifHCInUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCInMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCInBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"})`,
		Unit: "",
	},
	Switch_interface_out_errRate: &template.MetricsSqlTemplate{
		Sql:  `ifOutErrors{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/(ifHCOutUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCOutMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCOutBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"})`,
		Unit: "",
	},
	Switch_interface_in_dropRate: &template.MetricsSqlTemplate{
		Sql:  `ifInDiscards{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/(ifHCInUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCInMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCInBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"})`,
		Unit: "",
	},
	Switch_interface_out_dropRate: &template.MetricsSqlTemplate{
		Sql:  `ifOutDiscards{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/(ifHCOutUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCOutMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCOutBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"})`,
		Unit: "",
	},
	Switch_interface_in_errNum: &template.MetricsSqlTemplate{
		Sql:  `ifInErrors{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}`,
		Unit: "",
	},
	Switch_interface_out_errNum: &template.MetricsSqlTemplate{
		Sql:  `ifOutErrors{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}`,
		Unit: "",
	},
	Switch_interface_in_dropNum: &template.MetricsSqlTemplate{
		Sql:  `ifInDiscards{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}`,
		Unit: "",
	},
	Switch_interface_out_dropNum: &template.MetricsSqlTemplate{
		Sql:  `ifOutDiscards{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}`,
		Unit: "",
	},
	Switch_interface_in_packageNum: &template.MetricsSqlTemplate{
		//Sql:  `(increase(ifHCInUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m])+increase(ifHCInMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m])+increase(ifHCInBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m]))/300`,
		Sql:  `rate(ifHCInUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10m])+rate(ifHCInMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10m])+rate(ifHCInBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10])`,
		Unit: "",
	},
	Switch_interface_out_packageNum: &template.MetricsSqlTemplate{
		//Sql:  `(increase(ifHCOutUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m])+increase(ifHCOutMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m])+increase(ifHCOutBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m]))/300`,
		Sql:  `rate(ifHCOutUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10m])+rate(ifHCOutMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10m])+rate(ifHCOutBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10m])`,
		Unit: "",
	},
	Switch_interface_errRate: &template.MetricsSqlTemplate{
		Sql:  `(ifInErrors{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifOutErrors{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/(ifHCInUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCInMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCInBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCOutUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCOutMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCOutBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"})`,
		Unit: "",
	},
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/container/containerMetricsTemplate.go
```golang
package container

import (
	"bytes"
	"errors"
	gotemplate "text/template"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"
	"k8s.io/klog/v2"
)

var MetricsTemplateName = "container_metrics_template"

type Metrics struct {
	PodName string
}

func NewMetrics(podName string) *Metrics {
	return &Metrics{
		PodName: podName,
	}
}

func (s *Metrics) Get(key string) (*template.MetricsSqlTemplate, error) {
	if _, ok := processMetricsMap[key]; ok {
		return processMetricsMap[key], nil
	}
	return nil, errors.New("process template not found")
}

func (s *Metrics) ToString(key string) string {
	t, err := s.Get(key)
	if err != nil {
		klog.Errorf("Get process metrics template error, %s key not found", key)
		return ""
	}
	sqlTemplate, err := gotemplate.New(MetricsTemplateName).Parse(t.Sql)
	if err != nil {
		klog.Errorf("go template error %s", err.Error())
		return ""
	}
	b := new(bytes.Buffer)
	err = sqlTemplate.Execute(b, s)
	if err != nil {
		klog.Errorf("go template execute %s", err.Error())
		return ""
	}
	return b.String()
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/container/map.go
```golang
package container

import "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"

var (
	Container_cpu_usage_seconds_total = "container_cpu_usage_seconds_total"
	Container_memory_usage_bytes      = "container_memory_usage_bytes"
)
var processMetricsMap = map[string]*template.MetricsSqlTemplate{
	Container_cpu_usage_seconds_total: {
		Sql:  `rate(container_cpu_usage_seconds_total{container="",pod="{{.PodName}}"}[5m])`,
		Unit: "",
	},
	Container_memory_usage_bytes: {
		Sql:  `sum(container_memory_usage_bytes{container="",pod="{{.PodName}}"})`,
		Unit: "",
	},
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/mysql/mysql.go
```golang
package mysql

import "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"


var (
	DataAccess = "DataAccess"
	ResourceLoad = "ResourceLoad"
	QueryCache = "QueryCache"
	InnoDB = "InnoDB"
	MyISAM = "MyISAM"
)

var MysqlMonitorIndexMaps = map[string]*template.MysqlMonitorTemplates{
	DataAccess: &template.MysqlMonitorTemplates{
		IndexType:"DataAccess",
		List: []string{
			"qps",
			"tps",
			"com_delete",
			"com_select",
			"com_update",
			"com_insert",
			"com_replace",
			"select_scan",
			"slow_queries",
			"handler_read_rnd_next",
			"internal_affairs",
			"table_locks_waited"},
	},
	ResourceLoad: &template.MysqlMonitorTemplates{
		IndexType:"ResourceLoad",
		List: []string{
			"cpu_used_percent",
			"memory_used_percent",
			"resident_memory_size",
			"io",
			"iops",
			"network_io",
			"max_connections",
			"link"},
	},
	QueryCache: &template.MysqlMonitorTemplates{
		IndexType:"QueryCache",
		List: []string{
			"qcache_hit_ratio",
			"qcache_used_percent"},
	},
	InnoDB : &template.MysqlMonitorTemplates{
		IndexType:"InnoDB",
		List: []string{
			"innodb_data",
			"innodb_buffer_pool_hit_ratio",
			"innodb_buffer_pool_pages",
			"innodb_buffer_pool_read",
			"innodb_buffer_pool_use_ratio",
			"innodb_num_open_files",
			"innodb_data_read_written"},
	},
	MyISAM : &template.MysqlMonitorTemplates{
		IndexType:"MyISAM",
		List: []string{
			"myisam_keycache_readhit_ration",
			"myisam_keycache_used_percent"},
	},

}

var (
	// 数据访问
	qps = "qps"
	tps = "tps"
	comDelete = "com_delete"//delete操作数
	comSelect = "com_select"//com_select操作数
	comUpdate = "com_update"//com_update操作数
	comInsert = "com_insert"//com_insert操作数
	comReplace = "com_replace"//com_replace操作数
	selectScan = "select_scan" // 全表扫描数
	slowQueries = "slow_queries"//慢查询数
	handlerReadRndNext = "handler_read_rnd_next"//请求下一行数
	internalAffairs = "internal_affairs"//内部事务数
	tableLocksWaited = "table_locks_waited"// 表锁次数
	//资源及负载
	cpuUsedPercent = "cpu_used_percent" // CPU使用率
	memoryUsedPercent = "memory_used_percent" // 内存使用率
	residentMemorySize =  "resident_memory_size"//内存使用量
	io = "io" // io吞吐
	iops = "iops" // iops
	networkIo = "network_io" // 网络吞吐
	maxConnections = "max_connections" // 最大连接数
	link = "link" // 连接数
	//Query Cache
	qcacheHitRatio = "qcache_hit_ratio" // query cache命中率
	qcacheUsedPercent = "qcache_used_percent" // query cache使用率
	//InnoDB
	innodbData = "innodb_data" // InnoDB 磁盘访问次数
	innodbBufferPoolHitRatio = "innodb_buffer_pool_hit_ratio" // InnoDB 缓存命中率
	innodbBufferPoolPages = "innodb_buffer_pool_pages" // InnoDB 内存页数
	innodbBufferPoolRead = "innodb_buffer_pool_read"//InnoDB 读请求次数
	innodbBufferPoolUseRatio = "innodb_buffer_pool_use_ratio" // InnoDB 缓存使用率
	innodbNumOpenFiles = "innodb_num_open_files" // 当前 InnoDB 打开文件数量
	innodbDataReadWritten = "innodb_data_read_written"// InnoDB读取/写入数据量
	//MyISAM
	myisamKeycacheReadhitRation = "myisam_keycache_readhit_ration" // MyISAM 缓存命中率
	myisamKeycacheUsedPercent = "myisam_keycache_used_percent" // MyISAM 缓存使用率
)

var MysqlMonitorIndexMap = map[string]*template.MysqlMonitorTemplate{
	//todo 数据访问
	qps: &template.MysqlMonitorTemplate{
		Metric:     []string{"qps"},
		Name:        "qps",
		Unit:        "次/秒",
		UnitType:    "times/second",
		Copywriting: "QPS",

	},
	tps: &template.MysqlMonitorTemplate{
		Metric:     []string{"tps"},
		Name:        "tps",
		Unit:        "次/秒",
		UnitType:    "times/second",
		Copywriting: "TPS",
	},
	comDelete: &template.MysqlMonitorTemplate{
		Metric:     []string{"com_delete"},
		Name:        "com_delete",
		Unit:        "次/秒",
		UnitType:    "times/second",
		Copywriting: "Delete操作数",
	},
	comSelect: &template.MysqlMonitorTemplate{
		Metric:     []string{"com_select"},
		Name:        "com_select",
		Unit:        "次/秒",
		UnitType:    "times/second",
		Copywriting: "Select操作数",
	},
	comUpdate: &template.MysqlMonitorTemplate{
		Metric:     []string{"com_update"},
		Name:        "com_update",
		Unit:        "次/秒",
		UnitType:    "times/second",
		Copywriting: "Update操作数",
	},
	comInsert: &template.MysqlMonitorTemplate{
		Metric:     []string{"com_insert"},
		Name:        "com_insert",
		Unit:        "次/秒",
		UnitType:    "times/second",
		Copywriting: "Insert操作数",
	},
	comReplace: &template.MysqlMonitorTemplate{
		Metric:     []string{"com_replace"},
		Name:        "com_replace",
		Unit:        "次/秒",
		UnitType:    "times/second",
		Copywriting: "Replace操作数",
	},
	selectScan: &template.MysqlMonitorTemplate{
		Metric:     []string{"select_scan"},
		Name:        "select_scan",
		Unit:        "次/秒",
		UnitType:    "times/second",
		Copywriting: "全表扫描数",
	},
	slowQueries: &template.MysqlMonitorTemplate{
		Metric:     []string{"slow_queries"},
		Name:        "slow_queries",
		Unit:        "次",
		UnitType:    "second",
		Copywriting: "慢查询数",
	},
	handlerReadRndNext: &template.MysqlMonitorTemplate{
		Metric:     []string{"handler_read_rnd_next"},
		Name:        "handler_read_rnd_next",
		Unit:        "次/秒",
		UnitType:    "times/second",
		Copywriting: "读下一行请求数",
	},
	internalAffairs: &template.MysqlMonitorTemplate{
		Metric:     []string{"handler_rollback","handler_commit"},
		//Metric:     []string{"qps","tps"},
		Name:        "internal_affairs",
		Unit:        "次/秒",
		UnitType:    "times/second",
		Copywriting: "内部事务数",
	},
	tableLocksWaited: &template.MysqlMonitorTemplate{
		Metric:     []string{"table_locks_waited"},
		Name:        "table_locks_waited",
		Unit:        "次/秒",
		UnitType:    "times/second",
		Copywriting: "表锁次数",
	},
	//todo 资源及负载
	cpuUsedPercent: &template.MysqlMonitorTemplate{
		Metric:     []string{"cpu_used_percent"},
		Name:        "cpu_used_percent",
		Unit:        "%",
		UnitType:    "percentage",
		Copywriting: "CPU使用率",
	},
	memoryUsedPercent: &template.MysqlMonitorTemplate{
		Metric:     []string{"memory_used_percent"},
		Name:        "memory_used_percent",
		Unit:        "%",
		UnitType:    "percentage",
		Copywriting: "内存使用率",
	},
	residentMemorySize: &template.MysqlMonitorTemplate{
		Metric:     []string{"resident_memory_size"},
		Name:        "resident_memory_size",
		Unit:        "MB",
		UnitType:    "MB",
		Copywriting: "内存使用量",
	},
	io: &template.MysqlMonitorTemplate{
		Metric:     []string{"rbps","wbps"},
		Name:        "io",
		Unit:        "字节/秒",
		UnitType:    "bytes/second",
		Copywriting: "io吞吐",
	},
	iops: &template.MysqlMonitorTemplate{
		Metric:     []string{"riops","wiops"},
		Name:        "iops",
		Unit:        "次/秒",
		UnitType:    "times/second",
		Copywriting: "IOPS",
	},
	networkIo: &template.MysqlMonitorTemplate{
		Metric:     []string{"bytes_sent","bytes_received"},
		Name:        "network_io",
		Unit:        "kb/s",
		UnitType:    "kb/second",
		Copywriting: "网络吞吐",
	},
	maxConnections: &template.MysqlMonitorTemplate{
		Metric:     []string{"max_connections"},
		Name:        "max_connections",
		Unit:        "个",
		UnitType:    "individual",
		Copywriting: "最大连接数",
	},
	link: &template.MysqlMonitorTemplate{
		Metric:     []string{"threads_running","threads_connected"},
		Name:        "link",
		Unit:        "个",
		UnitType:    "individual",
		Copywriting: "连接数",
	},
	//todo query cache
	qcacheHitRatio: &template.MysqlMonitorTemplate{
		Metric:     []string{"qcache_hit_ratio"},
		Name:        "qcache_hit_ratio",
		Unit:        "%",
		UnitType:    "percentage",
		Copywriting: "query cache命中率",
	},
	qcacheUsedPercent: &template.MysqlMonitorTemplate{
		Metric:     []string{"qcache_used_percent"},
		Name:        "qcache_used_percent",
		Unit:        "%",
		UnitType:    "percentage",
		Copywriting: "query cache使用率",
	},
	// todo innodb
	innodbData: &template.MysqlMonitorTemplate{
		Metric:     []string{"innodb_data_fsyncs","innodb_data_reads","innodb_data_writes"},
		Name:        "innodb_data",
		Unit:        "次/秒",
		UnitType:    "times/second",
		Copywriting: "InnoDB 磁盘访问次数",
	},
	innodbBufferPoolHitRatio: &template.MysqlMonitorTemplate{
		Metric:     []string{"innodb_buffer_pool_hit_ratio"},
		Name:        "innodb_buffer_pool_hit_ratio",
		Unit:        "%",
		UnitType:    "percentage",
		Copywriting: "InnoDB 缓存命中率",
	},
	innodbBufferPoolPages: &template.MysqlMonitorTemplate{
		Metric:     []string{"innodb_buffer_pool_pages_free","innodb_buffer_pool_pages_total"},
		Name:        "innodb_buffer_pool_pages",
		Unit:        "个",
		UnitType:    "individual",
		Copywriting: "InnoDB 内存页数",
	},
	innodbBufferPoolRead: &template.MysqlMonitorTemplate{
		Metric:     []string{"innodb_buffer_pool_read_requests","innodb_buffer_pool_reads"},
		Name:        "innodb_buffer_pool_read",
		Unit:        "次/秒",
		UnitType:    "times/second",
		Copywriting: "InnoDB 读请求次数",
	},
	innodbBufferPoolUseRatio: &template.MysqlMonitorTemplate{
		Metric:     []string{"innodb_buffer_pool_use_ratio"},
		Name:        "innodb_buffer_pool_use_ratio",
		Unit:        "%",
		UnitType:    "percentage",
		Copywriting: "InnoDB 缓存使用率",
	},
	innodbNumOpenFiles: &template.MysqlMonitorTemplate{
		Metric:     []string{"innodb_num_open_files"},
		Name:        "innodb_num_open_files",
		Unit:        "个",
		UnitType:    "individual",
		Copywriting: "当前 InnoDB 打开文件数量",
	},
	innodbDataReadWritten: &template.MysqlMonitorTemplate{
	Metric:     []string{"innodb_data_read","innodb_data_written"},
	Name:        "innodb_data_read_written",
	Unit:        "个",
	UnitType:    "individual",
	Copywriting: "InnoDB 读取/写入数据量",
	},
	// todo MyISAM
	myisamKeycacheReadhitRation: &template.MysqlMonitorTemplate{
		Metric:     []string{"myisam_keycache_readhit_ration","myisam_keycache_writehit_ration"},
		Name:        "myisam_keycache_readhit_ration",
		Unit:        "%",
		UnitType:    "percentage",
		Copywriting: "MyISAM 缓存命中率",
	},
	myisamKeycacheUsedPercent: &template.MysqlMonitorTemplate{
		Metric:     []string{"myisam_keycache_used_percent"},
		Name:        "myisam_keycache_used_percent",
		Unit:        "%",
		UnitType:    "percentage",
		Copywriting: "MyISAM 缓存使用率",
	},
}



```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/opentsdb/metricTemplate.go
```golang
package opentsdb

var SwitchMetricsTemplateName = "swtich_metrics_tempalte"

type OpenTsdbLastMetric struct {
	Metric string            `json:"metric"`
	Tags   map[string]string `json:"tags"`
}

type OpenTsdbRangeMetric struct {
	Aggregator string            `json:"aggregator"`
	Metric     string            `json:"metric"`
	Tags       map[string]string `json:"tags"`
	Downsample string            `json:"downsample"`
}

func NewOpenTsdbLastMetric(metric string, tags map[string]string) OpenTsdbLastMetric {
	return OpenTsdbLastMetric{
		Metric: metric,
		Tags:   tags,
	}
}

func NewOpenTsdbRangeMetric(aggregator, metric, downsample string, tags map[string]string) OpenTsdbRangeMetric {
	return OpenTsdbRangeMetric{
		Aggregator: aggregator,
		Metric:     metric,
		Tags:       tags,
		Downsample: downsample,
	}
}

// func (s *SwitchMetics) Get(key string) (*template.MetricsSqlTemplate, error) {

// 	if _, ok := switchMetricsMap[key]; ok {
// 		return switchMetricsMap[key], nil
// 	} else {
// 		return nil, errors.New("swtich template not found")
// 	}

// }

// func (s *SwitchMetics) ToString(key string) string {
// 	t, err := s.Get(key)
// 	if err != nil {
// 		klog.Errorf("Get swtich metrics template error, %s key not found", key)
// 		return ""
// 	}
// 	sqlTeplate, err := gotemplate.New(SwitchMetricsTemplateName).Parse(t.Sql)
// 	if err != nil {
// 		klog.Errorf("go template error %s", err.Error())
// 		return ""
// 	}
// 	b := new(bytes.Buffer)
// 	err = sqlTeplate.Execute(b, s)
// 	if err != nil {
// 		klog.Errorf("go template execute %s", err.Error())
// 		return ""
// 	}
// 	return b.String()
// }

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/opentsdb/map.go
```golang
package opentsdb

import "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"

var (
	Eip_band_rate_out = "eip_band_rate_out"
	Eip_band_rate_in  = "eip_band_rate_in"
	Eip_pps_out       = "eip_pps_out"
	Eip_pps_in        = "eip_pps_in"
	Eip_flow_out      = "eip_flow_out"
	Eip_flow_in       = "eip_flow_in"
)

var OpenTsdbMetricsMap = map[string]*template.MetricsSqlTemplate{
	Eip_band_rate_out: &template.MetricsSqlTemplate{
		Sql:  `eip.utilization.out`,
		Unit: "",
	},
	Eip_band_rate_in: &template.MetricsSqlTemplate{
		Sql:  `eip.utilization.in`,
		Unit: "",
	},
	Eip_pps_out: &template.MetricsSqlTemplate{
		Sql:  `eip.pps.out`,
		Unit: "",
	},
	Eip_pps_in: &template.MetricsSqlTemplate{
		Sql:  `eip.pps.in`,
		Unit: "",
	},
	Eip_flow_out: &template.MetricsSqlTemplate{
		Sql:  `eip.bps.out`,
		Unit: "",
	},
	Eip_flow_in: &template.MetricsSqlTemplate{
		Sql:  `eip.bps.in`,
		Unit: "",
	},
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/physicalSwitch/switchMetricsTemplate.go
```golang
package physicalSwitch

import (
	"bytes"
	"errors"
	gotemplate "text/template"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"
	"k8s.io/klog/v2"
)

var SwitchMetricsTemplateName = "swtich_metrics_tempalte"

type SwitchMetics struct {
	IP           string
	IfIndex      int
	IfIndexRange string
}

func NewSwitchMetics(ip string, ifIndex int) *SwitchMetics {
	return &SwitchMetics{
		IP:      ip,
		IfIndex: ifIndex,
	}
}

func (s *SwitchMetics) Get(key string) (*template.MetricsSqlTemplate, error) {

	if _, ok := switchMetricsMap[key]; ok {
		return switchMetricsMap[key], nil
	} else {
		return nil, errors.New("swtich template not found")
	}

}

func (s *SwitchMetics) ToString(key string) string {
	t, err := s.Get(key)
	if err != nil {
		klog.Errorf("Get swtich metrics template error, %s key not found", key)
		return ""
	}
	sqlTeplate, err := gotemplate.New(SwitchMetricsTemplateName).Parse(t.Sql)
	if err != nil {
		klog.Errorf("go template error %s", err.Error())
		return ""
	}
	b := new(bytes.Buffer)
	err = sqlTeplate.Execute(b, s)
	if err != nil {
		klog.Errorf("go template execute %s", err.Error())
		return ""
	}
	return b.String()
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/physicalSwitch/map.go
```golang
package physicalSwitch

import "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"

var (
	Switch_up                       = "switch_up"
	Switch_cpu_usage_rate           = "switch_cpu_usage_rate"
	Switch_memory_usage_rate        = "switch_memory_usage_rate"
	Switch_power_usage_rate			= "switch_power_usage_rate"
	Switch_interface_oper_state     = "switch_interface_oper_state"
	Switch_interface_admin_state    = "switch_interface_admin_state"
	Switch_interface_in_flow        = "switch_interface_in_flow"
	Switch_interface_out_flow       = "switch_interface_out_flow"
	Switch_interface_in_flowRate    = "switch_interface_in_flowRate"
	Switch_interface_out_flowRate   = "switch_interface_out_flowRate"
	Switch_interface_in_packageNum  = "switch_interface_in_packageNum"
	Switch_interface_out_packageNum = "switch_interface_out_packageNum"
	Switch_interface_in_errRate     = "switch_interface_in_errRate"
	Switch_interface_out_errRate    = "switch_interface_out_errRate"
	Switch_interface_in_dropRate    = "switch_interface_in_dropRate"
	Switch_interface_out_dropRate   = "switch_interface_out_dropRate"
	Switch_interface_in_errNum      = "switch_interface_in_errNum"
	Switch_interface_out_errNum     = "switch_interface_out_errNum"
	Switch_interface_in_dropNum     = "switch_interface_in_dropNum"
	Switch_interface_out_dropNum    = "switch_interface_out_dropNum"
	Switch_interface_errRate        = "switch_interface_errRate"
)

var switchMetricsMap = map[string]*template.MetricsSqlTemplate{
	Switch_up: &template.MetricsSqlTemplate{
		Sql:  `up{instance="{{.IP}}" }`,
		Unit: "",
	},
	Switch_cpu_usage_rate: &template.MetricsSqlTemplate{
		Sql:  `cpuUsageRate{instance="{{.IP}}"}`,
		Unit: "",
	},
	Switch_memory_usage_rate: &template.MetricsSqlTemplate{
		Sql:  `memoryUsageRate{instance="{{.IP}}"}`,
		Unit: "",
	},
	Switch_power_usage_rate: &template.MetricsSqlTemplate{
		Sql:  `memoryUsageRate{instance="{{.IP}}"}`,
		Unit: "",
	},
	Switch_interface_oper_state: &template.MetricsSqlTemplate{
		Sql:  `ifOperStatus{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}`,
		Unit: "",
	},
	Switch_interface_admin_state: &template.MetricsSqlTemplate{
		Sql:  `ifAdminStatus{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}`,
		Unit: "",
	},
	Switch_interface_in_flow: &template.MetricsSqlTemplate{
		Sql:  `rate(ifHCInOctets{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10m])`,
		Unit: "",
	},
	Switch_interface_out_flow: &template.MetricsSqlTemplate{
		Sql:  `rate(ifHCOutOctets{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10m])`,
		Unit: "",
	},
	//`rate(ifHCInOctets{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m])/(ifHighSpeed{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/300/8*100)`
	Switch_interface_in_flowRate: &template.MetricsSqlTemplate{
		Sql:  `rate(ifHCInOctets{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m])/(ifHighSpeed{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/300)/1024/1024/8>0`,
		Unit: "",
	},
	
	//`rate(ifHCOutOctets{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m])/(ifHighSpeed{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/300/8*100>0)`
	Switch_interface_out_flowRate: &template.MetricsSqlTemplate{
		Sql:  `rate(ifHCOutOctets{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m])/(ifHighSpeed{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/300)/1024/1024/8>0`,
		Unit: "",
	},
	Switch_interface_in_errRate: &template.MetricsSqlTemplate{
		Sql:  `ifInErrors{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/(ifHCInUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCInMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCInBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}>0)`,
		Unit: "",
	},
	Switch_interface_out_errRate: &template.MetricsSqlTemplate{
		Sql:  `ifOutErrors{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/(ifHCOutUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCOutMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCOutBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}>0)`,
		Unit: "",
	},
	Switch_interface_in_dropRate: &template.MetricsSqlTemplate{
		Sql:  `ifInDiscards{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/(ifHCInUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCInMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCInBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}>0)`,
		Unit: "",
	},
	Switch_interface_out_dropRate: &template.MetricsSqlTemplate{
		Sql:  `ifOutDiscards{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/(ifHCOutUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCOutMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCOutBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}>0)`,
		Unit: "",
	},
	Switch_interface_in_errNum: &template.MetricsSqlTemplate{
		Sql:  `ifInErrors{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}`,
		Unit: "",
	},
	Switch_interface_out_errNum: &template.MetricsSqlTemplate{
		Sql:  `ifOutErrors{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}`,
		Unit: "",
	},
	Switch_interface_in_dropNum: &template.MetricsSqlTemplate{
		Sql:  `ifInDiscards{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}`,
		Unit: "",
	},
	Switch_interface_out_dropNum: &template.MetricsSqlTemplate{
		Sql:  `ifOutDiscards{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}`,
		Unit: "",
	},
	Switch_interface_in_packageNum: &template.MetricsSqlTemplate{
		//Sql:  `(increase(ifHCInUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m])+increase(ifHCInMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m])+increase(ifHCInBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m]))/300`,
		Sql:  `rate(ifHCInUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10m])+rate(ifHCInMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10m])+rate(ifHCInBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10])`,
		Unit: "",
	},
	Switch_interface_out_packageNum: &template.MetricsSqlTemplate{
		//Sql:  `(increase(ifHCOutUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m])+increase(ifHCOutMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m])+increase(ifHCOutBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[5m]))/300`,
		Sql:  `rate(ifHCOutUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10m])+rate(ifHCOutMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10m])+rate(ifHCOutBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}[10m])`,
		Unit: "",
	},
	Switch_interface_errRate: &template.MetricsSqlTemplate{
		Sql:  `(ifInErrors{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifOutErrors{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}/(ifHCInUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCInMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCInBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCOutUcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCOutMulticastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"}+ifHCOutBroadcastPkts{instance="{{.IP}}",ifIndex="{{.IfIndex}}"})`,
		Unit: "",
	},
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/eip/eipMetricTemplate.go
```golang
package eip

import (
	"bytes"
	"errors"
	gotemplate "text/template"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"
	"k8s.io/klog/v2"
)

var EipPoolMetricsTemplateName = "EipPool_metrics_tempalte"

type EipPoolMetics struct {
	Region string
	Cidr   string
}

func NewEipPoolMetics(region, cidr string) *EipPoolMetics {
	return &EipPoolMetics{
		Region: region,
		Cidr:   cidr,
	}
}

func (s *EipPoolMetics) Get(key string) (*template.MetricsSqlTemplate, error) {

	if _, ok := switchMetricsMap[key]; ok {
		return switchMetricsMap[key], nil
	} else {
		return nil, errors.New("swtich template not found")
	}

}

func (s *EipPoolMetics) ToString(key string) string {
	t, err := s.Get(key)
	if err != nil {
		klog.Errorf("Get swtich metrics template error, %s key not found", key)
		return ""
	}
	sqlTeplate, err := gotemplate.New(EipPoolMetricsTemplateName).Parse(t.Sql)
	if err != nil {
		klog.Errorf("go template error %s", err.Error())
		return ""
	}
	b := new(bytes.Buffer)
	err = sqlTeplate.Execute(b, s)
	if err != nil {
		klog.Errorf("go template execute %s", err.Error())
		return ""
	}
	return b.String()
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/eip/map.go
```golang
package eip

import "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"

var (
	eip_pool_used_rate               = "eip_pool_used_rate"
	eip_pool_ip_total                = "eip_pool_ip_total"
	eip_pool_used_rate_by_region     = "eip_pool_used_rate_by_region"
	eip_pool_used_rate_by_netSegment = "eip_pool_used_rate_by_netSegment"
)

var switchMetricsMap = map[string]*template.MetricsSqlTemplate{
	eip_pool_used_rate: &template.MetricsSqlTemplate{
		Sql:  `sum(sum_over_time(eip_used_count{region="{{.Region}}",cidr="{{.Cidr}}"}[10m]))/sum(sum_over_time(eip_ip_count{region="{{.Region}}",cidr="{{.Cidr}}"}[10m]))`,
		Unit: "",
	},
	eip_pool_used_rate_by_region: &template.MetricsSqlTemplate{
		Sql:  `sum(sum_over_time(eip_used_count{}[10m]))by(region)/sum(sum_over_time(eip_ip_count{}[10m]))by(region)`,
		Unit: "",
	},
	eip_pool_used_rate_by_netSegment: &template.MetricsSqlTemplate{
		Sql:  `sum_over_time(eip_used_count{ {{.Region}} }[10m])/sum_over_time(eip_ip_count{ {{.Region}} }[10m])`,
		Unit: "",
	},
	eip_pool_ip_total: &template.MetricsSqlTemplate{
		Sql:  `sum_over_time(eip_ip_total{region="{{.Region}}",cidr="{{.Cidr}}"}[10m])`,
		Unit: "",
	},
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/process/processMetricsTemplate.go
```golang
package process

import (
	"bytes"
	"errors"
	gotemplate "text/template"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"
	"k8s.io/klog/v2"
)

var MetricsTemplateName = "process_metrics_template"

type Metrics struct {
	IP        string
	GroupName string
	State     string
	NodeIP    string
}

func NewMetrics(ip, groupName, state, nodeIP string) *Metrics {
	return &Metrics{
		IP:        ip,
		GroupName: groupName,
		State:     state,
		NodeIP:    nodeIP,
	}
}

func (s *Metrics) Get(key string) (*template.MetricsSqlTemplate, error) {
	if _, ok := processMetricsMap[key]; ok {
		return processMetricsMap[key], nil
	}
	return nil, errors.New("process template not found")
}

func (s *Metrics) ToString(key string) string {
	t, err := s.Get(key)
	if err != nil {
		klog.Errorf("Get process metrics template error, %s key not found", key)
		return ""
	}
	sqlTemplate, err := gotemplate.New(MetricsTemplateName).Parse(t.Sql)
	if err != nil {
		klog.Errorf("go template error %s", err.Error())
		return ""
	}
	b := new(bytes.Buffer)
	err = sqlTemplate.Execute(b, s)
	if err != nil {
		klog.Errorf("go template execute %s", err.Error())
		return ""
	}
	return b.String()
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/process/map.go
```golang
package process

import "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"

var (
	Namedprocess_namegroup_states            = "namedprocess_namegroup_states"
	Namedprocess_namegroup_num_procs         = "namedprocess_namegroup_num_procs"
	Namedprocess_namegroup_cpu_seconds_total = "namedprocess_namegroup_cpu_seconds_total"
	Namedprocess_namegroup_memory_bytes      = "namedprocess_namegroup_memory_bytes"
	Namedprocess_namegroup_write_bytes_total = "namedprocess_namegroup_write_bytes_total"
	Namedprocess_namegroup_read_bytes_total  = "namedprocess_namegroup_read_bytes_total"
	Probe_success                            = "probe_success"
)
var processMetricsMap = map[string]*template.MetricsSqlTemplate{
	Namedprocess_namegroup_states: {
		Sql:  `namedprocess_namegroup_states{groupname=~"{{.GroupName}}",instance="{{.IP}}",state="{{.State}}"}`, //map[:`+groupName+`]  ;` + ip + `:9256;` + state + `
		Unit: "",
	},
	Namedprocess_namegroup_num_procs: {
		Sql:  `namedprocess_namegroup_num_procs{groupname=~"{{.GroupName}}",instance="{{.IP}}"}`, //map[:`+groupName+`]  ;` + ip + `:9256;` + state + `
		Unit: "",
	},
	Namedprocess_namegroup_cpu_seconds_total: {
		Sql:  `sum(rate(namedprocess_namegroup_cpu_seconds_total{groupname=~"{{.GroupName}}",instance="{{.IP}}"}[5m]))*100`, //map[:`+groupName+`]  ;{{.IP}};` + state + `
		Unit: "",
	},
	//Namedprocess_namegroup_memory_bytes: {
	//	Sql:  `sum(namedprocess_namegroup_memory_bytes{groupname=~"{{.GroupName}}",instance="{{.IP}}",memtype="resident"})/sum(namedprocess_namegroup_memory_bytes{groupname=~"{{.GroupName}}",instance="{{.IP}}"})*100`, //map[:`+groupName+`]  ;{{.IP}};` + state + `
	//	Unit: "",
	//},

	Namedprocess_namegroup_memory_bytes: {
		Sql:  `sum(namedprocess_namegroup_memory_bytes{groupname=~"{{.GroupName}}",instance="{{.IP}}",memtype="resident"})/avg(node_memory_MemTotal_bytes{instance="{{.NodeIP}}"})*100`, //map[:`+groupName+`]  ;{{.IP}};` + state + `
		Unit: "",
	},

	Namedprocess_namegroup_write_bytes_total: {
		Sql:  `rate(namedprocess_namegroup_write_bytes_total{groupname=~"{{.GroupName}}",instance="{{.IP}}"}[100s])`, //map[:`+groupName+`]  ;{{.IP}};` + state + `
		Unit: "",
	},
	Namedprocess_namegroup_read_bytes_total: {
		Sql:  `rate(namedprocess_namegroup_read_bytes_total{groupname=~"{{.GroupName}}",instance="{{.IP}}"}[100s])`, //map[:`+groupName+`]  ;{{.IP}};` + state + `
		Unit: "",
	},
	Probe_success: {
		Sql:  `probe_success{target=~"{{.IP}}"}`, //端口查询
		Unit: "",
	},
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/block/blockMetricTemplate.go
```golang
package block

import (
	"bytes"
	"errors"
	gotemplate "text/template"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"
	"k8s.io/klog/v2"
)

var BlockMetricsTemplateName = "block_metrics_tempalte"

type BlockMetics struct {
	Region       string
	Az           string
	ResourcePool string
}

func NewBlockMetics(region, az, resourcePool string) *BlockMetics {
	return &BlockMetics{
		Region:       region,
		Az:           az,
		ResourcePool: resourcePool,
	}
}

func (s *BlockMetics) Get(key string) (*template.MetricsSqlTemplate, error) {

	if _, ok := blockMetricsMap[key]; ok {
		return blockMetricsMap[key], nil
	} else {
		return nil, errors.New("swtich template not found")
	}

}

func (s *BlockMetics) ToString(key string) string {
	t, err := s.Get(key)
	if err != nil {
		klog.Errorf("Get swtich metrics template error, %s key not found", key)
		return ""
	}
	sqlTeplate, err := gotemplate.New(BlockMetricsTemplateName).Parse(t.Sql)
	if err != nil {
		klog.Errorf("go template error %s", err.Error())
		return ""
	}
	b := new(bytes.Buffer)
	err = sqlTeplate.Execute(b, s)
	if err != nil {
		klog.Errorf("go template execute %s", err.Error())
		return ""
	}
	return b.String()
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/template/block/map.go
```golang
package block

import "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template"

var (
	xuanwu_read_bw  = "xuanwu_read_bw"
	xuanwu_write_bw = "xuanwu_write_bw"
)

var blockMetricsMap = map[string]*template.MetricsSqlTemplate{
	xuanwu_read_bw: &template.MetricsSqlTemplate{
		Sql:  `xuanwu_read_bw{region="{{.Region}}",az="{{.Az}}",resourcePool="{{.ResourcePool}}"}`,
		Unit: "",
	},
	xuanwu_write_bw: &template.MetricsSqlTemplate{
		Sql:  `xuanwu_write_bw{region="{{.Region}}",az="{{.Az}}",resourcePool="{{.ResourcePool}}"}`,
		Unit: "",
	},
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/utils/apicache.go
```golang
package utils

import (
	"context"
	"encoding/json"
	redisclient "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"golang.org/x/sync/singleflight"
	"k8s.io/klog/v2"
)

// api结果临时缓存方案,永不过期,不能及时更新缓存
// 仅作为保证页面可正常使用的临时方案

var sg = singleflight.Group{}

type apiCache struct {
}

func NewApiCache() *apiCache {
	return &apiCache{}
}

func (ac apiCache) Get(queryKey string, fn func() (interface{}, error)) ([]byte, error) {
	cacheResult, err := redisclient.Get(context.Background(), queryKey, nil)
	if err != nil {
		klog.Errorf("%s - get redis error %v", queryKey, err)
		klog.Infof("%s - query start", queryKey)
		queryResult, err := query(queryKey, fn)
		klog.Infof("%s - query end", queryKey)
		if err != nil {
			klog.Errorf("%s - cache miss and query error: %v", queryKey, err)
			return nil, err
		} else {
			j, err := json.Marshal(queryResult)
			if err != nil {
				klog.Errorf("%s - Marshal error %v", queryKey, err)
				return nil, err
			}
			_, err = redisclient.SetNotExpire(context.Background(), queryKey, j)
			if err != nil {
				klog.Errorf("%s - set redis error %v", queryKey, err)
				return nil, err
			}
			klog.Infof("%s - redis set ok", queryKey)
			return j, nil
		}
	} else {
		klog.Infof("%s - get redis ok", queryKey)
		result := []byte(cacheResult)
		GoSafe(func() { updateCache(queryKey, fn) })
		return result, nil
	}
}

// query is a singleflight.Group.Do call
func query(key string, fn func() (interface{}, error)) (interface{}, error) {
	v, err, _ := sg.Do(key, fn)
	return v, err
}

func updateCache(queryKey string, fn func() (interface{}, error)) {

	klog.Infof("%s - update cache start", queryKey)
	klog.Infof("%s - update query start", queryKey)
	queryResult, err := query(queryKey, fn)
	klog.Infof("%s - update query end", queryKey)
	if err != nil {
		klog.Errorf("%s - update query err : %v", queryKey, err)
		return
	} else {
		j, err := json.Marshal(queryResult)
		if err != nil {
			klog.Errorf("%s - update Marshal error %v", queryKey, err)
			return
		}
		_, err = redisclient.SetNotExpire(context.Background(), queryKey, j)
		if err != nil {
			klog.Errorf("%s - update set redis error %v", queryKey, err)
			return
		}
		klog.Infof("%s - update redis set ok", queryKey)
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/utils/cache_test.go
```golang
package utils

import (
	"context"
	"errors"
	"fmt"
	"github.com/go-redis/redis/v8"
	"io"
	"net"
	"net/http"
	_ "net/http/pprof"
	"regexp"
	"testing"
	"time"
)

func hello() {
	fmt.Println("123")
}

func xixi(a int) (string, error) {
	fmt.Println(a)
	return "abc", nil
}

func haha(p ...int) (string, error) {
	fmt.Println(p)
	return "haha", errors.New("bad bad...")
}

type msg struct {
	name string
}

type specialMsg struct {
	msg
	age int
}

func lala(p ...int) (*msg, error) {
	fmt.Println(p)
	return &msg{
		name: "lalalaa",
	}, nil
}

func xaxa(a *msg) (string, error) {
	fmt.Println(a.name)
	return "ok", nil
}

func xaxa2(b *specialMsg) (string, error) {
	fmt.Println(b.name)
	return "lllala", nil
}
func xaxa3(a *msg, b *specialMsg) (string, error) {
	fmt.Println(b.name)
	fmt.Println(a.name)
	return b.name + a.name, nil
}

func TestNewStudent(t *testing.T) {
	//无参数调用
	k, _ := Invoke(hello)
	fmt.Println(k)
	//固定参数调用
	c, _ := Invoke(xixi, 12)
	fmt.Println(c)
	//可变参数调用
	j, _ := Invoke(haha)
	fmt.Println(j)
	//如何处理返回值
	fmt.Printf(j[0].String())
	fmt.Printf(j[0].Kind().String())
	err := j[1].Interface().(error)
	if err != nil {
		fmt.Printf(err.Error())
	}
	m, _ := Invoke(lala, 1, 2, 3)
	fmt.Println(m[0].Pointer())
	fmt.Println(m[0].Kind().String())
	//返回结构体指针(进行强制转换)
	rrr := m[0].Interface().(*msg)
	fmt.Println(rrr)
	fmt.Println(rrr.name)
	fmt.Println(m)

	tempP := &msg{
		name: "sdfdfdf",
	}
	ss, _ := Invoke(xaxa, tempP)
	fmt.Println(ss)
	tempSpecalMsg := &specialMsg{
		msg: msg{
			name: "aaaa1",
		},
		age: 0,
	}
	tempmsg := &msg{
		name: "bbbb",
	}
	//ss2, _ := Invoke(xaxa2, tempSpecalMsg)
	//fmt.Println(ss2)
	ss3, err := Invoke(xaxa3, tempmsg, tempSpecalMsg)
	for _, value := range ss3 {
		fmt.Println(value.Interface())
	}
	fmt.Println(ss3)
	fmt.Println(err)
}

func TestCache(t *testing.T) {
	port := 0
	go func() {
		server := &http.Server{Addr: ":0", Handler: nil}
		ln, err := net.Listen("tcp", server.Addr)
		if err != nil {
			t.Error(err)
		}
		go server.Serve(ln)
		time.Sleep(time.Second)
		port = ln.Addr().(*net.TCPAddr).Port
		t.Log(port)
	}()

	var rdb *redis.Client
	rdb = redis.NewClient(&redis.Options{
		Network:    "tcp",
		Addr:       "127.0.0.1:6379",
		Dialer:     nil,
		OnConnect:  nil,
		Username:   "",
		Password:   "",
		DB:         10,
		MaxRetries: 10,
	})

	cache, err := NewRedisCache(rdb, "test")
	if err != nil {
		t.Error(err)
		return
	}
	result, err := rdb.Ping(context.Background()).Result()
	if err != nil {
		t.Error(err)
		return
	}
	t.Logf("result %s", result)
	after := time.After(time.Second * 30)

	for {
		select {
		case <-time.After(time.Second):
			data, err := cache.GetData(context.Background(), "now", getfn, time.Second*10)
			if err != nil {
				t.Error(err)
			}
			t.Logf("data:%s", data)
			resp, err := http.Get(fmt.Sprintf("http://127.0.0.1:%d/debug/pprof/goroutine?debug=1", port))
			if err != nil {
				t.Error(err)
			}
			all, err := io.ReadAll(resp.Body)
			re := regexp.MustCompile("goroutine profile: total.*")

			t.Logf("%s", re.FindString(string(all)))
		case <-after:
			return
		}
	}
}

func getfn() (data string, err error) {
	<-time.After(time.Second * 12)
	data = fmt.Sprintf("%v", time.Now().String())
	return
}

func TestMap(t *testing.T) {

	m := make(map[string]*struct{ A string })
	_, ok := m["a"]
	if !ok {
		m["a"] = &struct{ A string }{A: fmt.Sprint("")}
	}
	mm := m["a"]
	mm.A = "A"

	t.Logf("%#v", m["a"])
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/utils/commonutil.go
```golang
package utils

import "fmt"

func If(condition bool, trueVal, falseVal interface{}) interface{} {
	if condition {
		return trueVal
	} else {
		return falseVal
	}
}

func UnitConvert(num int64) (size string) {
	if num < 1024 {
		//"B"
		return fmt.Sprintf("%.2f", float64(num)/float64(1))
	} else if num < (1024 * 1024) {
		//"KB"
		return fmt.Sprintf("%.2f", float64(num)/float64(1024))
	} else if num < (1024 * 1024 * 1024) {
		//"MB"
		return fmt.Sprintf("%.2f", float64(num)/float64(1024*1024))
	} else if num < (1024 * 1024 * 1024 * 1024) {
		//"GB"
		return fmt.Sprintf("%.2f", float64(num)/float64(1024*1024*1024))
	} else if num < (1024 * 1024 * 1024 * 1024 * 1024) {
		//"TB"
		return fmt.Sprintf("%.2f", float64(num)/float64(1024*1024*1024*1024))
	} else {
		//"EB"
		return fmt.Sprintf("%.2f", float64(num)/float64(1024*1024*1024*1024*1024))
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/utils/apicache_test.go
```golang
package utils

import "testing"

func TestApiCache_Get(t *testing.T) {
	apiCache := NewApiCache()

	key := "test/nt"
	fn := func() (interface{}, error) {
		return "test", nil
	}
	result, err := apiCache.Get(key, fn)
	if err != nil {
		t.Logf(err.Error())
	}

	t.Logf("result: %s", result)

	result, err = apiCache.Get(key, fn)
	if err != nil {
		t.Logf(err.Error())
	}

	t.Logf("result: %s", result)

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/utils/runtime.go
```golang
package utils

import "os"

func InK8s() bool {
	return len(os.Getenv("KUBERNETES_SERVICE_HOST")) > 0
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/utils/cache.go
```golang
package utils

import (
	"context"
	"errors"
	"fmt"
	"github.com/go-redis/redis/v8"
	"github.com/robfig/cron/v3"
	"k8s.io/klog/v2"
	"reflect"
	"time"
)

var ()

type CacheInterface interface {
	//写入缓存
	Save(key, value string) error
	//读取缓存
	Load(key string) (string, error)
}

type CacheDispatch interface {
	//GetData(fun interface{}, args ...interface{}) (interface{}, error)
}

var _ CacheInterface = new(RedisCache)
var _ CacheDispatch = new(RedisCache)

type CacheRecord struct {
	dataGet cb
	expire  time.Duration
	cronID  cron.EntryID
}

type RedisCache struct {
	aLocker     *Mutex
	bLocker     *Mutex
	redisClient *redis.Client
	cacheKey    string
	dataRecord  map[string]*CacheRecord
	cron        *cron.Cron
}

func NewRedisCache(redisClient *redis.Client, cacheKey string) (*RedisCache, error) {
	result, err := redisClient.Ping(context.Background()).Result()
	if err != nil {
		return nil, err
	} else if result != "PONG" {
		return nil, fmt.Errorf("ping error %s", result)
	}
	cronServer := cron.New()
	cronServer.Start()
	return &RedisCache{
		aLocker:     NewMutex(),
		bLocker:     NewMutex(),
		redisClient: redisClient,
		cacheKey:    cacheKey,
		dataRecord:  make(map[string]*CacheRecord),
		cron:        cronServer,
	}, nil
}

type cb func() (data string, err error)

const (
	aKeyPrefix = "data-cache-a"
	bKeyPrefix = "data-cache-b"
)

func (m *RedisCache) GetData(ctx context.Context, key string, getData cb, expire time.Duration) (string, error) {
	m.aLocker.Lock()
	defer m.aLocker.Unlock()
	// 触发缓存
	go m.doCache(ctx, key, expire)

	if key == "" {
		return "", errors.New("MISS KEY")
	}

	//record := CacheRecord{
	//	getData, expire, 0,
	//}
	if _, ok := m.dataRecord[key]; !ok {
		m.dataRecord[key] = &CacheRecord{
			getData, 0, 0,
		}
	}

	//filedKey := fmt.Sprintf("%s-%s", aKeyPrefix, key)
	CacheData, err := m.Load(key)

	return CacheData, err

}
func (m *RedisCache) InvokeData(fun interface{}, args ...interface{}) (interface{}, error) {
	return Invoke(fun, args...)
}

func (m *RedisCache) Save(key, value string) error {
	return m.redisClient.HSet(context.Background(), m.cacheKey, key, value).Err()
}

func (m *RedisCache) Load(key string) (string, error) {
	cmd := m.redisClient.HGet(context.Background(), m.cacheKey, key)
	if err := cmd.Err(); err != nil {
		if err == redis.Nil {
			klog.Warningf("filed %s does not exist,wait cache flush! \n", key)
		}
		return "", err
	}
	return cmd.Result()
}

//反射调用
func Invoke(f interface{}, params ...interface{}) (v []reflect.Value, err error) {
	defer func() {
		if rerr := recover(); rerr != nil {
			err = fmt.Errorf("%v", rerr)
		}
	}()
	fv := reflect.ValueOf(f)
	realParams := make([]reflect.Value, len(params)) //参数
	for i, item := range params {
		realParams[i] = reflect.ValueOf(item)
	}

	rs := fv.Call(realParams)
	return rs, nil
}

func (m *RedisCache) doCache(ctx context.Context, key string, expire time.Duration) {
	if m.bLocker.IsLocked() {
		return
	}
	m.bLocker.Lock()
	defer m.bLocker.Unlock()
	cacheRecord, ok := m.dataRecord[key]
	if !ok || cacheRecord == nil {
		return
	}
	value, err := cacheRecord.dataGet()
	//data, err := cacheRecord.dataGet()
	//if err != nil {
	//	klog.Error(err)
	//	return
	//}
	//value, err := json.Marshal(data)
	//if err != nil {
	//	klog.Error(err)
	//	return
	//}
	m.aLocker.Lock()
	defer m.aLocker.Unlock()
	err = m.Save(key, string(value))
	if err != nil {
		klog.Error(err)
	}

	if expire > 0 && cacheRecord.expire != expire {

		duration := cron.Every(expire)
		var job cron.FuncJob = func() {
			m.doCache(ctx, key, expire)
		}

		m.cron.Remove(cacheRecord.cronID)
		entryID := m.cron.Schedule(duration, job)

		cacheRecord.cronID = entryID
		cacheRecord.expire = expire

	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/utils/locker.go
```golang
package utils

import (
	"sync"
	"sync/atomic"
	"unsafe"
)

const (
	LockedFlag   int32 = 1
	UnlockedFlag int32 = 0
)

type Mutex struct {
	in     sync.Mutex
	status *int32
}

func NewMutex() *Mutex {
	status := UnlockedFlag
	return &Mutex{
		status: &status,
	}
}

func (m *Mutex) Lock() {
	m.in.Lock()
	atomic.StoreInt32(m.status, LockedFlag)
}

func (m *Mutex) Unlock() {
	m.in.Unlock()
	atomic.StoreInt32(m.status, UnlockedFlag)
}

func (m *Mutex) TryLock() bool {
	if atomic.CompareAndSwapInt32((*int32)(unsafe.Pointer(&m.in)), UnlockedFlag, LockedFlag) {
		atomic.StoreInt32(m.status, LockedFlag)
		return true
	}
	return false
}

func (m *Mutex) IsLocked() bool {
	if atomic.LoadInt32(m.status) == LockedFlag {
		return true
	}
	return false
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/utils/gosafe.go
```golang
package utils

import (
	"fmt"
	"k8s.io/klog/v2"
	"runtime/debug"
)

// GoSafe runs the given fn using another goroutine, recovers if fn panics.
func GoSafe(fn func()) {
	go RunSafe(fn)
}

//// RoutineId is only for debug, never use it in production.
//func RoutineId() uint64 {
//	b := make([]byte, 64)
//	b = b[:runtime.Stack(b, false)]
//	b = bytes.TrimPrefix(b, []byte("goroutine "))
//	b = b[:bytes.IndexByte(b, ' ')]
//	// if error, just return 0
//	n, _ := strconv.ParseUint(string(b), 10, 64)
//
//	return n
//}

// RunSafe runs the given fn, recovers if fn panics.
func RunSafe(fn func()) {
	defer Recover()

	fn()
}

// Recover is used with defer to do cleanup on panics.
// Use it like:
//  defer Recover(func() {})
func Recover(cleanups ...func()) {
	for _, cleanup := range cleanups {
		cleanup()
	}

	if p := recover(); p != nil {
		klog.Error(fmt.Sprintf("%s\n%s", p, string(debug.Stack())))
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/common.go
```golang
package models

import "net/http"

type (
	Region   string
	Az       string
	PageNo   int
	PageSize int
)

type Response struct {
	Code    int         `json:"code"`
	Message string      `json:"message"`
	Data    interface{} `json:"data"`
}

func NewResponse() *Response {
	return &Response{}
}

func NewSuccessResponse() *Response {
	return &Response{
		Code:    http.StatusOK,
		Message: "success",
	}
}
func (r *Response) SetData(data interface{}) *Response {
	r.Data = data
	return r
}
func (r *Response) SetCode(code int) *Response {
	r.Code = code
	return r
}

func (r *Response) SetMessage(msg string) *Response {
	r.Message = msg
	return r
}

type AlertType struct {
	Prefix string `json:"prefix"`
	Level  string `json:"level"`
	Unit   string `json:"unit"`
	Number int64  `json:"number"`
	Name   string `json:"name"`
	Kind   string `json:"kind"`
	Type   string `json:"type"`
}

func NewErrorResult(code int, err error) Response {
	return *NewResponse().SetCode(code).SetMessage(err.Error())
}

func NewBadRequestError(err error) Response {
	return NewErrorResult(http.StatusBadRequest, err)
}

func NewServerError(err error) Response {
	return NewErrorResult(http.StatusInternalServerError, err)
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/cloudproduct/response.go
```golang
package cloudproduct

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}
type MonitorBlocks struct {
	PageStruct
	DataList []MonitorBlock `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type MonitorBlock struct {
	ID            string  `json:"id"`
	Name          string  `json:"name"`
	UseStatus     string  `json:"useStatus"`
	RunningStatus string  `json:"runningStatus"`
	Region        string  `json:"region"`
	Az            string  `json:"az"`
	TenantId      string  `json:"tenantId"`
	TenantName    string  `json:"tenantName"`
	CreateTime    int64   `json:"createTime"`
	StorageType   string  `json:"storageType"`
	UsePercent    float64 `json:"usePercent"`
	Size          int     `json:"size"`
	BlockPool     string  `json:"blockPool"`
	RIO           float64 `json:"rio"`
	WIO           float64 `json:"wio"`
	RBand         string  `json:"rBand"`
	WBand         string  `json:"wBand"`
	MonitorStatus string  `json:"monitorStatus"`
	AlertNumber   int     `json:"alertNumber"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/cloudproduct/parameter.go
```golang
package cloudproduct

import (
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

type TopQuery struct {
	Region       string   `json:"region"`
	Az           string   `json:"az"`
	Name         []string `json:"name"`
	Pool         string   `json:"pool"`
	Lab          string   `json:"lab"`
	TenantId     string   `json:"tenantId"`
	InnerIp      string   `json:"innerIp"`
	OuterIp      string   `json:"outerIp"`
	Label        string   `json:"label"`
	State        string   `json:"state"`
	PhysicalHost string   `json:"physicalHost"`
	SearchKey    string   `json:"searchKey"`
	SearchValue  string   `json:"searchValue"`
	RunList      []string `json:"runList"`
	Start        float64  `json:"start"`
	End          float64  `json:"end"`
	TopK         string   `json:"topk"`
}

type ListQuery struct {
	PageNo        int      `json:"pageNo"`
	PageSize      int      `json:"pageSize"`
	Region        string   `json:"region"`
	Az            []string `json:"az"`
	Lab           string   `json:"lab"`
	Name          string   `json:"name"`
	TenantId      string   `json:"tenantId"`
	InnerIp       string   `json:"innerIp"`
	OuterIp       string   `json:"outerIp"`
	Label         string   `json:"label"`
	State         string   `json:"state"`
	PhysicalHost  string   `json:"physical_host"`
	Pool          string   `json:"pool"`
	StorageType   []string `json:"storageType"`
	UseStatus     []string `json:"useStatus"`
	RunningStatus []string `json:"runningStatus"`
	SearchKey     string   `json:"searchKey"`
	SearchValue   string   `json:"searchValue"`
	OrderCode     string   `json:"orderCode"`
	OrderType     string   `json:"orderType"`
}

type OverViewSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverView struct {
	Region  string                        `json:"region"`
	Az      string                        `json:"az"`
	Lab     string                        `json:"lab"`
	Alerts  []resourcepoolmodel.AlertType `json:"alerts"`
	Echarts []Chart                       `json:"echarts"`
}

type Chart struct {
	Info   OverInfo    `json:"info"`
	Values []ValueType `json:"values"`
}
type OverInfo struct {
	Name     string `json:"name"`
	Number   int    `json:"number"`
	Type     string `json:"type"` //p0/p1/p2/p3
	Kind     string `json:"kind"` //[错误,紧急error/警告，重要warn/信息、提醒、次要info/成功、使用中success/未使用、未开通disabled]
	Unit     string `json:"unit"`
	Label    string `json:"label"`
	UnitType string `json:"unitType"`
}

type ValueType struct {
	Value      interface{} `json:"value"`
	Name       string      `json:"name"`
	Timestamep string      `json:"timestamep"`
	SubName    string      `json:"subName"`
	VmId       string      `json:"vmId"`
	RegionCode string      `json:"regionCode"`
	Az         string      `json:"azCode"`
}

type OverViewTopSuccess struct {
	Code    int               `json:"code"`
	Message string            `json:"message"`
	Data    []OverViewLineNew `json:"data"`
}

type OverViewLine struct {
	Region string `json:"region"`
	Az     string `json:"az"`
	Lab    string `json:"lab"`
	Name   string `json:"name"`
	Unit   string `json:"unit"`
	//Alert  AlertLevels `json:"alert"`
	Echarts []EchartType `json:"echarts"`
}

type EchartType struct {
	Info   services.InfoType `json:"info"`
	Values []ValueType       `json:"values"`
}

type MonitorVmsSuccess struct {
	Code    int        `json:"code"`
	Message string     `json:"message"`
	Data    MonitorVms `json:"data"`
}

type MonitorVms struct {
	PageStruct
	DataList []MonitorVm `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type MonitorVm struct {
	ID            string  `json:"id"`
	Name          string  `json:"name"`
	VmType        string  `json:"vmType"`
	Status        string  `json:"status"`
	ComputePool   string  `json:"computePool"`
	Region        string  `json:"region"`
	Az            string  `json:"az"`
	TenantId      string  `json:"tenantId"`
	TenantName    string  `json:"tenantName"`
	PhysicalHost  string  `json:"physicalHost"`
	InnerIP       string  `json:"innerIp"`
	OuterIP       string  `json:"outerIp"`
	CreateTime    string  `json:"createTime"`
	CPUTotal      float64 `json:"cpuTotal"`
	CPUUse        float64 `json:"cpuUse"`
	CPUUseRate    float64 `json:"cpuUseRate"`
	MemoryTotal   string  `json:"memoryTotal"`
	MemoryUse     string  `json:"memoryUse"`
	MemoryUseRate float64 `json:"memoryUseRate"`
	DiskTotal     float64 `json:"diskTotal"`
	DiskUse       float64 `json:"diskUse"`
	DiskUseRate   float64 `json:"diskUseRate"`
	AlertAmount   int     `json:"alertAmount"`
	Flavor        string  `json:"flavor"`
}

type MetricSuccess struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    []MetricResult `json:"data"`
}

type MetricResult struct {
	Type       interface{} `json:"type"`
	MountPoint interface{} `json:"mountpoint"`
	Name       interface{} `json:"name"`
	Current    interface{} `json:"current"`
	Avg        interface{} `json:"avg"`
	Max        interface{} `json:"max"`
	Min        interface{} `json:"min"`
	Value      interface{} `json:"value"`
}

type VmListQuery struct {
	PageNo       int      `json:"pageNo"`
	PageSize     int      `json:"pageSize"`
	Region       string   `json:"region"`
	Az           []string `json:"az"`
	Name         string   `json:"name"`
	Pool         string   `json:"pool"`
	Lab          string   `json:"lab"`
	TenantId     string   `json:"tenantId"`
	InnerIp      string   `json:"innerIp"`
	OuterIp      string   `json:"outerIp"`
	Label        string   `json:"label"`
	State        string   `json:"state"`
	PhysicalHost string   `json:"physicalHost"`
	SearchKey    string   `json:"searchKey"`
	SearchValue  string   `json:"searchValue"`
	RunList      []string `json:"runList"`
	Metrics      []string `json:"metrics"`
	Start        string   `json:"start"`
	End          string   `json:"end"`
	TopK         string   `json:"topk"`
}

type AlertLevels struct {
	P0 int `json:"p0"`
	P1 int `json:"p1"`
	P2 int `json:"p2"`
	P3 int `json:"p3"`
}

//OverviewTop
type CMDBTopResult struct {
	Code    int        `json:"code"`
	Message string     `json:"message"`
	Data    CmdbTopVms `json:"data"`
}

type CmdbTopVms struct {
	PageStruct
	DataList []CmdbTopVm `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type CmdbTopVm struct {
	ID     string      `json:"id"`
	Name   string      `json:"name"`
	Value  interface{} `json:"value"`
	Status string      `json:"status"`
	Region string      `json:"region"`
	Az     string      `json:"az"`
}

type CmdbTopLoad struct {
	ID     string      `json:"id"`
	Name   string      `json:"name"`
	Value  interface{} `json:"value"`
	Status string      `json:"status"`
	Region string      `json:"region"`
	Az     string      `json:"az"`
	Eip    string      `json:"eip"`
	State  string      `json:"state"`
}


//other
type Result struct {
	Code    int         `json:"code"`
	Message string      `json:"messgae"`
	Data    interface{} `json:"data"`
}

type CMDBResult struct {
	Code    int     `json:"code"`
	Message string  `json:"message"`
	Data    CmdbVms `json:"data"`
}

// type ListQuery struct {
// 	PageNo       int      `json:"pageNo"`
// 	PageSize     int      `json:"pageSize"`
// 	Region       string   `json:"region"`
// 	Az           string   `json:"az"`
// 	Name         string   `json:"name"`
// 	Pool         string   `json:"pool"`
// 	Lab          string   `json:"lab"`
// 	TenantId     string   `json:"tenantId"`
// 	InnerIp      string   `json:"innerIp"`
// 	OuterIp      string   `json:"outerIp"`
// 	Label        string   `json:"label"`
// 	State        string   `json:"state"`
// 	PhysicalHost string   `json:"physicalHost"`
// 	SearchKey    string   `json:"searchKey"`
// 	SearchValue  string   `json:"searchValue"`
// 	RunList      []string `json:"runList"`
// 	Metrics      []string `json:"metrics"`
// 	Start        string   `json:"start"`
// 	End          string   `json:"end"`
// 	TopK         string   `json:"topk"`
// }

type CmdbVms struct {
	PageStruct
	DataList []CmdbVm `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type CmdbVm struct {
	ID   string `json:"id"`
	Name string `json:"name"`
	//Flavor     interface{} `json:"flavor"`
	Flavor     string `json:"flavor"`
	Status     string `json:"status"`
	Aggregate  string `json:"aggregate"`
	Region     string `json:"region"`
	RegionCode string `json:"regionCode"`
	Az         string `json:"az"`
	AzCode     string `json:"azCode"`
	TenantId   string `json:"tenantId"`
	TenantName string `json:"tenantName"`
	Hypervisor string `json:"hypervisor"`
	InnerIP    string `json:"innerIp"`
	PublicIP   string `json:"publicIp"`
	//CreateTime time.Time `json:"createTime"`
	CreateTime string      `json:"createTime"`
	Value      interface{} `json:"value"`
}

type VmTop struct {
	Id   string `json:"id"`
	Name string `json:"name"`
}

type ResponseMetric struct {
	Metric     string      `json:"metric"`
	Value      interface{} `json:"value"`
	CPUModeAvg interface{} `json:"cpuModeAvg"`
	Curren     interface{} `json:"curren"`
	Min        interface{} `json:"min"`
	Max        interface{} `json:"max"`
	Avg        interface{} `json:"avg"`
}

//
//type TSDBQueryRangeBody struct {
//	Start   string       `json:"start"`
//	End     string       `json:"end"`
//	Queries []RangeQuery `json:"queries"`
//}
//
//type QueryResult struct {
//	Metric    string      `json:"metric"`
//	Timestamp interface{} `json:"timestamp"`
//	Value     string      `json:"value"`
//	Tsuid     string      `json:"tsuid"`
//}
//
//type TSDBQueryBody struct {
//	ResolveNames bool        `json:"resolveNames"`
//	BackScan     int         `json:"backScan"`
//	Queries      []LastQuery `json:"queries"`
//}
//
//type QueryRangeResult struct {
//	Metric string      `json:"metric"`
//	Dps    interface{} `json:"dps"`
//}
//
//type RangeQuery struct {
//	Aggregator string            `json:"aggregator"`
//	Metric     string            `json:"metric"`
//	Tags       map[string]string `json:"tags"`
//}
//

type LastQuery struct {
	Metric string            `json:"metric"`
	Tags   map[string]string `json:"tags"`
}

type QueryList struct {
	List []string `json:"list"`
}

type TimeResult struct {
	TimeStamp interface{} `json:"timeStamp"`
	Result    interface{} `json:"result"`
}

type VmListPost struct {
	PageNo   int      `json:"pageNo"`
	PageSize int      `json:"pageSize"`
	Region   string   `json:"region"`
	Az       []string `json:"az"`
}

type OverViewLineNew struct {
	Region string `json:"region"`
	Az     string `json:"az"`
	Lab    string `json:"lab"`
	Name   string `json:"name"`
	Unit   string `json:"unit"`
	//Alert  AlertLevels `json:"alert"`
	Echarts []EchartTypeNew `json:"echarts"`
}

type EchartTypeNew struct {
	Info   services.InfoType `json:"info"`
	Values []VmValueType     `json:"values"`
}

//云主机
type VmValueType struct {
	Value      interface{} `json:"value"` //值
	Name       string      `json:"name"`  // 名称
	Timestamep string      `json:"timestamep"`
	SubName    string      `json:"subName"`    //子名称
	Id         string      `json:"Id"`         // 实例id
	RegionCode string      `json:"regionCode"` // region
	Az         string      `json:"azCode"`     //Az
	Status     string      `json:"status"`     // 筛选运行状态
	InstanceId string      `json:"InstanceId"`
	VpcName    string      `json:"vpcName"`
	VmId       string      `json:"vmId"`
}

type LoadValueType struct {
	Value      interface{} `json:"value"`        //值
	Name       string      `json:"name"` // 名称
	Timestamep string      `json:"timestamep"`
	SubName    string      `json:"subName"`    //子名称
	Id         string      `json:"id"` // 实例id
	RegionCode string      `json:"region"`     // region
	Az         string      `json:"azCode"`     //Az
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/cmdbservice/cmdbmodel.go
```golang
package cmdbservice

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

type ComputerPool struct {
	Name       string `json:"name"`
	Id         int    `json:"id"`
	Service    string `json:"service"`
	Region     string `json:"region"`
	Az         string `json:"az"`
	HostCount  int    `json:"hostCount"`
	VMCount    int    `json:"vmCount"`
	CreateTime int64  `json:"createTime"`
}

type ComputerPoolData struct {
	PageStruct
	DataList []ComputerPool `json:"dataList" description:"paging data"`
	//TotalCount int          `json:"total_count" description:"total count"`
}

type ComputerPoolResult struct {
	Code    int              `json:"code"`
	Message string           `json:"messgae"`
	Data    ComputerPoolData `json:"data"`
}

// 资源池服务器实体
type AggregateHosts struct {
	DataList   []Host `json:"dataList" description:"paging data"`
	PageStruct        //int              `json:"totalCount" description:"total count"`
}
type HostUrlPost struct {
	PageNo           int      `json:"pageNo"`
	PageSize         int      `json:"pageSize"`
	Region           string   `json:"region"`
	Az               string   `json:"az"`
	Status           []string `json:"status"`
	AssignmentStatus []string `json:"assignmentStatus"`
	StorageType      []string `json:"storageType"`
}

type BlockListPost struct {
	PageNo           int      `json:"pageNo"`
	PageSize         int      `json:"pageSize"`
	Region           string   `json:"region"`
	Az               []string `json:"az"`
	Status           []string `json:"status"`
	AssignmentStatus []string `json:"assignmentStatus"`
	ResourcePoolType []string `json:"resourcePoolType"`
}

type VmListPost struct {
	PageNo           int      `json:"pageNo"`
	PageSize         int      `json:"pageSize"`
	Region           string   `json:"region"`
	Az               []string `json:"az"`
	Name             string   `json:"name"`
	Status           []string `json:"status"`
	AssignmentStatus []string `json:"assignmentStatus"`
	StorageType      []string `json:"storageType"`
	TenantId         string   `json:"tenantId"`   //所属租户ID
	Hypervisor       string   `json:"hypervisor"` // 所属服务器
	Aggregate        *string  `json:"aggregate"`  // 所属资源池
	InnerIp          string   `json:"innerIp"`    // 内网ip
	PublicIp         string   `json:"publicIp"`   //  外网ip
}

type VmUrlPost struct {
	PageNo           int      `json:"pageNo"`
	PageSize         int      `json:"pageSize"`
	Status           []string `json:"status"`
	AssignmentStatus []string `json:"assignmentStatus"`
}
type HostsResult struct {
	Code    int            `json:"code"`
	Message string         `json:"messgae"`
	Data    AggregateHosts `json:"data"`
}
type HostDetailResult struct {
	Code    int    `json:"code"`
	Message string `json:"messgae"`
	Data    HostIp `json:"data"`
}
type ResourceResult struct {
	Code    int          `json:"code"`
	Message string       `json:"messgae"`
	Data    ResourceList `json:"data"`
}
type Resource struct {
	ResourceKey   string `json:"resourceKey"`
	ResourceValue string `json:"resourceValue"`
}
type ResourceList struct {
	ResourceType    []Resource `json:"resourceType"`
	ResourceSubType []Resource `json:"resourceSubType"`
}
type HostIp struct {
	ManagementIP string `json:"managementIP"`
}

type Host struct {
	Id               string `json:"id"`
	Name             string `json:"name"`
	Status           string `json:"status"`
	ResourcePoolType string `json:"resourcePoolType"`
	ResourcePool     string `json:"resourcePool"`
	Service          string `json:"service"`
	Region           string `json:"region"`
	Az               string `json:"az"`
	Room             string `json:"room"`
	Rack             string `json:"rack"`
	//RackPosition     string `json:"rackPosition"`
	SN string `json:"sn"`
	IP string `json:"ip"`
}

type VmsResult struct {
	Code    int           `json:"code"`
	Message string        `json:"messgae"`
	Data    AggregatesVms `json:"data"`
}

type AggregatesVms struct {
	PageStruct
	DataList []AggregatesVm `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type AggregatesVm struct {
	ID   string `json:"id"`
	Name string `json:"name"`
	//Flavor     interface{} `json:"flavor"`
	Flavor     string `json:"flavor"`
	Status     string `json:"status"`
	Aggregate  string `json:"aggregate"`
	Region     string `json:"region"`
	RegionCode string `json:"regionCode"`
	Az         string `json:"az"`
	AzCode     string `json:"azCode"`
	TenantId   string `json:"tenantId"`
	TenantName string `json:"tenantName"`
	Hypervisor string `json:"hypervisor"`
	InnerIP    string `json:"innerIp"`
	PublicIP   string `json:"publicIp"`
	//CreateTime time.Time `json:"createTime"`
	CreateTime string `json:"createTime"`
}

// 块存储资源池
type BlockReUrlPost struct {
	PageNo       int      `json:"pageNo"`
	PageSize     int      `json:"pageSize"`
	Name         string   `json:"name"`
	RegionCode   string   `json:"regionCode"`
	AzCode       []string `json:"azCode"`
	ResourcePool []string `json:"resourcePool"`
}
type BlockRe struct {
	Name       string `json:"name"`
	Id         int    `json:"id"`
	RegionName string `json:"regionName"`
	RegionCode string `json:"regionCode"`
	AzId       int    `json:"azId"`
	AzName     string `json:"azName"`
	AzCode     string `json:"azCode"`
	//ResourcePoolType string `json:"resourcePoolType"` //资源池类型(块存储)
	ResourcePool       string   `json:"resourcePool"` //资源池（高效云盘，云硬盘3.0）
	ClusterUrl         string   `json:"clusterUrl"`
	MetricUrl          string   `json:"metricUrl"`
	SliceUrl           string   `json:"sliceUrl"`
	StockUrl           string   `json:"stockUrl"`
	Addresss           []string `json:"addresss"`
	TenantId           string   `json:"tenantId"`
	TenantName         string   `json:"tenantName"`
	Attribute          string   `json:"attribute"`
	HostNumber         int      `json:"hostNumber"`
	CloudDiskNumber    int      `json:"cloudDiskNumber"`
	CloudDiskErrNumber int      `json:"cloudDiskErrNumber"`
	MonitorStatus      string   `json:"monitorStatus"`
	CreateTime         int64    `json:"createTime"`
}
type BlockStoragePoolListDataResult struct {
	PageStruct
	DataList []BlockRe `json:"dataList"`
}
type BlockStoragePoolResult struct {
	Code    int                            `json:"code"`
	Message string                         `json:"messgae"`
	Data    BlockStoragePoolListDataResult `json:"data"`
}

// 对象存储资源池
type ObjectStoragePoolListDataResult struct {
	PageStruct
	DataList []ObjectRe `json:"dataList"`
}
type ObjectStoragePoolResult struct {
	Code    int                             `json:"code"`
	Message string                          `json:"message"`
	Data    ObjectStoragePoolListDataResult `json:"data"`
}

type Ks3Host struct {
	Ip        string `json:"ip"`
	Port      int    `json:"port"`
	Status    int    `json:"status"`
	StatusMsg string `json:"status_msg"`
	Role      string `json:"role"`
}

type ObjectRe struct {
	Name         string    `json:"name"`
	Id           int       `json:"id"`
	RegionName   string    `json:"regionName"`
	RegionCode   string    `json:"regionCode"`
	AzCode       string    `json:"azCode"`
	ResourcePool string    `json:"resourcePool"`
	BucketNumber int       `json:"bucketNumber"`
	HostNumber   int       `json:"hostNumber"`
	TenantId     string    `json:"tenantId"`
	TenantName   string    `json:"tenantName"`
	ObjectNumber string    `json:"objectNumber"`
	CreateTime   int64     `json:"createTime"`
	Servers      []Ks3Host `json:"servers"`
	Status       string    `json:"status"`
	MetricUrl    string    `json:"metricUrl"`
}

type BucketRequest struct {
	PageStruct
	//ContentSelector string `json:"contentSelector"`
	//Count bool `json:"count"`
	Region      string   `json:"region"`
	Az          string   `json:"az"`
	Name        string   `json:"name"`
	Id          string   `json:"id"`
	TenantId    string   `json:"tenantId"`
	StorageType []string `json:"storageType"`
}

type ObjectStoragePoolBucketResult struct {
	Code    int                     `json:"code"`
	Message string                  `json:"message"`
	Data    ObjectStoragePoolBucket `json:"data"`
}
type ObjectStoragePoolBucket struct {
	PageStruct
	DataList []BucketDetail `json:"dataList"`
}

//type BucketDetail struct {
//	Id              string `json:"id"`
//	Name            string `json:"name"`
//	Size            int    `json:"size"`
//	StorageType     string `json:"storageType"`
//	Region          string `json:"region"`
//	TenantId        string `json:"tenantId"`
//	TenantName      string `json:"tenantName"`
//	InnerDomainName string `json:"innerDomainName"`
//	OuterDomainName string `json:"outerDomainName"`
//	CreateTime      int64  `json:"createTime"`
//	Policy          string `json:"policy"`
//}

type BucketDetail struct {
	ID                    string          `json:"id"`
	Name                  string          `json:"name"`
	Size                  int             `json:"size"`
	StorageType           string          `json:"storageType"`
	Region                string          `json:"region"`
	RegionCode            string          `json:"regionCode"`
	AzName                string          `json:"azName"`
	AzCode                string          `json:"azCode"`
	TenantID              string          `json:"tenantId"`
	TenantName            string          `json:"tenantName"`
	InnerDomainName       string          `json:"innerDomainName"`
	OuterDomainName       string          `json:"outerDomainName"`
	CreateTime            int             `json:"createTime"`
	Policy                string          `json:"policy"`
	BucketDomains         []BucketDomains `json:"bucketDomains"`
	ResourcePoolID        int             `json:"resourcePoolId"`
	ResourcePoolName      string          `json:"resourcePoolName"`
	ObjectCount           int             `json:"objectCount"`
	CurrentSize           int             `json:"currentSize"`
	Last30DayDownload     int             `json:"last30DayDownload"`
	Last30DayAPICallTimes int             `json:"last30DayAPICallTimes"`
}

type BucketDomains struct {
	AccessType string `json:"accessType"`
	Endpoint   string `json:"endpoint"`
	Domain     string `json:"domain"`
}
type RegionResponse struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    []Region `json:"data"`
}
type Region struct {
	RegionCode          string `json:"regionCode"`
	RegionName          string `json:"regionName"`
	RegionCodeAggregate string `json:"regionCodeAggregate"`
	ContainAzs          []Az   `json:"containAzs"`
}

type Az struct {
	AzCode          string `json:"azCode"`
	AzName          string `json:"azName"`
	AzCodeAggregate string `json:"azCodeAggregate"`
	ContainLabs     []Lab  `json:"containLabs"`
}

type Lab struct {
	UID     int    `json:"uid"`
	LabCode string `json:"labCode"`
	LabName string `json:"labName"`
}

type CMDBVmResult struct {
	Code    int     `json:"code"`
	Message string  `json:"message"`
	Data    CmdbVms `json:"data"`
}

type CMDBBlockResult struct {
	Code    int        `json:"code"`
	Message string     `json:"message"`
	Data    CmdbBlocks `json:"data"`
}

type CMDBVmDetailResult struct {
	Code    int    `json:"code"`
	Message string `json:"message"`
	Data    CmdbVm `json:"data"`
}

type CMDBNatResult struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    CmdbNats `json:"data"`
}

type CmdbNats struct {
	PageStruct
	DataList []NatInfo `json:"dataList" description:"paging data"`
}

type CmdbVms struct {
	PageStruct
	DataList []CmdbVm `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type CmdbVm struct {
	ID   string `json:"id"`
	Name string `json:"name"`
	//Flavor     interface{} `json:"flavor"`
	Flavor     string `json:"flavor"`
	Status     string `json:"status"`
	Aggregate  string `json:"aggregate"`
	Region     string `json:"region"`
	RegionCode string `json:"regionCode"`
	Az         string `json:"az"`
	AzCode     string `json:"azCode"`
	TenantId   string `json:"tenantId"`
	TenantName string `json:"tenantName"`
	Hypervisor string `json:"hypervisor"`
	InnerIP    string `json:"innerIp"`
	PublicIP   string `json:"publicIp"`
	//CreateTime time.Time `json:"createTime"`
	CreateTime int         `json:"createTime"`
	Value      interface{} `json:"value"`
	MetricDir  []string    `json:"metricDir"`
}

type BlockCMDBResult struct {
	Code    int        `json:"code"`
	Message string     `json:"message"`
	Data    CmdbBlocks `json:"data"`
}

type CmdbBlocks struct {
	PageStruct
	DataList []CloudDiskData `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

// 块存储详情
type CloudDiskDataDetail struct {
	Code    int           `json:"code"`
	Message string        `json:"message"`
	Data    CloudDiskData `json:"data"`
}

type CloudDiskData struct {
	Name             string      `json:"name"`
	InstanceId       string      `json:"instanceId"`
	Region           string      `json:"region"`
	Az               string      `json:"az"`
	ResourcePool     string      `json:"resourcePool"`
	ResourcePoolType string      `json:"resourcePoolType"`
	UseStatus        string      `json:"useStatus"`
	TenantId         string      `json:"tenantId"`
	TenantName       string      `json:"tenantName"`
	CreateTime       int64       `json:"createTime"`
	Size             int         `json:"size"`
	VmId             string      `json:"vmId"`
	MountPoint       string      `json:"mountPoint"`
	Value            interface{} `json:"value"`
}

type CloudDiskRequest struct {
	PageNo       int      `json:"pageNo"`
	PageSize     int      `json:"pageSize"`
	Region       string   `json:"region"`
	Az           []string `json:"az"`
	Name         string   `json:"name"`
	ResourcePool string   `json:"resourcePool"`
	InstanceId   string   `json:"instanceId"`
	TenantId     string   `json:"tenantId"`
	UseStatus    []string `json:"useStatus"`
	Type         []string `json:"type"`
}
type RegionRsp struct {
	Code    int          `json:"code"`
	Message string       `json:"message"`
	Data    []RegionData `json:"data"`
}
type RegionData struct {
	RegionCode          string `json:"regionCode"`
	RegionName          string `json:"regionName"`
	RegionCodeAggregate string `json:"regionCodeAggregate"`
}
type AzRsp struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    []AzData `json:"data"`
}
type AzData struct {
	AzCode string `json:"azCode"`
	AzName string `json:"azName"`
}

// 网络资源池
type NetworkPoolResult struct {
	Code    int           `json:"code"`
	Message string        `json:"messgae"`
	Data    []NetworkPool `json:"data"`
}
type NetworkPool struct {
	Hosts       []string `gorm:"column:hosts" json:"hosts"`
	PoolName    string   `gorm:"column:pool_name" json:"poolName"`
	PoolType    string   `gorm:"column:pool_type" json:"poolType"`
	RegionCode  string   `gorm:"column:region_code" json:"regionCode"`
	RegionName  string   `gorm:"column:region_name" json:"regionName"`
	ServerCount int      `gorm:"column:server_count" json:"serverCount"`
	NatCount    int      `gorm:"column:nat_count" json:"natCount"`
	LBCount     int      `gorm:"column:lb_count" json:"lbCount"`
	EipCount    int      `gorm:"column:eip_count" json:"eipCount"`
	BmCount     int      `gorm:"column:bm_count" json:"bmCount"`
	SLCount     int      `gorm:"column:sl_count" json:"slCount"`   //专线 数量
	VPNCount    int      `gorm:"column:vpn_conut" json:"vpnConut"` //VPN 数量
	P2pCount    int      `gorm:"column:p2p_count" json:"p2pCount"` //对等连接 数量
	CreatedAt   int      `gorm:"column:created_at" json:"createdAt"`
}

type NetworkPhysicalListResult struct {
	Code    int                  `json:"code"`
	Message string               `json:"messgae"`
	Data    PhysicalHostListData `json:"data"`
}

type PhysicalHostListData struct {
	DataList []PhysicalHostData `json:"result"`
}

type PhysicalHostData struct {
	Name              string `json:"name"`
	Uid               int    `json:"uid"`
	Runstatus         string `json:"runstatus"`
	AssignmentStatus  string `json:"assignmentStatus"`
	ResourcePoolType  string `json:"resourcePoolType"`
	ResourcePool      string `json:"resourcePool"`
	Service           string `json:"service"`
	HostRegionCode    string `json:"hostRegionCode"`
	HostRegionName    string `json:"hostRegionName"`
	HostAzCode        string `json:"hostAzCode"`
	HostAzName        string `json:"hostAzName"`
	HostLabCode       string `json:"hostLabCode"`
	HostLabName       string `json:"hostLabName"`
	HostRoomUid       int    `json:"hostRoomUid"`
	HostRoomName      string `json:"hostRoomName"`
	HostCabinetUid    int    `json:"hostCabinetUid"`
	HostCabinetName   string `json:"hostCabinetName"`
	HostRackUid       int    `json:"hostRackUid"`
	HostRackName      string `json:"hostRackName"`
	HostUnitUid       int    `json:"hostUnitUid"`
	HostUnitNumber    int    `json:"hostUnitNumber"`
	Sn                string `json:"sn"`
	Ip                string `json:"ip"`
	ManagementIP      string `json:"managementIP"`
	OutbandIP         string `json:"outbandIP"`
	Power             string `json:"power"`
	UplinkSwitch      string `json:"uplinkSwitch"`
	MaintenanceDue    int64  `json:"maintenanceDue"`
	MaintenanceStatus string `json:"maintenanceStatus"`
	Assetsnumber      string `json:"assetsnumber"`
	InputMethod       string `json:"inputMethod"`
	Description       string `json:"description"`
	CreateTime        int64  `json:"createTime"`
	CpuTotal          int    `json:"cpuTotal"`
	MemTotal          int    `json:"memoryTotal"`
}

type GetPoolStock struct {
	OpenNum     int          `json:"openNum"`
	VdiOpenNum  int          `json:"vdiOpenNum"`
	VdiWriteNum int          `json:"vdiWriteNum"`
	EBSServers  []EBSServers `json:"EBSServers"`
}
type EBSServers struct {
	ServerAddress string `json:"serverAddress"`
	UsedCU        int    `json:"usedCU"`
	TotalCU       int    `json:"totalCU"`
	DiskUsed      string `json:"diskUsed"`
	DiskFree      string `json:"diskFree"`
	DiskTotal     string `json:"diskTotal"`
}

type GetPoolClusters []struct {
	ID                int    `json:"id"`
	Region            string `json:"region"`
	AvailableZone     string `json:"available_zone"`
	VdiType           string `json:"vdi_type"`
	TotalDiskCapacity int    `json:"total_disk_capacity"`
	TotalUsedSpace    int    `json:"total_used_space"`
}

type HostListQuery struct {
	IpArray []string `json:"ipArray"`
}
type PhysicalHostListResult struct {
	Code    int                    `json:"code"`
	Message string                 `json:"messgae"`
	Data    PhysicalHostDataResult `json:"data"`
}
type PhysicalHostDataResult struct {
	DataList []PhysicalHostData `json:"dataList"`
}
type Container struct {
	Name        string `json:"name"` // 容器名称
	CpuUsage    string `json:"cpuUsage"`
	MemoryUsage string `json:"memoryUsage"`
	Status      string `json:"status"`
}
type ContainerResult struct {
	Code    int         `json:"code"`
	Message string      `json:"messgae"`
	Data    []Container `json:"data"`
}

type NetWorkUsageQuery struct {
	PageNo     int    `json:"pageNo"`
	PageSize   int    `json:"pageSize"`
	RegionCode string `json:"regionCode"`
}

type NetworkPoolUsageResult struct {
	Code    int        `json:"code"`
	Message string     `json:"messgae"`
	Data    DataResult `json:"data"`
}

type DataResult struct {
	Result []NetWorkInventory `json:"result"`
	Total  int                `json:"total"`
}

type NetWorkInventory struct {
	RegionCode       string  `json:"regionCode"`
	RegionName       string  `json:"regionName"`
	PoolType         string  `json:"poolType"`
	WayType          string  `json:"wayType"`
	Cidr             string  `json:"cidr"`
	IpCount          int     `son:"ipCount"`
	IpUsedCount      int     `json:"ipUsedCount"`
	IpValidCount     int     `json:"ipValidCount"`
	IpRemindCount    int     `json:"ipRemindCount"`
	IpUsedRatio      float64 `json:"ipUsedRatio"`
	IpAvailableRatio float64 `json:"ipAvailableRatio"`
	CpuTotal         int     `json:"cpuTotal"`
	CpuUsedRatio     float64 `json:"cpuUsedRatio"`
	MemTotal         int     `json:"memTotal"`
	MemUsedRatio     float64 `json:"memUsedRatio"`
}

type GetLoadListParam struct {
	InstanceType     []string `json:"instanceType"`
	OrderCode        string   `json:"orderCode"`
	OrderType        string   `json:"orderType"`
	PageNo           int      `json:"pageNo"`
	PageSize         int      `json:"pageSize"`
	Region           string   `json:"region"`
	ResourcePoolName string   `json:"resourcePoolName"`
	SearchType       string   `json:"searchType"`
	SearchValue      string   `json:"searchValue"`
}

type LoadResult struct {
	Code    int    `json:"code"`
	Message string `json:"message"`
	Data    Load   `json:"data"`
}

type Load struct {
	PageStruct
	DataList []LoadDataList `json:"dataList" description:"paging data"`
}

type LoadDataList struct {
	CreateTime       int    `json:"createTime"`
	Eip              string `json:"eip"`
	InstanceID       string `json:"instanceId"`
	InstanceName     string `json:"instanceName"`
	InstanceType     string `json:"instanceType"`
	IPVersion        string `json:"ipVersion"`
	LineType         string `json:"lineType"`
	ListenerNum      int    `json:"listenerNum"`
	NetType          string `json:"netType"`
	ProjectName      string `json:"projectName"`
	Region           string `json:"region"`
	ResourcePoolName string `json:"resourcePoolName"`
	ResourcePoolType string `json:"resourcePoolType"`
	State            string `json:"state"`
	TenantID         string `json:"tenantId"`
	TenantName       string `json:"tenantName"`
	VpcInstanceName  string `json:"vpcInstanceName"`
}

type NatListPost struct {
	PageNo   int `json:"pageNo"`
	PageSize int `json:"pageSize"`

	Region           string   `json:"region"`           //可用区
	ResourcePoolName string   `json:"resourcePoolName"` //资源池名称
	AZ               []string `json:"az"`

	//单选
	Scope   []string `json:"scope"`   //作用范围  [classic,custom] 所属的vpc,绑定的子网
	NatType []string `json:"natType"` //类型 ['public', 'private']

	//多选
	VpcName     []string `json:"vpcName"`     //所属VPC
	TenantId    []string `json:"tenantId"`    //租户ID
	TenantName  []string `json:"tenantName"`  //租户名称
	ProjectName []string `json:"projectName"` //所属项目名称 默认项目
}

type GetNatListParam struct {
	PageNo   int `json:"pageNo"`
	PageSize int `json:"pageSize"`

	Region           string `json:"region"`           //可用区
	ResourcePoolName string `json:"resourcePoolName"` //资源池名称

	//单选
	Scope   []string `json:"scope"`   //作用范围  [classic,custom] 所属的vpc,绑定的子网
	NatType []string `json:"natType"` //类型 ['public', 'private']

	//多选
	VpcName     []string `json:"vpcName"`     //所属VPC
	TenantId    []string `json:"tenantId"`    //租户ID
	TenantName  []string `json:"tenantName"`  //租户名称
	ProjectName []string `json:"projectName"` //所属项目名称 默认项目

	SearchType  string `json:"searchType"`  // 搜索类型 (实例名称)
	SearchValue string `json:"searchValue"` // 搜索值 (注意要支持模糊搜索)

	OrderCode string `json:"orderCode"`
	OrderType string `json:"orderType"`
}
type NatListResult struct {
	Code    int     `json:"code"`
	Message string  `json:"message"`
	Data    NatList `json:"data"`
}

type NatList struct {
	PageStruct
	DataList []NatInfo `json:"dataList" description:"paging data"`
}

type NatInfo struct {
	ResourcePoolName string `json:"resourcePoolName"` //资源池名称
	InstanceName     string `json:"instanceName"`     //实例名称
	InstanceId       string `json:"instanceId"`       //实例ID
	VpcName          string `json:"vpcName"`          //所属VPC
	Scope            string `json:"scope"`            //作用范围    [classic,custom] 所属的vpc,绑定的子网
	NatType          string `json:"natType"`          //类型       ['public', 'private'] 公网 内网
	Region           string `json:"region"`           //区域
	TenantId         string `json:"tenantId"`         //租户ID
	TenantName       string `json:"tenantName"`       //租户名称
	ProjectName      string `json:"projectName"`      //所属项目名称 默认项目
	Bandwidth        int    `json:"bandwidth"`        //带宽
	BoundSubNetNum   int    `json:"boundSubNetNum"`   //绑定子网数量
	CreateTime       int    `json:"createTime"`       //创建时间  秒级时间戳
}

type EIPInfoResult struct {
	Code    int     `json:"code"`
	Message string  `json:"message"`
	Data    EIPInfo `json:"data"`
}

type EIPInfo struct {
	// 基本信息（弹性IP自身信息）
	BoundId     string `json:"boundId"` // 实例ID
	IpAddr      string `json:"ipAddr"`  // IP地址
	Cidr        string `json:"cidr"`    // 所属网段
	RegionCode  string `json:"regionCode"`
	RegionName  string `json:"regionName"`
	WayType     string `json:"wayType"`   // 线路类型
	BandWidth   string `json:"bandWidth"` // 带宽
	IpVersion   string `json:"ipVersion"` // IP版本
	TenantId    string `json:"tenantId"`
	CreateDate  int    `json:"createTime"` //秒级时间戳
	Label       string // 标签
	Description string `json:"description"` // 描述
	// 绑定实例信息
	Id         string `json:"id"`
	BoundType  string `json:"boundType"`
	Name       string `json:"name"`       // 实例名称
	Flavor     string `json:"flavor"`     // 规格
	Status     string `json:"status"`     // 运行状态
	Aggregate  string `json:"aggregate"`  // 所属资源池
	Hypervisor string `json:"hypervisor"` // 所属服务器
}

// GetBmListParam 获取cmdb裸金属列表参数
type GetBmListParam struct {
	PageNo           int      `json:"pageNo"`
	PageSize         int      `json:"pageSize"`
	Region           string   `json:"region"`
	Az               []string `json:"az"`
	Id               []string `json:"id"`
	InstanceStates   []string `json:"instanceStates"`
	InstanceType     []string `json:"instanceType" description:"实例类型： 经典型 应用型 ['default', 'application']"`
	ProjectName      []string `json:"projectName"`
	PoolList         []string `json:"poolList" description:"所属资源池"`
	TenantIdList     []string `json:"tenantIdList" description:"所属租户id"`
	TenantNameList   []string `json:"tenantNameList" description:"所属租户名称"`
	ProjectNameList  []string `json:"projectNameList" description:"所属项目名称 默认项目"`
	ResourcePoolName string   `json:"resourcePoolName"`
	SearchKey        string   `json:"searchKey"`
	SearchValue      string   `json:"searchValue"`
	OrderCode        string   `json:"orderCode"`
	OrderType        string   `json:"orderType"`
}

// BmListResult 获取cmdb裸金属列表返回数据
type BmListResult struct {
	Code    int    `json:"code"`
	Message string `json:"message"`
	Data    Data   `json:"data"`
}
type Data struct {
	TotalCount int      `json:"totalCount"`
	PageNo     int      `json:"pageNo"`
	PageSize   int      `json:"pageSize"`
	DataList   []BmList `json:"dataList"`
}
type BmList struct {
	AlarmNum         int    `json:"alarmNum" description:"告警数量" `
	Az               string `json:"az"`
	AzName           string `json:"azName"`
	Bound            int    `json:"bound"`
	CPU              string `json:"cpu" description:"cpu实例配置" `
	CreateTime       string `json:"createTime"`
	ID               string `json:"id"`
	InstanceStates   string `json:"instanceStates"  description:"实例状态" `
	InstanceType     string `json:"instanceType"  description:"实例类型" `
	IntranetIP       string `json:"intranetIP"`
	LineType         string `json:"lineType"`
	Memory           string `json:"memory" description:"内存实例配置" `
	Name             string `json:"name"  description:"实例名称" `
	NetworkIP        string `json:"networkIP"`
	ProjectName      string `json:"projectName"  description:"所属项目" `
	Region           string `json:"region"`
	RegionName       string `json:"regionName"`
	ResourcePoolName string `json:"resourcePoolName"`
	Sn               string `json:"sn"`
	Storage          string `json:"storage"  description:"存储实例配置" `
	TenantID         string `json:"tenantId"`
	TenantName       string `json:"tenantName"`
	VpcName          string `json:"vpcName"`
}

type GetCmdbStoragePoolParam struct {
	PageNo       int      `json:"pageNo"`
	PageSize     int      `json:"pageSize"`
	Name         string   `json:"name"`
	RegionCode   string   `json:"regionCode"`
	ResourcePool []string `json:"resourcePool"`
	AzCode       []string `json:"azCode"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/physicalServer/serverParameter.go
```golang
package physicalServer

type PhyListQuery struct {
	PageNo   int `json:"pageNo"`
	PageSize int `json:"pageSize"`
	//Count    bool   `json:"count"`
	Region      string   `json:"region"`
	Az          []string `json:"az"`
	Lab         []string `json:"lab"`
	Pool        string   `json:"pool"`
	PoolType    []string `json:"poolType"`
	Node        []string `json:"node"`
	CpuErrNum   string   `json:"cpuErrNum"`
	MemErrNum   string   `json:"memErrNum"`
	DiskErrNum  string   `json:"diskErrNum"`
	Name        string   `json:"name"`
	Sn          string   `json:"sn"`
	Ip          string   `json:"ip"`
	Label       string   `json:"label"`
	SearchKey   string   `json:"searchKey"`
	SearchValue string   `json:"searchValue"`
	State       string   `json:"state"`
	OrderCode   string   `json:"orderCode"`
	OrderType   string   `json:"orderType"`
	RunList     []string `json:"runList"`
	Pools       []string `json:"pools"`
	IsAggragate string   `json:"isAggragate"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/physicalServer/serverResponse.go
```golang
package physicalServer

import (
	"github.com/prometheus/common/model"
	alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
)

type ListQuery struct {
	PageNo   int `json:"pageNo"`
	PageSize int `json:"pageSize"`
	//Count    bool   `json:"count"`
	Region    string `json:"region"`
	Az        string `json:"az"`
	Lab       string `json:"lab"`
	Name      string `json:"name"`
	Sn        string `json:"sn"`
	Ip        string `json:"ip"`
	Label     string `json:"label"`
	State     string `json:"state"`
	OrderCode string `json:"orderCode"`
	OrderType string `json:"orderType"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

type ResourceT struct {
	Rate    string `json:"rate"`
	Use     string `json:"use"`
	Surplus string `json:"surplus"`
}

//overview
type OverViewSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverView struct {
	Region        string                            `json:"region"`
	Az            string                            `json:"az"`
	Lab           string                            `json:"lab"`
	Alerts        []alertmanagermodel.OverviewAlert `json:"alerts"`
	State         []StateType                       `json:"state"`
	HardwareState []StateType                       `json:"hardwareState"`
}

type AlertType struct {
	Prefix string `json:"prefix"`
	Level  string `json:"level"`
	Unit   string `json:"unit"`
	Number int    `json:"number"`
	Name   string `json:"name"`
	Kind   string `json:"kind"`
	Type   string `json:"type"`
}
type StateType struct {
	Prefix  string         `json:"prefix"`
	Unit    string         `json:"unit"`
	Number  int            `json:"number"`
	Value   float64        `json:"value"`
	Name    string         `json:"name"`
	Kind    string         `json:"kind"`
	Type    string         `json:"type"`
	Remarks string         `json:"remarks"`
	Lables  []model.Metric `json:"lables"`
}

type OverViewTopSuccess struct {
	Code    int               `json:"code"`
	Message string            `json:"message"`
	Data    []OverviewTopType `json:"data"`
}

type OverviewTopType struct {
	Region string `json:"region"`
	Az     string `json:"az"`
	Lab    string `json:"lab"`
	Name   string `json:"name"`
	Unit   string `json:"unit"`
	//Alert  AlertLevels `json:"alert"`
	Echarts []EchartType `json:"echarts"`
}

type EchartType struct {
	Info   InfoType    `json:"info"`
	Values []ValueType `json:"values"`
}

type InfoType struct {
	Unit     string `json:"unit"`
	Name     string `json:"name"`
	UnitType string `json:"unitType"`
}

type ValueType struct {
	Value   interface{} `json:"value"`
	Name    string      `json:"name"`
	Ip      string      `json:"ip"`
	SubName string      `json:"subName"`
}

type PhysicalServer struct {
	Name        string  `json:"name"`
	State       string  `json:"state"`
	Pool        string  `json:"pool"`
	PoolType    string  `json:"poolType"`
	Node        string  `json:"node"`
	NodeType    string  `json:"nodeType"`
	Region      string  `json:"region"`
	Az          string  `json:"zone"`
	Lab         string  `json:"lab"`
	Sn          string  `json:"sn"`
	IP          string  `json:"ip"`
	Os          string  `json:"os"`
	CpuErrNum   int64   `json:"cpuErrNum"`
	CpuLoad     float64 `json:"cpuLoad"`
	MemErrNum   int64   `json:"memErrNum"`
	MemLoad     float64 `json:"memLoad"`
	DiskErrNum  int64   `json:"diskErrNum"`
	DiskLoad    float64 `json:"diskLoad"`
	AlertNumber int     `json:"alertNumber"`
	Label       string  `json:"label"`
}

//type MetricSuccess struct {
//	Code    int        `json:"code"`
//	Message string     `json:"message"`
//	Data    ListResult `json:"data"`
//}

type ListResult struct {
	PageStruct
	DataList []PhysicalServer `json:"dataList"`
}

type AlertDetail struct {
	Id        string `json:"id"`
	Name      string `json:"name"`
	Level     string `json:"level"`
	State     string `json:"state"`
	Rule      string `json:"rule"`
	Threshold string `json:"threshold"`
	LastTime  string `json:"lastTime"`
	RangeTime string `json:"rangeTime"`
	Handler   string `json:"handler"`
}

type AlertDetailSuccess struct {
	Code    int           `json:"code"`
	Message string        `json:"message"`
	Data    []AlertDetail `json:"data"`
}

type Success struct {
	Code    int        `json:"code"`
	Message string     `json:"message"`
	Data    ListResult `json:"data"`
}

//type TopKSuccess struct {
//	Code    int                               `json:"code"`
//	Message string                            `json:"message"`
//	Data    []prometheusmanager.RateTopResult `json:"data"`
//}

type ResponseMetric struct {
	TimeStamp  []string    `json:"timeStamp"`
	Metric     string      `json:"metric"`
	Value      interface{} `json:"value"`
	CPUModeAvg interface{} `json:"cpuModeAvg"`
	Curren     interface{} `json:"curren"`
	Min        interface{} `json:"min"`
	Max        interface{} `json:"max"`
}

type ResultT struct {
	Metric MetricType    `json:"metric"`
	Value  []interface{} `json:"value"`
}

type Lab struct {
	LabCode string `json:"labCode"`
	LabName string `json:"labName"`
}

type Az struct {
	AzCode          string `json:"azCode"`
	AzName          string `json:"azName"`
	AzCodeAggregate string `json:"azCodeAggregate"`
	ContainLabs     []Lab  `json:"az_labs"`
}

type RegionSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    []Region `json:"data"`
}
type Region struct {
	RegionCode          string `json:"regionCode"`
	RegionName          string `json:"regionName"`
	RegionCodeAggregate string `json:"regionCodeAggregate"`
	ContainAzs          []Az   `json:"region_azs"`
}

type RegionData struct {
	DataList []Region `json:"dataList"`
}

type ResponseObject struct {
	Code    int         `json:"code"`
	Message string      `json:"message"`
	Data    interface{} `json:"data"`
}

type TimeResult struct {
	TimeStamp interface{} `json:"timeStamp"`
	Result    interface{} `json:"result"`
}

type DgraphCount struct {
	Host []HostCount `json:"host"`
}

type HostCount struct {
	Count          int    `json:"count"`
	Label          string `json:"label"`
	Ip             string `json:"ip"`
	HostName       string `json:"hostname"`
	HostRegionName string `json:"hostRegionName"`
	HostLabName    string `json:"hostLabName"`
	HostAzName     string `json:"hostAzName"`
	Sn             string `json:"sn"`
	RunStatus      string `json:"runstatus"`
	Os             string `json:"system"`
	ServiceType    string `json:"serviceType"`
}

type QueryList struct {
	List     []string `json:"list"`
	Start    string   `json:"start"`
	End      string   `json:"end"`
	Ip       string   `json:"ip"`
	WorkName string   `json:"workName"`
}
type TopKQueryList struct {
	Region string   `json:"region"`
	Az     string   `json:"az"`
	Lab    string   `json:"lab"`
	Name   []string `json:"name"`
	Start  int64    `json:"start"`
	End    int64    `json:"end"`
	Step   string   `json:"step"`
	TopK   string   `json:"topK"`
}

//prometheus

type MetricType struct {
	MountPoint string `json:"mountpoint"`
}

type MetricSuccess struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    []MetricResult `json:"data"`
}

type MetricResult struct {
	Type       interface{} `json:"type"`
	MountPoint interface{} `json:"mountpoint"`
	Name       interface{} `json:"name"`
	Current    interface{} `json:"current"`
	Avg        interface{} `json:"avg"`
	Max        interface{} `json:"max"`
	Min        interface{} `json:"min"`
	Value      interface{} `json:"value"`
}

//dashboard
type RegionCurrentStates struct {
	Region               string `json:"region"`
	PhysicalRunningCount int    `json:"physicalRunningCount"`
	PhysicalErrorCount   int    `json:"physicalErrorCount"`
}

type AlertLevels struct {
	P0 int `json:"p0"`
	P1 int `json:"p1"`
	P2 int `json:"p2"`
	P3 int `json:"p3"`
}

//Hardware
type HardwareResponse struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    HardWare `json:"data"`
}
type HardWare struct {
	IpmiStatus    []StateType `json:"IpmiStatus" description:"带外连通状态"`
	InTemp        []StateType `json:"inTemp" description:"进风口温度"`
	OutTemp       []StateType `json:"outTemp" description:"出风口温度"`
	CpuState      []StateType `json:"cpuState" description:"cpu健康状况"`
	MemState      []StateType `json:"memState" description:"内存健康状况"`
	DiskState     []StateType `json:"diskState" description:"硬盘健康状况"`
	PowerState    []StateType `json:"powerState" description:"电源健康状况"`
	FanState      []StateType `json:"fanState" description:"风扇健康状况"`
	MainBoardList []MainBoard `json:"mainBoardList" description:"主板"`
	Cpu           CpuDetail   `json:"cpu" description:"cpu"`
	Mem           MemDetail   `json:"mem" description:"内存"`
	Disk          DiskDetail  `json:"disk" description:"硬盘"`
	PowerList     []Power     `json:"powerList" description:"电源"`
	FanList       []Fan       `json:"fanList" description:"风扇"`
	Work          []Work      `json:"work",description:"风扇"`
}
type MainBoard struct {
	Name          string  `json:"name" description:"名称"`
	State         float64 `json:"state" description:"健康状态"`
	Sn            string  `json:"sn" description:"序列号"`
	ProductNum    string  `json:"productNum" description:"产品部件号"`
	ProductTime   int64   `json:"productTime" description:"产品生产日期"`
	ProducFactory string  `json:"productFactory" description:"生产厂家"`
}

type CpuDetail struct {
	Sum     int   `json:"sum" description:"cpu总数"`
	Cores   int   `json:"cores" description:"cpu核心数"`
	CpuList []Cpu `json:"cpuList" description:"cpu列表"`
}
type Cpu struct {
	Name        string  `json:"name" description:"名称"`
	State       float64 `json:"state" description:"健康状态"`
	UsedRate    float64 `json:"usedRate" description:"使用率"`
	Temperature string  `json:"temperature" description:"温度"`
	Model       string  `json:"model" description:"型号"`
	ClockSpeed  string  `json:"cloudSpeed" description:"主频"`
	MaxClock    string  `json:"maxClock" description:"最大主频"`
	Cores       byte    `json:"cores" description:"核心数"`
	Threads     byte    `json:"threads" description:"线程数"`
	L1Cache     string  `json:"l1Cache" description:"L1缓存"`
	L2Cache     string  `json:"l2Cache" description:"L2缓存"`
	L3Cache     string  `json:"l3Cache" description:"L3缓存"`
}
type MemDetail struct {
	Sum      int      `json:"sum" description:"总数"`
	Capacity string   `json:"capacity" description:"总容量"`
	MemList  []Memory `json:"cpuList" description:"内存列表"`
}
type Memory struct {
	Name          string  `json:"name" description:"名称"`
	State         float64 `json:"state" description:"健康状态"`
	UsedRate      float64 `json:"usedRate" description:"使用率"`
	In            string  `json:"in" description:"在位信息"`
	Position      string  `json:"positon" description:"位置"`
	Channl        string  `json:"channl" description:"通道"`
	Slot          string  `json:"slot" description:"插槽"`
	Model         string  `json:"model" description:"型号"`
	Ranks         int     `json:"ranks" description:"ranks"`
	Width         int     `json:"width" description:"位宽"`
	MaxClock      int     `json:"maxClock" description:"最大主频"`
	Capacity      string  `json:"capacity" description:"容量"`
	Tech          string  `json:"tech" description:"技术"`
	Sn            string  `json:"sn" description:"序列号"`
	ProductNum    string  `json:"productNum" description:"产品部件号"`
	ProducFactory string  `json:"productFactory" description:"生产厂家"`
}

type DiskDetail struct {
	Sum      int    `json:"sum" description:"总数"`
	Capacity string `json:"capacity" description:"总容量"`
	DiskList []Disk `json:"diskList" description:"硬盘列表"`
}
type Disk struct {
	Name          string  `json:"name" description:"名称"`
	State         float64 `json:"state" description:"健康状态"`
	UpDown        string  `json:"upDown" description:"启用状态"`
	UsedRate      string  `json:"usedRate" description:"使用率"`
	In            string  `json:"in" description:"在位信息"`
	Capacity      string  `json:"capacity" description:"容量"`
	Domain        string  `json:"domain" description:"硬盘域"`
	Model         string  `json:"model" description:"型号"`
	DiskType      string  `json:"diskType" description:"类型"`
	Temperature   string  `json:"temperature" description:"温度"`
	Speed         float64 `json:"speed" description:"转速"`
	ProducFactory string  `json:"productFactory" description:"生产厂家"`
	Sn            string  `json:"sn" description:"序列号"`
}

type Power struct {
	Id              string  `json:"id" description:"序号"`
	State           float64 `json:"state" description:"健康状态"`
	In              string  `json:"in" description:"在位信息"`
	Temperature     string  `json:"temperature" description:"温度"`
	RatedPower      string  `json:"ratePower" description:"额定功率"`
	InputPower      float64 `json:"inputPower" description:"输入功率"`
	PowerInputModel string  `json:"powerInputModel" description:"电源输入模式"`
	Model           string  `json:"model" description:"型号"`
	FireWare        string  `json:"fireWare" description:"固件"`
	Sn              string  `json:"sn" description:"序列号"`
	ProductNum      string  `json:"productNum" description:"产品部件号"`
	ProducFactory   string  `json:"productFactory" description:"生产厂家"`
}

type Fan struct {
	Name       string  `json:"name" description:"名称"`
	State      float64 `json:"state" description:"健康状态"`
	In         string  `json:"in" description:"在位信息"`
	Speed      float64 `json:"speed" description:"转速"`
	SpeedRate  string  `json:"speedRate" description:"速率比"`
	Redundancy string  `json:"redundancy" description:"冗余"`
}

type Work struct {
	Name         string `json:"name"`
	HealthStatus string `json:"healthStatus"` // 健康状态
	Product      string `json:"product"`      // 厂商
	Vendor       string `json:"vendor"`       // 型号
	Speed        string `json:"speed"`        // 速率
	Units        string `json:"units"`
	Size         int    `json:"size"`
	Mac          string `json:"mac"`
}

type State struct {
	State string `json:"state" description:"状态"`
	Name  string `json:"name" description:"名称"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/esmanager/esmodel.go
```golang
package esmanagermodel

type EsLabels struct {
	Filter        string   `json:"filter"`
	Id            string   `json:"id"`
	AlertLevel    []string `json:"alertLevel"`
	AlertInstance string   `json:"alertInstance"`
	AlertName     string   `json:"alertName"`
	OrderType     string   `json:"orderType"`
	OrderCode     string   `json:"orderCode"`

	State    string `json:"state"`
	PageNo   int    `json:"pageNo"`
	PageSize int    `json:"pageSize"`
	//StorageType   []string `json:"storageType"`
	StateList []string `json:"stateList"`
	//RunningStatus []string `json:"runningStatus"`
	SearchKey           string `json:"searchKey"`
	SearchValue         string `json:"searchValue"`
	ResourceTypeCode    string `json:"resourceTypeCode"`
	ResourceSubTypeCode string `json:"resourceSubTypeCode"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/bm/bm.go
```golang
package bm

//ListQuery 裸金属列表请求参数
type ListQuery struct {
	PageNo         int      `json:"pageNo"`
	PageSize       int      `json:"pageSize"`
	SearchKey      string   `json:"searchKey"`
	SearchValue    string   `json:"searchValue"`
	Id             string   `json:"id"`
	Name           string   `json:"id"`
	OrderCode      string   `json:"orderCode"`
	OrderType      string   `json:"orderType"`
	Region         string   `json:"region"`
	Az             []string `json:"az"`
	InstanceStates []string `json:"instanceStates"`
	InstanceType   []string `json:"instanceType" description:"实例类型： 经典型 应用型 ['default', 'application']"`
	ProjectName    []string `json:"projectName" description:"所属项目名称 默认项目"`
	TenantId       []string `json:"tenantId" description:"所属租户id"`
	TenantName     []string `json:"tenantName" description:"所属租户名称"`
}

type MonitorBmSuccess struct {
	Code    int           `json:"code"`
	Message string        `json:"message"`
	Data    MonitorBm `json:"data"`
}

type MonitorBm struct {
	PageStruct
	DataList []MonitorInfo `json:"dataList" description:"paging data"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}
type MonitorInfo struct {
	BmConf
	ID             string `json:"id" description:"实例ID" `
	Name           string `json:"name"  description:"实例名称" `
	InstanceStates string `json:"instanceStates"  description:"实例状态" `
	InstanceType   string `json:"instanceType"  description:"实例类型" `
	Region         string `json:"region"`
	RegionName     string `json:"regionName"`
	Az             string `json:"az"`
	AzName         string `json:"azName"`
	TenantID       string `json:"tenantId"`
	TenantName     string `json:"tenantName"`
	ProjectName    string `json:"projectName"  description:"所属项目" `
	VpcName        string `json:"vpcName" description:"所属vpc"`
	Sn             string `json:"sn" description:"sn号"`
	IntranetIP     string `json:"intranetIP" description:"内网ip" `
	NetworkIP      string `json:"networkIP" description:"外网ip"`
	HostName       string `json:"hostName" description:"hostname"`
	Bound          int    `json:"bound" description:"是否绑定了资源  0:否 1:是"`
	CpuStatus      string `json:"cpuStatus" description:"cpu状态"`
	CpuRate        float64 `json:"cpuRate" description:"cpu使用率"`
	MemStatus      string `json:"memStatus" description:"内存状态"`
	MemRate        float64 `json:"memRate" description:"c内存使用率"`
	DiskStatus     string `json:"diskStatus" description:"磁盘状态"`
	DiskRate       float64 `json:"diskRate" description:"磁盘使用率"`
	AlarmNum       int    `json:"alarmNum" description:"告警数量" `
	CreateTime     string `json:"createTime"`
}

type BmConf struct {
	Cpu     string `json:"cpu"`
	Memory  string `json:"memory"`
	Storage string `json:"storage"`
}

type Item struct {
	PoolList        []string `json:"poolList" description:"所属资源池"`
	TenantIdList    []string `json:"tenantIdList" description:"所属租户id"`
	TenantNameList  []string `json:"tenantNameList" description:"所属租户名称"`
	ProjectNameList []string `json:"projectNameList" description:"所属项目名称 默认项目"`
}
```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/redis/redis.go
```golang
package redis

import (
	"net/http"

	vmmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cloudproduct"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

type ListQuery struct {
	PageNo   int    `json:"pageNo"`
	PageSize int    `json:"pageSize"`
	Region   string `json:"region"`

	Id         string `json:"id"`
	Name       string `json:"name"`
	Ip         string `json:"ip"`
	TenantId   string `json:"tenantId"`
	TenantName string `json:"tenantName"`

	Status         []string `json:"status"`
	TenantIdList   []string `json:"tenantIdList"`
	TenantNameList []string `json:"tenantNameList"`
	PoolList       []string `json:"poolList"`
	Az             []string `json:"az"`

	State        string   `json:"state"`
	PhysicalHost string   `json:"physical_host"`
	PoolId       string   `json:"poolId"`
	Pool         string   `json:"pool"`
	StorageType  []string `json:"storageType"`
	UseStatus    []string `json:"useStatus"`

	SearchKey   string `json:"searchKey"`
	SearchValue string `json:"searchValue"`
	OrderCode   string `json:"orderCode"`
	OrderType   string `json:"orderType"`
}

type OverviewQuery struct {
	PageNo        int      `json:"pageNo"`
	PageSize      int      `json:"pageSize"`
	Region        string   `json:"region"`
	Az            string   `json:"az"`
	Lab           string   `json:"lab"`
	Name          string   `json:"name"`
	TenantId      string   `json:"tenantId"`
	InnerIp       string   `json:"innerIp"`
	OuterIp       string   `json:"outerIp"`
	Label         string   `json:"label"`
	State         string   `json:"state"`
	PhysicalHost  string   `json:"physical_host"`
	Pool          string   `json:"pool"`
	StorageType   []string `json:"storageType"`
	UseStatus     []string `json:"useStatus"`
	RunningStatus []string `json:"runningStatus"`
	SearchKey     string   `json:"searchKey"`
	SearchValue   string   `json:"searchValue"`
	OrderCode     string   `json:"orderCode"`
	OrderType     string   `json:"orderType"`
}

// todo redis列表 返回数据
type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

type MonitorRedisPage struct {
	PageStruct
	DataList []MonitorRedis `json:"dataList" description:"paging data"`
}

type MonitorRedis struct {
	ID                string  `json:"id"`
	Name              string  `json:"name"`
	Status            string  `json:"status" description:"状态"`
	TenantId          string  `json:"tenantId" description:"租户id"`
	TenantName        string  `json:"tenantName" description:"租户名称"`
	Ip                string  `json:"ip" description:"IP地址"`
	Region            string  `json:"region" description:"所属区域"`
	RegionCode        string  `json:"regionCode" description:"所属区域Code"`
	Az                string  `json:"az" description:"所属可用区"`
	AzCode            string  `json:"azCode" description:"所属可用区编码"`
	PoolId            string  `json:"poolId" description:"所属资源池id"`
	PoolName          string  `json:"poolName" description:"所属资源池"`
	CPUUsedPercent    float64 `json:"cpuUsedPercent" description:"cpu使用率"`
	MemoryUsedPercent float64 `json:"memoryUsedPercent" description:"内存使用率"`
	IOPS              int64   `json:"iops" description:"IOPS （次/秒）"`
	NetInput          float64 `json:"netInput" description:"网络输入吞吐量（Kbps）"`
	NetOutput         float64 `json:"netOutput" description:"网络输出吞吐量（Kbps）"`
	Connect           int64   `json:"connect" description:"连接数"`
	QPS               int64   `json:"qps" description:"QPS （次/秒）"`
	TPS               int64   `json:"tps" description:"TPS （次/秒）"`
	CreateTime        int64   `json:"createTime"`
	InputKbps         float64 `json:"inputKbps" description:"redis每秒入流量"`
	OutputKbps        float64 `json:"outputKbps" description:"redis每秒出流量"`
	HitRate           float64 `json:"hitRate" description:"redis 缓存命中率"`
	Connection        float64 `json:"connection" description:"连接数使用率"`
	SlowLog           float64 `json:"slowLog" description:"慢查询数"`
	AlertNumber       int     `json:"alertNumber" description:"告警数量"`
}

//		input := metricsMap[inputQuery.Metric].Value // 每秒入流量
//		output := metricsMap[outputQuery.Metric].Value // 每秒出流量
//		hitRate := metricsMap[hitRateQuery.Metric].Value // 缓存命中率

//监控概览返回参数
type OverViewSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverView struct {
	Region string                        `json:"region"`
	Az     string                        `json:"az"`
	Lab    string                        `json:"lab"`
	Alerts []resourcepoolmodel.AlertType `json:"alerts"`
}

type Chart struct {
	Info   OverInfo    `json:"info"`
	Values []ValueType `json:"values"`
}

type OverInfo struct {
	Name     string `json:"name"`
	Number   int    `json:"number"`
	Type     string `json:"type"` //p0/p1/p2/p3
	Kind     string `json:"kind"` //[错误,紧急error/警告，重要warn/信息、提醒、次要info/成功、使用中success/未使用、未开通disabled]
	Unit     string `json:"unit"`
	Label    string `json:"label"`
	UnitType string `json:"unitType"`
}

//监控概览top请求参数
type TopQuery struct {
	Region       string   `json:"region"`
	Az           string   `json:"az"`
	Name         []string `json:"name"`
	Pool         string   `json:"pool"`
	Lab          string   `json:"lab"`
	TenantId     string   `json:"tenantId"`
	InnerIp      string   `json:"innerIp"`
	OuterIp      string   `json:"outerIp"`
	Label        string   `json:"label"`
	State        string   `json:"state"`
	PhysicalHost string   `json:"physicalHost"`
	SearchKey    string   `json:"searchKey"`
	SearchValue  string   `json:"searchValue"`
	RunList      []string `json:"runList"`
	Start        float64  `json:"start"`
	End          float64  `json:"end"`
	TopK         string   `json:"topk"`
}

//监控概览top返回参数
type OverViewTopSuccess struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    []OverViewLine `json:"data"`
}
type OverViewLine struct {
	Region  string       `json:"region"`
	Az      string       `json:"az"`
	Lab     string       `json:"lab"`
	Name    string       `json:"name"`
	Unit    string       `json:"unit"`
	Echarts []EchartType `json:"echarts"`
}

type EchartType struct {
	Info   services.InfoType `json:"info"`
	Values []ValueType       `json:"values"`
}

type ValueType struct {
	Value      interface{} `json:"value"`
	Name       string      `json:"name"`
	Timestamep string      `json:"timestamep"`
	SubName    string      `json:"subName"`
	VmId       string      `json:"vmId"`
}

//监控指标参数
type MetricQuery struct {
	Id        string   `json:"id"`
	IndexType string   `json:"indexType"`
	Name      []string `json:"name"`
	Start     float64  `json:"start"`
	End       float64  `json:"end"`
}

// 监控指标返回参数
type MetricLineSuccess struct {
	Code    int                 `json:"code"`
	Message string              `json:"message"`
	Data    []RedisOverViewLine `json:"data"`
}

type MetricInfoType struct {
	Metric      []string `json:"metric"`
	Name        string   `json:"name"`
	Unit        string   `json:"unit"`
	UnitType    string   `json:"unitType"`
	Copywriting string   `json:"copywriting"`
}

type RedisOverViewLine struct {
	Label       string            `json:"label"`
	Name        string            `json:"name"`
	Unit        string            `json:"unit"`
	UnitType    string            `json:"unitType"`
	Copywriting string            `json:"copywriting"`
	Echarts     []RedisEchartType `json:"echarts"`
}

type RedisEchartType struct {
	Info   InfoType             `json:"info"`
	Values []services.ValueType `json:"values"`
}

type InfoType struct {
	Name         string      `json:"name"`
	Label        string      `json:"label"`
	ResourcePool string      `json:"resourcePool"`
	Total        interface{} `json:"total"`
	Value        interface{} `json:"value"`
	Unit         string      `json:"unit"`
	UnitType     string      `json:"unitType"`
}
type Filter struct {
	Tenant       []map[string]string `json:"tenant"`
	ResourcePool []map[string]string `json:"resourcePool"`
}

type GetMonitorParam struct {
	Start    string              `gorm:"column:start" json:"start"`
	End      string              `gorm:"column:end" json:"end"`
	Name     string              `gorm:"column:name" json:"name"`
	Unit     string              `gorm:"column:Unit" json:"unit"`
	UnitType string              `gorm:"column:UnitType" json:"unitType"`
	Topk     int                 `gorm:"column:topk" json:"topk"`
	Ids      []vmmodel.CmdbTopVm `gorm:"column:Ids" json:"ids"`
	Metric   []string            `gorm:"column:metric" json:"metric"`
}

type ErrorResponse struct {
	Code    int    `json:"code"`
	Message string `json:"message"`
}

func (r ErrorResponse) Response(code int, err error) ErrorResponse {
	r.Code = code
	r.Message = err.Error()
	return r
}

func (r ErrorResponse) BadRequestResponse(err error) ErrorResponse {
	return r.Response(http.StatusBadRequest, err)
}

func (r ErrorResponse) InternalServerErrorResponse(err error) ErrorResponse {
	return r.Response(http.StatusInternalServerError, err)
}

type LogQueryParam struct {
	Id       string `json:"id"`
	Start    int64  `json:"start,omitempty"`
	End      int64  `json:"end,omitempty"`
	PageNum  int    `json:"page_num,omitempty"`
	PageSize int    `json:"page_size,omitempty"`
	LogType  string `json:"log_type,omitempty"`
	Context  string `json:"context,omitempty"`
}

type RunLog struct {
	Host struct {
		Name string `json:"name"`
	} `json:"host"`
	Message string `json:"message"`
	Event   struct {
		Created string `json:"created"`
		Dataset string `json:"dataset"`
	} `json:"event"`
}

type SlowLog struct {
	RunLog
	Redis struct {
		Slowlog struct {
			Cmd      string `json:"cmd"`
			Key      string `json:"key"`
			Duration struct {
				Us int64 `json:"us"`
			} `json:"duration"`
		} `json:"slowlog"`
	} `json:"redis"`
}

type LogData struct {
	Total int64         `json:"total"`
	Data  []interface{} `json:"data"`
}

type LogResponse struct {
	Code    int     `json:"code"`
	Message string  `json:"message"`
	Hits    LogData `json:"hits"`
}

type SlowLogData struct {
	Total int64     `json:"total"`
	Data  []SlowLog `json:"data"`
}

type SlowLogResponse struct {
	Code    int           `json:"code"`
	Message string        `json:"message"`
	Hits    []SlowLogData `json:"hits"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/alertmanager/alertmanagermodel.go
```golang
package alertmanagermodel

import "time"

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}
type Result struct {
	Code    int         `json:"code"`
	Message string      `json:"messgae"`
	Data    AlertResult `json:"data"`
}

type AlertQuery struct {
	Filter        string   `json:"filter"`
	Id            string   `json:"id"`
	AlertLevel    []string `json:"alertLevel"`
	AlertInstance string   `json:"alertInstance"`
	AlertName     string   `json:"alertName"`
	OrderType     string   `json:"orderType"`
	OrderCode     string   `json:"orderCode"`
	Region        string   `json:"region"`
	Az            []string `json:"az"`
	State         string   `json:"state"`
	PageNo        int      `json:"pageNo"`
	PageSize      int      `json:"pageSize"`
	//StorageType   []string `json:"storageType"`
	StateList []string `json:"stateList"`
	//RunningStatus []string `json:"runningStatus"`
	SearchKey              string   `json:"searchKey"`
	SearchValue            string   `json:"searchValue"`
	ResourceTypeCode       []string `json:"resourceTypeCode"`
	ResourceSubTypeCode    []string `json:"resourceSubTypeCode"`
	AlertTimeLength        []string `json:"alertTimeLength"`
	InstanceIp             string   `json:"instanceIp"`
	Handler                string   `json:"handler"`
	ExpressionWithChinaese string   `json:"expressionWithChinaese"`
	SvcId                  string   `json:"svcId"` // 所属服务id
	InstanceId             string   `json:"instanceId"`
	Module                 string   `json:"module"` // 模块
}

type HistoryAlertRequest struct {
	PolicyName          string   `json:"policyName"`
	AlertLevel          []string `json:"alertLevel"`
	StateList           []string `json:"stateList"`
	AlertState          string   `json:"alertState"`
	ResourceTypeCode    []string `json:"resourceTypeCode"`
	ResourceSubTypeCode []string `json:"resourceSubTypeCode"`
	PageNo              int      `json:"pageNo"`
	PageSize            int      `json:"pageSize"`
}

type ESQuery struct {
	PolicyName          string   `json:"policyName"`
	AlertLevel          []string `json:"alertLevel"`
	StateList           []string `json:"stateList"`
	AlertState          string   `json:"alertState"`
	ResourceTypeCode    []string `json:"resourceTypeCode"`
	ResourceSubTypeCode []string `json:"resourceSubTypeCode"`
	PageNo              int      `json:"pageNo"`
	PageSize            int      `json:"pageSize"`
}

type AlertData struct {
	Id string `json:"id"`
	//StartsAt        time.Time `json:"startsAt"`
	AlertName           string `json:"alertName"`
	PolicyName          string `json:"policyName"`
	AlertInstance       string `json:"alertInstance"`
	ResourceTypeCode    string `json:"resourceTypeCode"`
	ResourceTypeName    string `json:"resourceTypeName"`
	ResourceSubTypeCode string `json:"resourceSubTypeCode"`
	ResourceSubTypeName string `json:"resourceSubTypeName"`
	ServerType          string `json:"serverType"`
	//AlertType           string `json:"alertType"`
	Region                 string    `json:"region"`
	RegionName             string    `json:"regionName"`
	Az                     string    `json:"az"`
	AzName                 string    `json:"azName"`
	AlertLevel             string    `json:"alertLevel"`
	State                  string    `json:"state"`
	Status                 string    `json:"status"`
	StartsAt               time.Time `json:"startsAt"`
	EndsAt                 time.Time `json:"endsAt"`
	UpdatedAt              time.Time `json:"updatedAt"`
	Handler                string    `json:"handler"`
	ExpressionWithChinaese string    `json:"expressionWithChinaese"`
	ThresholdValue         string    `json:"thresholdValue"`
	AlertTimeLength        string    `json:"alertTimeLength"`
	AlertDuration          string    `json:"alertDuration"`
	InstanceIp             string    `json:"instanceIp"`
	SvcInstanceId          string    `json:"svcInstanceId"`
	SvcId                  string    `json:"svcId"`      // 所属服务id
	InstanceId             string    `json:"instanceId"` //触发告警的实例id
}

type AlertSuccess struct {
	Code    int         `json:"code"`
	Message string      `json:"message"`
	Data    AlertResult `json:"data"`
}
type AlertResult struct {
	PageStruct
	DataList []AlertData `json:"dataList"`
}

type AlertOverviewResponse struct {
	Code    int           `json:"code" description:"消息码"`
	Message string        `json:"message" description:"返回消息"`
	Data    AlertOverview `json:"data" description:"告警总览信息"`
}

type AlertOverview struct {
	ByLastTime     []*Value             `json:"byLastTime" description:"告警持续时长"`
	ByTotalNumber  LubanFETableStruct   `json:"byTotalNumber" description:"Top 10 告警总览"`
	BySeverity     LubanFETableStruct   `json:"bySeverity" description:"告警级别"`
	ByService      []*LubanFETileStruct `json:"byService" description:"关键服务告警统计"`
	ByPhysicalHost []*LubanFETileStruct `json:"byPhysicalHost" description:"物理设备告警统计"`
	ByResourcePool []*LubanFETileStruct `json:"byResourcePool" description:"资源池告警统计"`
	ByCloudProduct []*LubanFETileStruct `json:"byCloudProduct" description:"云产品告警统计"`
}

type SeverityOverview struct {
	P0Alert     AlertStruct `json:"p0"`
	P1Alert     AlertStruct `json:"p1"`
	P2Alert     AlertStruct `json:"p2"`
	P3Alert     AlertStruct `json:"p3"`
	TotalNumber int         `json:"total"`
}

type AlertStruct struct {
	ChineseName string `json:"chineseName"`
	Number      int    `json:"number"`
}

type LubanFETableStruct struct {
	Info   Info    `json:"info" description:"信息"`
	Values []Value `json:"values" description:"列表"`
}

type Value struct {
	Value int    `json:"value" description:"值"`
	Name  string `json:"name" description:"名字"`
	Key   string `json:"key" description:"名字"`
}

type Info struct {
	Name string `json:"name"`
}

type LubanFETileStruct struct {
	Prefix string     `json:"prefix"`
	Number int        `json:"number"`
	Unit   string     `json:"unit"`
	Label  string     `json:"label"`
	List   []TileItem `json:"list"`
}

type TileItem struct {
	Number int    `json:"number"`
	Unit   string `json:"unit"`
	Label  string `json:"label"`
	Kind   string `json:"kind"`
}

const (
	LessThanTenMinKey      = "lessThanTenMin"
	LessThanTenMinChinese  = "小于10分钟"
	TenMinToOneHourKey     = "tenMinToOneHour"
	TenMinToOneHourChinese = "10分钟到1小时"
	OneHourToOneDayKey     = "oneHourToOneDay"
	OneHourToOneDayChinese = "1小时到1天"
	MoreThanOneDayKey      = "moreThanOneDay"
	MoreThanOneDayChinese  = "大于1天"

	SeverityP0Key     = "p0"
	SeverityP0FEKind  = "error"
	SeverityP0Chinese = "紧急"
	SeverityP1Key     = "p1"
	SeverityP1FEKind  = "warn"
	SeverityP1Chinese = "重要"
	SeverityP2Key     = "p2"
	SeverityP2FEKind  = "minor"
	SeverityP2Chinese = "次要"
	SeverityP3Key     = "p3"
	SeverityP3FEKind  = "info"
	SeverityP3Chinese = "提醒"

	ResourceTypePhysical                 = "physicalResource"
	ResourceSubTypePhysicalServer        = "physicalServer"
	ResourceSubTypePhysicalServerChinese = "服务器"
	ResourceSubTypePhysicalSwitch        = "physicalSwitch"
	ResourceSubTypePhysicalSwitchChinese = "交换机"
	ResourceTypePool                     = "resourcePool"
	ResourceSubTypePoolKEC               = "kec"
	ResourceSubTypePoolKECChinese        = "计算资源池"
	ResourceSubTypePoolEBS               = "ebs"
	ResourceSubTypePoolEBSChinese        = "块存储资源池"
	// ResourceSubTypePoolEBS               = "ebs3.0"
	// ResourceSubTypePoolEBSChinese        = "块存储资源池"
	// ResourceSubTypePoolEHDD              = "ehdd"
	// ResourceSubTypePoolEHDDChinese       = "高效块存储资源池"
	ResourceSubTypePoolKS3              = "ks3"
	ResourceSubTypePoolKS3Chinese       = "对象存储资源池"
	ResourceTypeService                 = "service"
	ResourceSubTypeServiceGalaxy        = "service"
	ResourceSubTypeServiceGalaxyChinese = "银河平台"
	ResourceSubTypeServiceLuban         = "luban"
	ResourceSubTypeServiceLubanChinese  = "GMS运维平台"
	ResourceTypeCloud                   = "cloud"
	ResourceSubTypeCloudKEC             = "kec"
	ResourceSubTypeCloudKECChinese      = "云主机"
	ResourceSubTypeCloudEBS             = "ebs"
	ResourceSubTypeCloudEBSChinese      = "块存储"
	ResourceSubTypeCloudKS3             = "ks3"
	ResourceSubTypeCloudKS3Chinese      = "对象存储"
)

// AlertHandler 告警处理人
type AlertHandler struct {
	ID         int       `json:"id" gorm:"column:id"`
	CreatedAt  time.Time `json:"created_at" gorm:"column:created_at"`   // 创建时间
	UpdatedAt  time.Time `json:"updated_at" gorm:"column:updated_at"`   // 更新时间
	AlertId    string    `json:"alert_id" gorm:"column:alert_id"`       // 告警id
	PolicyId   string    `json:"policy_id" gorm:"column:policy_id"`     // 告警策略id
	PolicyName string    `json:"policy_name" gorm:"column:policy_name"` // 告警策略名称
	Handler    string    `json:"handler" gorm:"column:handler"`         // 告警处理人
}

func (h *AlertHandler) TableName() string {
	return "alert_handler"
}

// AlertHistory 告警历史
type AlertHistory struct {
	ID              int       `json:"id" gorm:"column:id"`
	CreatedAt       time.Time `json:"created_at" gorm:"column:created_at"`               // 创建时间
	UpdatedAt       time.Time `json:"updated_at" gorm:"column:updated_at"`               // 更新时间
	AlertId         string    `json:"alert_id" gorm:"column:alert_id"`                   // 告警id
	AlertName       string    `json:"alert_name" gorm:"column:alert_name"`               // 告警名称
	PolicyId        string    `json:"policy_id" gorm:"column:policy_id"`                 // 告警策略id
	PolicyName      string    `json:"policy_name" gorm:"column:policy_name"`             // 告警策略名称
	Severity        string    `json:"severity" gorm:"column:severity"`                   // 告警等级
	Status          string    `json:"status" gorm:"column:status"`                       // 告警状态
	ResourceType    string    `json:"resource_type" gorm:"column:resource_type"`         // 资源类型
	ResourceSubType string    `json:"resource_sub_type" gorm:"column:resource_sub_type"` // 资源子类型
	Rule            string    `json:"rule" gorm:"column:rule"`                           // 告警规则描述
	ThresholdLow    *float64  `json:"threshold_low" gorm:"column:threshold_low"`         // 告警低阈值
	ThresholdHigh   *float64  `json:"threshold_high" gorm:"column:threshold_high"`       // 告警高阈值
}

func (a *AlertHistory) TableName() string {
	return "alert_history"
}

// OverviewAlertParam 请求概览页告警参数
type OverviewAlertParam struct {
	Module        string   `json:"module"` // 模块
	Region        string   `json:"region"`
	Az            []string `json:"az"`
	AlertInstance string   `json:"alertInstance"`
}

// OverviewAlert 概览页告警
type OverviewAlert struct {
	Prefix string `json:"prefix"`
	Level  string `json:"level"`
	Unit   string `json:"unit"`
	Number int    `json:"number"`
	Name   string `json:"name"`
	Kind   string `json:"kind"`
	Type   string `json:"type"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/nat/query.go
```golang
package nat

//list
type ListQuery struct {
	PageNo   int `json:"pageNo"`
	PageSize int `json:"pageSize"`

	Region           string `json:"region"`           //可用区
	ResourcePoolName string `json:"resourcePoolName"` //资源池名称

	//单选
	Scope   []string `json:"scope"`   //作用范围  [classic,custom] 所属的vpc,绑定的子网
	NatType []string `json:"natType"` //类型 ['public', 'private']

	//多选
	VpcName     []string `json:"vpcName"`     //所属VPC
	TenantId    []string `json:"tenantId"`    //租户ID
	TenantName  []string `json:"tenantName"`  //租户名称
	ProjectName []string `json:"projectName"` //所属项目名称 默认项目

	SearchType  string `json:"searchType"`  // 搜索类型 (实例名称)
	SearchValue string `json:"searchValue"` // 搜索值 (注意要支持模糊搜索)

	OrderCode string `json:"orderCode"`
	OrderType string `json:"orderType"`
}

//监控指标参数
type MetricQuery struct {
	Id    string   `json:"id"`
	Name  []string `json:"name"`
	Start float64  `json:"start"`
	End   float64  `json:"end"`
}



type OverviewQuery struct {
	Region        string   `json:"region"`
	Az            string   `json:"az"`
	Lab           string   `json:"lab"`
}


//监控概览top请求参数
type TopQuery struct {
	Region       string   `json:"region"`
	Az           string   `json:"az"`
	Name         []string `json:"name"`
	Start        float64  `json:"start"`
	End          float64  `json:"end"`
	TopK         string   `json:"topk"`
}

type NatTopVm struct {
	ID     string      `json:"id"`
	Name   string      `json:"name"`
	Value  interface{} `json:"value"`
	Status string      `json:"status"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/nat/response.go
```golang
package nat

import (
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

//list
type (
	NatListRsp struct {
		TotalCount int       `json:"totalCount"`
		PageNo     int       `json:"pageNo"`
		PageSize   int       `json:"pageSize"`
		DataList   []NatInfo `json:"dataList"`
	}

	NatInfo struct {
		ResourcePoolName string `json:"resourcePoolName"` //资源池名称
		InstanceName     string `json:"instanceName"`     //实例名称
		InstanceId       string `json:"instanceId"`       //实例ID
		VpcName          string `json:"vpcName"`          //所属VPC
		Scope            string `json:"scope"`            //作用范围    [classic,custom] 所属的vpc,绑定的子网
		NatType          string `json:"natType"`          //类型       ['public', 'private'] 公网 内网
		Region           string `json:"region"`           //区域
		TenantId         string `json:"tenantId"`         //租户ID
		TenantName       string `json:"tenantName"`       //租户名称
		ProjectName      string `json:"projectName"`      //所属项目名称 默认项目
		Bandwidth        int    `json:"bandwidth"`        //带宽
		BoundSubNetNum   int    `json:"boundSubNetNum"`   //绑定子网数量
		CreateTime       int    `json:"createTime"`       //创建时间  秒级时间戳

		BPSIn  int64 `json:"bpsIn" description:"入网宽带 bps"`
		BPSOut int64 `json:"bpsOut" description:"出网宽带 bps"`
		PPSIn  int64 `json:"ppsIn" description:"每秒流入包数"`
		PPSOut int64 `json:"ppsOut" description:"每秒流出包数"`
	}

	MetricLine struct {
		Label       string       `json:"label"`
		Name        string       `json:"name"`
		Unit        string       `json:"unit"`
		UnitType    string       `json:"unitType"`
		Copywriting string       `json:"copywriting"`
		Echarts     []EchartType `json:"echarts"`
	}

	EchartType struct {
		Info   InfoType             `json:"info"`
		Values []services.ValueType `json:"values"`
	}

	InfoType struct {
		Name     string `json:"name"`
		Unit     string `json:"unit"`
		UnitType string `json:"unitType"`
	}

	// 监控指标返回参数
	MetricLineSuccess struct {
		Code    int          `json:"code"`
		Message string       `json:"message"`
		Data    []MetricLine `json:"data"`
	}
)


//监控概览返回参数
type OverViewSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverView struct {
	Region  string             `json:"region"`
	Az      string             `json:"az"`
	Alerts  []models.AlertType `json:"alerts"`
	Echarts []Chart            `json:"echarts"`
}

type Chart struct {
	Info   OverInfo    `json:"info"`
	Values []ValueType `json:"values"`
}

type OverInfo struct {
	Name     string `json:"name"`
	Number   int    `json:"number"`
	Type     string `json:"type"` //p0/p1/p2/p3
	Kind     string `json:"kind"` //[错误,紧急error/警告，重要warn/信息、提醒、次要info/成功、使用中success/未使用、未开通disabled]
	Unit     string `json:"unit"`
	Label    string `json:"label"`
	UnitType string `json:"unitType"`
}


//监控概览top返回参数
type OverViewTopSuccess struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    []OverViewLine `json:"data"`
}
type OverViewLine struct {
	Region  string       `json:"region"`
	Az      string       `json:"az"`
	Lab     string       `json:"lab"`
	Name    string       `json:"name"`
	Unit    string       `json:"unit"`
	Echarts []TopEchartType `json:"echarts"`
}

type TopEchartType struct {
	Info   services.InfoType `json:"info"`
	Values []ValueType       `json:"values"`
}

type ValueType struct {
	Value      interface{} `json:"value"`
	Name       string      `json:"name"`
	Timestamep string      `json:"timestamep"`
	SubName    string      `json:"subName"`
	VmId       string      `json:"vmId"`
}
```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/resourcepool/computerPoolmodel.go
```golang
package resourcepoolmodel

import (
	alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	"time"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

type ListQuery struct {
	PageNo        int      `json:"pageNo"`
	PageSize      int      `json:"pageSize"`
	Region        string   `json:"region"`
	Pool          string   `json:"pool"`
	Az            string   `json:"az"`
	Name          string   `json:"name"`
	OrderCode     string   `json:"orderCode"`
	OrderType     string   `json:"orderType"`
	ResourcePool  []string `json:"resourcePool"`
	StorageType   []string `json:"storageType"`
	MonitorStatus []string `json:"monitorStatus"`
	SearchKey     string   `json:"searchKey"`
	SearchValue   string   `json:"searchValue"`
}
type ComputerPoolListQuery struct {
	PageNo        int      `json:"pageNo"`
	PageSize      int      `json:"pageSize"`
	Region        string   `json:"region"`
	Pool          string   `json:"pool"`
	Az            []string `json:"az"`
	Name          string   `json:"name"`
	OrderCode     string   `json:"orderCode"`
	OrderType     string   `json:"orderType"`
	ResourcePool  []string `json:"resourcePool"`
	StorageType   []string `json:"storageType"`
	MonitorStatus []string `json:"monitorStatus"`
	SearchKey     string   `json:"searchKey"`
	SearchValue   string   `json:"searchValue"`
}

type BlockPoolListQuery struct {
	PageNo        int      `json:"pageNo"`
	PageSize      int      `json:"pageSize"`
	Region        string   `json:"region"`
	Pool          string   `json:"pool"`
	Az            []string `json:"az"`
	Name          string   `json:"name"`
	OrderCode     string   `json:"orderCode"`
	OrderType     string   `json:"orderType"`
	ResourcePool  []string `json:"resourcePool"`
	StorageType   []string `json:"storageType"`
	MonitorStatus []string `json:"monitorStatus"`
	SearchKey     string   `json:"searchKey"`
	SearchValue   string   `json:"searchValue"`
}

type OverviewLineQuery struct {
	Region string   `json:"region"`
	Az     string   `json:"az"`
	Lab    string   `json:"lab"`
	Name   []string `json:"name"`
	Start  float64  `json:"start"`
	End    float64  `json:"end"`
	Step   string   `json:"step"`
}
type MonitorTargetListQuery struct {
	Id    int      `json:"id"`
	Query string   `json:"query"`
	Qs    []string `json:"qs"`
	Start string   `json:"start"`
	End   string   `json:"end"`
	Step  string   `json:"step"`
}

type AggragateMonitorLite struct {
	Id   int    `json:"id"`
	Name string `json:"name"`
}

type AggragateMonitor struct {
	Id                  int     `json:"id"`
	Name                string  `json:"name"`
	Region              string  `json:"region"`
	Az                  string  `json:"az"`
	VcpuTotal           float64 `json:"vcpuTotal"`
	VcpuAvaiLable       float64 `json:"vcpuAvaiLable"`
	VcpuUtilizationRate float64 `json:"vcpuUtilizationRate"`
	VcpuUsedTotal       float64 `json:"vcpuUsedTotal"`
	MemTotal            float64 `json:"memTotal"`
	MemAvaiLable        float64 `json:"memAvaiLable"`
	MemUtilizationRate  float64 `json:"memUtilizationRate"`
	MemUsedTotal        float64 `json:"memUsedTotal"`
	DiskUtilizationRate  float64 `json:"diskUtilizationRate"`
	HostCount           int     `json:"hostCount"`
	VmCount             int     `json:"vmCount"`
	AlertCount          int     `json:"alertCount"`
	CreateTime          int64   `json:"createTime"` //秒级时间戳
}

type PhysicalServer struct {
	Name        string  `json:"name"`
	State       string  `json:"state"`
	Pool        string  `json:"pool"`
	Region      string  `json:"region"`
	Az          string  `json:"zone"`
	Lab         string  `json:"lab"`
	Sn          string  `json:"sn"`
	IP          string  `json:"ip"`
	Os          string  `json:"os"`
	CpuLoad     float64 `json:"cpuLoad"`
	MemLoad     float64 `json:"memLoad"`
	DiskLoad    float64 `json:"diskLoad"`
	AlertNumber int     `json:"alertNumber"`
	Label       string  `json:"label"`
}

type AggregateMonitorSuccess struct {
	Code    int                     `json:"code"`
	Message string                  `json:"message"`
	Data    AggregateMonitorsResult `json:"data"`
}

type AggregateMonitorsResultLite struct {
	PageStruct
	DataList []AggragateMonitorLite `json:"dataList" description:"paging data"`
}

type AggregateMonitorsResult struct {
	PageStruct
	DataList []AggragateMonitor `json:"dataList" description:"paging data"`
}

//监控指标
type PointData struct {
	Date time.Time   `json:"date"`
	Used interface{} `json:"used"`
}

type LineDataResultSuccess struct {
	Code    int              `json:"code"`
	Message string           `json:"message"`
	Data    []LineDataResult `json:"data"`
}
type LineDataResult struct {
	HostName string      `json:"hostName"`
	Values   interface{} `json:"values"`
}

// type CalculatResult struct {
// 	Cpu []LineDataResult `json:"cpu"`
// }
type DataT struct {
	ResultType string    `json:"resultType"`
	Result     []ResultT `json:"result"`
}

type ResponseMetric struct {
	Metric string `json:"metric"`
	Value  DataT  `json:"value"`
}
type ResultT struct {
	Metric interface{}   `json:"metric"`
	Values []interface{} `json:"values"`
}
type QueryResponseObject struct {
	Status string      `json:"status"`
	Data   interface{} `json:"data"`
}

//CMDB 计算资源池概览页struct
type CMDBOverViewQuery struct {
	Region   string `json:"region"`
	Az       string `json:"az"`
	DiskType string `json:"diskType"`
}
type CMDBAggregateOverview struct {
	CpuRate          []DistributedOverView `json:"cpuRate"`
	MemaryRate       []DistributedOverView `json:"MemaryRate"`
	DiskRate         []DistributedOverView `json:"DiskRate"`
	InstanceOverview []OverView            `json:"instanceOverview"`
}

type OverView struct {
	Name     string      `json:"name"`
	Code     string      `json:"code"`
	UnitType string      `json:"unitType"`
	Value    interface{} `json:"value"`
	Unit     interface{} `json:"unit"`
}

type DistributedOverView struct {
	Name        string     `json:"name"`
	Id          int        `json:"Id"`
	Distributed []OverView `json:"distributed"`
	//Distributed2 OverView `json:"distributed2"`
}

type AlertType struct {
	Prefix string `json:"prefix"`
	Level  string `json:"level"`
	Label  string `json:"label"`
	Unit   string `json:"unit"`
	Number int64  `json:"number"`
	Name   string `json:"name"`
	Kind   string `json:"kind"`
	Type   string `json:"type"`
}

type StateType struct {
	Region string `json:"region"`
	Az     string `json:"az"`
	Pool   string `json:"pool"`
	Prefix string `json:"prefix"`
	Unit   string `json:"unit"`
	Number int    `json:"number"`
	Name   string `json:"name"`
	Kind   string `json:"kind"`
	Type   string `json:"type"`
}

type OverViewSuccess struct {
	Code    int       `json:"code"`
	Message string    `json:"message"`
	Data    OverView1 `json:"data"`
}
type OverView1 struct {
	Region string      `json:"region"`
	Az     string      `json:"az"`
	Pool   string      `json:"pool"`
	Lab    string      `json:"lab"`
	Alerts []alertmanagermodel.OverviewAlert `json:"alerts"`
	State  []StateType `json:"state"`
	//AllTopK       []prometheusmanager.RateTopResult
}

type OverViewLine struct {
	//Region string `json:"region"`
	//Az     string `json:"az"`
	//Lab    string `json:"lab"`
	Label    string `json:"label"`
	Name     string `json:"name"`
	Unit     string `json:"unit"`
	UnitType string `json:"unitType"`
	//Alert  AlertLevels `json:"alert"`
	Echarts []EchartType `json:"echarts"`
}

type EchartType struct {
	Info   InfoType             `json:"info"`
	Values []services.ValueType `json:"values"`
}

type ValueType struct {
	Value      string  `json:"value"`
	Name       string  `json:"name"`
	TimeSteamp float64 `json:"timesteamp"`
}

type InfoType struct {
	Name         string      `json:"name"`
	Label        string      `json:"label"`
	ResourcePool string      `json:"resourcePool"`
	Total        interface{} `json:"total"`
	Value        interface{} `json:"value"`
	Unit         string      `json:"unit"`
	UnitType     string      `json:"unitType"`
}

type OverViewLineSuccess struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    []OverViewLine `json:"data"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/resourcepool/networkmodel.go
```golang
package resourcepoolmodel

import "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"

// 网络资源池监控概览请求参数
type NetworkOverviewQuery struct {
	Region   string `json:"region"`
	Az       string `json:"az"`
	PoolType string `json:"poolType"`
}

type NetPoolOverViewSuccess struct {
	Code    int          `json:"code"`
	Message string       `json:"message"`
	Data    OverViewData `json:"data"`
}

type OverViewData struct {
	Region  string       `json:"region"`
	Az      string       `json:"az"`
	Alerts  []NetAlert   `json:"alerts" description:"告警列表"`
	Echarts []EchartType `json:"echarts"`
}

type NetAlert struct {
	Prefix string        `json:"prefix"`
	Level  string        `json:"level" description:"告警级别 p0-p3"`
	Label  string        `json:"label"`
	Unit   string        `json:"unit"`
	Number int           `json:"number" description:"告警数量"`
	Name   string        `json:"name" description:"告警名称"`
	Kind   string        `json:"kind"`
	Type   string        `json:"type"`
	List   []SubNetAlert `json:"list"`
}

type SubNetAlert struct {
	Name   string `json:"name"`
	Code   string `json:"code"`
	Number int    `json:"number"`
	Unit   string `json:"unit"`
	Kind   string `json:"kind"`
}

//type NetEchart struct {
//	Name string       `json:"name"`
//	Data []EchartType `json:"data"`
//}

//网络资源池监控概览line请求参数
type NetworkOverviewLineQuery struct {
	Start    int64    `json:"start"`
	End      int64    `json:"end"`
	Name     []string `json:"name"`
	Region   string   `json:"region"`
	Az       string   `json:"az"`
	PoolType string   `json:"poolType"`
}

//网络资源池监控概览line响应数据
type NetOverviewLineSuccess struct {
	Code    int           `json:"code"`
	Message string        `json:"message"`
	Data    []NetLineData `json:"data"`
}

type NetLineData struct {
	Info  LineInfo   `json:"info"`
	Pools []PoolData `json:"pools"`
}

type LineInfo struct {
	Tyte     string `json:"_type"`
	Index    int    `json:"_index"`
	Name     string `json:"name" description:"指标名称"`
	Number   int    `json:"number" description:"总数之类的统计值"`
	Start    string `json:"start" description:"开始时间"`
	End      string `json:"end" description:"结束时间"`
	Unit     string `json:"unit" description:"指标的单位"`
	UnitType string `json:"unitType" description:"指标的单位类型"`
}

type PoolData struct {
	Info   PoolInfo             `json:"info"`
	Values []services.ValueType `json:"values"`
}

type PoolInfo struct {
	Name string `json:"name" description:"统计名称"`
	//Prognosis int    `json:"prognosis"`
}

type NetworkPoolLable struct {
	Region           string   `json:"region"`
	ResourcePoolType string   `json:"resourcePoolType"`
	ResourcePool     string   `json:"resourcePool"`
	HostList         []string `json:"-"`
	IPList           []string `json:"-"`
}

// 获取网络列表参数
type NetworkListQuery struct {
	Region    string   `json:"region"`
	IndexType string   `json:"indexType"`
	PoolType  []string `json:"poolType"`
	PoolName  string   `json:"poolName"`
	OrderCode string   `json:"orderCode"`
	OrderType string   `json:"orderType"`
}

// 网络列表返回数据
type NetworkPageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

type NetworkListPage struct {
	PageStruct
	DataList []NetworkList `json:"dataList" description:"paging data"`
}

type NetworkList struct {
	CreatedAt int `json:"createdAt"`
	EipCount  int `json:"eipCount"` // 弹性ip数量
	LbCount   int `json:"lbCount"`  // 负载均衡数量
	NatCount  int `json:"natCount"` //NAT 数量
	BMCount int `json:"bmCount"` //裸金属 数量
	SLCount int`json:"slCount"` //专线 数量
	VPNCount int `json:"vpnCount"` //VPN 数量
	P2pCount int `json:"p2pCount"` //对等连接 数量
	PoolName          string  `json:"poolName"` // 资源池名称
	PoolType          string  `json:"poolType"` // 资源池类型
	RegionCode        string  `json:"regionCode"`
	RegionName        string  `json:"regionName"`
	ServerCount       int     `json:"serverCount"` // 服务器数量
	CPUUsedPercent    float64 `json:"cpuUsedPercent" description:"cpu使用率"`
	MemoryUsedPercent float64 `json:"memoryUsedPercent" description:"内存使用率"`
	DiskUsedPercent   float64 `json:"diskUsedPercent" description:"磁盘使用率"`
}

//网络资源池监控概览line响应数据
type NetworkListSuccess struct {
	Code    int               `json:"code"`
	Message string            `json:"message"`
	Data    []NetworkListPage `json:"data"`
}

type NetWorkUsageQuery struct {
	PageNo     int    `json:"pageNo"`
	PageSize   int    `json:"pageSize"`
	RegionCode string `json:"region"`
}

type NetworkUsagePage struct {
	PageStruct
	DataList []NetWorkInventory `json:"dataList" description:"paging data"`
}
type NetWorkInventory struct {
	RegionCode       string  `json:"regionCode"`
	RegionName       string  `json:"regionName" description:"所属区域"`
	PoolType         string  `json:"poolType" description:"资源池"`
	WayType          string  `json:"wayType" description:"线路类型"`
	Cidr             string  `json:"cidr" description:"地址段"`
	IpCount          int     `json:"ipCount" description:"IP总数"`
	IpUsedCount      int     `json:"ipUsedCount" description:"已使用IP数量"`
	IpValidCount     int     `json:"ipValidCount" description:"可用IP数量"`
	IpRemindCount    int     `json:"ipRemindCount" description:"保留IP数量"`
	IpUsedRatio      float64 `json:"ipUsedRatio" description:"IP使用率"`
	IpAvailableRatio float64 `json:"ipAvailableRatio" description:"IP可用率"`
	CpuTotal         int     `json:"cpuTotal" description:"CPU总量"`
	CpuUsedRatio     float64 `json:"cpuUsedRatio" description:"CPU使用率"`
	MemTotal         int     `json:"memTotal" description:"内存总量"`
	MemUsedRatio     float64 `json:"memUsedRatio" description:"内存使用率"`
}
type NetPoolUsageSuccess struct {
	Code    int              `json:"code"`
	Message string           `json:"message"`
	Data    NetworkUsagePage `json:"data"`
}

// 网络资源池监控指标详情请求参数
type NetworkDetailQuery struct {
	PoolName   string `json:"poolName" valid:"required"`
	PoolType   string `json:"poolType" valid:"required"`
	Region     string `json:"region" valid:"required"`
	Hostname   string `json:"hostname" valid:"required"`
	TopK       int    `json:"topK" valid:"int"`     // 当且仅当排序需要传
	MetricName string `json:"metricName" valid:"required"`
	Start      int64  `json:"start" valid:"required"` // 单位是毫秒时间戳
	End        int64  `json:"end" valid:"required"`
}

type NetworkDetailSuccess struct {
	Code    int              `json:"code"`
	Message string           `json:"message"`
	Data    []PoolDetailData `json:"data"`
}

type PoolDetailData struct {
	Info   MetricInfo           `json:"info"`
	Values []services.ValueType `json:"values"`
}

// 指标信息详情
type MetricInfo struct {
	Name     string `json:"name" description:"线对应的名称"`
	Unit     string `json:"unit" description:"指标的单位"`
	UnitType string `json:"unitType" description:"指标的单位类型"`
}

type PoolDetailLabel struct {
	Region           string
	ResourcePoolType string
	ResourcePool     string
	AZ               string
	HostName         string
	Instance         string
	IP               string
	Eip              string
	Port             string
	Vni              string
	Domain           string
	Tgwtype          string
}

// 网络资源池监控指标详情请求参数
type NetworkTopLine struct {
	PoolName   string `form:"poolName" json:"poolName" validate:"required" label:"资源池名称"`
	PoolType   string `json:"poolType"`
	Region     string `json:"region"`
	Hostname   string `json:"hostname"` // 当且仅当排序需要传
	TopK       int    `json:"topK"`     // 当且仅当排序需要传
	MetricName string `json:"metricName"`
	Start      int64  `json:"start"` // 单位是毫秒时间戳
	End        int64  `json:"end"`
}
```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/resourcepool/objectstoragemodel.go
```golang
package resourcepoolmodel

import (
	alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

type ObjectStoragePoolSuccess struct {
	Code    int                             `json:"code"`
	Message string                          `json:"message"`
	Data    ObjectStoragePoolListDataResult `json:"data"`
}
type ObjectStoragePoolListDataResult struct {
	PageStruct
	DataList []ObjectStorageMonitor `json:"dataList"`
}

//	type objectStoragePoolList struct {
//		RequestId string    `json:"requestId"`
//		Returns   []BlockRe `json:"returns"`
//	}
type ObjectStorageMonitor struct {
	Id                int                         `json:"id"`
	Name              string                      `json:"name"`
	MonitorStatus     string                      `json:"monitorStatus"`
	Region            string                      `json:"region"`
	RegionCode        string                      `json:"regionCode"`
	AzCode            string                      `json:"azCode"`
	ResourcePool      string                      `json:"resourcePool"`
	CapacityTotal     float64                     `json:"capacityTotal"`
	CapacityUsedTotal float64                     `json:"capacityUsedTotal"`
	CapacityAvailable float64                     `json:"capacityAvailable"`
	CapacityUsedRate  float64                     `json:"capacityUsedRate"`
	BucketNumber      int                         `json:"bucketNumber"`
	HostNumber        int                         `json:"hostNumber"`
	BucketAmount      int                         `json:"bucketAmount"`
	ObjectAmount      string                      `json:"objectAmount"`
	RequestDelay      string                      `json:"requestDelay"`
	Bandwidth         string                      `json:"bandwidth"`
	Flow              string                      `json:"flow"`
	APIRequestAmount  string                      `json:"aPIRequestAmount"`
	ErrorReturnAmount int64                       `json:"errorReturnAmount"`
	HttpRequestAmount string                      `json:"httpRequestAmount"`
	HttpConnectAmount string                      `json:"httpConnectAmount"`
	CreateTime        int64                       `json:"createTime"`
	AlertAmount       string                      `json:"alertAmount"`
	Status            string                      `json:"status"`
	ServerStatus      []ObjectStorageServerStatus `json:"server_status"`
}

type ObjectStorageServerStatus struct {
	Address string `json:"address"`
	Role    string `json:"role"`
	Status  string `json:"status"`
}

type CMDBObjectStorageOverview struct {
	BucketSumOverview          ChartBaseOverview
	BucketCountOverview        []OverView                `json:"bucketCountOverview"`
	StorageUsedOverview        []OverView                `json:"storageUsedOverview"`
	BucketTotalStorageOverview ObjectDistributedOverView `json:"bucketTotalStorageOverview"`
}
type ObjectDistributedOverView struct {
	Name        string      `json:"name"`
	Code        string      `json:"code"`
	Value       interface{} `json:"value"`
	Unit        string      `json:"unit"`
	Distributed []OverView  `json:"distributed"`
	//Distributed2 OverView `json:"distributed2"`
}
type ObjectStoragePoolUsageResult struct {
	PageStruct
	DataList []ObjectStorageUsage `json:"dataList"`
}

//	type objectStoragePoolList struct {
//		RequestId string    `json:"requestId"`
//		Returns   []BlockRe `json:"returns"`
//	}
type ObjectStorageUsage struct {
	Id                         int     `json:"id"`
	Name                       string  `json:"name"`
	Region                     string  `json:"region"`
	RegionCode                 string  `json:"regionCode"`
	ResourcePool               string  `json:"resourcePool"`
	ResourcePoolType           string  `json:"resourcePoolType"`
	CapacityTotal              float64 `json:"capacityTotal"`
	CapacityUsedTotal          float64 `json:"capacityUsedTotal"`
	CapacityAvailable          float64 `json:"capacityAvailable"`
	CapacityUsedRate           float64 `json:"capacityUsedRate"`
	CapacityTotalLastWeek      float64 `json:"capacityTotalLastWeek"`
	CapacityUsedIncrementDay   float64 `json:"capacityUsedIncrementDay"`
	CapacityUsedIncrementWeek  float64 `json:"capacityUsedIncrementWeek"`
	CapacityUsedIncrementMonth float64 `json:"capacityUsedIncrementMonth"`
	RemainingDays              float64 `json:"remainingDays"`
	CreateTime                 int64   `json:"createTime"`
}
type ObjectStorageUsageQuery struct {
	Region    string `json:"region"`
	Name      string `json:"name"`
	PageNo    int    `json:"pageNo"`
	PageSize  int    `json:"pageSize"`
	OrderCode string `json:"orderCode"`
	OrderType string `json:"orderType"`
}

type ObjectOverViewSuccess struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    ObjectOverView `json:"data"`
}

type ObjectOverView struct {
	Region  string                            `json:"region"`
	Alerts  []alertmanagermodel.OverviewAlert `json:"alerts"`
	Echarts ObjectView                        `json:"echarts"`
	//State  RegionCurrentStates `json:"state"`
	//AllTopK       []prometheusmanager.RateTopResult
}
type ObjectView struct {
	Capacity []ChartInfo `json:"capacity"`
	Bucket   []ChartInfo `json:"bucket"`
	Qs       []ChartInfo `json:"qs"`
}
type ObjectOverViewLineSuccess struct {
	Code    int                `json:"code"`
	Message string             `json:"message"`
	Data    ObjectOverViewLine `json:"data"`
}

type ObjectOverViewLine struct {
	StorageType  string `json:"storageType"`
	ResourcePool string `json:"resourcePool"`
	Region       string `json:"region"`
	Az           string `json:"az"`
	Lab          string `json:"lab"`
	//Alert  AlertLevels `json:"alert"`
	Echarts []ObjectEchartType `json:"echarts"`
}

type ObjectEchartType struct {
	Info   ObjectInfoType `json:"info"`
	Values []ValueType    `json:"values"`
}

type ObjectInfoType struct {
	StorageType  string `json:"storageType"`
	ResourcePool string `json:"resourcePool"`
	Region       string `json:"region"`
	Az           string `json:"az"`
	Lab          string `json:"lab"`
	Name         string `json:"name"`
	SubName      string `json:"subName"`
	Total        string `json:"total"`
	TopK         int    `json:"topk"`
	Start        string `json:"start"`
	End          string `json:"end"`
}

type Echart struct {
	Name string      `json:"name"`
	Data []ChartInfo `json:"data"`
}

type ChartInfo struct {
	Info   InfoType             `json:"info"`
	Values []services.ValueType `json:"values"`
}

type ObjectOverviewLineQuery struct {
	Region string   `json:"region"`
	Pool   string   `json:"pool"`
	Name   []string `json:"name"`
	Start  int64    `json:"start"`
	End    int64    `json:"end"`
	Step   string   `json:"step"`
}

type BucketPoolMetricResponse struct {
	Code    int       `json:"code"`
	Message string    `json:"message"`
	Data    []MetricT `json:"data"`
}

type Cap struct {
	Total_disk_capacity int `json:"total_disk_capacity"`
	Total_used_space    int `json:"total_used_space"`
	Total_free_space    int `json:"total_free_space"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/resourcepool/databasePoolmodel.go
```golang
package resourcepoolmodel

import (
	promModel "github.com/prometheus/common/model"
	alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

type LineData struct {
	Info MetricLineInfo `json:"info"`
	Poll []Poll         `json:"poll"`
}

type MetricLineInfo struct {
	Tyte     string `json:"_type"`
	Index    int    `json:"_index"`
	Name     string `json:"name" description:"指标名称"`
	Number   int    `json:"number" description:"总数之类的统计值"`
	Start    string `json:"start" description:"开始时间"`
	End      string `json:"end" description:"结束时间"`
	Unit     string `json:"unit" description:"指标的单位"`
	UnitType string `json:"unitType" description:"指标的单位类型"`
}

type Poll struct {
	Info   PollOverviewInfo     `json:"info"`
	Values []services.ValueType `json:"values"`
}

type PollOverviewInfo struct {
	Name      string `json:"name" description:"统计名称"`
	Prognosis int    `json:"prognosis"`
}

type ResourcePoolInfo struct {
	ResourcePoolName string `json:"resourcePoolName"`
	ServersIps       string `json:"serversInfo"`
	DownServersNum   int    `json:"downServersNum"`
}

// 数据库监控概览请求参数
type DatabaseOverviewQuery struct {
	Region string `json:"region"`
	Az     string `json:"az"`
	Lab    string `json:"lab"`
}

// 数据库概览返回参数
type OverviewSuccess struct {
	Code    int              `json:"code"`
	Messgae string           `json:"messgae"`
	Data    OverviewDataData `json:"data"`
}

type OverviewDataData struct {
	Region    string                            `json:"region"`
	Az        string                            `json:"az"`
	Alerts    []alertmanagermodel.OverviewAlert `json:"alerts"`
	BlockView DatabaseViewType                  `json:"blockView"`
}

type Alerts struct {
	Prefix string `json:"prefix"`
	Level  string `json:"level"`
	Label  string `json:"label"`
	Unit   string `json:"unit"`
	Number int    `json:"number"`
	Name   string `json:"name"`
	Kind   string `json:"kind"`
	Type   string `json:"type"`
}

type DatabaseViewType struct {
	List [][]EchartType `json:"list"`
}

// 数据库监控概览line请求参数
type DatabaseOverviewLineQuery struct {
	Start  int64    `json:"start"`
	End    int64    `json:"end"`
	Name   []string `json:"name"`
	Region string   `json:"region"`
	Az     string   `json:"az"`
}

//数据库监控概览line返回参数

type DatabaseOverviewLineSuccess struct {
	Code    int        `json:"code"`
	Message string     `json:"message"`
	Data    []LineData `json:"data"`
}

// 数据库监控列表请求参数
type DatabaseListQuery struct {
	PageNo      int      `json:"pageNo"`
	PageSize    int      `json:"pageSize"`
	Region      string   `json:"region"`
	Az          string   `json:"az"`
	Name        string   `json:"name" description:"名称（模糊搜索）"`
	DbType      []string `json:"dbType" description:"数据库类型名称"`
	SearchKey   string   `json:"searchKey"`
	SearchValue string   `json:"searchValue"`
	OrderCode   string   `json:"orderCode"`
	OrderType   string   `json:"orderType"`
}

// 数据库监控列表返回参数
type DatabaseListSuccess struct {
	Code    int    `json:"code"`
	Message string `json:"message"`
	Data    Data   `json:"data"`
}

type Data struct {
	TotalCount int        `json:"totalCount"`
	PageNo     int        `json:"pageNo"`
	PageSize   int        `json:"pageSize"`
	DataList   []DataList `json:"dataList"`
}

type DataList struct {
	ID                  string  `json:"id" description:"资源池ID"`                 // 资源池ID
	Name                string  `json:"name" description:"资源池名称"`               // 资源池名称
	Region              string  `json:"region" description:"所属区域"`              // 所属区域
	DBType              string  `json:"dbType" description:"数据库类型名称"`           // 数据库类型 mysql/redis
	CPUUsedPercent      float64 `json:"cpuUsedPercent" description:"cpu使用率"`    // cpu使用率
	MemoryUsedPercent   float64 `json:"memoryUsedPercent" description:"内存使用率"`  // 内存使用率
	DiskUsedPercent     float64 `json:"diskUsedPercent" description:"磁盘使用率"`    // 磁盘使用率
	ServerCount         int     `json:"serverCount" description:"服务器数量"`        // 服务器数量
	AbnormalServerCount int     `json:"abnormalCount" description:"异常服务器数量"`    // 异常服务器数量
	InstanceTotal       int     `json:"instanceTotal" description:"最大可创建实例数量"`  // 最大可创建实例数量
	InstanceUsed        int     `json:"instanceUsed" description:"已创建的实例数量"`    // 已创建的实例数量
	AbnormalInstance    uint    `json:"abnormalInstance" description:"异常实例数量"`  // 异常实例数量
	InstanceUnused      int     `json:"instanceUnused" description:"当前可创建实例数量"` // 当前可创建实例数量（计算推荐）
	CreateTime          int64   `json:"createTime" description:"创建时间"`          // 创建时间
	WarningNum          int     `json:"warningNum" description:"告警数量"`          // 告警数量
}

type DatabaseMonitorQuery struct {
	Id     string `json:"id"`
	Metric string `json:"metric"`
	Start  int64  `json:"start"`
	End    int64  `json:"end"`
	Step   int    `json:"step"`
}

type DatabaseMonitorDetail struct {
	Hostname string                 `json:"hostname"`
	Values   []promModel.SamplePair `json:"values"`
}

type DatabaseMonitorLine struct {
	Code    int                     `json:"code"`
	Message string                  `json:"message"`
	Data    []DatabaseMonitorDetail `json:"data"`
}

type MysqlLable struct {
	Region           string   `json:"region"`
	ResourcePoolType string   `json:"resourcePoolType"`
	ResourcePool     string   `json:"resourcePool"`
	IPList           []string `json:"-"`
}

// 数据库服务器列表请求参数
type ServerListQuery struct {
	PageNo      int      `json:"pageNo"`
	PageSize    int      `json:"pageSize"`
	Region      string   `json:"region"`
	Id          string   `json:"id"`
	RunState    []string `json:"runState" description:"运行状态"`
	Az          []string `json:"az" description:"所属可用区"`
	Lab         []string `json:"lab" description:"所属机房编码 lab_code"`
	SearchKey   string   `json:"searchKey"`
	SearchValue string   `json:"searchValue"`
	OrderCode   string   `json:"orderCode"`
	OrderType   string   `json:"orderType"`
}

// 数据库实例列表请求参数
type InstanceListQuery struct {
	PageNo         int      `json:"pageNo"`
	PageSize       int      `json:"pageSize"`
	Region         string   `json:"region"`
	Id             string   `json:"id"`
	RunState       []string `json:"runState" description:"运行状态"`
	TenantIdList   []string `json:"tenantIdList"`
	TenantNameList []string `json:"tenantNameList"`
	Az             []string `json:"az" description:"所属可用区"`

	SearchKey   string `json:"searchKey"`
	SearchValue string `json:"searchValue"`
	OrderCode   string `json:"orderCode"`
	OrderType   string `json:"orderType"`
}

type ServerListPageData struct {
	TotalCount int        `json:"totalCount"`
	PageNo     int        `json:"pageNo"`
	PageSize   int        `json:"pageSize"`
	DataList   []DBServer `json:"dataList"`
}

type DBServer struct {
	Name              string  `json:"name"`
	State             string  `json:"state"`
	Region            string  `json:"region"`
	Az                string  `json:"zone"`
	Lab               string  `json:"lab"`
	Sn                string  `json:"sn"`
	IP                string  `json:"ip"`
	CPUTotal          int     `json:"cpuTotal" description:"cpu总量"`
	CPUUnused         int     `json:"cpuUnused" description:"cpu剩余量"`
	CPUUsedPercent    float64 `json:"cpuUsedPercent" description:"cpu使用率"`
	MemoryTotal       int     `json:"memoryTotal" description:"内存总量"`
	MemoryUnused      int     `json:"memoryUnused" description:"内存剩余量"`
	MemoryUsedPercent float64 `json:"memoryUsedPercent" description:"内存使用率"`
	DiskTotal         int     `json:"diskTotal" description:"磁盘总量"`
	DiskUnused        int     `json:"diskUnused" description:"磁盘剩余量"`
	DiskUsedPercent   float64 `json:"diskUsedPercent" description:"磁盘使用率"`
	CreateTime        int64   `json:"createTime"`
	AlertNumber       int     `json:"alertNumber"`
}

// 数据库服务器列表返回参数
type ServerListSuccess struct {
	Code    int                `json:"code"`
	Message string             `json:"message"`
	Data    ServerListPageData `json:"data"`
}

// 数据库实例列表返回参数
type InstanceListSuccess struct {
	Code    int                  `json:"code"`
	Message string               `json:"message"`
	Data    InstanceListPageData `json:"data"`
}

type InstanceListPageData struct {
	PageStruct
	DataList []InstanceMonitor `json:"dataList" description:"paging data"`
}

type InstanceMonitor struct {
	ID                string  `json:"id"`
	Name              string  `json:"name"`
	DbType            string  `json:"dbType"`
	Status            string  `json:"status" description:"状态"`
	TenantId          string  `json:"tenantId" description:"租户id"`
	TenantName        string  `json:"tenantName" description:"租户名称"`
	Ip                string  `json:"ip" description:"IP地址"`
	Region            string  `json:"region" description:"所属区域"`
	Az                string  `json:"az" description:"所属可用区"`
	AzCode            string  `json:"azCode" description:"所属可用区编码"`
	CPUUsedPercent    float64 `json:"cpuUsedPercent" description:"cpu使用率"`
	MemoryUsedPercent float64 `json:"memoryUsedPercent" description:"内存使用率"`
	IOPS              int64   `json:"iops" description:"IOPS （次/秒）"`
	NetInput          float64 `json:"netInput" description:"网络输入吞吐量（Kbps）"`
	NetOutput         float64 `json:"netOutput" description:"网络输出吞吐量（Kbps）"`
	Connect           int64   `json:"connect" description:"连接数"`
	QPS               int64   `json:"qps" description:"QPS （次/秒）"`
	TPS               int64   `json:"tps" description:"TPS （次/秒）"`
	CreateTime        int64   `json:"createTime"`
	AlertNumber       int     `json:"alertNumber" description:"告警数量"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/resourcepool/blockstoragemodel.go
```golang
package resourcepoolmodel

import alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"

type BlockStorageMonitor struct {
	Id                int         `json:"id"`
	Name              string      `json:"name"`
	MonitorStatus     string      `json:"monitorStatus"`
	Region            string      `json:"region"`
	RegionCode        string      `json:"regionCode"`
	Az                string      `json:"az"`
	AzCode            string      `json:"azCode"`
	ResourcePool      string      `json:"resourcePool"`
	HostNumber        int         `json:"hostNumber"`
	CloudDiskNumber   int         `json:"cloudDiskNumber"`
	CapacityTotal     float64     `json:"capacityTotal"`
	CapacityAvailable float64     `json:"capacityAvailable"`
	CapacityUsedRate  float64     `json:"capacityUsedRate"`
	ErrorRate         float64     `json:"errorRate"`
	IOInput           interface{} `json:"ioInput"`
	IODelay           interface{} `json:"ioDelay"`
	Bandwidth         interface{} `json:"bandwidth"`
	SnapShots         int         `json:"snapShots"`
	CreateTime        int64       `json:"createTime"`
	AlertAmount       int         `json:"alertAmount"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

type BlockStorageSuccess struct {
	Code    int                 `json:"code"`
	Message string              `json:"message"`
	Data    BlockStoragesResult `json:"data"`
}

type BlockStoragesResult struct {
	PageStruct
	DataList []BlockStorageMonitor `json:"dataList" description:"paging data"`
}
type StorageMonitorTargetQuery struct {
	Name   string   `json:"name"`
	Region string   `json:"region"`
	Az     string   `json:"az"`
	Query  string   `json:"query"`
	List   []string `json:"list"`
	Start  string   `json:"start"`
	End    string   `json:"end"`
	Step   string   `json:"step"`
}

type StorageLineDataSuccess struct {
	Code    int                     `json:"code"`
	Message string                  `json:"message"`
	Data    []StorageLineDataResult `json:"data"`
}
type StorageLineDataResult struct {
	Name   string      `json:"Name"`
	Values interface{} `json:"values"`
}
type QueryList struct {
	List []string `json:"list"`
}

type CMDBBlockStorageOverview struct {
	HostCountOverview    ChartBaseOverview          `json:"hostCountOverview"`
	VMCountOverview      []OverView                 `json:"hostStateOverview"`
	TotalStorageOverview []BlockDistributedOverView `json:"distributedOverview"`
}
type BlockDistributedOverView struct {
	Name        string      `json:"name"`
	Code        string      `json:"code"`
	Value       interface{} `json:"value"`
	Unit        string      `json:"unit"`
	Distributed []OverView  `json:"distributed"`
	//Distributed2 OverView `json:"distributed2"`
}

type ChartBaseOverview struct {
	Name  string      `json:"name"`
	Code  string      `json:"code"`
	Value interface{} `json:"value"`
	Unit  string      `json:"unit"`
}

type BlockPoolOverviewQuery struct {
	Region   string `json:"region"`
	Az       string `json:"az"`
	Name     string `json:"name"`
	DiskType string `json:"diskType"`
	Pool     string `json:"pool"`
}

type BlockPoolQuery struct {
	Region   string   `json:"region"`
	Az       []string `json:"az"`
	Name     string   `json:"name"`
	DiskType string   `json:"diskType"`
	Pool     string   `json:"pool"`
}
type BlockStoragesUseageResult struct {
	PageStruct
	DataList []BlockStorageUseage `json:"dataList" description:"paging data"`
}

type BlockStorageUseage struct {
	Id                int     `json:"id"`
	Name              string  `json:"name"`
	Region            string  `json:"region"`
	RegionCode        string  `json:"regionCode"`
	Az                string  `json:"az"`
	ResourcePool      string  `json:"resourcePool"`
	CapacityTotal     float64 `json:"capacityTotal"`
	CapacityAvailable float64 `json:"capacityAvailable"`
	CapacityUsedRate  float64 `json:"capacityUsedRate"`
	CreateTime        int64   `json:"createTime"`
	ServersNum        int     `json:"serversNum"`
	PhysicalSize      int     `json:"physicalSize"`
	PhysicalDosage    int     `json:"physicalDosage"`
	PhysicalSizeAll   int64   `json:"physicalSizeAll"`
	PhysicalUsageAll  int64   `json:"physicalUsageAll"`
	PhysicalRWRatio   float64 `json:"physicalRWRatio"`
	HighestDisk       int     `json:"highestDisk"`
	OpenNum           int     `json:"openNum"`
	VdiOpenNum        string  `json:"vdiOpenNum"`
	VdiWriteNum       string  `json:"vdiWriteNum"`
	SnapshotSize      int64   `json:"SnapshotSize"`
	Oversold          float64 `json:"oversold"`
	UnitTotal         int     `json:"unitTotal"`
	UnitUsed          int     `json:"unitUsed"`
	UnitRate          float64 `json:"unitRate"`
	WriteRateUp       float64 `json:"writeRateUp"`
	SalesRate         float64 `json:"salesRate"`
	Saleable          int     `json:"saleable"`
	AllocatedSize     int64   `json:"allocatedSize"` //分配量
	LogicalSize       int     `json:"LogicalSize"`
	LogicalUsage      int     `json:"LogicalUsage"`
}

var BlockStorageUseageQueryDoc string = `
        name:aggregate 必填，eg:["ebs3.0"]
		region:区域;默认值：all
		az:可用区;默认值：all
		pageNo:eg:1,页码，默认值1
		pageSize:eg:10, 页大小，默认值10
		orderCode:The orderCode of order.eg:cpuUsage;memoryRate
		orderType:The orderType of order.eg:升：asc;降：desc
`

type BlockStorageUseageQuery struct {
	Region      string   `json:"region"`
	Az          []string `json:"az"`
	StorageType []string `json:"storageType"`
	Name        []string `json:"name"`
	PageNo      int      `json:"pageNo"`
	PageSize    int      `json:"pageSize"`

	OrderCode string `json:"orderCode"`
	OrderType string `json:"orderType"`
}

type BlockOverViewSuccess struct {
	Code    int           `json:"code"`
	Message string        `json:"message"`
	Data    BlockOverView `json:"data"`
}
type BlockOverView struct {
	Region string `json:"region"`
	Az     string `json:"az"`
	//Lab       string       `json:"lab"`
	Alerts    []alertmanagermodel.OverviewAlert `json:"alerts"`
	BlockView BlockViewType                     `json:"blockView"`
	//AllTopK       []prometheusmanager.RateTopResult
}

type BlockViewType struct {
	List [][]EchartType `json:"list"`
	//Number   []EchartType `json:"number"`
}

type BlockPoolMetricResponse struct {
	Code    int       `json:"code"`
	Message string    `json:"message"`
	Data    []MetricT `json:"data"`
}

type MetricT struct {
	ID       string      `json:"id" description:"资源池id"`
	Name     string      `json:"name" description:"监控项名称"`
	Unit     string      `json:"unit" description:"监控项单位"`
	Value    interface{} `json:"value" description:"监控值"`
	UnitType string      `json:"unitType" description:"监控单位类型"`
	Type     string      `json:"type" description:"类型"`
	Kind     string      `json:"kind" description:"显示颜色类型"`
}

type BlockPoolOverViewSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type BlockPoolOverView struct {
	StorageType  string      `json:"storageType"`
	ResourcePool string      `json:"resourcePool"`
	Region       string      `json:"region"`
	Az           string      `json:"az"`
	Lab          string      `json:"lab"`
	Alerts       AlertLevels `json:"alerts"`
	Echarts      []Chart     `json:"echarts"`
	//State  RegionCurrentStates `json:"state"`
	//AllTopK       []prometheusmanager.RateTopResult
}
type AlertLevels struct {
	P0 int `json:"p0"`
	P1 int `json:"p1"`
	P2 int `json:"p2"`
	P3 int `json:"p3"`
}

type Chart struct {
	Info   OverInfo    `json:"info"`
	Values []ValueType `json:"values"`
}
type OverInfo struct {
	Region       string `json:"region"`
	Az           string `json:"az"`
	StorageType  string `json:"storageType"`
	ResourcePool string `json:"resourcePool"`
	Name         string `json:"name"`
	SubName      string `json:"subName"`
	Total        string `json:"total"`
}

//type RegionCurrentStates struct {
//	Region               string `json:"region"`
//	PhysicalRunningCount int    `json:"physicalRunningCount"`
//	PhysicalErrorCount   int    `json:"physicalErrorCount"`
//}

// OverviewLine
type BlockPoolOverViewLineSuccess struct {
	Code    int          `json:"code"`
	Message string       `json:"message"`
	Data    OverViewLine `json:"data"`
}

type BlockPoolOverViewLine struct {
	Region string `json:"region"`
	Az     string `json:"az"`
	Lab    string `json:"lab"`
	//Alert  AlertLevels `json:"alert"`
	Echarts []EchartType1 `json:"echarts"`
}

type EchartType1 struct {
	Info   Info        `json:"info"`
	Values []ValueType `json:"values"`
}

type Info struct {
	Region       string `json:"region"`
	Az           string `json:"az"`
	Lab          string `json:"lab"`
	Name         string `json:"name"`
	SubName      string `json:"subName"`
	StorageType  string `json:"storageType"`
	ResourcePool string `json:"resourcePool"`
	Total        string `json:"total"`
	TopK         int    `json:"topk"`
	Start        string `json:"start"`
	End          string `json:"end"`
}

// other
type Result struct {
	Code    int         `json:"code"`
	Message string      `json:"messgae"`
	Data    interface{} `json:"data"`
}

type BListQuery struct {
	PageNo   string `json:"pageNo"`
	PageSize string `json:"pageSize"`
	Id       string `json:"id"`
}

type MonitorHosts struct {
	PageStruct
	DataList []MonitorHost `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type MonitorHost struct {
	Id               string      `json:"id"`
	Name             string      `json:"name"`
	AssignmentStatus string      `json:"assignmentStatus"`
	ResourcePoolType string      `json:"resourcePoolType"`
	ResourcePool     string      `json:"resourcePool"`
	Region           string      `json:"region"`
	Az               string      `json:"az"`
	SN               string      `json:"sn"`
	Ip               string      `json:"ip"`
	State            string      `json:"state"`
	CpuUesd          interface{} `json:"cpuUesd"`
	MemUsed          interface{} `json:"memUsed"`
	AlertNumber      int         `json:"alertNumber"`
	Lable            string      `json:"lable"`
}

type DgraphCount struct {
	Host []HostCount `json:"host"`
}

type HostCount struct {
	Count          int    `json:"count"`
	Label          string `json:"label"`
	Ip             string `json:"ip"`
	HostName       string `json:"hostname"`
	HostRegionName string `json:"hostRegionName"`
	HostLabName    string `json:"hostLabName"`
	HostAzName     string `json:"hostAzName"`
	Sn             string `json:"sn"`
	RunStatus      string `json:"runstatus"`
	Os             string `json:"system"`
	ServiceType    string `json:"serviceType"`
}

type ChartValueItem struct {
	Value interface{} `json:"value"`
	Name  interface{} `json:"name"`
	Unit  string      `json:"unit"`
	//storage:存储的、percent:百分比的、number:数值的
	UnitType string `json:"unitType"`
}

type ChartData struct {
	Info   ChartInfoType    `json:"info"`
	Values []ChartValueItem `json:"values"`
}

type OverviewParameter struct {
	AzCode      string `json:"az"`
	RegionCode  string `json:"region"`
	StorageType string `json:"diskType"`
	PoolName    string `json:"pool"`
}

type OverviewLineChartsParameter struct {
	OverviewParameter
	ChartNames []string `json:"name"`
	StartTime  int64    `json:"start"`
	EndTime    int64    `json:"end"`
}

type OverviewLineChartsResponse struct {
	Code    int                    `json:"code"`
	Message string                 `json:"message"`
	Data    map[string][]ChartData `json:"data"`
}

type ChartInfoType struct {
	Name  string      `json:"name"`
	Value interface{} `json:"value"`
	Unit  string      `json:"unit"`
	//storage:存储的、percent:百分比的、number:数值的
	UnitType string `json:"unitType"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/dbmsservice/dbmsmodel.go
```golang
package dbmsservice

type DBResourcePoolListResult struct {
	Code    int                    `json:"code"`
	Message string                 `json:"messgae"`
	Data    DBResourcePoolListData `json:"data"`
}

type DBResourcePoolListData struct {
	Total uint             `json:"total"`
	Data  []DBResourcePool `json:"data"`
}

type DBResourcePool struct {
	ID               string       `json:"id"`            // 资源池ID
	DBType           string       `json:"dbType"`        // 数据库类型 mysql/redis
	Name             string       `json:"name"`          // 资源池名称
	Region           string       `json:"region"`        // 所属区域
	RegionCode       string       `json:"regionCode"`    // 所属区域Code
	ServerCount      uint         `json:"serverCount"`   // 服务器数量
	Servers          []Server     `json:"servers"`       // 该资源池包含的服务器
	InstanceCount    uint         `json:"instanceCount"` // 实例数量
	Instances        []DBInstance `json:"instances"`     // 该资源池下包含的实例
	CreateTime       int64        `json:"createTime"`    // 创建时间
	Performance      Performance  `json:"performance"`
	ResourcePoolType string       `json:"resourcePoolType"` //数据库类型
}

type Server struct {
	ID               int         `json:"id"`              // 服务器Id
	Ip               string      `json:"ip"`              // 服务器ip
	Name             string      `json:"name"`            // 服务器名称
	RunState         string      `json:"runState"`        // 运行状态
	AllocationState  int         `json:"allocationState"` // 分配状态
	Region           string      `json:"region"`          // 所属区域
	RegionCode       string      `json:"regionCode"`
	Az               string      `json:"az"` // 所属可用区
	AzCode           string      `json:"azCode"`
	LabName          string      `json:"labName"` // 所属机房
	LabCode          string      `json:"labCode"`
	RackName         string      `json:"rackName"`         // 所属机架位
	Unit             uint        `json:"unit"`             // 所占U位
	ResourcePoolID   string      `json:"resourcePoolId"`   // 所属资源池ID
	ResourcePoolName string      `json:"resourcePoolName"` // 所属资源池名称
	Sn               string      `json:"sn"`               // SN
	CreateTime       int64       `json:"createTime"`
	Performance      Performance `json:"performance"`
}

type DBInstance struct {
	ID               string `json:"id"`               // 数据库实例
	Name             string `json:"name"`             // 数据库实例名称
	DBType           int    `json:"dbType"`           // 数据库类型 mysql/redis
	Status           string `json:"status"`           // 状态
	TenantId         string `json:"tenantId"`         // 所属租户ID
	TenantName       string `json:"tenantName"`       // 所属租户名称
	IP               string `json:"ip"`               // 实例IP
	Port             uint   `json:"port"`             // 实例端口
	InstanceType     int    `json:"instanceType"`     // 实例类型
	InstanceVersion  string `json:"instanceVersion"`  // 实例版本（数据库版本）
	Memory           uint   `json:"memory"`           // 注册内存容量
	Disk             uint   `json:"disk"`             // 注册存储容量
	ServiceBeginTime string `json:"serviceBeginTime"` // 实例创建时间
	ServiceEndTime   string `json:"serviceEndTime"`   // 实例过期时间
}

type Performance struct {
	CPUTotal          int     `json:"cpuTotal"`          // cpu总量
	CPUUsed           int     `json:"cpuUsed"`           // cpu使用量
	CPUUnused         int     `json:"cpuUnused"`         // cpu剩余量
	CPUUsedPercent    float64 `json:"cpuUsedPercent"`    // cpu使用率
	MemoryTotal       int     `json:"memoryTotal"`       // 内存总量
	MemoryUsed        int     `json:"memoryUsed"`        // 内存使用量
	MemoryUnused      int     `json:"memoryUnused"`      // 内存剩余量
	MemoryUsedPercent float64 `json:"memoryUsedPercent"` // 内存使用率
	DiskTotal         int     `json:"diskTotal"`         // 磁盘总量
	DiskUsed          int     `json:"diskUsed"`          // 磁盘使用量
	DiskUnused        int     `json:"diskUnused"`        // 磁盘剩余量
	DiskUsedPercent   float64 `json:"diskUsedPercent"`   // 磁盘使用率
	//InstanceTotal       uint    `json:"instanceTotal"`     // 最大可创建实例数量
	//InstanceUnused      int    `json:"instanceUnused"`    // 还可以创建的实例数量（计算推荐）
	//InstanceUsed        uint    `json:"instanceUsed"`      // 已创建的实例数量
	InstanceTotal       int     `json:"instanceTotal"`  // 最大可创建实例数量
	InstanceUnused      int     `json:"instanceUnused"` // 还可以创建的实例数量（计算推荐）
	InstanceUsed        int     `json:"instanceUsed"`   // 已创建的实例数量
	InstanceUsedPercent float64 `json:"instanceUsedPercent"`
	// 已创建的实例数量在DBResourcePool
}

type DBResourcePoolResult struct {
	Code    int            `json:"code"`
	Message string         `json:"messgae"`
	Data    DBResourcePool `json:"data"`
}

//
type DBInstanceListResult struct {
	Code    int              `json:"code"`
	Message string           `json:"message"`
	Data    InstanceListData `json:"data"`
}

type InstanceListData struct {
	Total int    `json:"total"`
	Data  []Data `json:"data"`
}

type Data struct {
	ID               string `json:"id"`
	Name             string `json:"name"`
	DbType           string `json:"dbType"`
	Status           int    `json:"status"`
	TenantID         string `json:"tenantId"`
	TenantName       string `json:"tenantName"`
	IP               string `json:"ip"`
	Port             int    `json:"port"`
	InstanceType     int    `json:"instanceType"`
	InstanceVersion  string `json:"instanceVersion"`
	Memory           int    `json:"memory"`
	Disk             int    `json:"disk"`
	ServiceBeginTime int64  `json:"serviceBeginTime"`
	ServiceEndTime   int    `json:"serviceEndTime"`
	AzCode           string `json:"azCode"`
	AzName           string `json:"azName"`
	RegionCode       string `json:"regionCode"`
	RegionName       string `json:"regionName"`
}

type ServerListData struct {
	Total uint     `json:"total"`
	Data  []Server `json:"data"`
}

type DBServerListResult struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    ServerListData `json:"data"`
}

//获取mysql列表参数
type MysqlRequestParam struct {
	PageNo              int      `json:"pageNo"`
	PageSize            int      `json:"pageSize"`
	Region              string   `json:"region"`
	SearchKey           string   `json:"searchKey"`
	SearchValue         string   `json:"searchValue"`
	OrderCode           string   `json:"orderCode"`
	OrderType           string   `json:"orderType"`
	AzCodeList          []string `json:"azCodeList"`
	TenantIDList        []string `json:"tenantIDList"`
	TenantNameList      []string `json:"tenantNameList"`
	InstanceTypeList    []string `json:"instanceTypeList"`
	BillTypeList        []string `json:"billType"`
	StatusList          []string `json:"statusList"`
	InstanceVersionList []string `json:"instanceVersionList"`
	PoolName            []string `json:"poolName"`
}


type MysqlListResult struct {
	Code    int                    `json:"code"`
	Message string                 `json:"messgae"`
	Data    MysqlListData `json:"data"`
}

type MysqlListData struct {
	TotalCount int         `json:"totalCount"`
	PageNo     int         `json:"pageNo"`
	PageSize   int         `json:"pageSize"`
	DataList   []MysqlList `json:"dataList"`
}

type MysqlList struct {
	ID               string `json:"id" example:"ID"`                     // 数据库实例
	Name             string `json:"name" example:"数据库实例名称"`              // 数据库实例名称
	DBType           string `json:"dbType" example:"数据库类型"`              // 数据库类型 mysql/redis
	Status           string `json:"status" example:"状态"`                 // 状态
	TenantId         string `json:"tenantId" example:"租户ID"`             // 所属租户ID
	TenantName       string `json:"tenantName" example:"租户名称"`           // 所属租户名称
	IP               string `json:"ip" example:"实例IP"`                   // 实例IP
	Port             uint   `json:"port" example:"3306"`                 // 实例端口
	InstanceType     string `json:"instanceType" example:"实例类型:高可用|单机版"` // 实例类型
	InstanceVersion  string `json:"instanceVersion" example:"数据库版本"`     // 实例版本（数据库版本）
	Memory           uint   `json:"memory" example:"2"`                  // 注册内存容量
	Disk             uint   `json:"disk" example:"30"`                   // 注册存储容量
	ServiceBeginTime string `json:"serviceBeginTime" example:"实例创建时间"`   // 实例创建时间
	ServiceEndTime   string `json:"serviceEndTime" example:"实例过期时间"`     // 实例过期时间
	AzCode           string `json:"azCode"`
	AzName           string `json:"azName" example:"所属可用区"` // 所属可用区
	RegionCode       string `json:"regionCode"`
	RegionName       string `json:"regionName" example:"所属区域"` // 所属区域
	SlaveAzName      string `json:"slaveAzName"`
	SlaveAzCode      string `json:"slaveAzCode"`
	BillType         string `json:"billType" example:"计费类型:包年包月"`                           // 计费方式
	AzType           string `json:"azType" example:"可用区类型:单可用区|高可用区"`                       // 可用区类型
	ResourcePool     string `json:"resourcePool" gorm:"resource_pool" example:"所属资源池"`      // 所属资源池
	ResourcePoolId   string `json:"resourcePoolId" gorm:"resource_pool_id" example:"所属资源池"` // 所属资源池id
	Op               string `json:"op" example:"操作"`                                        // 操作
}



//获取mRedis列表参数
type RedisRequestParam struct {
	PageNo              int      `json:"pageNo"`
	PageSize            int      `json:"pageSize"`
	Region              string   `json:"region"`
	SearchKey           string   `json:"searchKey"`
	SearchValue         string   `json:"searchValue"`
	OrderCode           string   `json:"orderCode"`
	OrderType           string   `json:"orderType"`
	AzCodeList          []string `json:"azCodeList"`
	TenantIDList        []string `json:"tenantIDList"`
	TenantNameList      []string `json:"tenantNameList"`
	InstanceTypeList    []string `json:"instanceTypeList"`
	BillTypeList        []string `json:"billType"`
	StatusList          []string `json:"statusList"`
	InstanceVersionList []string `json:"instanceVersionList"`
	PoolName            []string `json:"poolName"`
}



type RedisListResult struct {
	Message string `json:"message"`
	Code int `json:"code"`
	Data RedisListData `json:"data"`
}

type RedisListData struct {
	TotalCount int `json:"totalCount"`
	PageNo int `json:"pageNo"`
	PageSize int `json:"pageSize"`
	InstanceList []InstanceList `json:"instanceList"`
}
type InstanceList struct {
	ID               string `json:"id" example:"ID"`                     // 数据库实例
	Name             string `json:"name" example:"数据库实例名称"`              // 数据库实例名称
	DBType           string `json:"dbType" example:"数据库类型"`              // 数据库类型 mysql/redis
	Status           string `json:"status" example:"状态"`                 // 状态
	TenantId         string `json:"tenantId" example:"租户ID"`             // 所属租户ID
	TenantName       string `json:"tenantName" example:"租户名称"`           // 所属租户名称
	IP               string `json:"ip" example:"实例IP"`                   // 实例IP
	Port             uint   `json:"port" example:"3306"`                 // 实例端口
	InstanceType     string `json:"instanceType" example:"实例类型:高可用|单机版"` // 实例类型
	InstanceVersion  string `json:"instanceVersion" example:"数据库版本"`     // 实例版本（数据库版本）
	Memory           uint   `json:"memory" example:"2"`                  // 注册内存容量
	Disk             uint   `json:"disk" example:"30"`                   // 注册存储容量
	ServiceBeginTime string `json:"serviceBeginTime" example:"实例创建时间"`   // 实例创建时间
	ServiceEndTime   string `json:"serviceEndTime" example:"实例过期时间"`     // 实例过期时间
	AzCode           string `json:"azCode"`
	AzName           string `json:"azName" example:"所属可用区"` // 所属可用区
	RegionCode       string `json:"regionCode"`
	RegionName       string `json:"regionName" example:"所属区域"` // 所属区域
	SlaveAzName      string `json:"slaveAzName"`
	SlaveAzCode      string `json:"slaveAzCode"`
	BillType         string `json:"billType" example:"计费类型:包年包月"`                           // 计费方式
	AzType           string `json:"azType" example:"可用区类型:单可用区|高可用区"`                       // 可用区类型
	ResourcePool     string `json:"resourcePool" gorm:"resource_pool" example:"所属资源池"`      // 所属资源池
	ResourcePoolId   string `json:"resourcePoolId" gorm:"resource_pool_id" example:"所属资源池"` // 所属资源池id
	Op               string `json:"op" example:"操作"`                                        // 操作
}


//
//type RedisListResult struct {
//	Code    int                    `json:"code"`
//	Message string                 `json:"messgae"`
//	Data    RedisListData 		   `json:"data"`
//}
//
//type RedisListData struct {
//	TotalCount int         `json:"totalCount"`
//	PageNo     int         `json:"pageNo"`
//	PageSize   int         `json:"pageSize"`
//	DataList   []RedisList `json:"dataList"`
//}
//
//type RedisList struct {
//	ID               string `json:"id" example:"ID"`                     // 数据库实例
//	Name             string `json:"name" example:"数据库实例名称"`              // 数据库实例名称
//	DBType           string `json:"dbType" example:"数据库类型"`              // 数据库类型 mysql/redis
//	Status           string `json:"status" example:"状态"`                 // 状态
//	TenantId         string `json:"tenantId" example:"租户ID"`             // 所属租户ID
//	TenantName       string `json:"tenantName" example:"租户名称"`           // 所属租户名称
//	IP               string `json:"ip" example:"实例IP"`                   // 实例IP
//	Port             uint   `json:"port" example:"3306"`                 // 实例端口
//	InstanceType     string `json:"instanceType" example:"实例类型:高可用|单机版"` // 实例类型
//	InstanceVersion  string `json:"instanceVersion" example:"数据库版本"`     // 实例版本（数据库版本）
//	Memory           uint   `json:"memory" example:"2"`                  // 注册内存容量
//	Disk             uint   `json:"disk" example:"30"`                   // 注册存储容量
//	ServiceBeginTime string `json:"serviceBeginTime" example:"实例创建时间"`   // 实例创建时间
//	ServiceEndTime   string `json:"serviceEndTime" example:"实例过期时间"`     // 实例过期时间
//	AzCode           string `json:"azCode"`
//	AzName           string `json:"azName" example:"所属可用区"` // 所属可用区
//	RegionCode       string `json:"regionCode"`
//	RegionName       string `json:"regionName" example:"所属区域"` // 所属区域
//	SlaveAzName      string `json:"slaveAzName"`
//	SlaveAzCode      string `json:"slaveAzCode"`
//	BillType         string `json:"billType" example:"计费类型:包年包月"`                           // 计费方式
//	AzType           string `json:"azType" example:"可用区类型:单可用区|高可用区"`                       // 可用区类型
//	ResourcePool     string `json:"resourcePool" gorm:"resource_pool" example:"所属资源池"`      // 所属资源池
//	ResourcePoolId   string `json:"resourcePoolId" gorm:"resource_pool_id" example:"所属资源池"` // 所属资源池id
//	Op               string `json:"op" example:"操作"`                                        // 操作
//}
//


```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/servicemonitor/servicemodel.go
```golang
package servicemodel

import (
	alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	"time"
)

type ServiceEntity struct {
	Name           string `json:"name"`
	Cmdline        string `json:"cmdline"`
	RunState       string `json:"runState"`
	ProcessNumber  string `json:"processNumber"`
	PyhsicalHost   string `json:"pyhsicalHost"`
	Region         string `json:"region"`
	Az             string `json:"az"`
	CpuUtilization string `json:"cpuUtilization"`
	MemUtilization string `json:"memUtilization"`
	DiskIO         string `json:"diskIO"`
	AlertNumber    int    `json:"alertNumber"`
	Label          string `json:"label"`
	VmId           string `json:"vmId"`
	BuiltIn        int8   `json:"builtIn" description:"是否内置"`
}

type ServiceSuccess struct {
	Code    int           `json:"code"`
	Message string        `json:"message"`
	Data    ServiceResult `json:"data"`
}
type ServiceResult struct {
	PageStruct
	DataList []ServiceEntity `json:"dataList" description:"paging data"`
}
type ListQuery struct {
	PageNo    int      `json:"pageNo"`
	PageSize  int      `json:"pageSize"`
	Region    string   `json:"region"`
	Az        []string `json:"az"`
	Name      string   `json:"name"`
	OrderCode string   `json:"orderCode"`
	OrderType string   `json:"orderType"`
	//ResourcePool []string `json:"resourcePool"`
	RunState []string `json:"runState"`
	//MonitorStatus []string `json:"monitorStatus"`
	SearchKey   string `json:"searchKey"`
	SearchValue string `json:"searchValue"`
}

type ProcessListQuery struct {
	PageNo    int      `json:"pageNo"`
	PageSize  int      `json:"pageSize"`
	Name      string   `json:"name"`
	Ip        string   `json:"ip"`
	Cmdline   string   `json:"cmdline"`
	VmId      string   `json:"vmId"`
	BuiltIn   int8     `json:"builtIn" description:"是否内置"`
	OrderCode string   `json:"orderCode"`
	OrderType string   `json:"orderType"`
	RunState  []string `json:"runState"`
}
type ProcessEntity struct {
	Name            string  `json:"name"`
	Pid             int     `json:"pid"`
	PPid            int     `json:"ppid"`
	CpuUtilization  float64 `json:"cpuUtilization"`
	MemUtilization  float64 `json:"memUtilization"`
	DiskUtilization float64 `json:"diskUtilization"`
	RunStatus       string  `json:"runStatus"`
	Cmdline         string  `json:"cmdline"`
}

type ProcessSuccess struct {
	Code    int           `json:"code"`
	Message string        `json:"message"`
	Data    ProcessResult `json:"data"`
}
type ProcessResult struct {
	PageStruct
	DataList []ProcessEntity `json:"dataList" description:"paging data"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

//overview
type OverViewSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverView struct {
	Region string      `json:"region"`
	Alerts []alertmanagermodel.OverviewAlert `json:"alerts"`
	State  StateData   `json:"state"`
	//AllTopK       []prometheusmanager.RateTopResult
}

type AlertData struct {
	Level  string `json:"level"`
	Unit   string `json:"unit"`
	Number int    `json:"number"`
	Name   string `json:"name"`
	Kind   string `json:"kind"`
	Type   string `json:"type"`
}
type StateData struct {
	Info  Info          `json:"info"`
	Vlues []StateEntity `json:"values"`
}
type Info struct {
	Code   string `json:"code"`
	Unit   string `json:"unit"`
	Number int    `json:"number"`
	Name   string `json:"name"`
	Kind   string `json:"kind"`
	Type   string `json:"type"`
}
type StateEntity struct {
	Code  string `json:"code"`
	Unit  string `json:"unit"`
	Value int    `json:"value"`
	Name  string `json:"name"`
	Kind  string `json:"kind"`
	Type  string `json:"type"`
}
type BusinessserviceinstanceResult struct {
	PageStruct
	DataList []Businessserviceinstance `json:"dataList"`
}
type Businessserviceinstance struct {
	Id               string `json:"id" description:"服务实例ID"`
	AzCode           int    `json:"azCode" description:"可用区code"`          //az id
	AzName           int    `json:"azName" description:"可用区名称"`            //az id
	RegionCode       int    `json:"regionCode" description:"区域code"`       //region id
	RegionName       int    `json:"regionName" description:"区域名称"`         //region id
	Name             string `json:"name" description:"服务实例名称"`             // 服务实例名称
	Status           string `json:"status" description:"服务实例状态"`           // 服务实例状态
	ProcessCount     int    `json:"processCount" description:"进程数"`        // 进程数
	HostName         string `json:"hostName" description:"所属主机"`           // 所属主机
	HostSn           string `json:"hostSn" description:"所属主机sn"`           //所属主机id
	InstanceHostType string `json:"instanceHostType" description:"所属主机类型"` // 所属主机类型
	AlertCount       int    `json:"alertCount" description:"告警数量"`         // 告警数量
	AlertStrategy    string `json:"alertStrategy" description:"告警策略"`      // 告警策略
	MaintenanceTags  string `json:"maintenanceTags" description:"运维标签"`    // 运维标签
}

//type PodMetrics struct {
//	Kind       string `json:"kind"`
//	APIVersion string `json:"apiVersion"`
//	Metadata   struct {
//		SelfLink string `json:"selfLink"`
//	} `json:"Metadata"`
//	Items []struct {
//		Metadata struct {
//			Name              string    `json:"name"`
//			Namespace         string    `json:"namespace"`
//			SelfLink          string    `json:"selfLink"`
//			CreationTimestamp time.Time `json:"creationTimestamp"`
//		} `json:"Metadata"`
//		Timestamp  time.Time `json:"timestamp"`
//		Window     string    `json:"window"`
//		Containers []struct {
//			Name  string `json:"name"`
//			Usage struct {
//				cpu    string `json:"cpu"`
//				Memory string `json:"memory"`
//			} `json:"usage"`
//		} `json:"containers"`
//	} `json:"items"`
//}

type PodMetrics struct {
	Kind       string `json:"kind"`
	APIVersion string `json:"apiVersion"`
	Metadata   struct {
		SelfLink string `json:"selfLink"`
	} `json:"Metadata"`
	Timestamp  time.Time `json:"timestamp"`
	Window     string    `json:"window"`
	Containers []struct {
		Name  string `json:"name"`
		Usage struct {
			Cpu    string `json:"cpu"`
			Memory string `json:"memory"`
		} `json:"usage"`
	} `json:"containers"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/k3sEs/k3s.go
```golang
package k3ses

type BucketAggregationChargeInfo struct {
	BucketCreatedTime      string `json:"bucketCreatedTime"`
	BucketDeletedFlag      bool   `json:"bucketDeletedFlag"`
	BucketLastModifiedTime string `json:"bucketLastModifiedTime"`
	Date                   string `json:"date"`
	DeleteSize             int    `json:"deleteSize"`
	ID                     int    `json:"id"`
	Name                   string `json:"name"`
	PutSize                int    `json:"putSize"`
	Region                 string `json:"region"`
	StorageClass           string `json:"storageClass"`
	Total                  int    `json:"total"`
	UserID                 string `json:"userId"`
}

type BucketObjectCountInfo struct {
	BucketCreatedTime      string `json:"bucketCreatedTime"`
	BucketDeletedFlag      bool   `json:"bucketDeletedFlag"`
	BucketLastModifiedTime string `json:"bucketLastModifiedTime"`
	Date                   string `json:"date"`
	DeleteCount            int64  `json:"deleteCount"`
	ID                     int64  `json:"id"`
	Name                   string `json:"name"`
	PutCount               int64  `json:"putCount"`
	Region                 string `json:"region"`
	StorageClass           string `json:"storageClass"`
	TotalCount             int64  `json:"totalCount"`
	UserID                 string `json:"userId"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/load/response.go
```golang
package load

import (
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

//概览页 返回值
type LoadOverviewResponse struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverView struct {
	Region  string             `json:"region"`
	Az      string             `json:"az"`
	Alerts  []models.AlertType `json:"alerts"`
	Echarts []Chart            `json:"echarts"`
}

//概览页top 返回值
type LoadOverviewTopResponse struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    []OverViewLine `json:"data"`
}

type OverViewLine struct {
	Region  string       `json:"region"`
	Az      string       `json:"az"`
	Lab     string       `json:"lab"`
	Name    string       `json:"name"`
	Unit    string       `json:"unit"`
	Echarts []EchartType `json:"echarts"`
}

type EchartType struct {
	Info   services.InfoType `json:"info"`
	Values []ValueType       `json:"values"`
}

type MetricLineInfo struct {
	Tyte     string `json:"_type"`
	Index    int    `json:"_index"`
	Name     string `json:"name" description:"指标名称"`
	Number   int    `json:"number" description:"总数之类的统计值"`
	Start    string `json:"start" description:"开始时间"`
	End      string `json:"end" description:"结束时间"`
	Unit     string `json:"unit" description:"指标的单位"`
	UnitType string `json:"unitType" description:"指标的单位类型"`
}

type Chart struct {
	Info   OverInfo    `json:"info"`
	Values []ValueType `json:"values"`
}

type ValueType struct {
	Value      interface{} `json:"value"`
	Name       string      `json:"name"`
	Timestamep string      `json:"timestamep"`
	SubName    string      `json:"subName"`
	VmId       string      `json:"vmId"`
}

type OverInfo struct {
	Name     string `json:"name"`
	Number   int    `json:"number"`
	Type     string `json:"type"` //p0/p1/p2/p3
	Kind     string `json:"kind"` //[错误,紧急error/警告，重要warn/信息、提醒、次要info/成功、使用中success/未使用、未开通disabled]
	Unit     string `json:"unit"`
	Label    string `json:"label"`
	UnitType string `json:"unitType"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}
type MonitorPage struct {
	PageStruct
	DataList []MonitorInfo `json:"dataList" description:"paging data"`
	Item     Item          `json:"item" description:"筛选列表"`
}

type Item struct {
	PoolList        []string `json:"poolList" description:"所属资源池"`
	TenantIdList    []string `json:"tenantIdList" description:"所属租户id"`
	TenantNameList  []string `json:"tenantNameList" description:"所属租户名称"`
	ProjectNameList []string `json:"projectNameList" description:"所属项目名称 默认项目"`
}
type MonitorInfo struct {
	ResourcePoolType string `json:"resourcePoolType"` //资源池类型
	IpVersion        string `json:"ipVersion"`        //IP版本 4 6
	InstanceName     string `json:"instanceName" description:"实例名称"`
	InstanceId       string `json:"instanceId" description:"实例id"`
	State            string `json:"state" description:"状态: 开启 已停止 [active] [stop]"`
	InstanceType     string `json:"instanceType" description:"实例类型: 经典型 应用型 ['default', 'application']"`
	LineType         string `json:"lineType" description:"线路类型: [bgp,private]"`
	NetType          string `json:"netType" description:"网络类型: 公网 私网 [public,private]"`
	VPCInstanceName  string `json:"vpcInstanceName" description:"VPC实例名称"`
	Eip              string `json:"eip" description:"弹性IP"`
	//缺少后端服务
	Region           string `json:"region" description:"所属区域编码"`
	RegionName       string `json:"regionName" description:"所属区域名称"`
	ResourcePoolName string `json:"resourcePoolName" description:"所属资源池"`
	TenantId         string `json:"tenantId" description:"所属租户id"`
	TenantName       string `json:"tenantName" description:"所属租户"`
	ProjectName      string `json:"projectName" description:"所属项目名称: 默认项目"`
	BPSIn            int64  `json:"bpsIn" description:"入网宽带 bps"`
	BPSOut           int64  `json:"bpsOut" description:"出网宽带 bps"`
	PPSIn            int64  `json:"ppsIn" description:"每秒流入包数"`
	PPSOut           int64  `json:"ppsOut" description:"每秒流出包数"`
	CPS              int64  `json:"cps" description:"每秒新建连接数"`
	ConcurrentConn   int64  `json:"concurrentConn" description:"并发连接数"`
	CreateTime       int    `json:"createTime" description:"创建时间  秒级时间戳"`
	ListenerNum      int    `json:"listenerNum"` //监听器数量
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/load/parameter.go
```golang
package load

import "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"

//overview
type OverviewQuery struct {
	Region string `json:"region"`
	Az     string `json:"az"`
}

//overviewTop
type OverviewTopQuery struct {
	Region   string   `json:"region"`
	Az       string   `json:"az"`
	Name     []string `json:"name"`
	TopK     string   `jons:"topk"`
	Start    float64  `json:"start"`
	End      float64  `json:"end"`
	FlowType int      `json:"flowType"`
}

//list
type EipListQuery struct {
	Region      string   `json:"region"`
	Az          []string `json:"az"`
	PageNo      int      `json:"pageNo"`
	PageSize    int      `json:"pageSize"`
	SearchKey   string   `json:"searchKey"`
	SearchValue string   `json:"searchValue"`
	Pool        string   `json:"pool"`
	OrderCode   string   `json:"orderCode"`
	OrderType   string   `json:"orderType"`
	Ip          string   `json:"ip"`
	State       []string `json:"state"`
	NetSegment  []string `json:"netSegment"`
	LineType    []string `json:"lineType"`
	XgwCluster  []string `json:"xgwCluster"`
	BoundState  []int    `json:"boundState"`
}

//metric
type EipMetricLineQuery struct {
	Ip    string   `json:"ip"`
	Id    string   `json:"id"`
	Name  []string `json:"name"`
	Start float64  `json:"start"`
	End   float64  `json:"end"`
	Step  float64  `json:"step"`
}

//eipPool
type EipPoolOverviewQuery struct {
	Region string `json:"region"`
	Az     string `json:"az"`
}

//overviewLine
type EipPoolOverviewLineQuery struct {
	Region string   `json:"region"`
	Az     string   `json:"az"`
	Name   []string `json:"name"`
	Start  int64    `json:"start"`
	End    int64    `json:"end"`
	Step   int64    `json:"step"`
}

//list
type EipPoolListQuery struct {
	Region      string   `json:"region"`
	Az          []string `json:"az"`
	PageNo      int      `json:"pageNo"`
	PageSize    int      `json:"pageSize"`
	SearchKey   string   `json:"searchKey"`
	SearchValue string   `json:"searchValue"`
	Pool        string   `json:"pool"`
	OrderCode   string   `json:"orderCode"`
	OrderType   string   `json:"orderType"`
}

//metric
type EipPoolMetricLineQuery struct {
	NetSegment string   `json:"netSegment"`
	Name       []string `json:"name"`
	Start      int64    `json:"start"`
	End        int64    `json:"end"`
	Step       int      `json:"step"`
}

type ListQuery struct {
	PageNo   int    `json:"pageNo"`
	PageSize int    `json:"pageSize"`
	Region   string `json:"region"`

	ResourcePoolName string `json:"resourcePoolName"`
	State            string `json:"state" description:"状态： 开启 已停止 [active]"`
	InstanceType     string `json:"instanceType" description:"实例类型： 经典型 应用型 ['default', 'application']"`
	LineType         string `json:"lineType" description:"线路类型 [bgp,private]"`
	NetType          string `json:"netType" description:"网络类型  公网 私网 [public,private]"`

	PoolList        []string `json:"poolList" description:"所属资源池"`
	TenantIdList    []string `json:"tenantIdList" description:"所属租户id"`
	TenantNameList  []string `json:"tenantNameList" description:"所属租户名称"`
	ProjectNameList []string `json:"projectNameList" description:"所属项目名称 默认项目"`

	SearchKey   string `json:"searchKey"`
	SearchValue string `json:"searchValue"`
	OrderCode   string `json:"orderCode"`
	OrderType   string `json:"orderType"`
}

type LoadTopVm struct {
	ID     string      `json:"id"`
	EipId  string      `json:"eidId"`
	Name   string      `json:"name"`
	Value  interface{} `json:"value"`
	Status string      `json:"status"`
}

type LoadMetricQuery struct {
	Id    string  `json:"id"`
	Name  string  `json:"name"`
	Start float64 `json:"start"`
	End   float64 `json:"end"`
}

type LoadMetricRsp struct {
	Label       string     `json:"label"`
	Name        string     `json:"name"`
	Unit        string     `json:"unit"`
	UnitType    string     `json:"unitType"`
	Copywriting string     `json:"copywriting"`
	Echarts     []LineType `json:"echarts"`
}

type LineType struct {
	Info   InfoType             `json:"info"`
	Values []services.ValueType `json:"values"`
}

type InfoType struct {
	Name     string `json:"name"`
	Unit     string `json:"unit"`
	UnitType string `json:"unitType"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/object/object.go
```golang
package object

import (
	"encoding/json"

	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"k8s.io/klog/v2"
)

type HostUrlPost struct {
	PageNo   int    `json:"pageNo"`
	PageSize int    `json:"pageSize"`
	Region   string `json:"region"`
}
type CMDBResult struct {
	Code    int       `json:"code"`
	Message string    `json:"messgae"`
	Data    CmdbBucks `json:"data"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

type ListQuery struct {
	PageNo        int      `json:"pageNo"`
	PageSize      int      `json:"pageSize"`
	Region        string   `json:"region"`
	Az            string   `json:"az"`
	Lab           string   `json:"lab"`
	Name          string   `json:"name"`
	TenantId      string   `json:"tenantId"`
	InnerIp       string   `json:"innerIp"`
	OuterIp       string   `json:"outerIp"`
	Label         string   `json:"label"`
	State         string   `json:"state"`
	PhysicalHost  string   `json:"physical_host"`
	Pool          string   `json:"pool"`
	StorageType   []string `json:"storageType"`
	MonitorStatus []string `json:"monitorStatus"`
	SearchKey     string   `json:"searchKey"`
	SearchValue   string   `json:"searchValue"`
}

type BucketQuery struct {
	Region      string   `json:"region"`
	Name        []string `json:"name"`
	StorageType string   `json:"storageType"`
	Start       string   `json:"start"`
	End         string   `json:"end"`
	TopK        string   `json:"topk"`
}

type OverviewQuery struct {
	Region      string   `json:"region"`
	Az          string   `json:"az"`
	Name        []string `json:"name"`
	StorageType string   `json:"storageType"`
}

type CmdbBucks struct {
	PageStruct
	DataList []CmdbBucket `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type CmdbBucket struct {
	ID              string `json:"id"`
	Name            string `json:"name"`
	PoolId          int    `json:"resourcePoolId"`
	Pool            string `json:"resourcePoolName"`
	Region          string `json:"region"`
	RegionCode      string `json:"regionCode"`
	Az              string `json:"az"`
	TenantId        string `json:"tenantId"`
	TenantName      string `json:"tenantName"`
	CreateTime      int    `json:"createTime"`
	Size            int    `json:"size"`
	StorageType     string `json:"storageType"`
	InnerDomainName string `json:"innerDomainName"`
	OuterDomainName string `json:"outerDomainName"`
	Policy          string `json:"policy"`
	//BucketDomains         string `json:"bucketDomains"`
	CurrentSize           int   `json:"currentSize"`
	Last30DayDownload     int   `json:"last30DayDownload"`
	Last30DayAPICallTimes int   `json:"last30DayApiCallTimes"`
	ObjectCount           int64 `json:"objectCount"`
}

type MonitorBucketsSuccess struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    MonitorBuckets `json:"data"`
}
type MonitorBuckets struct {
	PageStruct
	DataList []MonitorBucket `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type MonitorBucket struct {
	ID               string  `json:"id"`
	Name             string  `json:"name"`
	ObjectPool       string  `json:"objectPool"`
	Region           string  `json:"region"`
	Az               string  `json:"az"`
	TenantId         string  `json:"tenantId"`
	TenantName       string  `json:"tenantName"`
	CreateTime       int     `json:"createTime"`
	StorageType      string  `json:"storageType"`
	CapacityTotal    int     `json:"capacityTotal"`
	InFlow           string  `json:"inFlow"`
	OutFlow          string  `json:"outFlow"`
	DownLoad         string  `json:"downLoad"`
	APIRequestNumber float64 `json:"apiRequestNumber"`
	RequestDelay     string  `json:"requestDelay"`
	MonitorStatus    string  `json:"monitorStatus"`
	AlertNumber      int     `json:"alertNumber"`
	TotalCount       int64   `json:"totalCount"`
	DeleteCount      int64   `json:"deleteCount"`
	PutCount         int64   `json:"putCount"`
}

// overview
type OverviewSuccess struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    OverviewBucket `json:"data"`
}

type OverviewBucket struct {
	Region      string                        `json:"region"`
	Az          string                        `json:"az"`
	StorageType string                        `json:"storageType"`
	Alert       []resourcepoolmodel.AlertType `json:"alert"`
	Echarts     []Chart                       `json:"echarts"`
}

type Chart struct {
	Info   OverInfo    `json:"info"`
	Values []ValueType `json:"values"`
}
type OverInfo struct {
	Prefix      string      `json:"prefix"`
	Region      string      `json:"region"`
	Az          string      `json:"az"`
	Number      string      `json:"number"`
	Label       string      `json:"label"`
	StorageType string      `json:"storageType"`
	Name        string      `json:"name"`
	SubName     string      `json:"subName"`
	Total       interface{} `json:"value"`
	Type        string      `json:"type"` //p0/p1/p2/p3
	Kind        string      `json:"kind"` //[错误,紧急error/警告，重要warn/信息、提醒、次要info/成功、使用中success/未使用、未开通disabled]
	Unit        string      `json:"unit"`
	UnitType    string      `json:"unitType"` // storage:存储的、percent:百分比的、number:数值的
}

type ChartBig struct {
	Info   OverInfoBig `json:"info"`
	Values []ValueType `json:"values"`
}

type OverInfoBig struct {
	Prefix      string `json:"prefix"`
	Region      string `json:"region"`
	Az          string `json:"az"`
	Number      string `json:"number"`
	Label       string `json:"label"`
	StorageType string `json:"storageType"`
	Name        string `json:"name"`
	SubName     string `json:"subName"`
	Total       int64  `json:"value"`
	Type        string `json:"type"` //p0/p1/p2/p3
	Kind        string `json:"kind"` //[错误,紧急error/警告，重要warn/信息、提醒、次要info/成功、使用中success/未使用、未开通disabled]
	Unit        string `json:"unit"`
	UnitType    string `json:"unitType"` // storage:存储的、percent:百分比的、number:数值的
}

type PrometheusStoreInfo struct {
	Status string `json:"status"`
	Data   struct {
		ResultType string `json:"resultType"`
		Result     []struct {
			Metric struct {
				Storageclass string `json:"storageclass"`
			} `json:"metric"`
			Value []interface{} `json:"value"`
		} `json:"result"`
	} `json:"data"`
}

type PrometheusWideInfo struct {
	Status string `json:"status"`
	Data   struct {
		ResultType string `json:"resultType"`
		Result     []struct {
			Metric struct {
				Cdn     string `json:"cdn"`
				Isinner string `json:"isinner"`
			} `json:"metric"`
			Value []interface{} `json:"value"`
		} `json:"result"`
	} `json:"data"`
}

type PrometheusSumInfo struct {
	Status string `json:"status"`
	Data   struct {
		ResultType string `json:"resultType"`
		Result     []struct {
			Metric struct {
			} `json:"metric"`
			Value []interface{} `json:"value"`
		} `json:"result"`
	} `json:"data"`
}

type PrometheusBucketIdInfo struct {
	Status string `json:"status"`
	Data   struct {
		ResultType string `json:"resultType"`
		Result     []struct {
			Metric struct {
				Bucketid   string `json:"bucketid"`
				BucketName string `json:"bucketname"`
			} `json:"metric"`
			Value []interface{} `json:"value"`
		} `json:"result"`
	} `json:"data"`
}

type MetricSuccess struct {
	Code    int              `json:"code"`
	Message string           `json:"message"`
	Data    []MetricLineInfo `json:"data"`
}

type MetricLineSuccess struct {
	Code    int              `json:"code"`
	Message string           `json:"message"`
	Data    []MetricLineType `json:"data"`
}

type MetricType struct {
	Id                 string `json:"id"`
	Capacity           string `json:"capacity"`
	CapacityDownload30 string `json:"capacityDownload30"`
	ApiNumber30        string `json:"apiNumber30"`
	TotalReceive       string `json:"totalReceive"`
	TotalTransmit      string `json:"totalTransmit"`
}

type MetricLineType struct {
	Id      string   `json:"id"`
	Name    string   `json:"name"`
	SubName string   `json:"subName"`
	Start   string   `json:"start"`
	End     string   `json:"end"`
	Echarts []Echart `json:"echarts"`
}

type Echart struct {
	Info   MetricLineInfo `json:"info"`
	Values []ValueType    `json:"values"`
}

type MetricLineInfo struct {
	Id      string `json:"id"`
	Label   string `json:"label"`
	Number  int    `json:"number"`
	Type    string `json:"type"`
	Kind    string `json:"kind"`
	SubName string `json:"subName"`
	Start   string `json:"start"`
	End     string `json:"end"`
	Unit    string `json:"unit"`
}

type OverviewTopSuccess struct {
	Code    int               `json:"code"`
	Message string            `json:"message"`
	Data    []OverviewTopType `json:"data"`
}

type OverviewTopType struct {
	Region      string      `json:"region"`
	Name        string      `json:"name"`
	StorageType string      `json:"storageType"`
	Echarts     []ChartType `json:"echarts"`
}

type ChartType struct {
	Info   OverInfo    `json:"info"`
	Values []ValueType `json:"values"`
}

type AlertLevels struct {
	P0 int `json:"p0"`
	P1 int `json:"p1"`
	P2 int `json:"p2"`
	P3 int `json:"p3"`
}

//type InfoType struct {
//	Name    string `json:"name"`
//	SubName string `json:"subName"`
//	Total   string `json:"total"`
//}

type TopInfoType struct {
	Name  string `json:"name"`
	TopK  int    `json:"topk"`
	Start string `json:"start"`
	End   string `json:"end"`
}

type ValueType struct {
	Value      float64 `json:"value"`
	Name       string  `json:"name"`
	BucketId   string  `json:"bucketId"`
	BucketName string  `json:"bucketName"`
	Timestamp  string  `json:"timestamp"`
	UnitType   string  `json:"unitType"` // storage:存储的、percent:百分比的、number:数值的
	SubName    string  `json:"subName"`
}

type QueryList struct {
	List  []string `json:"list"`
	Start string   `json:"start"`
	End   string   `json:"end"`
	Step  string   `json:"step"`
}

type MetricResult struct {
	End     string `json:"end"`
	ID      string `json:"id"`
	Kind    string `json:"kind"`
	Label   string `json:"label"`
	Number  int    `json:"number"`
	Start   string `json:"start"`
	SubName string `json:"subName"`
	Type    string `json:"type"`
	Unit    string `json:"unit"`
}
type ResponseObject struct {
	Code    int         `json:"code"`
	Message string      `json:"message"`
	Data    interface{} `json:"data"`
}

type TimeResult struct {
	TimeStamp interface{} `json:"timeStamp"`
	Result    interface{} `json:"result"`
}

type MetricBucketType struct {
	Echarts []resourcepoolmodel.EchartType `json:"echarts"`
	End     string                         `json:"end"`
	ID      string                         `json:"id"`
	Name    string                         `json:"name"`
	Start   string                         `json:"start"`
	SubName string                         `json:"subName"`
}

type MetricInfo struct {
	End      string `json:"end"`
	ID       string `json:"id"`
	Kind     string `json:"kind"`
	Label    string `json:"label"`
	Name     string `json:"name"`
	Number   int    `json:"number"`
	Value    int    `json:"value"`
	Start    string `json:"start"`
	SubName  string `json:"subName"`
	Type     string `json:"type"`
	Unit     string `json:"unit"`
	UnitType string `json:"unitType"`
}

type MetricValues struct {
	Name       interface{} `json:"name"`
	Timestamep json.Number `json:"timestamep"`
	Value      json.Number `json:"value"`
}

type MetricEcharts struct {
	Info   MetricInfo     `json:"info"`
	Values []MetricValues `json:"values"`
}

type MetricT struct {
	HealthyState string `json:"healthyState"`
	ID           string `json:"id"`
	Total        string `json:"total"`
	UsePercent   string `json:"usePercent"`
	UseState     string `json:"useState"`
	Used         string `json:"used"`
	Name         string `json:"name"`
	Unit         string `json:"unit"`
	Value        string `json:"value"`
	UnitType     string `json:"unitType"`
}
type PrometheusQueryResp struct {
	Metric map[string]interface{} `json:"metric"`
	Values [][2]interface{}       `json:"values"`
}

type CapacitySuccessMap struct {
	BucketId   string `json:"bucketId"`
	BucketName string `json:"bucketName"`
	Value      string `json:"value"`
}

func (p *PrometheusQueryResp) UnmarshalJSON(bytes []byte) error {
	klog.Info(string(bytes))
	valMap := make(map[string]interface{})
	err := json.Unmarshal(bytes, &valMap)
	if err != nil {
		return err
	}
	p.Metric = valMap["metric"].(map[string]interface{})
	v := valMap["values"].([]interface{})
	for _, arr := range v {
		p.Values = append(p.Values, [2]interface{}{arr.([]interface{})[0], arr.([]interface{})[1]})
	}
	return nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/mysql/mysql.go
```golang
package mysql

import (
	vmmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cloudproduct"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

type ListQuery struct {
	PageNo   int    `json:"pageNo"`
	PageSize int    `json:"pageSize"`
	Region   string `json:"region"`

	Id         string `json:"id"`
	Name       string `json:"name"`
	Ip         string `json:"ip"`
	TenantId   string `json:"tenantId"`
	TenantName string `json:"tenantName"`

	Status         []string `json:"status"`
	TenantIdList   []string `json:"tenantIdList"`
	TenantNameList []string `json:"tenantNameList"`
	PoolName       []string `json:"poolName"`
	Az             []string `json:"az"`

	State        string   `json:"state"`
	PhysicalHost string   `json:"physical_host"`
	PoolId       string   `json:"poolId"`
	Pool         string   `json:"pool"`
	StorageType  []string `json:"storageType"`
	UseStatus    []string `json:"useStatus"`

	SearchKey   string `json:"searchKey"`
	SearchValue string `json:"searchValue"`
	OrderCode   string `json:"orderCode"`
	OrderType   string `json:"orderType"`
}

type OverviewQuery struct {
	PageNo        int      `json:"pageNo"`
	PageSize      int      `json:"pageSize"`
	Region        string   `json:"region"`
	Az            string   `json:"az"`
	Lab           string   `json:"lab"`
	Name          string   `json:"name"`
	TenantId      string   `json:"tenantId"`
	InnerIp       string   `json:"innerIp"`
	OuterIp       string   `json:"outerIp"`
	Label         string   `json:"label"`
	State         string   `json:"state"`
	PhysicalHost  string   `json:"physical_host"`
	Pool          string   `json:"pool"`
	StorageType   []string `json:"storageType"`
	UseStatus     []string `json:"useStatus"`
	RunningStatus []string `json:"runningStatus"`
	SearchKey     string   `json:"searchKey"`
	SearchValue   string   `json:"searchValue"`
	OrderCode     string   `json:"orderCode"`
	OrderType     string   `json:"orderType"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

type MonitorMysqlPage struct {
	PageStruct
	DataList []MonitorMysql `json:"dataList" description:"paging data"`
}

type MonitorMysql struct {
	ID                string  `json:"id"`
	Name              string  `json:"name"`
	Status            string  `json:"status" description:"状态"`
	TenantId          string  `json:"tenantId" description:"租户id"`
	TenantName        string  `json:"tenantName" description:"租户名称"`
	Ip                string  `json:"ip" description:"IP地址"`
	Region            string  `json:"region" description:"所属区域"`
	RegionCode        string  `json:"regionCode" description:"所属区域Code"`
	Az                string  `json:"az" description:"所属可用区"`
	AzCode            string  `json:"azCode" description:"所属可用区编码"`
	PoolId            string  `json:"poolId" description:"所属资源池id"`
	PoolName          string  `json:"poolName" description:"所属资源池"`
	CPUUsedPercent    float64 `json:"cpuUsedPercent" description:"cpu使用率"`
	MemoryUsedPercent float64 `json:"memoryUsedPercent" description:"内存使用率"`
	IOPS              string  `json:"iops" description:"IOPS （次/秒）"`
	NetInput          float64 `json:"netInput" description:"网络输入吞吐量（Kbps）"`
	NetOutput         float64 `json:"netOutput" description:"网络输出吞吐量（Kbps）"`
	Connect           int64   `json:"connect" description:"连接数"`
	QPS               int64   `json:"qps" description:"QPS （次/秒）"`
	TPS               int64   `json:"tps" description:"TPS （次/秒）"`
	CreateTime        int64   `json:"createTime"`
	AlertNumber       int     `json:"alertNumber" description:"告警数量"`
}

//监控概览返回参数
type OverViewSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverView struct {
	Region string                        `json:"region"`
	Az     string                        `json:"az"`
	Lab    string                        `json:"lab"`
	Alerts []resourcepoolmodel.AlertType `json:"alerts"`
}

type Chart struct {
	Info   OverInfo    `json:"info"`
	Values []ValueType `json:"values"`
}

type OverInfo struct {
	Name     string `json:"name"`
	Number   int    `json:"number"`
	Type     string `json:"type"` //p0/p1/p2/p3
	Kind     string `json:"kind"` //[错误,紧急error/警告，重要warn/信息、提醒、次要info/成功、使用中success/未使用、未开通disabled]
	Unit     string `json:"unit"`
	Label    string `json:"label"`
	UnitType string `json:"unitType"`
}

//监控概览top请求参数
type TopQuery struct {
	Region       string   `json:"region"`
	Az           string   `json:"az"`
	Name         []string `json:"name"`
	Pool         string   `json:"pool"`
	Lab          string   `json:"lab"`
	TenantId     string   `json:"tenantId"`
	InnerIp      string   `json:"innerIp"`
	OuterIp      string   `json:"outerIp"`
	Label        string   `json:"label"`
	State        string   `json:"state"`
	PhysicalHost string   `json:"physicalHost"`
	SearchKey    string   `json:"searchKey"`
	SearchValue  string   `json:"searchValue"`
	RunList      []string `json:"runList"`
	Start        float64  `json:"start"`
	End          float64  `json:"end"`
	TopK         string   `json:"topk"`
}

//监控概览top返回参数
type OverViewTopSuccess struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    []OverViewLine `json:"data"`
}
type OverViewTopSuccessNew struct {
	Code    int                       `json:"code"`
	Message string                    `json:"message"`
	Data    []vmmodel.OverViewLineNew `json:"data"`
}
type OverViewLine struct {
	Region  string       `json:"region"`
	Az      string       `json:"az"`
	Lab     string       `json:"lab"`
	Name    string       `json:"name"`
	Unit    string       `json:"unit"`
	Echarts []EchartType `json:"echarts"`
}

type EchartType struct {
	Info   services.InfoType `json:"info"`
	Values []ValueType       `json:"values"`
}

type ValueType struct {
	Value      interface{} `json:"value"`
	Name       string      `json:"name"`
	Timestamep string      `json:"timestamep"`
	SubName    string      `json:"subName"`
	VmId       string      `json:"vmId"`
}

//监控指标参数
type MetricQuery struct {
	Id        string  `json:"id"`
	IndexType string  `json:"indexType"`
	Name      string  `json:"name"`
	Start     float64 `json:"start"`
	End       float64 `json:"end"`
}

// 监控指标返回参数
type MetricLineSuccess struct {
	Code    int                 `json:"code"`
	Message string              `json:"message"`
	Data    []MysqlOverViewLine `json:"data"`
}

type MetricInfoType struct {
	Metric      []string `json:"metric"`
	Name        string   `json:"name"`
	Unit        string   `json:"unit"`
	UnitType    string   `json:"unitType"`
	Copywriting string   `json:"copywriting"`
}

type MysqlOverViewLine struct {
	Label       string            `json:"label"`
	Name        string            `json:"name"`
	Unit        string            `json:"unit"`
	UnitType    string            `json:"unitType"`
	Copywriting string            `json:"copywriting"`
	Echarts     []MysqlEchartType `json:"echarts"`
}

type MysqlEchartType struct {
	Info   InfoType             `json:"info"`
	Values []services.ValueType `json:"values"`
}

type InfoType struct {
	Name         string      `json:"name"`
	Label        string      `json:"label"`
	ResourcePool string      `json:"resourcePool"`
	Total        interface{} `json:"total"`
	Value        interface{} `json:"value"`
	Unit         string      `json:"unit"`
	UnitType     string      `json:"unitType"`
}
type Filter struct {
	Tenant       []map[string]string `json:"tenant"`
	ResourcePool []map[string]string `json:"resourcePool"`
}

//		Param(ws.BodyParameter("id", "实例id`").DataType("string").Required(true)).
//		Param(ws.BodyParameter("pageNo", "页码，默认值：`1`").Required(true)).
//		Param(ws.BodyParameter("pageSize", "页大小，默认值：`10`").Required(true)).
//		Param(ws.BodyParameter("start", "The start time of TopK").Required(false)).
//		Param(ws.BodyParameter("end", "The end time of TopK").Required(false)).

// mysql 日志列表请求参数
type LogsListMetricQuery struct {
	ID        string  `json:"id"`
	Name      string  `json:"name"`
	DbLogType string  `json:"dbLogType"`
	PageNo    int     `json:"pageNo"`
	PageSize  int     `json:"pageSize"`
	Start     float64 `json:"start"`
	End       float64 `json:"end"`
}

// mysql 日志列表返回数据
type LogsListSuccess struct {
	PageStruct
	Data []LogsListData `json:"data"`
}

type LogsListData struct {
	ID          string `json:"id"`
	Name        string `json:"name"`
	Data        string `json:"data"`
	Size        string `json:"size"`
	StartTime   string `json:"start_time"`
	EndTime     string `json:"end_time"`
	LogFileName string `json:"log_file_name"`
	TimeStr     string `json:"time_str"`
}

type LogsList struct {
	InstanceID     string `json:"instanceId"`
	GroupID        string `json:"groupId"`
	LogType        string `json:"logType"`
	LogURL         string `json:"logUrl"`
	FileCreateTime int64  `json:"fileCreateTime"` // 文件开始时间
	Created        int64  `json:"created"`        // 文件结束时间
	Size           int    `json:"size"`
	RawSize        int    `json:"raw_size"`
	FistEventTime  int64  `json:"fistEventTime"` // binlog 日志开始时间
	LastEventTime  int64  `json:"lastEventTime"` // binlog日志结束时间
}

type GetMonitorParam struct {
	Start    string              `gorm:"column:start" json:"start"`
	End      string              `gorm:"column:end" json:"end"`
	Name     string              `gorm:"column:name" json:"name"`
	Unit     string              `gorm:"column:Unit" json:"unit"`
	UnitType string              `gorm:"column:UnitType" json:"unitType"`
	Topk     int                 `gorm:"column:topk" json:"topk"`
	Ids      []vmmodel.CmdbTopVm `gorm:"column:Ids" json:"ids"`
	Metric   []string            `gorm:"column:metric" json:"metric"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/prometheus/prometheusmodel.go
```golang
package prometheusModel

//type PhysicalServerOver struct {
//	Alerts        handler.AlertLevels
//	State         handler.RegionCurrentStates
//	ResourceUsage []ResourceT
//	AllTopK       []prometheusmanager.RateTopResult
//}

type ListQuery struct {
	PageNo   int `json:"pageNo"`
	PageSize int `json:"pageSize"`
	//Count    bool   `json:"count"`
	Region string `json:"region"`
	Az     string `json:"az"`
	Lab    string `json:"lab"`
	Name   string `json:"name"`
	Sn     string `json:"sn"`
	Ip     string `json:"ip"`
	Label  string `json:"label"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

type ResourceT struct {
	Rate    string `json:"rate"`
	Use     string `json:"use"`
	Surplus string `json:"surplus"`
}

//type PhysicalServerOverSuccess struct {
//	Code    int                `json:"code"`
//	Message string             `json:"message"`
//	Data    PhysicalServerOver `json:"data"`
//}

type PhysicalServer struct {
	Name        string      `json:"name"`
	State       string      `json:"state"`
	Pool        string      `json:"pool"`
	Region      string      `json:"region"`
	Az          string      `json:"zone"`
	Lab         string      `json:"lab"`
	Sn          string      `json:"sn"`
	IP          string      `json:"ip"`
	Os          string      `json:"os"`
	CpuLoad     interface{} `json:"cpuLoad"`
	MemLoad     interface{} `json:"memLoad"`
	DiskLoad    interface{} `json:"diskLoad"`
	AlertNumber int         `json:"alertNumber"`
	Label       string      `json:"label"`
}

type PhysicalServerListResult struct {
	PageStruct
	DataList []PhysicalServer `json:"dataList"`
}

type PhysicalServerAlertDetail struct {
	Id        string `json:"id"`
	Name      string `json:"name"`
	Level     string `json:"level"`
	State     string `json:"state"`
	Rule      string `json:"rule"`
	Threshold string `json:"threshold"`
	LastTime  string `json:"lastTime"`
	RangeTime string `json:"rangeTime"`
	Handler   string `json:"handler"`
}

type PhysicalServerAlertDetailSuccess struct {
	Code    int                         `json:"code"`
	Message string                      `json:"message"`
	Data    []PhysicalServerAlertDetail `json:"data"`
}

type PhysicalServerSuccess struct {
	Code    int              `json:"code"`
	Message string           `json:"message"`
	Data    []PhysicalServer `json:"data"`
}

//type TopKSuccess struct {
//	Code    int                               `json:"code"`
//	Message string                            `json:"message"`
//	Data    []prometheusmanager.RateTopResult `json:"data"`
//}

type Lab struct {
	LabCode string `json:"labCode"`
	LabName string `json:"labName"`
}

type Az struct {
	AzCode          string `json:"azCode"`
	AzName          string `json:"azName"`
	AzCodeAggregate string `json:"azCodeAggregate"`
	ContainLabs     []Lab  `json:"containLabs"`
}

type Region struct {
	RegionCode          string `json:"regionCode"`
	RegionName          string `json:"regionName"`
	RegionCodeAggregate string `json:"regionCodeAggregate"`
	ContainAzs          []Az   `json:"containAzs"`
}

type RegionData struct {
	DataList []Region `json:"dataList"`
}

type ResponseObject struct {
	Code    int         `json:"code"`
	Message string      `json:"message"`
	Data    interface{} `json:"data"`
}

type DgraphCount struct {
	Host []HostCount `json:"host"`
}

type HostCount struct {
	Count          int    `json:"count"`
	Label          string `json:"label"`
	Ip             string `json:"ip"`
	HostName       string `json:"hostname"`
	HostRegionName string `json:"hostRegionName"`
	HostLabName    string `json:"hostLabName"`
	HostAzName     string `json:"hostAzName"`
	Sn             string `json:"sn"`
	RunStatus      string `json:"runstatus"`
	Os             string `json:"system"`
	ServiceType    string `json:"serviceType"`
}
type MonitorTargetQuery struct {
	Ip    string   `json:"ip"`
	Query []string `json:"query"`
	Start string   `json:"start"`
	End   string   `json:"end"`
	Step  string   `json:"step"`
}
type QueryList struct {
	List []string `json:"list"`
}

type QueryResponseObject struct {
	Status string      `json:"status"`
	Data   interface{} `json:"data"`
}

type DataT struct {
	ResultType string      `json:"resultType"`
	Result     interface{} `json:"result"`
}

type ResultT struct {
	Metric interface{}   `json:"metric"`
	Value  []interface{} `json:"value"`
}

type ResponseMetric struct {
	Metric string      `json:"metric"`
	Value  interface{} `json:"value"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/prometheus/labels/matcher.go
```golang
// Copyright 2017 The Prometheus Authors
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package labels

import (
	"fmt"
	"strings"

	"github.com/prometheus/common/model"
)

// MatchType is an enum for label matching types.
type MatchType int

// Possible MatchTypes.
const (
	MatchEqual MatchType = iota
	MatchNotEqual
	MatchRegexp
	MatchNotRegexp
)

var matchTypeToStr = [...]string{
	MatchEqual:     "=",
	MatchNotEqual:  "!=",
	MatchRegexp:    "=~",
	MatchNotRegexp: "!~",
}

func (m MatchType) String() string {
	if m < MatchEqual || m > MatchNotRegexp {
		m = MatchEqual
	}
	return matchTypeToStr[m]
}

// Matcher models the matching of a label.
type Matcher struct {
	Type  MatchType
	Name  model.LabelName
	Value model.LabelValue

	re *FastRegexMatcher
}

// NewMatcher returns a matcher object.
func NewMatcher(mt MatchType, n, v string) (*Matcher, error) {
	m := &Matcher{
		Type:  mt,
		Name:  model.LabelName(n),
		Value: model.LabelValue(v),
	}
	if mt == MatchRegexp || mt == MatchNotRegexp {
		re, err := NewFastRegexMatcher(v)
		if err != nil {
			return nil, err
		}
		m.re = re
	}
	return m, nil
}

func (m *Matcher) String() string {
	return fmt.Sprintf("%s%s%q", m.Name, m.Type, m.Value)
}

// Matches returns whether the matcher matches the given string value.
func (m *Matcher) Matches(s string) bool {
	switch m.Type {
	case MatchEqual:
		return model.LabelValue(s) == m.Value
	case MatchNotEqual:
		return model.LabelValue(s) != m.Value
	case MatchRegexp:
		return m.re.MatchString(s)
	case MatchNotRegexp:
		return !m.re.MatchString(s)
	default:
		return false
	}
}

// GetRegexString returns the regex string.
func (m *Matcher) GetRegexString() string {
	if m.re == nil {
		return ""
	}
	return m.re.GetRegexString()
}

// MatcherPairs is a sortable slice of Matcher pointers. It implements
// sort.Interface.
type MatcherPairs []*Matcher

func (mps MatcherPairs) Len() int {
	return len(mps)
}

func (mps MatcherPairs) Less(i, j int) bool {
	switch {
	case mps[i].Name > mps[j].Name:
		return false
	case mps[i].Name < mps[j].Name:
		return true
	case mps[i].Value > mps[j].Value:
		return false
	case mps[i].Value < mps[j].Value:
		return true
	default:
		return false
	}
}

func (mps MatcherPairs) Swap(i, j int) {
	mps[i], mps[j] = mps[j], mps[i]
}

func (mps MatcherPairs) String() string {
	matcherStrings := make([]string, 0, mps.Len())
	for _, m := range mps {
		matcherStrings = append(matcherStrings, m.String())
	}
	return strings.Join(matcherStrings, ",")
}

func (mps *MatcherPairs) AddMatcher(mt MatchType, n, v string) error {
	m, err := NewMatcher(mt, n, v)
	if err != nil {
		return err
	}
	*mps = append(*mps, m)
	return nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/prometheus/labels/labels.go
```golang
// Copyright 2017 The Prometheus Authors
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package labels

import (
	"bytes"
	"encoding/json"
	"sort"
	"strconv"

	"github.com/cespare/xxhash/v2"
)

// Well-known label names used by Prometheus components.
const (
	MetricName   = "__name__"
	AlertName    = "alertname"
	BucketLabel  = "le"
	InstanceName = "instance"

	labelSep = '\xfe'
)

var seps = []byte{'\xff'}

// Label is a key/value pair of strings.
type Label struct {
	Name, Value string
}

// Labels is a sorted set of labels. Order has to be guaranteed upon
// instantiation.
type Labels []Label

func (ls Labels) Len() int           { return len(ls) }
func (ls Labels) Swap(i, j int)      { ls[i], ls[j] = ls[j], ls[i] }
func (ls Labels) Less(i, j int) bool { return ls[i].Name < ls[j].Name }

func (ls Labels) String() string {
	var b bytes.Buffer

	b.WriteByte('{')
	for i, l := range ls {
		if i > 0 {
			b.WriteByte(',')
			b.WriteByte(' ')
		}
		b.WriteString(l.Name)
		b.WriteByte('=')
		b.WriteString(strconv.Quote(l.Value))
	}
	b.WriteByte('}')
	return b.String()
}

// Bytes returns ls as a byte slice.
// It uses an byte invalid character as a separator and so should not be used for printing.
func (ls Labels) Bytes(buf []byte) []byte {
	b := bytes.NewBuffer(buf[:0])
	b.WriteByte(labelSep)
	for i, l := range ls {
		if i > 0 {
			b.WriteByte(seps[0])
		}
		b.WriteString(l.Name)
		b.WriteByte(seps[0])
		b.WriteString(l.Value)
	}
	return b.Bytes()
}

// MarshalJSON implements json.Marshaler.
func (ls Labels) MarshalJSON() ([]byte, error) {
	return json.Marshal(ls.Map())
}

// UnmarshalJSON implements json.Unmarshaler.
func (ls *Labels) UnmarshalJSON(b []byte) error {
	var m map[string]string

	if err := json.Unmarshal(b, &m); err != nil {
		return err
	}

	*ls = FromMap(m)
	return nil
}

// MarshalYAML implements yaml.Marshaler.
func (ls Labels) MarshalYAML() (interface{}, error) {
	return ls.Map(), nil
}

// UnmarshalYAML implements yaml.Unmarshaler.
func (ls *Labels) UnmarshalYAML(unmarshal func(interface{}) error) error {
	var m map[string]string

	if err := unmarshal(&m); err != nil {
		return err
	}

	*ls = FromMap(m)
	return nil
}

// MatchLabels returns a subset of Labels that matches/does not match with the provided label names based on the 'on' boolean.
// If on is set to true, it returns the subset of labels that match with the provided label names and its inverse when 'on' is set to false.
func (ls Labels) MatchLabels(on bool, names ...string) Labels {
	matchedLabels := Labels{}

	nameSet := map[string]struct{}{}
	for _, n := range names {
		nameSet[n] = struct{}{}
	}

	for _, v := range ls {
		if _, ok := nameSet[v.Name]; on == ok && (on || v.Name != MetricName) {
			matchedLabels = append(matchedLabels, v)
		}
	}

	return matchedLabels
}

// Hash returns a hash value for the label set.
func (ls Labels) Hash() uint64 {
	// Use xxhash.Sum64(b) for fast path as it's faster.
	b := make([]byte, 0, 1024)
	for i, v := range ls {
		if len(b)+len(v.Name)+len(v.Value)+2 >= cap(b) {
			// If labels entry is 1KB+ do not allocate whole entry.
			h := xxhash.New()
			_, _ = h.Write(b)
			for _, v := range ls[i:] {
				_, _ = h.WriteString(v.Name)
				_, _ = h.Write(seps)
				_, _ = h.WriteString(v.Value)
				_, _ = h.Write(seps)
			}
			return h.Sum64()
		}

		b = append(b, v.Name...)
		b = append(b, seps[0])
		b = append(b, v.Value...)
		b = append(b, seps[0])
	}
	return xxhash.Sum64(b)
}

// HashForLabels returns a hash value for the labels matching the provided names.
// 'names' have to be sorted in ascending order.
func (ls Labels) HashForLabels(b []byte, names ...string) (uint64, []byte) {
	b = b[:0]
	i, j := 0, 0
	for i < len(ls) && j < len(names) {
		if names[j] < ls[i].Name {
			j++
		} else if ls[i].Name < names[j] {
			i++
		} else {
			b = append(b, ls[i].Name...)
			b = append(b, seps[0])
			b = append(b, ls[i].Value...)
			b = append(b, seps[0])
			i++
			j++
		}
	}
	return xxhash.Sum64(b), b
}

// HashWithoutLabels returns a hash value for all labels except those matching
// the provided names.
// 'names' have to be sorted in ascending order.
func (ls Labels) HashWithoutLabels(b []byte, names ...string) (uint64, []byte) {
	b = b[:0]
	j := 0
	for i := range ls {
		for j < len(names) && names[j] < ls[i].Name {
			j++
		}
		if ls[i].Name == MetricName || (j < len(names) && ls[i].Name == names[j]) {
			continue
		}
		b = append(b, ls[i].Name...)
		b = append(b, seps[0])
		b = append(b, ls[i].Value...)
		b = append(b, seps[0])
	}
	return xxhash.Sum64(b), b
}

// WithLabels returns a new labels.Labels from ls that only contains labels matching names.
// 'names' have to be sorted in ascending order.
func (ls Labels) WithLabels(names ...string) Labels {
	ret := make([]Label, 0, len(ls))

	i, j := 0, 0
	for i < len(ls) && j < len(names) {
		if names[j] < ls[i].Name {
			j++
		} else if ls[i].Name < names[j] {
			i++
		} else {
			ret = append(ret, ls[i])
			i++
			j++
		}
	}
	return ret
}

// WithoutLabels returns a new labels.Labels from ls that contains labels not matching names.
// 'names' have to be sorted in ascending order.
func (ls Labels) WithoutLabels(names ...string) Labels {
	ret := make([]Label, 0, len(ls))

	j := 0
	for i := range ls {
		for j < len(names) && names[j] < ls[i].Name {
			j++
		}
		if ls[i].Name == MetricName || (j < len(names) && ls[i].Name == names[j]) {
			continue
		}
		ret = append(ret, ls[i])
	}
	return ret
}

// Copy returns a copy of the labels.
func (ls Labels) Copy() Labels {
	res := make(Labels, len(ls))
	copy(res, ls)
	return res
}

// Get returns the value for the label with the given name.
// Returns an empty string if the label doesn't exist.
func (ls Labels) Get(name string) string {
	for _, l := range ls {
		if l.Name == name {
			return l.Value
		}
	}
	return ""
}

// Has returns true if the label with the given name is present.
func (ls Labels) Has(name string) bool {
	for _, l := range ls {
		if l.Name == name {
			return true
		}
	}
	return false
}

// HasDuplicateLabelNames returns whether ls has duplicate label names.
// It assumes that the labelset is sorted.
func (ls Labels) HasDuplicateLabelNames() (string, bool) {
	for i, l := range ls {
		if i == 0 {
			continue
		}
		if l.Name == ls[i-1].Name {
			return l.Name, true
		}
	}
	return "", false
}

// WithoutEmpty returns the labelset without empty labels.
// May return the same labelset.
func (ls Labels) WithoutEmpty() Labels {
	for _, v := range ls {
		if v.Value != "" {
			continue
		}
		// Do not copy the slice until it's necessary.
		els := make(Labels, 0, len(ls)-1)
		for _, v := range ls {
			if v.Value != "" {
				els = append(els, v)
			}
		}
		return els
	}
	return ls
}

// Equal returns whether the two label sets are equal.
func Equal(ls, o Labels) bool {
	if len(ls) != len(o) {
		return false
	}
	for i, l := range ls {
		if l != o[i] {
			return false
		}
	}
	return true
}

// Map returns a string map of the labels.
func (ls Labels) Map() map[string]string {
	m := make(map[string]string, len(ls))
	for _, l := range ls {
		m[l.Name] = l.Value
	}
	return m
}

// New returns a sorted Labels from the given labels.
// The caller has to guarantee that all label names are unique.
func New(ls ...Label) Labels {
	set := make(Labels, 0, len(ls))
	for _, l := range ls {
		set = append(set, l)
	}
	sort.Sort(set)

	return set
}

// FromMap returns new sorted Labels from the given map.
func FromMap(m map[string]string) Labels {
	l := make([]Label, 0, len(m))
	for k, v := range m {
		l = append(l, Label{Name: k, Value: v})
	}
	return New(l...)
}

// FromStrings creates new labels from pairs of strings.
func FromStrings(ss ...string) Labels {
	if len(ss)%2 != 0 {
		panic("invalid number of strings")
	}
	var res Labels
	for i := 0; i < len(ss); i += 2 {
		res = append(res, Label{Name: ss[i], Value: ss[i+1]})
	}

	sort.Sort(res)
	return res
}

// Compare compares the two label sets.
// The result will be 0 if a==b, <0 if a < b, and >0 if a > b.
func Compare(a, b Labels) int {
	l := len(a)
	if len(b) < l {
		l = len(b)
	}

	for i := 0; i < l; i++ {
		if a[i].Name != b[i].Name {
			if a[i].Name < b[i].Name {
				return -1
			}
			return 1
		}
		if a[i].Value != b[i].Value {
			if a[i].Value < b[i].Value {
				return -1
			}
			return 1
		}
	}
	// If all labels so far were in common, the set with fewer labels comes first.
	return len(a) - len(b)
}

// Builder allows modifying Labels.
type Builder struct {
	base Labels
	del  []string
	add  []Label
}

// NewBuilder returns a new LabelsBuilder.
func NewBuilder(base Labels) *Builder {
	b := &Builder{
		del: make([]string, 0, 5),
		add: make([]Label, 0, 5),
	}
	b.Reset(base)
	return b
}

// Reset clears all current state for the builder.
func (b *Builder) Reset(base Labels) {
	b.base = base
	b.del = b.del[:0]
	b.add = b.add[:0]
	for _, l := range b.base {
		if l.Value == "" {
			b.del = append(b.del, l.Name)
		}
	}
}

// Del deletes the label of the given name.
func (b *Builder) Del(ns ...string) *Builder {
	for _, n := range ns {
		for i, a := range b.add {
			if a.Name == n {
				b.add = append(b.add[:i], b.add[i+1:]...)
			}
		}
		b.del = append(b.del, n)
	}
	return b
}

// Set the name/value pair as a label.
func (b *Builder) Set(n, v string) *Builder {
	if v == "" {
		// Empty labels are the same as missing labels.
		return b.Del(n)
	}
	for i, a := range b.add {
		if a.Name == n {
			b.add[i].Value = v
			return b
		}
	}
	b.add = append(b.add, Label{Name: n, Value: v})

	return b
}

// Labels returns the labels from the builder. If no modifications
// were made, the original labels are returned.
func (b *Builder) Labels() Labels {
	if len(b.del) == 0 && len(b.add) == 0 {
		return b.base
	}

	// In the general case, labels are removed, modified or moved
	// rather than added.
	res := make(Labels, 0, len(b.base))
Outer:
	for _, l := range b.base {
		for _, n := range b.del {
			if l.Name == n {
				continue Outer
			}
		}
		for _, la := range b.add {
			if l.Name == la.Name {
				continue Outer
			}
		}
		res = append(res, l)
	}
	res = append(res, b.add...)
	sort.Sort(res)

	return res
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/prometheus/labels/regexp.go
```golang
// Copyright 2020 The Prometheus Authors
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package labels

import (
	"strings"

	"github.com/grafana/regexp"
	"github.com/grafana/regexp/syntax"
)

type FastRegexMatcher struct {
	re       *regexp.Regexp
	prefix   string
	suffix   string
	contains string
}

func NewFastRegexMatcher(v string) (*FastRegexMatcher, error) {
	re, err := regexp.Compile("^(?:" + v + ")$")
	if err != nil {
		return nil, err
	}

	parsed, err := syntax.Parse(v, syntax.Perl)
	if err != nil {
		return nil, err
	}

	m := &FastRegexMatcher{
		re: re,
	}

	if parsed.Op == syntax.OpConcat {
		m.prefix, m.suffix, m.contains = optimizeConcatRegex(parsed)
	}

	return m, nil
}

func (m *FastRegexMatcher) MatchString(s string) bool {
	if m.prefix != "" && !strings.HasPrefix(s, m.prefix) {
		return false
	}
	if m.suffix != "" && !strings.HasSuffix(s, m.suffix) {
		return false
	}
	if m.contains != "" && !strings.Contains(s, m.contains) {
		return false
	}
	return m.re.MatchString(s)
}

func (m *FastRegexMatcher) GetRegexString() string {
	return m.re.String()
}

// optimizeConcatRegex returns literal prefix/suffix text that can be safely
// checked against the label value before running the regexp matcher.
func optimizeConcatRegex(r *syntax.Regexp) (prefix, suffix, contains string) {
	sub := r.Sub

	// We can safely remove begin and end text matchers respectively
	// at the beginning and end of the regexp.
	if len(sub) > 0 && sub[0].Op == syntax.OpBeginText {
		sub = sub[1:]
	}
	if len(sub) > 0 && sub[len(sub)-1].Op == syntax.OpEndText {
		sub = sub[:len(sub)-1]
	}

	if len(sub) == 0 {
		return
	}

	// Given Prometheus regex matchers are always anchored to the begin/end
	// of the text, if the first/last operations are literals, we can safely
	// treat them as prefix/suffix.
	if sub[0].Op == syntax.OpLiteral && (sub[0].Flags&syntax.FoldCase) == 0 {
		prefix = string(sub[0].Rune)
	}
	if last := len(sub) - 1; sub[last].Op == syntax.OpLiteral && (sub[last].Flags&syntax.FoldCase) == 0 {
		suffix = string(sub[last].Rune)
	}

	// If contains any literal which is not a prefix/suffix, we keep the
	// 1st one. We do not keep the whole list of literals to simplify the
	// fast path.
	for i := 1; i < len(sub)-1; i++ {
		if sub[i].Op == syntax.OpLiteral && (sub[i].Flags&syntax.FoldCase) == 0 {
			contains = string(sub[i].Rune)
			break
		}
	}

	return
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/physicalSwitch/switchParameter.go
```golang
package physicalSwitch

import "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"

type RegionAzsBody struct {
	Region   models.Region `json:"region"`
	Azs      []models.Az   `json:"az"`
	PageNo   int           `json:"pageNo"`
	PageSize int           `json:"pageSize"`
}

//list
type SwitchListQuery struct {
	Region      string   `json:"region"`
	Az          []string `json:"az"`
	CpuErrNum   string   `json:"cpuErrNum"`
	MemErrNum   string   `json:"memErrNum"`
	PageNo      int      `json:"pageNo"`
	PageSize    int      `json:"pageSize"`
	SearchKey   string   `json:"searchKey"`
	SearchValue string   `json:"searchValue"`
	Name        string   `json:"name"`
	Sn          string   `json:"sn"`
	OrderCode   string   `json:"orderCode"`
	OrderType   string   `json:"orderType"`
	RunState    []string `json:"runState"`
	SnmpState   []string `json:"snmpState"`
}

type CMDBSwitchListResult struct {
	Code    int         `json:"code"`
	Message string      `json:"message"`
	Data    CmdbSwitchs `json:"data"`
}

type CmdbSwitchs struct {
	PageStruct
	DataList []SwitchNew `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type SwitchNew struct {
	Id        int    `json:"id" gorm:"column:id;"`               // Uid
	Name      string `json:"name" gorm:"column:name;unique"`     // 名称
	RunStatus string `json:"runStatus" gorm:"column:run_status"` // 运行状态
	SnmpStatus 		   int `json:"snmpStatus" gorm:"column:snmp_status"`// snmp状态
	Sn        string `json:"sn" gorm:"column:sn;unique"`         // SN号
	// SwitchRole     string `json:"switchRole" gorm:"column:switch_role"`          // 角色
	// SwitchRackName string `json:"switchRackName" gorm:"column:Switch_rack_name"` // 机架位名称
	//SwitchUnitNumber   string `json:"switchUnitNumber" gorm:"column:switch_unit_number"`    // 所占U位
	SwitchType string `json:"switchType" gorm:"column:switch_type"` // 交换机型号
	//ManagementIP       string `json:"managementIp" gorm:"column:management_ip"`             // 管理IP
	OutBandIP string `json:"outbandIP" gorm:"column:out_band_ip"` // 外带IP
	//SwitchManufacturer string `json:"switchManufacturer" gorm:"column:switch_manufacturer"` // 交换机厂商
	//MaintenanceDue     utils.Datetime `json:"maintenanceDue" gorm:"column:maintenance_due"`         // 维保到期时间
	// MaintenanceDue    int    `json:"maintenanceDue" gorm:"column:maintenance_due"`       // 维保到期时间
	// MainMaintainer    string `json:"mainMaintainer" gorm:"column:main_maintainer"`       // 维护人
	// MaintenanceStatus string `json:"maintenanceStatus" gorm:"column:maintenance_status"` // 维保状态
	// InterfaceCount    int    `json:"interfaceCount" gorm:"column:interface_count"`       //接口数量
	// OsVersion         string `json:"osVersion" gorm:"column:os_version"`                 // OS版本
	// HardwareVersion   string `json:"hardwareVersion" gorm:"column:hardware_version"`     // 硬件版本
	// AssetsNumber      string `json:"assetsNumber" gorm:"column:assets_number"`           // 资产编号
	Label string `json:"label" gorm:"column:label"` // 标签
	//Description       string `json:"description" gorm:"column:description"`              // 描述
	RegionName string `json:"regionName" gorm:"column:region_name"`
	//RegionCode        string `json:"regionCode" gorm:"column:region_code"`
	AzName string `json:"azName" gorm:"column:az_name"`
	// AzCode            string `json:"azCode" gorm:"column:az_code"`
	// LabName           string `json:"labName" gorm:"column:lab_name"`
	// LabCode           string `json:"labCode" gorm:"column:lab_code"`
	// RoomCode          string `json:"switchRoomCode,omitempty" gorm:"column:room_code"`
	// RoomName          string `json:"switchRoomName,omitempty" gorm:"column:sroom_name"`
	// CabintCode        string `json:"cabintCode" gorm:"column:cabint_code"`
	// CabintName        string `json:"cabintName" gorm:"column:cabint_name"`
	// InputTime         int    `json:"inputTime" gorm:"column:input_time"`
	// CreateTime        int    `json:"createTime" gorm:"column:create_time"` // 创建时间
	// Creator           string `json:"creator" gorm:"column:creator"`        // 创建人
	// Updater           string `json:"updater" gorm:"column:updater"`        // 更新者
	// UpdateTime        int    `json:"updateTime" gorm:"column:update_time"` // 更新时间
	//TotalCount         int            `json:"-" gorm:"column:total_count"`
	//PowerWorkRate      string         `json:"powerWorkRate"`      //  电源功率
	// Cpu       []CPU      `json:"cpu" gorm:"-"`
	// Memory    []Memory   `json:"memory" gorm:"-"`
	// PortInfos []PortInfo `json:"switch_port" gorm:"-"`
}

type CPU struct {
	CPUType   string `json:"cpuType,omitempty"`   // 型号
	CoreCount int    `json:"coreCount,omitempty"` // 总核心数
	Frequency string `json:"frequency,omitempty"` // 频率
}

type Memory struct {
	MemoryType string `json:"memoryType,omitempty"` // 型号
	MemoryCap  string `json:"memoryCap,omitempty"`  // 总容量
	Count      int    `json:"count,omitempty"`      // 数量
}

type PortInfo struct {
	PortType    string `json:"portType,omitempty"`    // 类型
	PortMarking string `json:"portMarking,omitempty"` // 型号
	PortSpecs   string `json:"portSpecs,omitempty"`   // 规格
	Count       int    `json:"count,omitempty"`       // 数量
}

//overview
type SwitchOverviewQuery struct {
	Region string `json:"region"`
	Az     string `json:"az"`
}

//top
type SwitchOverviewTopQuery struct {
	Region string   `json:"region"`
	Az     string   `json:"az"`
	Name   []string `json:"name"`
	Topk   string   `json:"topk"`
	Start  float64  `json:"start"`
	End    float64  `json:"end"`
}
type SwitchOverviewTopKQuery struct {
	Region models.Region `json:"region"`
	Azs    models.Az     `json:"az"`
	Topk   int           `json:"topk"`
	Start  string        `json:"start"`
	End    string        `json:"end"`
	Name   []string      `json:"name"`
}

//switchMetricLine
type SwitchMetricLineQuery struct {
	Sn    string   `json:"sn"`
	Start float64  `json:"start"`
	End   float64  `json:"end"`
	List  []string `json:"list"`
}

//interface
type CmdbInterfaceLayOutRes struct {
	Code    int                             `json:"code"`
	Message string                          `json:"message"`
	Data    SwitchInterfaceLayoutListResult `json:"data"`
}
type CmdbInterfaceLayOut struct {
}

type SwitchInterfaceLayoutListResult struct {
	TotalCount int64 `json:"totalCount"`
	//PageNo     int                     `json:"pageNo"`
	//PageSize   int                     `json:"pageSize"`
	DataList []SwitchInterfaceLayout `json:"dataList"`
}

type SwitchInterfaceLayout struct {
	SwitchClass   int    `json:"switchClass" gorm:"column:switch_class"`     //  not null comment '交换机分类',
	SwitchType    string `json:"switchType" gorm:"column:switch_type"`       //not null comment '交换机类型',
	InterfaceType string `json:"interfaceType" gorm:"column:interface_type"` // not null comment '接口类型',
	Address       string `json:"address" gorm:"column:address"`              //not null comment '位置信息，',
	StartIndex    int    `json:"startIndex" gorm:"column:start_index"`       //not null comment '接口起始index',
	X             int    `json:"X" gorm:"column:x"`                          // not null comment '行',
	Y             int    `json:"y" gorm:"column:y"`                          // not null comment '列',
}

type SwitchInterfaceListQuery struct {
	PageNo    int      `json:"pageNo`
	PageSize  int      `json:"pageSize"`
	Name      string   `json:"name"`
	Sn        string   `json:"sn"`
	RunList   []string `json:"runList"`
	OrderCode string   `json:"orderCode"`
	OrderType string   `json:"orderType"`
}

type InterfaceQuery struct {
	Sn    string `json:"sn"`
	Index string `json:"index"`
}

type SwitchInterfaceLineQuery struct {
	Start float64  `json:"start`
	End   float64  `json:"end"`
	Name  []string `json:"name"`
	Sn    string   `json:"sn"`
	Index string   `json:"index"`
}

//switchMetric
type SwitchMetricRequest struct {
}

type SwitchIfDetailParams struct {
	PageNo    int      `json:"pageNo"`
	PageSize  int      `json:"pageSize"`
	RunStatus []string `json:"runStatus"`
	Name      string   `json:"name"`
	Sn        string   `json:"sn"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/physicalSwitch/swtichResponse.go
```golang
package physicalSwitch

import (
	alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

type Result struct {
	Code    int         `json:"code"`
	Message string      `json:"messgae"`
	Data    interface{} `json:"data"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

//overview
type SwitchOverviewResponse struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverView struct {
	Region        string                            `json:"region"`
	Az            string                            `json:"azs"`
	Alerts        []alertmanagermodel.OverviewAlert `json:"alerts"`
	SwitchState   []StateType                       `json:"switchState"`
	IfState       []StateType                       `json:"ifState"`
	HardwareState []StateType                       `json:"hardwareState"`
}

//overviewTop
type SwitchOverviewTopResponse struct {
	Code    int               `json:"code"`
	Message string            `json:"message"`
	Data    []OverviewTopType `json:"data"`
}

type OverviewTopType struct {
	Region string `json:"region"`
	Az     string `json:"az"`
	Name   string `json:"name"`
	Unit   string `json:"unit"`
	//Alert  AlertLevels `json:"alert"`
	Echarts []EchartType `json:"echarts"`
}

type EchartType struct {
	Info   InfoType             `json:"info"`
	Values []services.ValueType `json:"values"`
}

type InfoType struct {
	Type     string `json:"_type"`
	Unit     string `json:"unit"`
	Name     string `json:"name"`
	UnitType string `json:"unitType"`
}

type ValueType struct {
	Value     interface{} `json:"value"`
	Name      string      `json:"name"`
	Timestamp string      `json:"timestamp"`
}

type StateType struct {
	Prefix string  `json:"prefix"`
	Unit   string  `json:"unit"`
	Number int     `json:"number"`
	Value  float64 `json:"value"`
	Name   string  `json:"name"`
	Kind   string  `json:"kind"`
	Type   string  `json:"type"`
}

//list
type SwitchListResponse struct {
	Code    int              `json:"code"`
	Message string           `json:"message"`
	Data    SwitchListResult `json:"data"`
}

type SwitchListResult struct {
	PageStruct
	DataList []Switch `json:"dataList"`
}

type Switch struct {
	ID         int     `json:"id" description:"交换机ID"`
	Ip         string  `json:"ip" description:"交换机ip"`
	Name       string  `json:"name" description:"交换机名称"`
	RunState   string  `json:"runState" description:"运行状态"`
	Pool       string  `json:"pool" description:"所属资源池"`
	Region     string  `json:"region" description:"区域"`
	Az         string  `json:"az" description:"可用区"`
	Sn         string  `json:"sn" description:"sn号"`
	ErrPortNum int     `json:"errPortNum" description:"异常接口数"`
	CpuErrNum  int     `json:"cpuErrNum" description:"cpu故障数量"`
	CpuLoad    float64 `json:"cpuLoad" description:"cpu利用率"`
	MemErrNum  int     `json:"memErrNum" description:"内存故障数量"`
	MemLoad    float64 `json:"memLoad" description:"内存利用率"`
	//DiskLoad    float64 `json:"diskLoad" description:"磁盘利用率"`
	Power       string `json:"power" description:"电源功率"`
	SnmpState   string `json:"snmpState" description:"snmp的状态"`
	AlertNumber int    `json:"alertNumber" description:"告警数量"`
	Label       string `json:"label" description:"标签"`
}

//type MetricSuccess struct {
//	Code    int        `json:"code"`
//	Message string     `json:"message"`
//	Data    ListResult `json:"data"`
//}

//alert
type Alert struct {
	Id        string `json:"id" description:"告警id"`
	Name      string `json:"name" description:"告警名称"`
	Level     string `json:"level" description:"告警等级"`
	Instance  string `json:"instance" description:"告警实例"`
	State     string `json:"state" description:"状态"`
	Rule      string `json:"rule" description:"告警规则"`
	Threshold string `json:"threshold" description:"阈值"`
	LastTime  string `json:"lastTime" description:"最近发生时间"`
	RangeTime string `json:"rangeTime" description:"持续时间"`
	Handler   string `json:"handler" description:"处理人"`
}

type AlertDetail struct {
	PageStruct
	DataList []Alert `json:"dataList"`
}

type AlertDetailSuccess struct {
	Code    int         `json:"code"`
	Message string      `json:"message"`
	Data    AlertDetail `json:"data"`
}

//interfaceList
type Interface struct {
	Id             string           `json:"id" description:"接口id"`
	Index          int              `json:"index" description:"接口索引"`
	Name           string           `json:"name" description:"接口名称"`
	InterFaceType  string           `json:"interFaceType" description:"接口类型"`
	InterFaceBand  int              `json:"InterFaceBand" description:"接口带宽"`
	State          string           `json:"state" description:"接口状态"`
	Ip             string           `json:"ip" description:"接口ip"`
	Mac            string           `json:"mac" description:"接口mac"`
	NextDevice     NextDeviceDetail `json:"nextDevice" description:"对端设备"`
	NextDescr      string           `json:"nextDescr" description:"对端设备描述"`
	NextInterface  string           `json:"nextInterface" description:"对端接口"`
	InDropPercent  float64          `json:"inDropPercent" description:"接收丢包率"`
	OutDropPercent float64          `json:"outDropPercent" description:"发送丢包率"`
	InErrPercent   float64          `json:"inErrPercent" description:"接收错包率"`
	OutErrPercent  float64          `json:"outErrPercent" description:"发送错包率"`
	InBandPercent  float64          `json:"inBandPercent" description:"接收带宽利用率"`
	OutBandPercent float64          `json:"outBandPercent" description:"发送带宽利用率"`
	Operate        string           `json:"operate" description:"操作"`
	//OrtherEndType  int              `json:"ortherEndType" description:"对端设备类型：1:switch;0:server"`
	OrtherEndDesc string `json:"ortherEndDesc" description:"对端设备描述"`
}

type NextDeviceDetail struct {
	Name       string `json:"name" description:"对端设备名称"`
	Interface  string `json:"interface" description:"对端设备接口"`
	DeviceType string `json:"deviceType" description:"对端设备类型"`
	DeviceId   int    `json:"deviceId" description:"对端设备Id"`
	State      string `json:"state" description:"对端设备状态"`
	Sn         string `json:"sn" description:"对端设备sn"`
	Ip         string `json:"ip" description:"对端设备ip"`
}

type InterfaceDetail struct {
	PageStruct
	DataList []Interface `json:"dataList"`
}
type InterfaceListSuccess struct {
	Code    int             `json:"code"`
	Message string          `json:"message"`
	Data    InterfaceDetail `json:"data"`
}

type CMDBInterfaceSeries struct {
	ManagementIp  string `json:"managementIp"`
	OutBandIp     string `json:"outBandIp"`
	SwitchType    string `json:"switchType"`
	InterfaceType string `json:"interfaceType"`
	Index         int    `json:"index"`
}
type CMDBInterfaceSeriesResult struct {
	TotalCount int64                 `json:"totalCount"`
	PageNo     int                   `json:"pageNo"`
	PageSize   int                   `json:"pageSize"`
	DataList   []CMDBInterfaceSeries `json:"dataList"`
}
type CMDBInterfaceSeriesData struct {
	Data CMDBInterfaceSeriesResult `json:"data"`
}

type CMDBInterfaceDetails struct {
	Sn                string `json:"sn"`
	IfIndex           int    `json:"ifIndex"`  //接口索引
	IfName            string `json:"ifName"`   // 接口名称
	IfStatus          int    `json:"ifStatus"` //接口运行状态
	IfIp              string `json:"ifIp"`     //接口ip
	IfMac             string `json:"ifMac"`    //接口MAC
	IfType            string `json:"ifType"`
	IfSpeed           int    `json:"ifSpeed"`         //接口带宽
	OrtherEndDevice   string `json:"ortherEndDevice"` //对端设备名称
	OrtherEndIf       string `json:"ortherEndIf"`     //对端接口名称
	OrtherEndType     string `json:"ortherEndType"`
	OrtherEndDescr    string `json:"ortherEndDescr"` //对端设备描述
	OrtherEndDeviceId int    `json:"ortherEndDeviceId"`
}
type CMDBInterfaceDetailsResult struct {
	DataList []CMDBInterfaceDetails `json:"dataList"`
}
type CMDBInterfaceDetailsData struct {
	Data CMDBInterfaceDetailsResult `json:"data"`
}

//switchMetric
type SwitchMetricSuccess struct {
	Code    int          `json:"code"`
	Message string       `json:"message"`
	Data    SwitchMetric `json:"data"`
}

type SwitchMetric struct {
	Sn           string  `json:"sn" description:"交换机的sn"`
	Name         string  `json:"name" description:"交换机的名称"`
	SwitchStates []Info  `json:"switchStates" description:"交换机监控项"`
	IfStates     []IfNum `json:"ifStates" description:"四种接口状态数据"`
	Blocks       []Block `json:"blocks" description:"block数组"`
}

type IfNum struct {
	Prefix string `json:"prefix"`
	Level  string `json:"level"`
	Unit   string `json:"unit"`
	Number int    `json:"number"`
	Name   string `json:"name"`
	Kind   string `json:"kind"`
	State  string `json:"state"`
	Type   string `json:"type"`
}

type Block struct {
	BlockType string      `json:"blockType" description:"接口类型;eg:electrical/sfp/qsfp"`
	IfList    [][]IfState `json:"ifList" description:"一个block接口二维数组"`
}

type IfState struct {
	Index int    `json:"index" description:"接口序号;eg:1"`
	State string `json:"state" description:"接口状态;eg:normal/err/shutdown"`
	//State string `json:"state" description:"接口状态;eg:normal/err/shutdown/noConn"`
}

type IsStatus []IfState

func (s IsStatus) Len() int {
	return len(s)
}

func (s IsStatus) Less(i, j int) bool {
	return s[i].Index < s[j].Index
}

func (s IsStatus) Swap(i, j int) {
	s[i], s[j] = s[j], s[i]
}

//switchMetricLine
type SwitchMetricLineResponse struct {
	Code    int                     `json:"code"`
	Message string                  `json:"message"`
	Data    map[string][]EchartType `json:"data"`
}
type IfDetailMetric struct {
	Index    string `json:"id" description:"接口id"`
	Name     string `json:"name" description:"接口名称"`
	State    string `json:"state" description:"接口状态;"`
	AlertNum int    `json:"alertNum" description:"告警数量"`
	// InFlow      float64 `json:"inFlow" description:"接收速率"`
	// OutFlow     float64 `json:"outFlow" description:"发送速率"`
	InBandRate  interface{} `json:"inBandRate" description:"接受带宽利用率"`
	OutBandRate interface{} `json:"outBandRate" description:"发送带宽利用率"`
	InDropRate  interface{} `json:"inDropRate" description:"接受丢包率"`
	OutDropRate interface{} `json:"outDropRate" description:"发送丢包率"`
	InErrRate   interface{} `json:"inErrRate" description:"接受错包率"`
	OutErrRate  interface{} `json:"outErrRate" description:"发送错包率"`
}

type Info struct {
	Metric string  `json:"metric" description:"监控项名称"`
	Name   string  `json:"name" description:"监控项名称"`
	Value  float64 `json:"value" description:"监控项的值"`
}

//interfaceMetric
type MetricSuccess struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    IfDetailMetric `json:"data"`
}

//interfaceLineMetric
type IfMetricLineResponse struct {
	Code    int             `json:"code"`
	Message string          `json:"message"`
	Data    IfMutilLineData `json:"data"`
}

type IfMutilLineData struct {
	Echarts []Echart `json:"echarts"`
}

type IfMetricSingleLineResponse struct {
	Code    int              `json:"code"`
	Message string           `json:"message"`
	Data    []MetricLineType `json:"data"`
}

type MetricLineType struct {
	Id      string   `json:"id"`
	Name    string   `json:"name"`
	SubName string   `json:"subName"`
	Start   string   `json:"start"`
	End     string   `json:"end"`
	Echarts []Echart `json:"echarts"`
}

type Echart struct {
	Info   MetricLineInfo       `json:"info"`
	Values []services.ValueType `json:"values"`
}

type MetricLineInfo struct {
	Tyte     string `json:"_type"`
	Index    int    `json:"_index"`
	Name     string `json:"name" description:"指标名称"`
	Number   int    `json:"number" description:"总数之类的统计值"`
	Start    string `json:"start" description:"开始时间"`
	End      string `json:"end" description:"结束时间"`
	Unit     string `json:"unit" description:"指标的单位"`
	UnitType string `json:"unitType" description:"指标的单位类型"`
	Max      string `json:"max" description:"指标的最大值"`
	Min      string `json:"min" description:"指标的最小值"`
	Avg      string `json:"avg" description:"指标的平均值"`
	Cur      string `json:"cur" description:"指标的当前值"`
}

//interfaceName
type SwitchIfNameSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    []string `json:"data"`
}

//Hardware
type HardwareResponse struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    HardWare `json:"data"`
}
type HardWare struct {
	InTemp        []StateType `json:"inTemp" description:"进风口温度"`
	OutTemp       []StateType `json:"outTemp" description:"出风口温度"`
	CpuState      []StateType `json:"cpuState" description:"cpu健康状况"`
	MemState      []StateType `json:"memState" description:"内存健康状况"`
	IfState       []StateType `json:"IfState" description:"端口健康状况"`
	PowerState    []StateType `json:"powerState" description:"电源健康状况"`
	FanState      []StateType `json:"fanState" description:"风扇健康状况"`
	MainBoardList []MainBoard `json:"mainBoardList" description:"主板"`
	Cpu           CpuDetail   `json:"cpu" description:"cpu"`
	Mem           MemDetail   `json:"mem" description:"内存"`
	PowerList     []Power     `json:"powerList" description:"电源"`
	FanList       []Fan       `json:"fanList" description:"风扇"`
}
type MainBoard struct {
	Name       string `json:"name" description:"名称"`
	State      int    `json:"state" description:"健康状态 1:健康；2：告警；3：故障；0：未知"`
	Sn         string `json:"sn" description:"序列号"`
	ProductNum string `json:"productNum" description:"产品部件号"`
	//ProductTime   int64  `json:"productTime" description:"产品生产日期"`
	ProductTime   string `json:"productTime" description:"产品生产日期"`
	ProducFactory string `json:"productFactory" description:"生产厂家"`
}
type CpuDetail struct {
	Sum     int64 `json:"sum" description:"cpu总数"`
	Cores   int64 `json:"cores" description:"cpu核心数"`
	CpuList []Cpu `json:"cpuList" description:"cpu列表"`
}
type Cpu struct {
	Name        string  `json:"name" description:"名称"`
	State       int     `json:"state" description:"健康状态 1:健康；2：告警；3：故障；0：未知"`
	UsedRate    float64 `json:"usedRate" description:"使用率"`
	Temperature int     `json:"temperature" description:"温度"`
	Model       string  `json:"model" description:"型号"`
	ClockSpeed  string  `json:"cloudSpeed" description:"主频"`
	MaxClock    string  `json:"maxClock" description:"最大主频"`
	Cores       int     `json:"cores" description:"核心数"`
	Threads     int     `json:"threads" description:"线程数"`
	L1Cache     string  `json:"l1Cache" description:"L1缓存"`
	L2Cache     string  `json:"l2Cache" description:"L2缓存"`
	L3Cache     string  `json:"l3Cache" description:"L3缓存"`
}

type MemDetail struct {
	Sum      int64          `json:"sum" description:"总数"`
	Capacity string         `json:"capacity" description:"总容量"`
	MemList  []MemoryDetail `json:"cpuList" description:"内存列表"`
}

type MemoryDetail struct {
	Name          string  `json:"name" description:"名称"`
	State         int     `json:"state" description:"健康状态 1:健康；2：告警；3：故障；0：未知"`
	UsedRate      float64 `json:"usedRate" description:"使用率"`
	In            string  `json:"in" description:"在位信息"`
	Position      string  `json:"positon" description:"位置"`
	Channl        string  `json:"channl" description:"通道"`
	Slot          string  `json:"slot" description:"插槽"`
	Model         string  `json:"model" description:"型号"`
	Ranks         string  `json:"ranks" description:"ranks"`
	Width         int     `json:"width" description:"位宽"`
	MaxClock      string  `json:"maxClock" description:"最大主频"`
	Capacity      int     `json:"capacity" description:"容量"`
	Tech          string  `json:"tech" description:"技术"`
	Sn            string  `json:"sn" description:"序列号"`
	ProductNum    string  `json:"productNum" description:"产品部件号"`
	ProducFactory string  `json:"productFactory" description:"生产厂家"`
}

// type Disk struct {
// 	Name          string  `json:"name" description:"名称"`
// 	State         string  `json:"state" description:"健康状态"`
// 	UpDown        string  `json:"upDown description:"启用状态"`
// 	UsedRate      float64 `json:"usedRate" description:"使用率"`
// 	In            string  `json:"in" description:"在位信息"`
// 	Capacity      string  `json:"capacity" description:"容量"`
// 	Domain        string  `json:"domain" description:"硬盘域"`
// 	Model         string  `json:"model" description:"型号"`
// 	DiskType      string  `json:"diskType" description:"类型"`
// 	ProducFactory string  `json:"productFactory" description:"生产厂家"`
// 	Sn            string  `json:"sn" description:"序列号"`
// }

type Power struct {
	Id              string `json:"id" description:"序号"`
	State           int    `json:"state" description:"健康状态 1:健康；2：告警；3：故障；0：未知"`
	In              string `json:"in" description:"在位信息"`
	Temperature     int    `json:"temperature" description:"温度"`
	RatedPower      string `json:"ratePower" description:"额定功率"`
	InputPower      string `json:"inputPower" description:"输入功率"`
	PowerInputModel string `json:"powerInputModel" description:"电源输入模式"`
	Model           string `json:"model" description:"型号"`
	FireWare        string `json:"fireWare" description:"固件"`
	Sn              string `json:"sn" description:"序列号"`
	ProductNum      string `json:"productNum" description:"产品部件号"`
	ProducFactory   string `json:"productFactory" description:"生产厂家"`
}

type Fan struct {
	Name       string  `json:"name" description:"名称"`
	State      int     `json:"state" description:"健康状态 1:健康；2：告警；3：故障；0：未知"`
	In         string  `json:"in" description:"在位信息"`
	Speed      int     `json:"speed" description:"转速"`
	SpeedRate  float64 `json:"speedRate" description:"速率比"`
	Redundancy string  `json:"redundancy" description:"冗余"`
}

type (
	SwitchFan struct {
		Name       string  `json:"name"`
		Health     int     `json:"health"` //1:健康；2：告警；3：故障；0：未知
		Exist      bool    `json:"exist"`  //false:不在位；true：在位
		Speed      int     `json:"speed"`  //rpm
		SpeedRatio float64 `json:"speedRatio"`
		Redundant  bool    `json:"redundant"` //false:不冗余；true：冗余
	}

	SwitchPower struct {
		Name            string `json:"name"`
		Health          int    `json:"health"` //1:健康；2：告警；3：故障；0：未知
		Exist           bool   `json:"exist"`  //false:不在位；true：在位
		Temperature     int    `json:"temperature"`
		RatedPower      int    `json:"ratedPower"`
		InPower         int    `json:"inPower"`
		InModel         string `json:"inModel"`
		PowerType       string `json:"powerType"`
		FirmwareVersion string `json:"firmwareVersion"`
		MfgName         string `json:"mfgName"`
		SerialNum       string `json:"serialNum"`
		PartNum         string `json:"partNum"`
	}

	SwitchCpu struct {
		Name        string  `json:"name"`
		Health      int     `json:"health"` //1:健康；2：告警；3：故障；0：未知
		Utilization float64 `json:"utilization"`
		Temperature int     `json:"temperature"`
		CpuType     string  `json:"cpuType"`
		MainHertz   float64 `json:"mainHertz"`
		MaxHertz    float64 `json:"maxHertz"`
		CacheLv     int     `json:"cacheLv"` //1：1级；2：2级；3：3级
	}

	SwitchMemory struct {
		Name        string  `json:"name"`
		Health      int     `json:"health"` //1:健康；2：告警；3：故障；0：未知
		Utilization float64 `json:"utilization"`
		Exist       bool    `json:"exist"` //false:不在位；true：在位
		Location    string  `json:"location"`
		Tunnel      string  `json:"tunnel"`
		SlotNum     string  `json:"slotNum"`
		MemType     string  `json:"memType"`
		Ranks       string  `json:"ranks"`
		BitWide     int     `json:"bitWide"`
		MaxHertz    float64 `json:"maxHertz"`
		Capacity    int     `json:"capacity"`
		Technology  string  `json:"technology"`
		MfgName     string  `json:"mfgName"`
		SerialNum   string  `json:"serialNum"`
		PartNum     string  `json:"partNum"`
	}

	SwitchBoard struct {
		Name             string `json:"name"`
		Health           int    `json:"health"` //1:健康；2：告警；3：故障；0：未知
		ManufacturedDate string `json:"manufacturedDate"`
		MfgName          string `json:"mfgName"`
		SerialNum        string `json:"serialNum"`
		PartNum          string `json:"partNum"`
	}

	SwitchView struct {
		AirInLet    int          `json:"airInLet"`
		AirOutLet   int          `json:"airOutLet"`
		IfHealth    SwitchHealth `json:"ifHealth"`
		CpuHealth   SwitchHealth `json:"cpuHealth"`
		MemHealth   SwitchHealth `json:"memHealth"`
		PowerHealth SwitchHealth `json:"powerHealth"`
		FanHealth   SwitchHealth `json:"fanHealth"`
	}

	SwitchHealth struct {
		Normal   int `json:"normal" gorm:"column:normal"`
		AbNormal int `json:"abNormal" gorm:"column:ab_normal"`
		Alarm    int `json:"alarm" gorm:"column:alarm"`
		UnKnown  int `json:"unKnown" gorm:"column:unKnown"`
		Total    int `json:"total" gorm:"column:total"`
	}
)

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/eip/response.go
```golang
package eip

import (
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

type Result struct {
	Code    int         `json:"code"`
	Message string      `json:"messgae"`
	Data    interface{} `json:"data"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

//overview
type EipPoolOverviewResponse struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}
type EipOverviewResponse struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverView struct {
	Region string             `json:"region"`
	Az     string             `json:"az"`
	Alerts []models.AlertType `json:"alerts"`
}

//overviewLine
type OverviewLineResponse struct {
	Code    int                `json:"code"`
	Message string             `json:"message"`
	Data    []OverviewLineData `json:"data"`
}

type OverviewLineData struct {
	Region  string       `json:"region"`
	Az      string       `json:"az"`
	Lab     string       `json:"lab"`
	Name    string       `json:"name"`
	Unit    string       `json:"unit"`
	Echarts []Echart `json:"echarts"`
}

type Echart struct {
	Info   MetricLineInfo       `json:"info"`
	Values []services.ValueType `json:"values"`
}

type MetricLineInfo struct {
	Tyte     string `json:"_type"`
	Index    int    `json:"_index"`
	Name     string `json:"name" description:"指标名称"`
	Number   int    `json:"number" description:"总数之类的统计值"`
	Start    string `json:"start" description:"开始时间"`
	End      string `json:"end" description:"结束时间"`
	Unit     string `json:"unit" description:"指标的单位"`
	UnitType string `json:"unitType" description:"指标的单位类型"`
}


type EipTop struct {
	ID     string      `json:"id"`
	EipId  string      `json:"eidId"`
	Name   string      `json:"name"`
	Value  interface{} `json:"value"`
	Status string      `json:"status"`
}


// type IfMetricSingleLineResponse struct {
// 	Code    int              `json:"code"`
// 	Message string           `json:"message"`
// 	Data    []MetricLineType `json:"data"`
// }

// type MetricLineType struct {
// 	Id      string   `json:"id"`
// 	Name    string   `json:"name"`
// 	SubName string   `json:"subName"`
// 	Start   string   `json:"start"`
// 	End     string   `json:"end"`
// 	Echarts []Echart `json:"echarts"`
// }




//overviewTop
type OverviewTopResponse struct {
	Code    int               `json:"code"`
	Message string            `json:"message"`
	Data    []OverviewTopData `json:"data"`
}

type OverviewTopData struct {
	Echarts []Echart `json:"echarts"`
}

//poollist
type EipPoolListResp struct {
	Code    int               `json:"code"`
	Message string            `json:"messgae"`
	Data    EipPoolListResult `json:"data"`
}
type EipPoolListResult struct {
	PageStruct
	DataList []EipPool `json:"dataList"`
}

type EipPool struct {
	NetSegment  string  `json:"netSegment" description:"资源池名称（网段）"`
	Region      string  `json:"region" description:"资源池所在区域"`
	EipTotal    int     `json:"eipTotao" description:"弹性ip总数"`
	IpUsedRate  float64 `json:"ipUsedRate" description:"ip使用率"`
	IpAvaRate   float64 `json:"ipAvaRate" description:"ip可用率"`
	InFlow      string  `json:"inFlow" description:"入网流量"`
	OutFlow     string  `json:"outFlow" description:"出网流量"`
	OutPackages string  `json:"outPackages"  description:"每秒流出包数"`
	InPackages  string  `json:"inPackages"  description:"每秒流入包数"`
	AlertNumber int     `json:"alertNumber" description:"告警数量"`
	CreateTime  int     `json:"createTime"` //秒级时间戳
	Label       string  `json:"label" description:"标签"`
}

//list
type EipListResp struct {
	Code    int           `json:"code"`
	Message string        `json:"messgae"`
	Data    EipListResult `json:"data"`
}
type EipListResult struct {
	PageStruct
	DataList       []Eip    `json:"dataList"`
	NetSegmentList []string `json:"netSegmentList"`
}

type Eip struct {
	Id          string `json:"id"`
	Eip         string `json:"eip" description:"ip地址"`
	XgwCluster  string `json:"xgwCluster"` // eip 所属资源池
	State       string `json:"state" description:"状态:banded(已绑定)/unband(已分配未绑定)/unallocated(未分配)/reserver(保留)"`
	Region      string `json:"region" description:"所属区域"`
	NetSegment  string `json:"netSegment" description:"资源池名称（网段）"`
	LineType    string `json:"lineType" description:"线路类型:bgp/console_eip/giant内网链路"`
	BandWidth   string `json:"bandWidth" description:"带宽"`
	IpVersion   string `json:"ipVersion" description:"ip版本"`
	OutBandRate float64 `json:"outBandRate" description:"出向带宽利用率"`
	InBandRate  float64 `json:"inBandRate" description:"入向带宽利用率"`
	InFlow      float64 `json:"inFlow" description:"入网流量"`
	OutFlow     float64 `json:"outFlow" description:"出网流量"`
	OutPackages float64 `json:"outPackages"  description:"每秒流出包数"`
	InPackages  float64 `json:"inPackages"  description:"每秒流入包数"`
	AlertNumber int    `json:"alertNumber" description:"告警数量"`
	Label       string `json:"label" description:"标签"`
	HostId      string `json:"hostId"`
	CreateTime  int    `json:"createTime"` //秒级时间戳
}

//资源池的监控详情
type NetSegmentResponse struct {
	Code    int              `json:"code"`
	Message string           `json:"message"`
	Data    []MetricLineType `json:"data"`
}

type MetricLineType struct {
	Id      string   `json:"id"`
	Name    string   `json:"name"`
	SubName string   `json:"subName"`
	Start   string   `json:"start"`
	End     string   `json:"end"`
	Echarts []Echart `json:"echarts"`
}
type EipResponse struct {
	Code    int              `json:"code"`
	Message string           `json:"message"`
	Data    []MetricLineType `json:"data"`
}

type EipPoolUsageResponse struct {
	Code    int                  `json:"code"`
	Message string               `json:"message"`
	Data    []EipPoolUsageResult `json:"data"`
}

type EipPoolUsageResult struct {
	PageStruct
	DataList []EipPoolUsage `json:"dataList"`
}

type EipPoolUsage struct {
	Region     string  `json:"region"`
	Pool       string  `json:"pool"`
	IpVersion  string  `json:"ipVersion" description:"ip版本"`
	IpTotal    int     `json:"ipTotal" description:"ip总数"`
	UsedNum    int     `json:"usedNum" description:"已使用ip数"`
	AvaNum     int     `json:"avaNum" description:"可用ip数"`
	ReserveNum int     `json:"reserveNum" description:"保留ip数"`
	UsedRate   float64 `json:"usedRate" description:"ip使用率"`
	AvaRate    float64 `json:"avaRate" description:"ip可用率"`
	CreateTime int     `json:"createTime"` //秒级时间戳
}

type Clusters struct {
	Id   string `json:"id"`
	Name string `json:"name"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/eip/util.go
```golang
package eip

//eip
type CmdbEip struct {
	Id         string `json:"id"`
	XgwCluster string `json:"xgwCluster"` // eip 所属资源池
	IpAddr     string `json:"ipAddr"`
	BoundId    string `json:"boundId"`    // 绑定实例Id
	BoundState int    `json:"boundState"` //0:保留；1:未分配；2：已分配未绑定；3已绑定
	NetSegName string `json:"netSegName"`
	Cidr       string `json:"cidr"`
	RegionCode string `json:"regionCode"`
	RegionName string `json:"regionName"`
	IpVersion  string `json:"ipVersion"`
	WayType    string `json:"wayType"`
	TenantId   string `json:"tenantId"`
	BoundType  string `json:"boundType"`
	BoundName  string `json:"boundName"`
	NetCard    string `json:"netCard"`
	CardType   string `json:"cardType"`
	Bandwidth  string `json:"bandWidth"`
	//RowNum int `json:"-"`
	CreateTime int `json:"createTime"` //秒级时间戳
}

type CmdbEipListResponse struct {
	Code    int             `json:"code"`
	Message string          `json:"messgae"`
	Data    CmdbEipListData `json:"data"`
}

type CmdbEipListData struct {
	PageStruct
	DataList []CmdbEip
}

type CmdbEipListQuery struct {
	Region []string `json:"region"`
	// Az          []string `json:"az"`
	PageNo      int      `json:"pageNo"`
	PageSize    int      `json:"pageSize"`
	BoundState  []int    `json:"boundState"`
	SearchKey   string   `json:"searchKey"`
	SearchValue string   `json:"searchValue"`
	BoundType   []string `json:"boundType"`
	PoolName    string   `json:"poolName"`
	Cidr []string `json:"cidr"` // 所属网段
	WayType []string `json:"wayType"` // 线路类型
	// OrderCode   string   `json:"orderCode"`
	// OrderType   string   `json:"orderType"`
	// Ip          string   `json:"ip"`
}

//eipPool
type Segment struct {
	Id                  string  `json:"id"`
	Cidr                string  `json:"cidr"`
	NetSegName          string  `json:"netSegName"`
	RegionCode          string  `json:"regionCode"`
	RegionName          string  `json:"regionName"`
	RegionAggregateCode string  `json:"regionAggregateCode"`
	IpVersion           string  `json:"ipVersion"`
	IpCount             int     `json:"ipCount"`
	UsedIpCount         int     `json:"usedIpCount"`
	RemainingIpCount    int     `json:"remainingIpCount"`
	RetainedIpCount     int     `json:"retainedIpCount"`
	AvailableRatio      float64 `json:"availableRatio"`
	UsedRatio           float64 `json:"usedRatio"`
	CreateTime          int     `json:"createTime"` //秒级时间戳
}

type CmdbEipPoolListResponse struct {
	Code    int                 `json:"code"`
	Message string              `json:"messgae"`
	Data    CmdbEipPoolListData `json:"data"`
}

type CmdbEipPoolListData struct {
	PageStruct
	DataList []Segment
}

type CmdbEipPoolListQuery struct {
	//Region []string `json:"region"`
	// Az          []string `json:"az"`
	PageNo   int `json:"pageNo"`
	PageSize int `json:"pageSize"`
	// SearchKey   string   `json:"searchKey"`
	// SearchValue string   `json:"searchValue"`
	// Pool        string   `json:"pool"`
	// OrderCode   string   `json:"orderCode"`
	// OrderType   string   `json:"orderType"`
	// Ip          string   `json:"ip"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/eip/parameter.go
```golang
package eip

//overview
type EipOverviewQuery struct {
	Region string `json:"region"`
	Az     string `json:"az"`
}

//overviewLine
type EipOverviewLineQuery struct {
	Region string   `json:"region"`
	Az     string   `json:"az"`
	Name   []string `json:"name"`
	TopK   string   `jons:"topk"`
	Start  float64  `json:"start"`
	End    float64  `json:"end"`
	Step   float64  `json:"step"`
}

//list
type EipListQuery struct {
	Region      string   `json:"region"`
	Az          []string `json:"az"`
	PageNo      int      `json:"pageNo"`
	PageSize    int      `json:"pageSize"`
	SearchKey   string   `json:"searchKey"`
	SearchType   string   `json:"searchType"`
	SearchValue string   `json:"searchValue"`
	OrderCode   string   `json:"orderCode"`
	OrderType   string   `json:"orderType"`
	Ip          string   `json:"ip"`
	State       []string `json:"state"` // 状态
	NetSegment  []string `json:"netSegment"`
	LineType    []string `json:"lineType"`
	XgwCluster  []string `json:"xgwCluster"`
	BoundState  []int    `json:"boundState"`
	BoundType   []string `json:"boundType"`
	PoolName    string   `json:"poolName"`
	Cidr []string `json:"cidr"` // 所属网段
	WayType []string `json:"wayType"` // 线路类型
}



//metric
type EipMetricLineQuery struct {
	Ip    string   `json:"ip"`
	Id    string   `json:"id"`
	Name  []string `json:"name"`
	Start float64  `json:"start"`
	End   float64  `json:"end"`
	Step  float64  `json:"step"`
}

//eipPool
type EipPoolOverviewQuery struct {
	Region string `json:"region"`
	Az     string `json:"az"`
}

//overviewLine
type EipPoolOverviewLineQuery struct {
	Region string   `json:"region"`
	Az     string   `json:"az"`
	Name   []string `json:"name"`
	Start  int64    `json:"start"`
	End    int64    `json:"end"`
	Step   int64    `json:"step"`
}

//list
type EipPoolListQuery struct {
	Region      string   `json:"region"`
	Az          []string `json:"az"`
	PageNo      int      `json:"pageNo"`
	PageSize    int      `json:"pageSize"`
	SearchKey   string   `json:"searchKey"`
	SearchValue string   `json:"searchValue"`
	Pool        string   `json:"pool"`
	OrderCode   string   `json:"orderCode"`
	OrderType   string   `json:"orderType"`
}

//metric
type EipPoolMetricLineQuery struct {
	NetSegment string   `json:"netSegment"`
	Name       []string `json:"name"`
	Start      int64    `json:"start"`
	End        int64    `json:"end"`
	Step       int      `json:"step"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/models/block/block.go
```golang
package block

import (
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

type ListQuery struct {
	PageNo        int      `json:"pageNo"`
	PageSize      int      `json:"pageSize"`
	Region        string   `json:"region"`
	Az            []string `json:"az"`
	Lab           string   `json:"lab"`
	Name          string   `json:"name"`
	TenantId      string   `json:"tenantId"`
	InnerIp       string   `json:"innerIp"`
	OuterIp       string   `json:"outerIp"`
	Label         string   `json:"label"`
	State         string   `json:"state"`
	PhysicalHost  string   `json:"physical_host"`
	Pool          string   `json:"pool"`
	StorageType   []string `json:"storageType"`
	UseStatus     []string `json:"useStatus"`
	RunningStatus []string `json:"runningStatus"`
	SearchKey     string   `json:"searchKey"`
	SearchValue   string   `json:"searchValue"`
	OrderCode     string   `json:"orderCode"`
	OrderType     string   `json:"orderType"`
}

//overviewLine
type BlockOverviewLineQuery struct {
	Region   string   `json:"region"`
	Az       string   `json:"az"`
	Name     []string `json:"name"`
	TopK     string   `jons:"topk"`
	Start    float64  `json:"start"`
	End      float64  `json:"end"`
	Step     float64  `json:"step"`
	DiskType string   `json:"diskType"`
}
type OverviewLineData struct {
	Region  string        `json:"region"`
	Az      string        `json:"az"`
	Lab     string        `json:"lab"`
	Name    string        `json:"name"`
	Unit    string        `json:"unit"`
	Echarts []BlockEchart `json:"echarts"`
}
type OverViewSuccess struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    OverView `json:"data"`
}

type OverViewParameter struct {
	AzCode     string `json:"az"`
	RegionCode string `json:"region"`
	DiskType   string `json:"diskType"`
}

type AlertLevels struct {
	P0 int `json:"p0"`
	P1 int `json:"p1"`
	P2 int `json:"p2"`
	P3 int `json:"p3"`
}
type OverView struct {
	Alerts  []resourcepoolmodel.AlertType `json:"alerts"`
	Echarts []EchartType                  `json:"echarts"`
}

type EchartType struct {
	Name string      `json:"name"`
	Data []ChartInfo `json:"data"`
}

type ChartInfo struct {
	Info   InfoType    `json:"info"`
	Values []ValueType `json:"values"`
}

type InfoType struct {
	Region  string `json:"region,omitempty"`
	Az      string `json:"az,omitempty"`
	Lab     string `json:"lab,omitempty"`
	Label   string `json:"label,omitempty"`
	Name    string `json:"name,omitempty"`
	SubName string `json:"subName,omitempty"`
	//Sub2Name string `json:"sub2Name"`
	Total    interface{} `json:"total"`
	Value    interface{} `json:"value"`
	Unit     string      `json:"unit"`
	UnitType string      `json:"unitType"`
}

//OverviewTop
type OverViewTopSuccess struct {
	Code    int            `json:"code"`
	Message string         `json:"message"`
	Data    []OverViewLine `json:"data"`
}

type OverViewLine struct {
	Region   string   `json:"region"`
	Az       string   `json:"az"`
	Name     string   `json:"name"`
	Unit     string   `json:"unit"`
	DiskType string   `json:"diskType"`
	Echarts  []Echart `json:"echarts"`
}

//metric
type MetricSuccess struct {
	Code    int          `json:"code"`
	Message string       `json:"message"`
	Data    []MetricInfo `json:"data"`
}
type MetricInfo struct {
	Id         string `json:"id"`
	Name       string `json:"name"`
	Label      string `json:"label"`
	Unit       string `json:"unit"`
	StatusText string `json:"statusText"`
	Number     string `json:"number"`
	Type       string `json:"type"`
	Kind       string `json:"kind"`
}

type MetricLineSuccess struct {
	Code    int              `json:"code"`
	Message string           `json:"message"`
	Data    []MetricLineType `json:"data"`
}

type MetricLineType struct {
	Id      string   `json:"id"`
	Label   string   `json:"label"`
	Name    string   `json:"name"`
	Number  string   `json:"number"`
	Echarts []Echart `json:"echarts"`
}

type Echart struct {
	Info   services.InfoType    `json:"info"`
	Values []services.ValueType `json:"values"`
}

type BlockEchart struct {
	Info   services.InfoType         `json:"info"`
	Values []services.BlockValueType `json:"values"`
}

type MetricLineInfo struct {
	Id      string `json:"id"`
	Name    string `json:"name"`
	Unit    string `json:"unit"`
	SubName string `json:"subName"`
	Start   string `json:"start"`
	End     string `json:"end"`
}

//common
type ValueType struct {
	Value      interface{} `json:"value"`
	Name       string      `json:"name"`
	Timestamep string      `json:"timestamep,omitempty"`
	Label      string      `json:"label,omitempty"`
}

//other
type Result struct {
	Code    int         `json:"code"`
	Message string      `json:"message"`
	Data    interface{} `json:"data"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

type MetricQuery struct {
	Id    string   `json:"id"`
	Name  []string `json:"name"`
	Start float64  `json:"start"`
	End   float64  `json:"end"`
}
type MonitorBlocksSuccess struct {
	Code    int           `json:"code"`
	Message string        `json:"message"`
	Data    MonitorBlocks `json:"data"`
}

type MonitorBlocks struct {
	PageStruct
	DataList []MonitorBlock `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type MonitorBlock struct {
	ID            string  `json:"id"`
	Name          string  `json:"name"`
	UseStatus     string  `json:"useStatus"`
	RunningStatus string  `json:"runningStatus"`
	Region        string  `json:"region"`
	Az            string  `json:"az"`
	TenantId      string  `json:"tenantId"`
	TenantName    string  `json:"tenantName"`
	CreateTime    int64   `json:"createTime"`
	StorageType   string  `json:"storageType"`
	UsePercent    float64 `json:"usePercent"`
	Size          int     `json:"size"`
	BlockPool     string  `json:"blockPool"`
	RIO           float64 `json:"rio"`
	WIO           float64 `json:"wio"`
	RBand         string  `json:"rBand"`
	WBand         string  `json:"wBand"`
	MonitorStatus string  `json:"monitorStatus"`
	AlertNumber   int     `json:"alertNumber"`
	VmId          string  `json:"vmId"`
	MountPoint    string  `json:"mountPoint"`
}

type TopQuery struct {
	Region   string   `json:"region"`
	Az       string   `json:"az"`
	Name     []string `json:"name"`
	DiskType string   `json:"diskType"`
	Start    float64  `json:"start"`
	End      float64  `json:"end"`
	TopK     string   `json:"topk"`
}
type CmdbTopBlock struct {
	ID     string      `json:"id"`
	Name   string      `json:"name"`
	Value  interface{} `json:"value"`
	Status string      `json:"status"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/version/version.go
```golang
package version

import (
	"fmt"
)

var (
	Version   = "v0.1"
	GitHash   = "unknown"
	BuildTime = "unknown"
	GoVersion = "unknown"
)

func Info() string {
	return fmt.Sprintf("Version: %s\nGitHash: %s\nBuildTime: %s\nGoVersion: %s\n", Version, GitHash, BuildTime, GoVersion)
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/version/version-handler.go
```golang
package version

import "github.com/emicklei/go-restful/v3"

func NewVersionService() *restful.WebService {
	ws := new(restful.WebService)
	ws.
		Path("/version").
		Consumes(restful.MIME_XML, restful.MIME_JSON).
		Produces(restful.MIME_JSON, restful.MIME_XML)

	ws.Route(ws.GET("/").To(getVersion).Doc("Version"))
	return ws
}

func getVersion(request *restful.Request, response *restful.Response) {
	s := Info()
	response.Write([]byte(s))
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/client/alert-client.go
```golang
package client

import (
	"context"

	"github.com/prometheus/alertmanager/api/v2/client"
	"github.com/prometheus/alertmanager/api/v2/client/alert"
	"github.com/prometheus/alertmanager/api/v2/models"
	"k8s.io/klog/v2"
)

type AlertClient struct {
	apiClient *client.Alertmanager
}

var defaultAlertClient = NewAlertClient()

func NewAlertClient() *AlertClient {
	return &AlertClient{
		apiClient: defaultAlertManager(),
	}
}
func defaultAlertManager() *client.Alertmanager {
	config := client.TransportConfig{}
	inCluster := true
	if GetClient() == nil {
		inCluster = false
	}
	if inCluster {
		config.Host = "pm-kube-prometheus-stack-alertmanager.monitoring:9093"
	} else {
		config.Host = "luban.alert.galaxy.cloud"
	}
	config.BasePath = "/api/v2"
	clientAlert := client.NewHTTPClientWithConfig(nil, &config)

	return clientAlert
}
func (ac *AlertClient) GetAlerts(params *alert.GetAlertsParams) (models.GettableAlerts, error) {

	res, err := ac.apiClient.Alert.GetAlerts(params)
	if err != nil {
		klog.Error(err)
		return nil, err
	}
	if res == nil {
		return nil, err
	}
	return res.Payload, err
}
func GetAlerts(params *alert.GetAlertsParams) (models.GettableAlerts, error) {
	//var silenced bool = false
	//var inhibited bool = false
	//var active bool = true
	//ctx, cancel := context.WithTimeout(context.TODO(), TimeOut)
	//defer cancel()
	//params := &alert.GetAlertsParams{
	//	Silenced:  &silenced,
	//	Active:    &active,
	//	Inhibited: &inhibited,
	//	Context:   ctx,
	//	Filter:    []string{"lubanAlarmView=端口状态"},
	//}
	ctx, cancel := context.WithTimeout(context.TODO(), TimeOut)
	defer cancel()
	params.Context = ctx
	return defaultAlertClient.GetAlerts(params)
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/client/outer-client.go
```golang
package client

import (
	"flag"

	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
	"k8s.io/client-go/tools/clientcmd"
)

var (
	OuterClient   *kubernetes.Clientset
	RestfulConfig *rest.Config
)

func GetOuterClient() *kubernetes.Clientset {
	if InnerClient != nil {
		return OuterClient
	} else {
		return initOuterClient()
	}
}

func initOuterClient() *kubernetes.Clientset {

	var kubeconfig *string
	kubeconfig = flag.String("kubeconfig", "~/.kube/", "absolute path to the kubeconfig file")

	flag.Parse()

	// use the current context in kubeconfig
	config, err := clientcmd.BuildConfigFromFlags("", *kubeconfig)
	if err != nil {
		panic(err.Error())
	}

	// create the clientset
	clientset, e := kubernetes.NewForConfig(config)
	if e != nil {
		panic(e.Error())
	}
	return clientset
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/client/inner-client.go
```golang
package client

import (
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
	"k8s.io/klog/v2"
)

var (
	InnerClient *kubernetes.Clientset
	RestConfig  *rest.Config
)

func GetClient() *kubernetes.Clientset {
	if InnerClient != nil {
		return InnerClient
	} else {
		return initClient()
	}
}
func GetToken() string {
	if RestConfig == nil {
		RestConfig, _ = rest.InClusterConfig()
	}
	return RestConfig.BearerToken
}

func initClient() *kubernetes.Clientset {

	config, err := rest.InClusterConfig()

	if err != nil {
		klog.Errorf("init k8s inner client error: %v", err.Error())
		return nil
	}
	// creates the clientset
	clientset, err := kubernetes.NewForConfig(config)
	if err != nil {
		klog.Errorf("get k8s inner client set error: %v", err.Error())
		return nil
	}
	return clientset
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/client/redisclusterConn.go
```golang
package client

import (
	"context"
	"errors"
	"github.com/go-redis/redis/v8"
	"k8s.io/klog/v2"
	"os"
	"time"
)

var (
	rClient *redis.Client
)

const (
	DbmsRdsLogsErrlog    = "dbms_rds_logs_errlog"
	DbmsRdsLogsSlowQuery = "dbms_rds_logs_slowquery"
	DbmsRdsLogsBinlog    = "dbms_rds_logs_binlog"
)

func init() {
	//var rHost = "asset.luban.sdns.galaxy.cloud:9379"

	var rHost = "asset.luban.sdns.galaxy.cloud:32753"
	var rPassword = "123456"

	rHost = os.Getenv("REDIS_CLIENT_HOST")
	rPassword = os.Getenv("REDIS_CLIENT_PASSWORD")
	//if inK8s() {
	//	rHost = "redis-master.luban:6379"
	//	klog.Info("eip gredis in kubernetes")
	//}
	klog.Info("REDIS_CLIENT_HOST ", rHost)
	klog.Info("REDIS_CLIENT_PASSWORD ", rPassword)
	rClient = redis.NewClient(&redis.Options{
		Addr:     rHost,
		Password: rPassword,
		DB:       0, // use default DB
	})
}

// 判断是否在k8s内
func inK8s() bool {
	return len(os.Getenv("KUBERNETES_SERVICE_HOST")) > 0
}

/**
*	hash设置 键值
*	@param: k key
*	@param: field字段
*	@param: v 值
 */
func HSet(ctx context.Context, k, field string, v interface{}) (rs int64, err error) {
	return rClient.HSet(ctx, k, field, v).Result()
}

func HDel(ctx context.Context, k, field string) (rs int64, err error) {
	return rClient.HDel(ctx, k, field).Result()
}
func HDelBatch(ctx context.Context, k string, fields []string) (rs int64, err error) {
	return rClient.HDel(ctx, k, fields...).Result()
}

/**
*	hash获取值
*	@param:
*	@param:k key
 */
func HGet(ctx context.Context, k, field string) (rs string, err error) {
	return rClient.HGet(ctx, k, field).Result()
}

func HGetAll(ctx context.Context, k string) (rs map[string]string, err error) {
	return rClient.HGetAll(ctx, k).Result()
}

/**
*	获取hash所有fields
*	@param: context 实例
*	@param: k 键
 */
func HKeys(ctx context.Context, k string) (rs []string, err error) {
	return rClient.HKeys(ctx, k).Result()
}

/**
*	获取hash多个值
*	@param: context 实例
*	@param: k 键
*	@param: field 要获取的字段
 */
func HMGet(ctx context.Context, k string, fields []string) (rs []interface{}, err error) {
	return rClient.HMGet(ctx, k, fields...).Result()
}

// Expire
/**
*	设置过期时间
*	@param: context 实例
*	@param: k 键
*	@param: expiration 过期时间 单位秒
*	@return: rs bool 设置成功失败 err 错误信息
 */
func Expire(ctx context.Context, k string, expiration int) (rs bool, err error) {
	return rClient.Expire(ctx, k, time.Duration(expiration)*time.Second).Result()
}

func Set(ctx context.Context, k string, v interface{}) (rs string, err error) {
	return rClient.Set(ctx, k, v, 1).Result()
}

func SetNotExpire(ctx context.Context, k string, v interface{}) (rs string, err error) {
	return rClient.Set(ctx, k, v, -1).Result()
}

func Get(ctx context.Context, k string, v interface{}) (rs string, err error) {
	return rClient.Get(ctx, k).Result()
}

func ZAdd(ctx context.Context, k string, scores []float64, members []interface{}) (rs int64, err error) {
	if len(scores) != len(members) {
		return 0, errors.New("zadd scores != members")
	}
	zs := make([]*redis.Z, 0)
	for i, v := range scores {
		zs = append(zs, &redis.Z{
			Score:  v,
			Member: members[i],
		})
	}
	return rClient.ZAdd(ctx, k, zs...).Result()
}

func ZAddNx(ctx context.Context, k string, scores float64, members interface{}) (rs int64, err error) {
	zs := &redis.Z{Score: scores, Member: members}
	return rClient.ZAddNX(ctx, k, zs).Result()
}

/**
*	遍历有序集合 递减排序
*	@param: context 实例
*	@param: k 键
*	@param: s 开始位置
*	@param: s 结束位置
 */
func ZRevRange(ctx context.Context, k string, start, stop int64) (rs []string, err error) {
	return rClient.ZRevRange(ctx, k, start, stop).Result()
}

/**
*	遍历有序集合 递增排序
*	@param: context 实例
*	@param: k 键
*	@param: s 开始位置
*	@param: s 结束位置
 */
func ZRange(ctx context.Context, k string, s, e int64) (rs []string, err error) {
	return rClient.ZRange(ctx, k, s, e).Result()
}

/**
*	删除指定键的值
*	@param: context 实例
*	@param: key 键
*	@return :v 1 成功 0 没有该键
 */
func Del(ctx context.Context, k string) (rs int64, err error) {
	return rClient.Del(ctx, k).Result()
}

/**
*	重命名指定键
*	@param: context 实例
*	@param: key 键
*	@return :v 1 成功 0 没有该键
 */
func Rename(ctx context.Context, oldKey, newKey string) (rs string, err error) {
	return rClient.Rename(ctx, oldKey, newKey).Result()
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/client/ks3-client.go
```golang
package client

import (
	"fmt"
	"github.com/ks3sdklib/aws-sdk-go/aws"
	"github.com/ks3sdklib/aws-sdk-go/aws/credentials"
	"github.com/ks3sdklib/aws-sdk-go/service/s3"
	"k8s.io/klog/v2"
	"os"
	"time"
)

var (
	ks3Client *s3.S3
)

func init() {
	ak := os.Getenv("KS3_AK")
	klog.Info("KS3_AK",ak)
	if ak == ""{
		ak = "AKLTKnBCVgZsQwOn9vJ4n_Qm1g"
	}
	sk := os.Getenv("KS3_SK")
	klog.Info("KS3_SK",sk)
	if sk == ""{
		sk = "OEeCCH0N+XSRyIn+I5MEa+Kou92ie6r2LGe10sIxCeB0F6qXuEsbWUGg9QJXHIIyUg=="
	}
	endpoint := os.Getenv("KS3_ENDPOINT")
	klog.Info("KS3_ENDPOINT",endpoint)
	if endpoint == ""{
		endpoint = "obs-cn-shanghai-2.yunyan.com"
	}
	credentials := credentials.NewStaticCredentials(ak, sk, "")
	ks3Client = s3.New(&aws.Config{
		Region: "shanghai",
		Credentials: credentials,
		Endpoint: endpoint, //ks3地址
		DisableSSL: true, //是否禁用https
		LogLevel: 1, //是否开启日志,0为关闭日志，1为开启日志
		S3ForcePathStyle: true, //是否强制使用path style方式访问,默认不使用，true开启
		LogHTTPBody: true, //是否把HTTP请求body打入日志
		Logger: os.Stdout, //打日志的位置
	})

}


// 获取日志列表
func ListObjects(BucketName ,Prefix ,Marker string ,MaxKeys int64  )(rst *s3.ListObjectsOutput , err error ) {

	resp, err := ks3Client.ListObjects(&s3.ListObjectsInput{
		Bucket: aws.String(BucketName),
		Prefix: aws.String(Prefix), //文件前缀
		Marker:  aws.String(Marker), //从按个key开始获取
		MaxKeys: aws.Long(MaxKeys), //最大数量
	})
	if err != nil {
		klog.Errorf("get ks3 ListObjects err :",err)
	}

	return resp ,nil
}

// 生成日志下载外连
func GetObjectInput(key ,fileName string) string  {

	filesName  := fmt.Sprintf("attachment; filename=%s",fileName)
	params := &s3.GetObjectInput{
		Bucket: aws.String("rds-cn-shanghai-2"), // bucket名称
		Key: aws.String( key), // object key
		ResponseContentDisposition: aws.String(filesName),
	}
	timeUnixNano := time.Duration(time.Now().UnixNano()+ int64(24 * time.Hour))

	resp, err := ks3Client.GetObjectPresignedUrl(params,timeUnixNano)

	//第二个参数为外链过期时间，为纳秒级的时间戳
	if err!=nil {
		klog.Errorf("get log download fdil ",err)
	}
	return  resp.String()
}
```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/client/alert-client_test.go
```golang
package client

import (
	"context"
	"github.com/prometheus/alertmanager/api/v2/client/alert"
	"k8s.io/klog/v2"
	"testing"
)

func TestAlertClient_GetAlerts(t *testing.T) {
	var silenced bool = false
	var inhibited bool = false
	var active bool = true
	ctx, cancel := context.WithTimeout(context.TODO(), TimeOut)
	defer cancel()
	params := &alert.GetAlertsParams{
		Silenced:  &silenced,
		Active:    &active,
		Inhibited: &inhibited,
		Context:   ctx,
		Filter:    []string{"lubanAlarmView=端口状态"},
	}
	res, err := defaultAlertClient.GetAlerts(params)
	if err != nil {
		klog.Error(err)
	}
	klog.Infof("res:%#v", res)
	// for _, v := range labels {
	// 	fmt.Println("key=", v.Metric["groupname"], "value=", v.Value)
	// }
	// tests := []struct {
	// 	name    string
	// 	ac      *AlertClient
	// 	want    *alert.GetAlertsOK
	// 	wantErr bool
	// }{
	// 	// TODO: Add test cases.
	// }
	// for _, tt := range tests {
	// 	t.Run(tt.name, func(t *testing.T) {
	// 		got, err := tt.ac.GetAlerts()
	// 		if (err != nil) != tt.wantErr {
	// 			t.Errorf("AlertClient.GetAlerts() error = %v, wantErr %v", err, tt.wantErr)
	// 			return
	// 		}
	// 		if !reflect.DeepEqual(got, tt.want) {
	// 			t.Errorf("AlertClient.GetAlerts() = %v, want %v", got, tt.want)
	// 		}
	// 	})
	// }
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/client/elastic.go
```golang
package client

import (
	"fmt"
	"github.com/olivere/elastic/v7"
	"k8s.io/klog/v2"
	"log"
	"os"
)

var (
	EsClient *elastic.Client
)

func init() {
	host := fmt.Sprintf("http://%s", "ks3es.luban.sdns.galaxy.cloud:9200")
	var err error
	EsClient, err = elastic.NewClient(elastic.SetURL(host), elastic.SetSniff(false),
		elastic.SetErrorLog(log.New(os.Stderr, "ES-ERROR ", log.LstdFlags)),
		elastic.SetInfoLog(log.New(os.Stdout, "ES-INFO ", log.LstdFlags)),
		elastic.SetTraceLog(log.New(os.Stdout, "ES-TRACE ", log.LstdFlags)))
	if err != nil {
		klog.Errorf("init bucket  elastic client error : %s", err.Error())
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/client/ipmi-client.go
```golang
package client
//
//import (
//	"fmt"
//	"github.com/eoidc/goipmi"
//)
//
//
//func IpmiClient() {
//	fmt.Println("ipmi init")
//
//	host := "10.254.32.110"
//	user := "ipmiuser"
//	password := "TXwWu5t#0l"
//
//	// 创建 IPMI 客户端
//	client, err := ipmi.NewClient(&ipmi.Connection{
//		Hostname:    host,
//		Port:        623,
//		Username:    user,
//		Password:    password,
//	})
//	if err != nil {
//		fmt.Println("Error creating IPMI client:", err)
//	}
//	defer client.Close()
//	// 获取 BMC 信息
//	bmcInfo, err := client.DeviceID()
//	if err != nil {
//		fmt.Println("Error getting BMC information:", err)
//	}
//	// 打印 BMC 信息
//	fmt.Printf("BMC manufacturer: %s\n", bmcInfo.ManufacturerID)
//	fmt.Printf("BMC product: %s\n", bmcInfo.ProductID)
//}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/client/prom-client.go
```golang
package client

import (
	"context"
	"github.com/prometheus/client_golang/api"
	"github.com/prometheus/client_golang/api/prometheus/v1"
	"github.com/prometheus/common/model"
	"k8s.io/klog/v2"
	"time"
)

const (
	TimeOut = 60 * time.Second
)

type PromClient struct {
	apiClient v1.API
}

var defaultClient = NewPromClient()

func NewPromClient() *PromClient {
	return &PromClient{
		apiClient: defaultPromQueryApi(),
	}
}

func defaultPromQueryApi() v1.API {
	promConfig := api.Config{}
	inCluster := true
	if GetClient() == nil {
		inCluster = false
	}
	if inCluster {
		promConfig.Address = "http://pm-kube-prometheus-stack-prometheus.monitoring:9090"
	} else {
		promConfig.Address = "http://luban.prometheus.galaxy.cloud"
	}
	client, err := api.NewClient(promConfig)
	if err == nil {
		return v1.NewAPI(client)
	}
	klog.Errorf("init prometheus client error : %s", err.Error())
	return nil
}

func (c *PromClient) Query(query string, ts time.Time) (model.Value, v1.Warnings, error) {
	klog.Infof("prometheus query sql: %s", query)
	ctx, cancel := context.WithTimeout(context.TODO(), TimeOut)
	defer cancel()
	return c.apiClient.Query(ctx, query, ts)
}

func (c *PromClient) QueryRange(query string, r v1.Range) (model.Value, v1.Warnings, error) {
	klog.Infof("prometheus query sql: %s", query)
	ctx, cancel := context.WithTimeout(context.TODO(), TimeOut)
	defer cancel()
	klog.Infof("prometheus range: %s", r)
	return c.apiClient.QueryRange(ctx, query, r)
}

func (c *PromClient) VectorQuery(query string) (v model.Vector, err error) {

	t := time.Now().Add(time.Second * -1)
	//time.Now()
	value, warnings, err := c.Query(query, t)
	if err != nil {
		klog.Errorf("prometheus query sql: %s, error: %v", query, err)
		return
	}
	if len(warnings) > 0 {
		klog.Warningf("prometheus query sql: %s, warnings: %v", query, warnings)
	}
	v, _ = value.(model.Vector)
	return
}

func (c *PromClient) VectorQuerySpecifiedTime(query string, ts time.Time) (v model.Vector, err error) {

	value, warnings, err := c.Query(query, ts)
	if err != nil {
		klog.Errorf("prometheus query sql: %s, error: %v", query, err)
		return
	}
	if len(warnings) > 0 {
		klog.Warningf("prometheus query sql: %s, warnings: %v", query, warnings)
	}
	v, _ = value.(model.Vector)
	return
}

func (c *PromClient) MatrixQuery(query string, r v1.Range) (v model.Matrix, err error) {
	value, warnings, err := c.QueryRange(query, r)
	if err != nil {
		klog.Errorf("prometheus query sql: %s, error: %v", query, err)
		return
	}
	if len(warnings) > 0 {
		klog.Warningf("prometheus query sql: %s, warnings: %v", query, warnings)
	}
	v, _ = value.(model.Matrix)
	return
}

func VectorQuery(query string) (model.Vector, error) {
	klog.Infof("promQL_DEUBG: %s", query)
	return defaultClient.VectorQuery(query)
}

func VectorQuerySpecifiedTime(query string, ts time.Time) (model.Vector, error) {
	return defaultClient.VectorQuerySpecifiedTime(query, ts)
}

func MatrixQuery(query string, r v1.Range) (model.Matrix, error) {
	klog.Infof("promQL_DEUBG: %s", query)
	return defaultClient.MatrixQuery(query, r)
}

//	// Query performs a query for the given time.
//	Query(ctx context.Context, query string, ts time.Time) (model.Value, Warnings, error)
//	// QueryRange performs a query for the given range.
//	QueryRange(ctx context.Context, query string, r Range) (model.Value, Warnings, error)

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/client/prometheus_test.go
```golang
package client_test

import (
	"fmt"
	v1 "github.com/prometheus/client_golang/api/prometheus/v1"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"testing"
	"time"
)

func TestVectorQuery(t *testing.T) {
	labels, err := client.VectorQuery(`namedprocess_namegroup_states`)
	fmt.Println(err)
	for _, v := range labels {
		fmt.Println("key=", v.Metric["groupname"], "value=", v.Value)
	}
}

func TestMatrixQuery(t *testing.T) {
	end := time.Now()
	start := end.Add(-5 * time.Minute)
	values, err := client.MatrixQuery(`irate(node_cpu_seconds_total{mode="idle"}[5m])`, v1.Range{
		Start: start,
		End:   end,
		Step:  15 * time.Second,
	})
	fmt.Println(err)
	for _, i := range values {
		fmt.Printf("%s\n", i.Metric.String())
		for _, j := range i.Values {
			fmt.Printf("\t%s %s\n", j.Timestamp.String(), j.Value.String())
		}
	}

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/client/storage_api_client.go
```golang
package client

import (
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"k8s.io/klog/v2"
	"net/http"
	"strings"
	"time"
)

type SimpleHttpClient struct {
	httpClient *http.Client
}

func NewSimpleHttpClient() *SimpleHttpClient {
	return &SimpleHttpClient{
		httpClient: &http.Client{
			Timeout: 10 * time.Second,
		},
	}
}

func (s *SimpleHttpClient) SimpleHttpGet(url string) ([]byte, error) {
	resp, err := s.httpClient.Get(url)
	// TODO check response code,  4xx 5xx, make error
	if err != nil {
		klog.Errorf("Error when get url: %s, %s", url, err)
		return nil, err
	}
	if strings.HasPrefix(resp.Status, "5") || strings.HasPrefix(resp.Status, "4") {
		err = errors.New(fmt.Sprintf("Error when Get url=(%s) with %s status", url, resp.Status))
		klog.Error(err)
		return nil, err
	}
	defer resp.Body.Close()
	return io.ReadAll(resp.Body)
}

func (s *SimpleHttpClient) Do(req *http.Request) ([]byte, error) {
	resp, err := s.httpClient.Do(req)
	if err != nil {
		klog.Error("SimpleHttpClient Do err: " + err.Error())
		return nil, err
	}
	defer resp.Body.Close()
	return io.ReadAll(resp.Body)
}

type Ks3Cap struct {
	TotalDiskCapacity int64 `json:"total_disk_capacity,omitempty"`
	TotalUsedSpace    int64 `json:"total_used_space,omitempty"`
	TotalFreeSpace    int64 `json:"total_free_space,omitempty"`
}

type Ks3Server struct {
	IP        string `json:"ip,omitempty"`
	Port      int    `json:"port,omitempty"`
	Status    int    `json:"status,omitempty"`
	StatusMsg string `json:"status_msg,omitempty"`
	Role      string `json:"role,omitempty"`
}

type EbsCap struct {
	Id                int    `json:"id,omitempty"`
	Region            string `json:"region,omitempty"`
	AvailableZone     string `json:"available_zone,omitempty"`
	VdiType           string `json:"vdi_type,omitempty"`
	TotalDiskCapacity int64  `json:"total_disk_capacity,omitempty"`
	TotalUsedSpace    int64  `json:"total_used_space,omitempty"`
}

type EBSStock struct {
	OpenNum     int         `json:"openNum"`
	VdiOpenNum  int64       `json:"vdiOpenNum"`
	VdiWriteNum int64       `json:"vdiWriteNum"`
	EBSServers  []EBSServer `json:"EBSServers"`
}
type EBSServer struct {
	ServerAddress string `json:"serverAddress"`
	Status        string `json:"status"`
	StoreId       int64  `json:"storeId"`
	UsedCU        int    `json:"usedCU"`
	TotalCU       int    `json:"totalCU"`
	DiskUsed      string `json:"diskUsed"`
	DiskFree      string `json:"diskFree"`
	DiskTotal     string `json:"diskTotal"`
	Zone          string `json:"zone"`
	CacheStore    int    `json:"cacheStore"`
}

type TabletConfig struct {
	ReserveSpace int64 `json:"reserveSpace"`
}

type EBSSlice struct {
	TableName  string `json:"table_name"`  //分片关联的云硬盘 //u89a081b7e03c4755ac2a16a17276fc08:volume-2889814c-467e-4e1b-8e9c-07fc35e8fcae
	TableId    int    `json:"table_id"`    //分片关联的云硬盘id  520
	TabletName int    `json:"tablet_name"` // 分片名称 104
	Replicas   string `json:"replicas"`    //所在服务器/副本状态  10.178.225.216:9002(kFollower)
}

type VdiInfo struct {
	Vid                   int64       `json:"vid"`
	Name                  string      `json:"name"`
	Size                  int64       `json:"size"`
	UsedSize              int64       `json:"usedSize"`
	SizeHumanReadable     string      `json:"sizeHumanReadable"`
	UsedSizeHumanReadable string      `json:"usedSizeHumanReadable"`
	Status                string      `json:"status"`
	CreateTime            string      `json:"createTime"`
	Az                    string      `json:"availableZone"`
	VdiType               string      `json:"vdiType"`
	Cluster               string      `json:"cluster"`
	LastMountTime         string      `json:"lastMountTime"`
	LastSnapshotTime      string      `json:"lastSnapshotTime"`
	Snapshots             []*Snapshot `json:"snapshots"`
}

type Snapshot struct {
	Vid                   int64  `json:"vid"`
	Name                  string `json:"name"`
	VdiName               string `json:"vdiName"`
	Size                  int64  `json:"size"`
	UsedSize              int64  `json:"usedSize"`
	SizeHumanReadable     string `json:"sizeHumanReadable"`
	UsedSizeHumanReadable string `json:"usedSizeHumanReadable"`
	Status                string `json:"status"`
	CreateTime            string `json:"createTime"`
}

type StorageApiClient struct {
	Host       string
	HttpClient *SimpleHttpClient
}

func NewStorageApiClient(host string) *StorageApiClient {
	return &StorageApiClient{
		Host:       host,
		HttpClient: NewSimpleHttpClient(),
	}
}

func (s *StorageApiClient) GetKs3Cap() (*Ks3Cap, error) {
	cluster := &Ks3Cap{}
	url := fmt.Sprintf("http://%s/ks3/metric", s.Host)
	respData, err := s.HttpClient.SimpleHttpGet(url)
	if err != nil {
		klog.Error("GetKs3Cap http request error...." + err.Error())
		return cluster, err
	}
	err = json.Unmarshal(respData, cluster)
	if err != nil {
		klog.Error("GetKs3Cap json unmarshal error...." + err.Error())
		return cluster, err
	}
	return cluster, nil
}

func (s *StorageApiClient) GetKs3ServerList() ([]*Ks3Server, error) {
	servers := make([]*Ks3Server, 0)
	url := fmt.Sprintf("http://%s/ks3/cluster", s.Host)
	respData, err := s.HttpClient.SimpleHttpGet(url)
	if err != nil {
		klog.Error("GetKs3ServerList http request error...." + err.Error())
		return servers, err
	}
	err = json.Unmarshal(respData, &servers)
	if err != nil {
		klog.Error("GetKs3ServerList json unmarshal error...." + err.Error())
		return servers, err
	}
	return servers, nil
}

func (s *StorageApiClient) GetEbsCap() (*EbsCap, error) {
	var capList []*EbsCap
	url := fmt.Sprintf("http://%s/ebs/metric", s.Host)
	respData, err := s.HttpClient.SimpleHttpGet(url)
	if err != nil {
		klog.Error("GetEbsCap http request error...." + err.Error())
		return nil, err
	}
	err = json.Unmarshal(respData, &capList)
	if err != nil {
		klog.Error("GetEbsCap json unmarshal error...." + err.Error())
		return nil, err
	}
	if len(capList) > 0 {
		for _, cap := range capList {
			if cap.Id != 0 {
				return cap, nil
			}
		}
		return capList[0], nil
	}
	return nil, errors.New("empty data")
}

// GetEbsStock 方法弃用，原因是计算开盘量的时候没有过滤快照的数据，导致开盘量大于正常值
func (s *StorageApiClient) GetEbsStock() (*EBSStock, error) {
	var stock EBSStock
	url := fmt.Sprintf("http://%s/ebs/stock", s.Host)
	respData, err := s.HttpClient.SimpleHttpGet(url)
	if err != nil {
		klog.Error("GetEbsCap http request error...." + err.Error())
		return nil, err
	}
	err = json.Unmarshal(respData, &stock)
	if err != nil {
		klog.Error("GetEbsCap json unmarshal error...." + err.Error())
		return nil, err
	}
	return &stock, nil
}

func (s *StorageApiClient) GetEbsSlice() ([]*EBSSlice, error) {
	var slice []*EBSSlice
	url := fmt.Sprintf("http://%s/ebs/slice", s.Host)
	respData, err := s.HttpClient.SimpleHttpGet(url)
	if err != nil {
		klog.Error("GetEbsCap http request error...." + err.Error())
		return nil, err
	}
	err = json.Unmarshal(respData, &slice)
	if err != nil {
		klog.Error("GetEbsCap json unmarshal error...." + err.Error())
		return nil, err
	}
	return slice, nil
}

func (s *StorageApiClient) GetEbsServerList() ([]*EBSServer, error) {
	var servers []*EBSServer
	url := fmt.Sprintf("http://%s/ebs/servers", s.Host)
	respData, err := s.HttpClient.SimpleHttpGet(url)
	if err != nil {
		klog.Error("GetEbsServerList http request error...." + err.Error())
		return nil, err
	}
	err = json.Unmarshal(respData, &servers)
	if err != nil {
		klog.Error("GetEbsServerList json unmarshal error...." + err.Error())
		return nil, err
	}
	return servers, nil
}

func (s *StorageApiClient) GetEbsTabletConfig() (*TabletConfig, error) {
	var config TabletConfig
	url := fmt.Sprintf("http://%s/ebs/tabletserver/conf", s.Host)
	respData, err := s.HttpClient.SimpleHttpGet(url)
	if err != nil {
		klog.Error("GetEbsTabletConfig http request error...." + err.Error())
		return nil, err
	}
	err = json.Unmarshal(respData, &config)
	if err != nil {
		klog.Error("GetEbsTabletConfig json unmarshal error...." + err.Error())
		return nil, err
	}
	return &config, nil
}

func (s *StorageApiClient) GetEbsVdiNameList() ([]string, error) {
	vdis := make([]string, 0)
	url := fmt.Sprintf("http://%s/ebs/vdis", s.Host)
	respData, err := s.HttpClient.SimpleHttpGet(url)
	if err != nil {
		klog.Error("GetEbsVdiNameList http request error...." + err.Error())
		return nil, err
	}
	err = json.Unmarshal(respData, &vdis)
	if err != nil {
		klog.Error("GetEbsVdiNameList json unmarshal error...." + err.Error())
		return nil, err
	}
	return vdis, nil
}

func (s *StorageApiClient) GetEbsVdiInfo(name string) (*VdiInfo, error) {
	var vdi VdiInfo
	url := fmt.Sprintf("http://%s/ebs/vdi/%s", s.Host, name)
	respData, err := s.HttpClient.SimpleHttpGet(url)
	if err != nil {
		klog.Error("GetEbsVdiInfo http request error...." + err.Error())
		return nil, err
	}
	err = json.Unmarshal(respData, &vdi)
	if err != nil {
		klog.Error("GetEbsVdiInfo json unmarshal error...." + err.Error())
		return nil, err
	}
	return &vdi, nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/logging/send-logging-data.go
```golang
package logging

import (
	"bytes"
	"encoding/json"
	"fmt"
	"github.com/go-basic/uuid"
	"io/ioutil"
	"k8s.io/klog/v2"
	"net"
	"net/http"
	"os"
	"time"
)

var (
	AuditType         = "audit_group"
	LoggingType       = "luban_group"
	esIndexDateFormat = "2006.01.01"
	AuditIndexName    = "audit-ops-luban"
	NormonIndexName   = "service-ops-luban"
	esURL             = "http://elasticsearch-master.elastic-system:9200"
	revision          = "unknown"
)

type LubanAuditOpsLog struct {
	UserName  string `json:"user_name"`
	EventName string `json:"event_name"`
	//EventType     string `json:"event_type"`
	//ResourceType  string `json:"resource_type"`
	ServiceName string `json:"service_name"`
	EventTime   int64  `json:"event_time"`
	//ErrorCode     int    `json:"error_code"`
	RequestId string `json:"request_id"`
	EventID   string `json:"event_id"`
	//SoureIP       string `json:"soure_ip"`
	OperateType   string `json:"operate_type"`
	OperateResult string `json:"operate_result"`
	ResourceName  string `json:"resource_name"`
}

type LubanLog struct {
	ServiceType     string `json:"service_type"`
	ServiceInstance string `json:"service_instance"`
	Message         string `json:"message"`
	RequestId       string `json:"request_id"`
	RequestMethod   string `json:"request_method"`
	Hostname        string `json:"hostname"`
	Timestamp       string `json:"@timestamp"`
}

var localIp string

func LocalIp() string {
	addrs, err := net.InterfaceAddrs()
	if err != nil {
		klog.Errorf(err.Error())
	}
	var ip string = "localhost"
	for _, address := range addrs {
		if ipnet, ok := address.(*net.IPNet); ok && !ipnet.IP.IsLoopback() {
			if ipnet.IP.To4() != nil {
				ip = ipnet.IP.String()
			}
		}
	}
	return ip
}

func NewLubanLog(requestMethod, message string) LubanLog {
	hostname, _ := os.Hostname()
	now := time.Now()
	if localIp == "" {
		localIp = LocalIp()
	}
	return LubanLog{
		RequestId:       uuid.New(),
		ServiceType:     "Laban-Server",
		ServiceInstance: localIp,
		RequestMethod:   requestMethod,
		Hostname:        hostname,
		Message:         message,
		Timestamp:       now.Format(time.RFC3339),
	}
}

func NewLubanAuditOpsLog(userName, eventName, resourceName string) LubanAuditOpsLog {
	return LubanAuditOpsLog{
		UserName:    userName,
		EventName:   eventName,
		EventTime:   time.Now().Unix(),
		ServiceName: "Laban-Server",
		//EventType:   eventType,
		EventID:       uuid.New(),
		RequestId:     uuid.New(),
		ResourceName:  resourceName,
		OperateResult: "success",
		OperateType:   "监控告警",
	}
}

func SendData(data interface{}, indexName, esType string) {
	index := fmt.Sprintf("%s-%s/%s", indexName, fmt.Sprintf("%d.%d.%d", time.Now().Year(), time.Now().Month(), time.Now().Day()), esType)
	url := fmt.Sprintf("%s/%s", esURL, index)
	b, _ := json.Marshal(data)
	req, err := http.NewRequest("POST", url, bytes.NewBuffer(b))
	if err != nil {
		fmt.Println(err)
		return
	}
	req.Header.Set("Content-Type", "application/json")

	timeOutClient := http.Client{Timeout: 3 * time.Second}
	resp, err := timeOutClient.Do(req)
	if err != nil {
		klog.Error(err)
		return
	}

	body, err := ioutil.ReadAll(resp.Body)
	defer resp.Body.Close()
	if err != nil {
		klog.Error(err)
		return
	}

	if resp.StatusCode/100 != 2 {
		klog.Infof("POST to Elasticsearch on %q returned HTTP %d:  %s", url, resp.StatusCode, body)
		klog.Error(err)
		return
	}

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/common.go
```golang
package services

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"io/ioutil"
	"math"
	"net/http"
	"os"
	"reflect"
	"strconv"
	"strings"
	"time"

	_ "github.com/go-sql-driver/mysql"
	"github.com/jmoiron/sqlx"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	"k8s.io/klog/v2"
)

var RegionCodeNameMap = map[string]string{
	"cn-shanghai-2": "上海二区",
}

var Duration string

// func SortSlice(in []interface{}, rule string) (rst []interface) {

// 	return
// }

//四舍五入法
func Round(x float64) int {
	return int(math.Floor(x + 0/5))
}

// Strval 获取变量的字符串值
// 浮点型 3.0将会转换成字符串3, "3"
// 非数值或字符类型的变量将会被转换成JSON格式字符串
func Strval(value interface{}) string {
	// interface 转 string
	var key string
	if value == nil {
		return key
	}

	switch value.(type) {
	case float64:
		ft := value.(float64)
		key = strconv.FormatFloat(ft, 'f', 2, 64)
	case float32:
		ft := value.(float32)
		key = strconv.FormatFloat(float64(ft), 'f', 2, 64)
	case int:
		it := value.(int)
		key = strconv.Itoa(it)
	case uint:
		it := value.(uint)
		key = strconv.Itoa(int(it))
	case int8:
		it := value.(int8)
		key = strconv.Itoa(int(it))
	case uint8:
		it := value.(uint8)
		key = strconv.Itoa(int(it))
	case int16:
		it := value.(int16)
		key = strconv.Itoa(int(it))
	case uint16:
		it := value.(uint16)
		key = strconv.Itoa(int(it))
	case int32:
		it := value.(int32)
		key = strconv.Itoa(int(it))
	case uint32:
		it := value.(uint32)
		key = strconv.Itoa(int(it))
	case int64:
		it := value.(int64)
		key = strconv.FormatInt(it, 10)
	case uint64:
		it := value.(uint64)
		key = strconv.FormatUint(it, 10)
	case string:
		key = value.(string)
	case []byte:
		key = string(value.([]byte))
	case []interface{}:
		float, _ := strconv.ParseFloat(Strval(value.([]interface{})[1]), 64)
		key = string(Strval(float))
	default:
		newValue, _ := json.Marshal(value)
		key = string(newValue)
	}

	return key
}

func In(haystack interface{}, needle interface{}) bool {
	sVal := reflect.ValueOf(haystack)
	kind := sVal.Kind()
	if kind == reflect.Slice || kind == reflect.Array {
		for i := 0; i < sVal.Len(); i++ {
			if sVal.Index(i).Interface() == needle {
				return true
			}
		}

		return false
	}

	return false
}

func Format_Size(fileSize float64) (size string) {
	if fileSize >= 0 {

		if fileSize < 1024.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2f_B", fileSize)
		} else if fileSize < (1024.0 * 1024.0) {
			return fmt.Sprintf("%.2f_KB", fileSize/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2f_MB", fileSize/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2f_GB", fileSize/1024.0/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2f_TB", fileSize/1024.0/1024.0/1024.0/1024.0)
		} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
			return fmt.Sprintf("%.2f_EB", fileSize/1024.0/1024.0/1024.0/1024.0/1024.0)
		}
	}

	if fileSize < 0 {
		fileSize = -fileSize

		if fileSize < 1024.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2f_B", -fileSize)
		} else if fileSize < (1024.0 * 1024.0) {
			return fmt.Sprintf("%.2f_KB", -fileSize/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2f_MB", -fileSize/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2f_GB", -fileSize/1024.0/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2f_TB", -fileSize/1024.0/1024.0/1024.0/1024.0)
		} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
			return fmt.Sprintf("%.2f_EB", -fileSize/1024.0/1024.0/1024.0/1024.0/1024.0)
		}
	}
	return ""
}

func FormatSize(fileSize float64) (size string) {
	if fileSize >= 0 {

		if fileSize < 1024.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2fB", fileSize)
		} else if fileSize < (1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fKB", fileSize/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fMB", fileSize/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fGB", fileSize/1024.0/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fTB", fileSize/1024.0/1024.0/1024.0/1024.0)
		} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
			return fmt.Sprintf("%.2fEB", fileSize/1024.0/1024.0/1024.0/1024.0/1024.0)
		}
	}

	if fileSize < 0 {
		fileSize = -fileSize

		if fileSize < 1024.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2fB", -fileSize)
		} else if fileSize < (1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fKB", -fileSize/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fMB", -fileSize/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fGB", -fileSize/1024.0/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fTB", -fileSize/1024.0/1024.0/1024.0/1024.0)
		} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
			return fmt.Sprintf("%.2fEB", -fileSize/1024.0/1024.0/1024.0/1024.0/1024.0)
		}
	}
	return ""

}

func FormatSizeForHardware(fileSize float64) (size string) {
	if fileSize >= 0 {

		if fileSize < 1024.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2fB", fileSize)
		} else if fileSize < (1000.0 * 1000.0) {
			return fmt.Sprintf("%.2fKB", fileSize/1000.0)
		} else if fileSize < (1000.0 * 1000.0 * 1000.0) {
			return fmt.Sprintf("%.2fMB", fileSize/1000.0/1000.0)
		} else if fileSize < (1000.0 * 1000.0 * 1000.0 * 1000.0) {
			return fmt.Sprintf("%.2fGB", fileSize/1000.0/1000.0/1000.0)
		} else if fileSize < (1000.0 * 1000.0 * 1000.0 * 1000.0 * 1000.0) {
			return fmt.Sprintf("%.2fTB", fileSize/1000.0/1000.0/1000.0/1000.0)
		} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
			return fmt.Sprintf("%.2fEB", fileSize/1000.0/1000.0/1000.0/1000.0/1000.0)
		}
	}

	if fileSize < 0 {
		fileSize = -fileSize

		if fileSize < 1024.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2fB", -fileSize)
		} else if fileSize < (1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fKB", -fileSize/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fMB", -fileSize/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fGB", -fileSize/1024.0/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fTB", -fileSize/1024.0/1024.0/1024.0/1024.0)
		} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
			return fmt.Sprintf("%.2fEB", -fileSize/1024.0/1024.0/1024.0/1024.0/1024.0)
		}
	}
	return ""

}

func FormatSizePerSecond(fileSize float64) (size string) {
	if fileSize >= 0 {

		if fileSize < 1024.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2fB/s", fileSize)
		} else if fileSize < (1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fKB/s", fileSize/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fMB/s", fileSize/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fGB/s", fileSize/1024.0/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fTB/s", fileSize/1024.0/1024.0/1024.0/1024.0)
		} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
			return fmt.Sprintf("%.2fEB/s", fileSize/1024.0/1024.0/1024.0/1024.0/1024.0)
		}
	}

	if fileSize < 0 {
		fileSize = -fileSize

		if fileSize < 1024.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2fB", -fileSize)
		} else if fileSize < (1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fKB", -fileSize/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fMB", -fileSize/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fGB", -fileSize/1024.0/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fTB", -fileSize/1024.0/1024.0/1024.0/1024.0)
		} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
			return fmt.Sprintf("%.2fEB", -fileSize/1024.0/1024.0/1024.0/1024.0/1024.0)
		}
	}
	return ""

}

func FormatSizePerSecondForLittleB(fileSize float64) (size string) {
	if fileSize >= 0 {

		if fileSize < 1024.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2fb/s", fileSize)
		} else if fileSize < (1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fKb/s", fileSize/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fMb/s", fileSize/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fGb/s", fileSize/1024.0/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fTb/s", fileSize/1024.0/1024.0/1024.0/1024.0)
		} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
			return fmt.Sprintf("%.2fEb/s", fileSize/1024.0/1024.0/1024.0/1024.0/1024.0)
		}
	}

	if fileSize < 0 {
		fileSize = -fileSize

		if fileSize < 1024.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2fB", -fileSize)
		} else if fileSize < (1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fKB", -fileSize/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fMB", -fileSize/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fGB", -fileSize/1024.0/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fTB", -fileSize/1024.0/1024.0/1024.0/1024.0)
		} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
			return fmt.Sprintf("%.2fEB", -fileSize/1024.0/1024.0/1024.0/1024.0/1024.0)
		}
	}
	return ""

}

func FormatSecond(fileSize float64) (size string) {
	if fileSize >= 0 {

		if fileSize > 1.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2fs", fileSize)
		} else if fileSize > (1.0 / 1000.0) {
			return fmt.Sprintf("%.2fms", fileSize*1000.0)
		} else if fileSize > (1.0 / 1000.0 / 1000.0) {
			return fmt.Sprintf("%.2fμs", fileSize*1000.0*1000.0)
			//} else if fileSize > (1.0/1000/1000/1000) {
			//	return fmt.Sprintf("%.2fns", fileSize * 1000.0 * 1000.0 * 1000.0)
			//} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0 * 1024.0) {
			//	return fmt.Sprintf("%.2fTB", fileSize/1024.0/1024.0/1024.0/1024.0)
		} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
			return fmt.Sprintf("%.2fns", fileSize*1000.0*1000.0*1000.0)
		}
	}

	if fileSize < 0 {
		fileSize = -fileSize

		if fileSize < 1024.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2fB", -fileSize)
		} else if fileSize < (1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fKB", -fileSize/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fMB", -fileSize/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fGB", -fileSize/1024.0/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fTB", -fileSize/1024.0/1024.0/1024.0/1024.0)
		} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
			return fmt.Sprintf("%.2fEB", -fileSize/1024.0/1024.0/1024.0/1024.0/1024.0)
		}
	}
	return ""

}

func TimeToStep(fileSize float64) (size string) {
	//处理的单位是秒
	klog.Info("rangTime")
	klog.Info(fileSize)
	if fileSize >= 0 {

		if fileSize <= 3600.0*24.0*2 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return "60" //1m
		} else if fileSize <= (3600.0 * 24.0 * 7) {
			return "3600" //1h fixme 3600 7天间隔特定bug
		} else {
			return "86400" //1d
		}
	}
	return ""
}

func TimeToStepForInt(fileSize int64) (size int) {
	//处理的单位是秒
	klog.Info("rangTime")
	klog.Info(fileSize)
	if fileSize >= 0 {

		if fileSize <= 3600.0*24.0*2 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return 60 //1m
		} else if fileSize <= (3600.0 * 24.0 * 7) {
			return 3600 //1h fixme 3600 7天间隔特定bug
		} else {
			return 86400 //1d
		}
	}
	return 0
}

func TimeToStepForTSDB(fileSize float64) (size string) {
	klog.Info("Tsdb_rangTime")
	klog.Info(fileSize)
	if fileSize >= 0 {

		if fileSize <= 3600.0*24.0*2 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return "60s-avg-null" //1m
		} else if fileSize <= (3600.0 * 24.0 * 7) {
			return "1h-avg-null" //1h
		} else {
			return "24h-avg-null" //1d
		}
	}
	return ""
}

func TimeToStepForTSDBK(duration float64) (size string) {
	klog.Infof("Tsdb_rangTime: %f", duration)

	if duration >= 0 {
		if duration <= 3600.0*24.0*2 {
			//return strconv.FormatInt(duration, 10) + "B"
			return "60s-avg-zero" //1m
		} else if duration <= (3600.0 * 24.0 * 7) {
			return "1h-avg-zero" //1h
		} else {
			return "24h-avg-zero" //1d
		}

	}
	return ""
}

func TimeToStepForTSDBKNew(duration float64) (size string) {
	klog.Infof("Tsdb_rangTime New : %f", duration)

	if duration >= 0 {
		if duration <= 3600.0 { //0.5h/1h
			return "5m-avg-zero"
		} else if duration <= (3600.0 * 3) { // 3h
			return "10m-avg-zero"
		} else if duration <= (3600.0 * 24.0 * 7) { // 12h 24h 7d
			return "1h-avg-zero"
		} else { // 30d
			return "1d-avg-zero"
		}

	}
	return ""
}

func TimeToStepForTSDBKNew111(duration float64) (size string) {
	if duration >= 0 {
		if duration <= 3600.0 { //0.5h/1h
			return "300"
		} else if duration <= (3600.0 * 3) { // 3h
			return "600"
		} else if duration <= (3600.0 * 24.0 * 7) { // 12h 24h 7d
			return "3600"
		} else { // 30d
			return "86400"
		}

	}
	return ""
}


func FormatTime(fileSize float64) (size string) {
	if fileSize >= 0 {

		if fileSize < 3600.0*24.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("30m")
		} else if fileSize < (3600.0 * 24.0 * 2) {
			return fmt.Sprintf("1d")
		} else if fileSize < (3600.0 * 24.0 * 8) {
			return fmt.Sprintf("1w")
		} else {
			return fmt.Sprintf("30d")
		}
	}

	if fileSize < 0 {
		fileSize = -fileSize

		if fileSize < 1024.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2fB", -fileSize)
		} else if fileSize < (1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fKB", -fileSize/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fMB", -fileSize/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fGB", -fileSize/1024.0/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fTB", -fileSize/1024.0/1024.0/1024.0/1024.0)
		} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
			return fmt.Sprintf("%.2fEB", -fileSize/1024.0/1024.0/1024.0/1024.0/1024.0)
		}
	}
	return ""

}

func FormatNumberWithSign(fileSize float64) (size string) {
	if fileSize >= 0 {

		if fileSize < 1000 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2f", fileSize)
		} else if fileSize > 1e3 {
			return fmt.Sprintf("%.2fk", fileSize/1e3)
		} else if fileSize > 1e4 {
			return fmt.Sprintf("%.2fw", fileSize/1e4)
		} else {
			return fmt.Sprintf("%.2fe", fileSize/1e8)
		}
	}

	if fileSize < 0 {
		fileSize = -fileSize

		if fileSize < 1024.0 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%.2fB", -fileSize)
		} else if fileSize < (1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fKB", -fileSize/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fMB", -fileSize/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fGB", -fileSize/1024.0/1024.0/1024.0)
		} else if fileSize < (1024.0 * 1024.0 * 1024.0 * 1024.0 * 1024.0) {
			return fmt.Sprintf("%.2fTB", -fileSize/1024.0/1024.0/1024.0/1024.0)
		} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
			return fmt.Sprintf("%.2fEB", -fileSize/1024.0/1024.0/1024.0/1024.0/1024.0)
		}
	}
	return ""

}

func Form2(r interface{}) interface{} {
	switch r.(type) {
	case string:
		vv, _ := strconv.ParseFloat(r.(string), 64)
		ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", vv), 64)
		r = ss
		return r
	case float64:
		ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", r.(float64)), 64)
		r = ss
		return r
	}
	return 0.0
}

func FormPercent(r interface{}) float64 {
	switch r.(type) {
	case string:
		vv, _ := strconv.ParseFloat(r.(string), 64)
		ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", vv), 64)
		return ss
	case float64:
		ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", r.(float64)), 64)
		return ss
	}
	return 0
}

func FormPercentWithSign(r interface{}) string {
	switch r.(type) {
	case string:
		vv, _ := strconv.ParseFloat(r.(string), 64)
		ss := fmt.Sprintf("%.2f%%", vv*100)
		return ss
	case float64:
		ss := fmt.Sprintf("%.2f%%", 100*r.(float64))
		return ss
	}
	return ""
}

//get total count

func GetTotalCount(url, method string) int {
	klog.Info(url)
	c := http.Client{}
	cmdb := CMDBResult{}
	hostUrlPost := cmdbmodel.HostUrlPost{
		PageNo:   1,
		PageSize: 1,
		Region:   "all",
		Az:       "all",
	}
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	if method == "get" {
		resp, err := c.Get(url)
		if err != nil {
			klog.Info(err)
			return 0
		}
		b, er := io.ReadAll(resp.Body)
		if er != nil {
			klog.Info(er)
			return 0
		}

		e := json.Unmarshal(b, &cmdb)
		if e != nil {
			return 0
		}
	} else {
		resp, err := c.Post(url, "application/json", jsoninfo)
		if err != nil {
			klog.Info(err)
			return 0
		}
		b, er := io.ReadAll(resp.Body)
		if er != nil {
			klog.Info(er)
			return 0
		}

		e := json.Unmarshal(b, &cmdb)
		if e != nil {
			return 0
		}
	}
	return cmdb.Data.TotalCount

}

func GetMutilAzTotalCount(url, method string) int {
	klog.Info(url)
	c := http.Client{Timeout: time.Second * 60}
	cmdb := CMDBResult{}
	hostUrlPost := cmdbmodel.VmListPost{
		PageNo:   1,
		PageSize: 1,
		Region:   "all",
		Az:       []string{},
	}
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	if method == "get" {
		resp, err := c.Get(url)
		if err != nil {
			klog.Info(err)
			return 0
		}
		b, er := io.ReadAll(resp.Body)
		if er != nil {
			klog.Info(er)
			return 0
		}

		e := json.Unmarshal(b, &cmdb)
		if e != nil {
			return 0
		}
	} else {
		resp, err := c.Post(url, "application/json", jsoninfo)
		if err != nil {
			klog.Info(err)
			return 0
		}
		b, er := io.ReadAll(resp.Body)
		if er != nil {
			klog.Info(er)
			return 0
		}

		e := json.Unmarshal(b, &cmdb)
		if e != nil {
			klog.Info(e)
			return 0
		}
	}

	return cmdb.Data.TotalCount

}

func GetBlockAzTotalCount(url, method string) int {
	klog.Info(url)
	c := http.Client{Timeout: time.Second * 60}
	cmdb := CMDBResult{}
	hostUrlPost := cmdbmodel.BlockListPost{
		PageNo:   1,
		PageSize: 1,
		Region:   "all",
		Az:       []string{},
	}
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	if method == "get" {
		resp, err := c.Get(url)
		if err != nil {
			klog.Info(err)
			return 0
		}
		b, er := io.ReadAll(resp.Body)
		if er != nil {
			klog.Info(er)
			return 0
		}

		e := json.Unmarshal(b, &cmdb)
		if e != nil {
			return 0
		}
	} else {
		resp, err := c.Post(url, "application/json", jsoninfo)
		if err != nil {
			klog.Info(err)
			return 0
		}
		b, er := io.ReadAll(resp.Body)
		if er != nil {
			klog.Info(er)
			return 0
		}

		e := json.Unmarshal(b, &cmdb)
		if e != nil {
			klog.Info(e)
			return 0
		}
	}

	return cmdb.Data.TotalCount

}

func QueryTotalCount(url, region, az, method string, storageType []string) int {
	c := http.Client{}
	resp := new(http.Response)
	cmdb := CMDBResult{}
	hostUrlPost := cmdbmodel.HostUrlPost{
		PageNo:      1,
		PageSize:    1,
		Region:      region,
		Az:          az,
		StorageType: storageType,
	}
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	if method == "get" {
		resp, _ = c.Get(url)
	} else {
		resp, _ = c.Post(url, "application/json", jsoninfo)
	}
	b, _ := io.ReadAll(resp.Body)

	err := json.Unmarshal(b, &cmdb)
	if err != nil {
		return 0
	}
	return cmdb.Data.TotalCount
}

func PromeForRangeValue(r interface{}) []ValueType {
	result := make([]ValueType, 0, 100)

	value := r.([][]interface{})
	for i := 0; i < len(value); i++ {
		v := value[i]
		rr := ValueType{TimeSteamp: v[0], Value: v[1], Name: v[0]}
		result = append(result, rr)
	}

	return result
}

func PromeForRangeValueForms(r interface{}) []ValueType {
	result := make([]ValueType, 0, 100)

	value := r.([][]interface{})
	for i := 0; i < len(value); i++ {
		v := value[i]
		rr := ValueType{TimeSteamp: Strval(v[0]) + "000", Value: v[1], Name: Strval(v[0]) + "000"}
		result = append(result, rr)
	}

	return result
}

func PromeForRangeValue2(r interface{}) []ValueType {
	result := make([]ValueType, 0, 100)
	data := r.([]interface{})
	for _, dat := range data {
		arr := dat.([]interface{})
		rr := ValueType{TimeSteamp: arr[0], Value: arr[1], Name: arr[0]}
		result = append(result, rr)
	}
	return result
}

func RangeValueForForePercent(r interface{}) []ValueType {
	result := make([]ValueType, 0, 100)
	data := r.([]interface{})
	for _, dat := range data {
		arr := dat.([]interface{})
		rr := ValueType{TimeSteamp: arr[0], Value: arr[1].(float64) / 100, Name: arr[0]}
		result = append(result, rr)
	}
	return result
}

func RangeValueForForePercent2(r interface{}) []ValueType {
	result := make([]ValueType, 0, 100)
	data := r.([]interface{})
	for _, dat := range data {
		arr := dat.([]interface{})
		rr := ValueType{TimeSteamp: arr[0], Value: arr[1].(float64), Name: arr[0]}
		result = append(result, rr)
	}
	return result
}

type ValueType struct {
	Value      interface{} `json:"value"`
	TimeSteamp interface{} `json:"timesteamp"`
	Name       interface{} `json:"name"`
	SubName    string      `json:"subName"`
	Id         string      `json:"id"`
	Percent    interface{} `json:"percent"`
	IsForecast bool        `json:"isForecast"`
	Day        string      `json:"day"`
}

type BlockValueType struct {
	Value        interface{} `json:"value"` //值
	Name         string      `json:"name"`  // 名称
	Timestamep   string      `json:"timestamep"`
	SubName      string      `json:"subName"`          //子名称
	Id           string      `json:"instanceId"`       // 实例id
	RegionCode   string      `json:"regionCode"`       // region
	Az           string      `json:"azCode"`           //Az
	Status       string      `json:"useStatus"`        // 筛选使用状态
	ResourceType string      `json:"resourcePoolType"` // 存储类型
}

type InfoType struct {
	Name        string `json:"name"`
	Unit        string `json:"unit"`
	UnitType    string `json:"unitType"`
	Copywriting string `json:"copywriting"`
}

type CMDBResult struct {
	Code    int        `json:"code"`
	Message string     `json:"message"`
	Data    CmdbBlocks `json:"data"`
}
type CmdbBlocks struct {
	PageStruct
	//DataList []CloudDiskData `json:"dataList" description:"paging data"`
	//TotalCount int            `json:"totalCount" description:"total count"`
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

func CalculatePromStep(startTime time.Time, endTime time.Time) string {
	h := endTime.Sub(startTime).Hours()
	switch {
	case h <= 24*2:
		return "1m"
	case h <= 24*7:
		return "1h"
	default:
		return "1d"
	}
}

var StorageMap = map[string]string{
	"STANDARD":    "标准存储",
	"ARCHIVE":     "归档存储",
	"STANDARD_IA": "低频存储",
}

func GenerateTopK(k int) string {
	return fmt.Sprintf("top%d", k)
}

func MakeMysqlClient() *sqlx.DB {
	conn := os.Getenv("CloudMonitor_DB_Connection")
	klog.Info("conn")
	klog.Info(conn)
	db, err := sqlx.Open("mysql", conn)
	//db, err := sqlx.Open("mysql", "monitor:Galaxy123@tcp("+config.CloudMonitorAlertMySql+")/monitor2_uic?charset=utf8&loc=Asia%2FShanghai")
	if err != nil {
		klog.Error("failed to connect database,err:" + err.Error())
	}
	return db
}

func MakeMysqlYunyanClient() *sqlx.DB {
	db, err := sqlx.Open("mysql", "neutron:4@KcjV1jeVJd@tcp(10.178.225.231:8306)/neutron?charset=utf8&loc=Asia%2FShanghai")
	if err != nil {
		klog.Error("failed to connect database,err:" + err.Error())
	}
	fmt.Printf("dbdbdbdbdb %+v", db)
	return db
}

//获取两个时间之间的差值：*天*时*分*秒
func DataTimeDiff(start, end time.Time) string {
	diff := end.Unix() - start.Unix()
	days := diff / (3600 * 24)
	hourDiff := diff - days*3600*24
	hourss := (hourDiff) / 3600
	minutesDiff := hourDiff - hourss*3600
	minutes := minutesDiff / 60
	secondsDiff := minutesDiff - minutes*60
	res := ""
	if days > 0 {
		res = fmt.Sprintf("%d天%d时%d分%d秒", days, hourss, minutes, secondsDiff)
	} else if hourss > 0 {
		res = fmt.Sprintf("%d时%d分%d秒", hourss, minutes, secondsDiff)
	} else if minutes > 0 {
		res = fmt.Sprintf("%d分%d秒", minutes, secondsDiff)
	} else if secondsDiff > 0 {
		res = fmt.Sprintf("%d秒", secondsDiff)
	}
	return res
}

func GetPromValuesSlice(r interface{}) []float64 {
	if r == nil {
		return []float64{0}
	}
	result := []float64{}

	valu := r.(map[string]interface{})

	if Data, o := valu["values"]; o {
		value := Data.([]interface{})
		for i := 0; i < len(value); i++ {
			v := value[i].([]interface{})
			//if v[1].(string) == "NaN"{
			//	result = append(result, 0)
			//	continue
			//}
			switch v[1].(type) {
			case string:

				vv, _ := strconv.ParseFloat(v[1].(string), 64)
				//ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", vv), 64)
				//sss := services.FormatSize(ss)
				//v[1] = sss
				result = append(result, vv)
			case float64:
				ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", v[1].(float64)), 64)

				//sss := services.FormatSize(ss)
				//v[1] = sss
				result = append(result, ss)
			}
		}
		//result = res.(string)
	}

	return result
}

func GetPromValueMax(vals []float64) float64 {
	var max = vals[0]
	for _, val := range vals {
		if val > max {
			max = val
		}
	}
	return max
}

func GetPromValueMin(vals []float64) float64 {
	var min = vals[0]
	for _, val := range vals {
		if val < min {
			min = val
		}
	}
	return min
}

func GetPromValueAvg(vals []float64) float64 {
	l := len(vals)
	sum := 0.0
	for _, val := range vals {
		sum += val / float64(l)
	}
	return sum
}

func GetPromDuration(s string) string {
	if Duration := config.PromeTimeDurtion; Duration == "" {
		Duration = "10m"
		return Duration
	}
	return s
}

//20220111以后可以按照下面这两个方法使用
//通用方法调用接口传url 参数以及返回结构体即可
func DoPost(url string, para map[string]interface{}, result interface{}) interface{} {
	klog.Infof("http url : %s", url)
	client := &http.Client{
		Timeout: time.Second * 3,
	}
	body, err := json.Marshal(para)
	if err != nil {
		fmt.Errorf("json Unmarshal error : %v ", err.Error())
	}
	req, _ := http.NewRequest(http.MethodPost, url, bytes.NewBuffer(body))

	req.Header.Add("Content-Type", "application/json")
	req.Header.Add("x-auth-test", "true")
	resp, err := client.Do(req)
	if err != nil {
		fmt.Errorf("http do error : %v ", err.Error())
	}
	defer resp.Body.Close()
	b, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		fmt.Errorf("read body error : %v ", err.Error())
	}
	err = json.Unmarshal(b, result)
	if err != nil {
		fmt.Errorf("json Unmarshal error : %v ", err.Error())
	}
	return result
}

func DoGet(url string, para map[string]string, result interface{}) interface{} {
	klog.Infof("http url : %s", url)
	client := &http.Client{
		Timeout: time.Second * 3,
	}
	body, err := json.Marshal(para)
	if err != nil {
		fmt.Errorf("json Unmarshal error : %v ", err.Error())
	}
	req, _ := http.NewRequest(http.MethodGet, url, bytes.NewBuffer(body))

	query := req.URL.Query()
	for k, v := range para {
		query.Set(k, v)
	}
	req.URL, _ = req.URL.Parse(url + "?" + query.Encode())

	req.Header.Add("Content-Type", "application/json")
	req.Header.Add("x-auth-test", "true")
	resp, err := client.Do(req)
	if err != nil {
		fmt.Errorf("http do error : %v ", err.Error())
	}
	defer resp.Body.Close()
	b, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		fmt.Errorf("read body error : %v ", err.Error())
	}
	err = json.Unmarshal(b, result)
	if err != nil {
		fmt.Errorf("json Unmarshal error : %v ", err.Error())
	}
	return result
}

func FormatFloat64(value interface{}) float64 {
	// interface 转 string
	var key float64
	if value == nil {
		return key
	}

	switch value.(type) {
	case float64:
		ft := value.(float64)
		return ft
	case float32:
		ft := value.(float32)
		return float64(ft)
	case int:
		it := value.(int)
		return float64(it)
	case int64:
		it := value.(int64)
		return float64(it)
	case string:
		vv := value.(string)
		it, _ := strconv.ParseFloat(vv, 64)
		return float64(it)
	}

	return key
}

func FormatInt64(value interface{}) int64 {
	// interface 转 string
	var key int64
	if value == nil {
		return key
	}

	switch value.(type) {
	case float64:
		ft := value.(float64)
		return int64(ft)
	case float32:
		ft := value.(float32)
		return int64(ft)
	case int:
		ft := value.(int)
		return int64(ft)
	}

	return key
}

func FormCMDBStorageM(fileSize int) string {

	if fileSize >= 0 {

		if fileSize < 1024 {
			//return strconv.FormatInt(fileSize, 10) + "B"
			return fmt.Sprintf("%dMB", fileSize)
		} else if fileSize < (1024 * 1024) {
			return fmt.Sprintf("%.2dGB", fileSize/1024)
		} else if fileSize < (1024 * 1024 * 1024) {
			return fmt.Sprintf("%.2dTB", fileSize/1024/1024)
		}
	}
	return ""
}

func BuildCommonCondition(region, az string, extConditions ...string) string {
	var conditions []string
	if len(extConditions) > 0 {
		conditions = append(conditions, extConditions...)
	}
	if az != "" && az != "all" {
		conditions = append(conditions, "az=\""+az+"\"")
	}
	if region != "" && region != "all" {
		conditions = append(conditions, "region=\""+region+"\"")
	}
	var conditionStr string
	if len(conditions) > 0 {
		conditionStr = strings.Join(conditions, ",")
	}
	return conditionStr
}

// 切片去重
func RemoveDuplicateElement(languages []string) []string {
	result := make([]string, 0, len(languages))
	temp := map[string]struct{}{}
	for _, item := range languages {
		if _, ok := temp[item]; !ok { //如果字典中找不到元素，ok=false，!ok为true，就往切片中append元素。
			temp[item] = struct{}{}
			result = append(result, item)
		}
	}
	return result
}

func Maximum(slice []int) int {
	max := slice[0]
	for i := 0; i < len(slice); i++ {
		if max < slice[i] {
			max = slice[i]
		}
	}
	return max
}

func FormatFileSize(fileSize int64) (size string) {
	if fileSize < 1024 {
		return fmt.Sprintf("%.2fB", float64(fileSize)/float64(1))
	} else if fileSize < (1024 * 1024) {
		return fmt.Sprintf("%.2fKB", float64(fileSize)/float64(1024))
	} else if fileSize < (1024 * 1024 * 1024) {
		return fmt.Sprintf("%.2fMB", float64(fileSize)/float64(1024*1024))
	} else if fileSize < (1024 * 1024 * 1024 * 1024) {
		return fmt.Sprintf("%.2fGB", float64(fileSize)/float64(1024*1024*1024))
	} else if fileSize < (1024 * 1024 * 1024 * 1024 * 1024) {
		return fmt.Sprintf("%.2fTB", float64(fileSize)/float64(1024*1024*1024*1024))
	} else { //if fileSize < (1024 * 1024 * 1024 * 1024 * 1024 * 1024)
		return fmt.Sprintf("%.2fEB", float64(fileSize)/float64(1024*1024*1024*1024*1024))
	}
}

func IsValueInList(list []string, subStr string) bool {
	for _, v := range list {
		vLower := strings.ToLower(v)
		subStrLower := strings.ToLower(subStr)
		if strings.Contains(vLower, subStrLower) {
			return true
		}
	}
	return false
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/dgraphmanager/dgraphservices.go
```golang
package dgraphmanager

import (
	"context"
	"encoding/json"
	"sync"

	prom "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"

	"github.com/dgraph-io/dgo/v200"
	"github.com/dgraph-io/dgo/v200/protos/api"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"google.golang.org/grpc"
	"k8s.io/klog/v2"
)

var (
	re     = Data{}
	once   sync.Once
	dgraph *dgo.Dgraph
)

type Data struct {
	Host []Host `json:"host"`
}
type Host struct {
	Count int `json:"count"`
}

func GetAllPhysicals(typeName string) int {
	dg := newClient()
	//ctx := context.Background()
	txn := dg.NewReadOnlyTxn().BestEffort()
	//vars := make(map[string]string)
	//vars["$enname"] = "ZhaoYao"
	s := `{
		host(func: has(sn)) @filter(eq(type, "physical_server")) {
			count(uid)
		}}`

	Dresp, err := txn.Query(context.Background(), s)
	if err != nil {
		klog.Error("Query dgraph error...")
	}
	e := json.Unmarshal(Dresp.Json, &re)
	if e != nil {
		klog.Error("json unmarshal error...." + e.Error())
	}
	b := re.Host[0].Count
	return b
}

func GetAllPhysicalsDetails(typeName string) int {
	//1从dgraph中获取ip hostname 资源池类型（等晓哲） 资源池
	//2根据资源池类型分组ip
	//3拿IP去Prometheus获取cpu 内存 磁盘使用量 总量 以当前时间点往前推七天的值
	//4将相同资源池类型的从Prometheus获取的值 使用量 总量相加相除算百分比
	//5
	dg := newClient()
	//ctx := context.Background()
	txn := dg.NewReadOnlyTxn().BestEffort()
	//vars := make(map[string]string)
	//vars["$enname"] = "ZhaoYao"
	s := `{
		host(func: has(sn)) @filter(eq(type, "physical_server")) {
			count(uid)
		}}`

	Dresp, err := txn.Query(context.Background(), s)
	if err != nil {
		klog.Error("Query dgraph error...")
	}
	e := json.Unmarshal(Dresp.Json, &re)
	if e != nil {
		klog.Error("json unmarshal error...." + e.Error())
	}
	b := re.Host[0].Count
	return b
}

func newClient() *dgo.Dgraph {
	// Dial a gRPC connection. The address to dial to can be configured when
	// setting up the dgraph cluster.
	once.Do(func() {
		con, err := grpc.Dial(config.GetDefaultUrl(config.DgraphGrpcService), grpc.WithInsecure())
		if err != nil {
			klog.Error("connect grpc error")
		}
		//defer con.Close()
		dgraph = dgo.NewDgraphClient(api.NewDgraphClient(con))
	})

	return dgraph
}

func NewDgraphClient() *dgo.Dgraph {
	// Dial a gRPC connection. The address to dial to can be configured when
	// setting up the dgraph cluster.
	var once sync.Once
	var dgraph *dgo.Dgraph
	once.Do(func() {
		con, err := grpc.Dial(config.GetDefaultUrl(config.DgraphGrpcService), grpc.WithInsecure())
		if err != nil {
			klog.Error("connect grpc error")
		}
		//defer con.Close()
		dgraph = dgo.NewDgraphClient(api.NewDgraphClient(con))
	})

	return dgraph
}

func GetDgraph(query string) DgraphCount {
	dg := NewDgraphClient()
	txn := dg.NewReadOnlyTxn().BestEffort()

	Dresp, err := txn.Query(context.Background(), query)
	if err != nil {
		klog.Error(err.Error())
	}
	re := DgraphCount{Host: make([]HostCount, 0, 31)}
	e := json.Unmarshal(Dresp.Json, &re)
	if e != nil {
		klog.Error("json unmarshal error...." + e.Error())
	}
	return re
}

func String2int(s []prom.RateTop, d []cmdbmodel.PhysicalHostData) []Column {
	c := []Column{}
	for i := 0; i < len(s); i++ {
		for j := 0; j < len(d); j++ {
			if s[i].Instance == d[j].ManagementIP+":9100" {
				s[i].Instance = d[j].Name
				s[i].Ip = d[j].ManagementIP
				break
			}
		}
		a := Column{Name: s[i].Instance, Percent: s[i].Value, Ip: s[i].Ip}
		c = append(c, a)
	}
	return c
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/dgraphmanager/model.go
```golang
package dgraphmanager

type DgraphCount struct {
	Host []HostCount `json:"host"`
}

type HostCount struct {
	Count          int    `json:"count"`
	Label          string `json:"label"`
	Ip             string `json:"ip"`
	HostName       string `json:"hostname"`
	HostRegionName string `json:"hostRegionName"`
	HostRegionCode string `json:"hostRegionCode"`
	HostLabName    string `json:"hostLabName"`
	HostAzName     string `json:"hostAzName"`
	HostAzCode     string `json:"hostAzCode"`
	Sn             string `json:"sn"`
	RunStatus      string `json:"runstatus"`
	Os             string `json:"system"`
	ServiceType    string `json:"serviceType"`
}

type Column struct {
	Name    string `json:"name"`
	Percent string `json:"percent"`
	Ip      string `json:"ip"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/prometheusmanager/prometheusservice.go
```golang
package prometheusmanager

import (
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"strconv"
	"strings"
	"time"

	"k8s.io/klog/v2"

	"net/url"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	prometheusModel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/prometheus"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

type RateTopResult struct {
	Metric string    `json:"metric"`
	Result []RateTop `json:"result"`
}

type RateTop struct {
	Instance string        `json:"instance"`
	Value    string        `json:"value"`
	Values   []interface{} `json:"values"`
	Ip       string        `json:"ip"`
}

// 获取CPU总量
func GetCpuTotal(ips string, gtime time.Time) (RateTopResult, error) {
	param := `count(node_cpu_seconds_total{instance=~"(` + ips + `)",mode='system'})`
	data, err := GetRateData(param, gtime)
	return data, err
}

// 获取CPU使用率
func GetCpuRate(ips string, gtime time.Time) (RateTopResult, error) {
	param := `100*(1-sum(increase(node_cpu_seconds_total{instance=~"(` + ips + `)",mode="idle"}[5m]))/sum(increase(node_cpu_seconds_total{instance=~"(` + ips + `)"}[5m])))`
	data, err := GetRateData(param, gtime)
	return data, err
}

// 获取CPU使用率
func GetCpuRateNew(poolName string, gtime time.Time) (RateTopResult, error) {
	param := `100*(1-sum(increase(node_cpu_seconds_total{resourcePool="` + poolName + `",mode="idle"}[5m]))/sum(increase(node_cpu_seconds_total{resourcePool="` + poolName + `"}[5m])))`
	data, err := GetRateData(param, gtime)
	return data, err
}

// 获取内存总量
func GetMemoryTotal(ips string, gtime time.Time) (RateTopResult, error) {
	param := `sum(node_memory_MemTotal_bytes{instance=~"(` + ips + `)"})`
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetMemoryRateNew(poolName string, gtime time.Time) (RateTopResult, error) {
	param := `100-sum(node_memory_MemAvailable_bytes{resourcePool="` + poolName + `"})/sum(node_memory_MemTotal_bytes{resourcePool="` + poolName + `"})*100`
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetMemoryRate(ips string, gtime time.Time) (RateTopResult, error) {
	param := `100-sum(node_memory_MemAvailable_bytes{instance=~"(` + ips + `)"})/sum(node_memory_MemTotal_bytes{instance=~"(` + ips + `)"})*100`
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetDiskRateNew(poolName string, gtime time.Time) (RateTopResult, error) {
	param := `(sum(node_filesystem_size_bytes{resourcePool="` + poolName + `",device=~"/dev/.*"})-sum(node_filesystem_free_bytes{resourcePool="` + poolName + `",device=~"/dev/.*"}))*100/(sum(node_filesystem_avail_bytes{resourcePool="` + poolName + `",device=~"/dev/.*"})+sum(node_filesystem_size_bytes{resourcePool="` + poolName + `",device=~"/dev/.*"})-sum(node_filesystem_free_bytes{resourcePool="` + poolName + `",device=~"/dev/.*"}))`
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetDiskRate(ips string, gtime time.Time) (RateTopResult, error) {
	param := `(sum(node_filesystem_size_bytes{instance=~"(` + ips + `)",device=~"/dev/.*"})-sum(node_filesystem_free_bytes{instance=~"(` + ips + `)",device=~"/dev/.*"}))*100/(sum(node_filesystem_avail_bytes{instance=~"(` + ips + `)",device=~"/dev/.*"})+sum(node_filesystem_size_bytes{instance=~"(` + ips + `)",device=~"/dev/.*"})-sum(node_filesystem_free_bytes{instance=~"(` + ips + `)",device=~"/dev/.*"}))`
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetCpuRateTop(top string, ips string, gtime time.Time) (RateTopResult, error) {
	//param := `topk(` + top + `,((1-sum(increase(node_cpu_seconds_total{instance=~"(` + ips + `)",mode="idle"}[5m]))by(instance)/sum(increase(node_cpu_seconds_total{instance=~"(` + ips + `)"}[5m]))by(instance))*100))`
	param := `topk(` + top + `,100 - sum(node_cpu_seconds_total{instance=~"(` + ips + `)",mode="idle"})by(instance) / sum(node_cpu_seconds_total{instance=~"(` + ips + `)"})by(instance) * 100)`
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetCpuRateTopK(top, ips, t string, gtime time.Time) (RateTopResult, error) {
	param := `topk(` + top + `,((1-sum(avg_over_time(node_cpu_seconds_total{instance=~"(` + ips + `)",mode="idle"}[` + t + `]))by(instance)/sum(avg_over_time(node_cpu_seconds_total{instance=~"(` + ips + `)"}[` + t + `]))by(instance))*100))`
	data, err := GetRateData(param, gtime)
	return data, err
}

// 服务器cpu使用率top
func GetCpuRateTopKNew(top, ips, t string, gtime time.Time) (RateTopResult, error) {
	param := `topk(` + top + `,avg(instance:cpu_use_percent:avg` + t + `{instance=~"(` + ips + `)"})by(instance))`
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetMemoryRateTop(top string, ips string, gtime time.Time) (RateTopResult, error) {
	param := `topk(` + top + `,100-((node_memory_MemAvailable_bytes{instance=~"(` + ips + `)"}*100)/node_memory_MemTotal_bytes{instance=~"(` + ips + `)"}))`
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetMemoryRateTopK(top, ips, t string, gtime time.Time) (RateTopResult, error) {
	param := `topk(` + top + `,1-(avg_over_time(node_memory_MemAvailable_bytes{instance=~"(` + ips + `)"}[` + t + `]))/(avg_over_time(node_memory_MemTotal_bytes{instance=~"(` + ips + `)"}[` + t + `])))`
	data, err := GetRateData(param, gtime)
	return data, err
}

// 服务器mem使用率top
func GetMemoryRateTopKNew(top, label, t string, gtime time.Time) (RateTopResult, error) {
	param := `topk(` + top + `,avg(avg_over_time(instance:memory_use_percent{` + label + `}[` + t + `]))by(instance))`
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetNetworkReceiveRateTopK(top, ips, t string, gtime time.Time) (RateTopResult, error) {
	param := `topk(` + top + `,sum(avg_over_time(node_network_receive_bytes_total{instance=~"(` + ips + `)",device=~"(?i)^(en|eth).+$"}[` + t + `]))by(instance))`
	data, err := GetRateData(param, gtime)
	return data, err
}

// 服务器网卡入口流量使用率top
func GetNetworkReceiveRateTopKNew(top, label, t string, gtime time.Time) (RateTopResult, error) {
	param := `topk(` + top + `,sum(instance:network_reveive_bps:avg` + t + `{` + label + `})by(instance))`
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetDiskRateTop(top string, ips string, gtime time.Time) (RateTopResult, error) {
	//param := `topk(` + top + `,(node_filesystem_size_bytes{instance=~"(` + ips + `)",device=~"/dev/.*"}-node_filesystem_free_bytes{instance=~"(` + ips + `)",device=~"/dev/.*"})*100/(node_filesystem_avail_bytes{instance=~"(` + ips + `)",device=~"/dev/.*"}+node_filesystem_size_bytes{instance=~"(` + ips + `)",device=~"/dev/.*"}-node_filesystem_free_bytes{instance=~"(` + ips + `)",fstype=~"ext.*|xfs",mountpoint="/"}))`
	param := `topk(` + top + `,100 - sum(node_filesystem_free_bytes{instance=~"(` + ips + `)",mountpoint=~"/vm_data|/|/boot",fstype!="rootfs"})by(instance) / sum(node_filesystem_size_bytes{instance=~"(` + ips + `)",mountpoint=~"/vm_data|/|/boot",fstype!="rootfs"})by(instance) * 100)`
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetDiskRateTopK(top, ips, t string, gtime time.Time) (RateTopResult, error) {
	param := `topk(` + top + `,1 - sum(avg_over_time(node_filesystem_free_bytes{instance=~"(` + ips + `)",mountpoint=~"/vm_data|/|/boot",fstype!="rootfs"}[` + t + `]))by(instance) / sum(avg_over_time(node_filesystem_size_bytes{instance=~"(` + ips + `)",mountpoint=~"/vm_data|/|/boot",fstype!="rootfs"}[` + t + `]))by(instance))`
	data, err := GetRateData(param, gtime)
	return data, err
}

// 服务器Disk使用率top
func GetDiskRateTopKNew(top, label, t string, gtime time.Time) (RateTopResult, error) {
	param := `topk(` + top + `,1 - sum(avg_over_time(node_filesystem_free_bytes{` + label + `,mountpoint=~"/vm_data|/|/boot",fstype!="rootfs"}[` + t + `]))by(instance)/sum(avg_over_time(node_filesystem_size_bytes{` + label + `,mountpoint=~"/vm_data|/|/boot",fstype!="rootfs"}[` + t + `]))by(instance))`
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetNetworkTransmitRateTopK(top, ips, t string, gtime time.Time) (RateTopResult, error) {
	param := `topk(` + top + `,sum(avg_over_time(node_network_transmit_bytes_total{instance=~"(` + ips + `)",device=~"(?i)^(en|eth).+$"}[` + t + `]))by(instance))`
	data, err := GetRateData(param, gtime)
	return data, err
}

// 服务器网卡出口流量使用率top
func GetNetworkTransmitRateTopKNew(top, label, t string, gtime time.Time) (RateTopResult, error) {
	param := `topk(` + top + `,sum(instance:network_transmit_bps:avg` + t + `{` + label + `})by(instance))`
	data, err := GetRateData(param, gtime)
	return data, err
}

// 从prometheus中获取 不需要ips了需要ks3,ebs_ssd,ebs3_ssd,ehdd_ehdd
func GetCapRate(region string, poolName string, gtime time.Time) (RateTopResult, error) {

	param := fmt.Sprintf(`1024*1024*1024*storage_resource_pool_usage{resourcePoolName="%v"}[10m]/storage_resource_pool_total{resourcePoolName="%v"}[10m] *100`, poolName, poolName)
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetCapTotal(region string, poolName string, gtime time.Time) (RateTopResult, error) {

	param := fmt.Sprintf(`storage_resource_pool_total{resourcePoolName="%v"}[11m]`, poolName)
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetCapTotalMultiAz(region, az, poolName string, gtime time.Time) (RateTopResult, error) {

	param := fmt.Sprintf(`storage_resource_pool_total{resourcePoolName="%v",az="%v"}[11m]`, poolName, az)
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetCapUsed(region string, poolName string, gtime time.Time) (RateTopResult, error) {

	param := fmt.Sprintf(`storage_resource_pool_usage{resourcePoolName="%v"}[11m]`, poolName)
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetEbsCapTotal(region, az, poolName string, gtime time.Time) (RateTopResult, error) {
	query := services.BuildCommonCondition(region, az, "resourcePoolName=\""+poolName+"\"")
	param := fmt.Sprintf(`storage_resource_pool_total{%v}[11m]`, query)
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetEbsCapUsed(region, az, poolName string, gtime time.Time) (RateTopResult, error) {
	query := services.BuildCommonCondition(region, az, "resourcePoolName=\""+poolName+"\"")
	param := fmt.Sprintf(`storage_resource_pool_usage{%v}[11m]`, query)
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetCapUsedMultiAz(region, az, poolName string, gtime time.Time) (RateTopResult, error) {
	param := fmt.Sprintf(`storage_resource_pool_usage{resourcePoolName="%v",az="%v"}[11m]`, poolName, az)
	data, err := GetRateData(param, gtime)
	return data, err
}

func GetStorageUseQuery(region, az, poolName, start, end, step, metric string) prometheusModel.ResponseMetric {

	responseMetric := prometheusModel.ResponseMetric{}
	rangIf := false
	if start != "" && end != "" && step != "" {
		rangIf = true
	}
	switch metric {
	case "CapRate":
		query := fmt.Sprintf(`storage_resource_pool_usage{resourcePoolName="%v"}/storage_resource_pool_total{resourcePoolName="%v"}`, poolName, poolName)
		c, _ := PrometheusQuery(rangIf, start, end, step, query)
		r := prometheusModel.ResponseMetric{}
		r.Metric = metric
		r.Value = c
		responseMetric = r
	case "CapTotal":
		query := fmt.Sprintf(`storage_resource_pool_total{resourcePoolName="%v",az="%v"}`, poolName, az)
		if poolName == "ks3" || strings.Contains(poolName, "ks3") {
			query = fmt.Sprintf(`floor(storage_resource_pool_total{resourcePoolName="%v"})`, poolName)
		}
		c, _ := PrometheusQuery(rangIf, start, end, step, query)
		r := prometheusModel.ResponseMetric{}
		r.Metric = "总量"
		r.Value = c
		responseMetric = r
	case "CapUsed":
		query := fmt.Sprintf(`storage_resource_pool_usage{resourcePoolName="%v"}`, poolName)
		c, _ := PrometheusQuery(rangIf, start, end, step, query)
		r := prometheusModel.ResponseMetric{}
		r.Metric = metric
		r.Value = c
		responseMetric = r
	}
	return responseMetric
}

func GetServiceQuery(ip, groupName, state, start, end, step, metric string) prometheusModel.ResponseMetric {

	responseMetric := prometheusModel.ResponseMetric{}
	rangIf := false
	if start != "" && end != "" && step != "" {
		rangIf = true
	}
	switch metric {
	case "ProcessStates":
		c, _ := PrometheusQuery(rangIf, start, end, step, `namedprocess_namegroup_states{groupname="map[:`+groupName+`]",instance="`+ip+`:9256",state="`+state+`"}`)
		r := prometheusModel.ResponseMetric{}
		r.Metric = metric //服务状态
		r.Value = c
		responseMetric = r
	case "ProcessThreadNum":
		c, _ := PrometheusQuery(rangIf, start, end, step, `namedprocess_namegroup_num_threads{groupname="map[:`+groupName+`]",instance="`+ip+`:9256"}`)
		r := prometheusModel.ResponseMetric{}
		r.Metric = metric //服务线程数量
		r.Value = c
		responseMetric = r
	case "CapRate":
		c, _ := PrometheusQuery(rangIf, start, end, step, `sum(rate(namedprocess_namegroup_cpu_seconds_total{groupname="map[:`+groupName+`]",instance="`+ip+`:9256"}[5m]))*100`)
		r := prometheusModel.ResponseMetric{}
		r.Metric = metric
		r.Value = c
		responseMetric = r
	case "MemoryRate":
		c, _ := PrometheusQuery(rangIf, start, end, step, `sum(namedprocess_namegroup_memory_bytes{groupname="map[:`+groupName+`]",instance="`+ip+`:9256",memtype="resident"})/sum(namedprocess_namegroup_memory_bytes{groupname="map[:`+groupName+`]",instance="`+ip+`:9256"})*100`)
		r := prometheusModel.ResponseMetric{}
		r.Metric = metric
		r.Value = c
		responseMetric = r
	case "DiskRate":
		c, _ := PrometheusQuery(rangIf, start, end, step, `sum(namedprocess_namegroup_memory_bytes{groupname="map[:`+groupName+`]",instance="`+ip+`:9256",memtype="resident"})/sum(namedprocess_namegroup_memory_bytes{groupname="map[:`+groupName+`]",instance="`+ip+`:9256"})`)
		r := prometheusModel.ResponseMetric{}
		r.Metric = metric
		r.Value = c
		responseMetric = r
	case "DiskIOWrite":
		c, _ := PrometheusQuery(rangIf, start, end, step, `rate(namedprocess_namegroup_write_bytes_total{groupname="map[:`+groupName+`]",instance="`+ip+`:9256"}[100s])`)
		r := prometheusModel.ResponseMetric{}
		r.Metric = metric
		r.Value = c
		responseMetric = r
	case "DiskIORead":
		c, _ := PrometheusQuery(rangIf, start, end, step, `rate(namedprocess_namegroup_read_bytes_total{groupname="map[:`+groupName+`]",instance="`+ip+`:9256"}[100s])`)
		r := prometheusModel.ResponseMetric{}
		r.Metric = metric
		r.Value = c
		responseMetric = r
	}
	return responseMetric
}

const (
	/*
	  1、对象存储概览
	*/
	STORE_TOTAL = "sum(sum_over_time(bucket_store_total%s[10m]))by(storageclass)"    //存储总流量
	WIDE_UP     = "sum(sum_over_time(bucket_wide_up%s[10m]))by(isinner,cdn)"         //总流入流量
	WIDE_DOWN   = "sum(sum_over_time(bucket_wide_down%s[10m]))by(isinner,cdn)"       //总流出流量
	API_REQUEST = "sum(sum_over_time(bucket_wide_times%s[10m]))"                     //总体API请求
	STORE_COUNT = "count(sum(sum_over_time(bucket_store_total%s[10m]))by(bucketid))" //存储空间(Bucket)数量

	/*
	  2、对象存储概览top
	*/
	TOTAL_FLOW_UP    = "topk(%s,sum(sum_over_time(bucket_wide_up%s[%s]))by(bucketid,bucketname))"                 //总流量监控流入
	TOTAL_FLOW_DOWN  = "topk(%s,sum(sum_over_time(bucket_wide_down%s[%s]))by(bucketid,bucketname))"               //总流量监控流出
	TOTAL_REQUEST    = "topk(%s,sum(sum_over_time(bucket_wide_times%s[%s]))by(bucketid,bucketname))"              //总请求监控
	CAPACITY         = "topk(%s,sum(sum_over_time(bucket_store_total%s[%s]))by(bucketid,bucketname))"             //空间容量
	CAPACITY_ERR     = "topk(%s,sum(sum_over_time(bucket_wide_times{code!=\"200\"}[%s]))by(bucketid,bucketname))" //空间异常
	CAPACITY_SUCCESS = "sum(sum_over_time(bucket_wide_times%s[%s]))by(bucketid,bucketname)"                       //存储空间请求总数                                                                //存储空间成功率

	/*
		3、图表查询下拉选项
	*/
	CDN = "cdn"
	OUT = "out"
	IN  = "in"

	/*
	  4、操作
	*/
	READ  = "read"
	WRITE = "write"
)

// 云产品监控-对象存储概览
func GetBucketOverview(region, storageType, metric string) []byte {
	queryInfo := ""
	hasRegion := region != ""
	hasStorageType := storageType != ""
	hasAPI := metric == "APIGet" || metric == "APIPut"
	if hasRegion || hasStorageType || hasAPI {
		queryInfo = "{%s}"
	}
	queryInput := ""
	var queryArray []string
	if hasRegion {
		queryArray = append(queryArray, fmt.Sprintf("region=\"%s\"", region))
	}
	if hasStorageType {
		queryArray = append(queryArray, fmt.Sprintf("storageclass=\"%s\"", storageType))
	}
	//API请求特殊处理
	if metric == "APIGet" {
		queryArray = append(queryArray, fmt.Sprintf("operation=~\"%s\"", "REST.GET.*"))
	}
	if metric == "APIPut" {
		queryArray = append(queryArray, fmt.Sprintf("operation=~\"%s\"", "REST.PUT.*"))
	}
	if len(queryArray) > 0 {
		queryInput = strings.Join(queryArray, ",")
	}
	if queryInput != "" && queryInfo != "" {
		queryInfo = fmt.Sprintf(queryInfo, queryInput)
	}
	switch metric {
	//存储总容量
	case "BucketStore":
		queryInfo = fmt.Sprintf(STORE_TOTAL, queryInfo)
		//流入总量
	case "WideUp":
		queryInfo = fmt.Sprintf(WIDE_UP, queryInfo)
		//流出总量
	case "WideDown":
		queryInfo = fmt.Sprintf(WIDE_DOWN, queryInfo)
	case "APIGet", "APIPut":
		queryInfo = fmt.Sprintf(API_REQUEST, queryInfo)
	case "StoreCount":
		queryInfo = fmt.Sprintf(STORE_COUNT, queryInfo)
	}
	c, _ := PrometheusBasicQuery(false, "", "", "", queryInfo)
	return c
}

// 云产品监控-对象存储概览top
func GetBucketOverviewTop(region, storageType, flowSelect, requestType, operate, metric, time, top, code string) []byte {
	queryInfo := ""
	hasRegion := region != ""
	hasStorageType := storageType != ""
	hasFlowSelect := flowSelect != ""
	hasRequestType := requestType != ""
	hasOperate := operate != ""
	if hasRegion || hasStorageType || hasFlowSelect || hasRequestType || hasOperate {
		queryInfo = "{%s}"
	}
	queryInput := ""
	var queryArray []string
	if hasRegion {
		queryArray = append(queryArray, fmt.Sprintf("region=\"%s\"", region))
	}
	if hasStorageType {
		queryArray = append(queryArray, fmt.Sprintf("storageclass=\"%s\"", storageType))
	}
	//处理下拉选项查询
	if hasFlowSelect {
		flowSelectInput := ""
		switch flowSelect {
		case CDN:
			flowSelectInput = "cdn!=\"-\""
		case OUT:
			flowSelectInput = "cdn=\"-\",isinner=\"false\""
		case IN:
			flowSelectInput = "cdn=\"-\",isinner=\"true\""
		}
		queryArray = append(queryArray, flowSelectInput)
	}
	//处理操作
	if hasOperate {
		operateInput := ""
		switch operate {
		case READ:
			operateInput = "operation=~\"REST.HEAD.OBJECT|REST.GET.BUCKET.LOCATION\""
		case WRITE:
			operateInput = "operation=\"REST.PUT.OBJECT\""
		}
		queryArray = append(queryArray, operateInput)
	}
	if code != "" {
		queryArray = append(queryArray, code)
	}
	if hasRequestType {
		if requestType == "get" {
			queryArray = append(queryArray, fmt.Sprintf("operation=~\"%s\"", "REST.GET.*"))
		} else {
			queryArray = append(queryArray, fmt.Sprintf("operation=~\"%s\"", "REST.PUT.*"))
		}
	}
	if len(queryArray) > 0 {
		queryInput = strings.Join(queryArray, ",")
	}
	if queryInput != "" && queryInfo != "" {
		queryInfo = fmt.Sprintf(queryInfo, queryInput)
	}
	switch metric {
	//总流量监控流入
	case "totalFlowUp":
		queryInfo = fmt.Sprintf(TOTAL_FLOW_UP, top, queryInfo, time)
		//总流量监控流出
	case "totalFlowDown":
		queryInfo = fmt.Sprintf(TOTAL_FLOW_DOWN, top, queryInfo, time)
		//总请求监控
	case "totalRequest":
		queryInfo = fmt.Sprintf(TOTAL_REQUEST, top, queryInfo, time)
		//空间容量
	case "capacity":
		queryInfo = fmt.Sprintf(CAPACITY, top, queryInfo, time)
		//空间异常
	case "capacityErr":
		queryInfo = fmt.Sprintf(CAPACITY_ERR, top, time)
		//存储空间成功率
	case "capacitySuccess":
		queryInfo = fmt.Sprintf(CAPACITY_SUCCESS, queryInfo, time)
	}
	c, _ := PrometheusBasicQuery(false, "", "", "", queryInfo)
	return c
}

func GetRateData(param string, gtime time.Time) (RateTopResult, error) {
	klog.Infof("get prometheus sql %s", param)
	client := http.Client{}
	api := "http://" + config.GetDefaultUrl(config.PrometheusService) + "/api/v1/query?query="
	//param := `100 * (1 - sum(increase(node_cpu_seconds_total{instance=~"(`+ips+`)",mode="idle"}[5m])) / sum(increase(node_cpu_seconds_total{instance=~"(`+ips+`)"}[5m])))`
	//param := `rate%28process_cpu_seconds_total%7Bjob%3D%22external-nodes%22%2Cinstance%3D%7E%22%2810.177.9.11%3A9100%29%22%7D%5B5m%5D%29`
	//date:=""
	pTime := "&time=" + fmt.Sprintf("%v", gtime.Unix()) //"&time=1619335251.963"

	resp, err := client.Get(api + url.QueryEscape(param) + pTime) //(`http://10.177.152.168:9090/api/v1/query?query=(sum(node_memory_MemTotal_bytes{instance=~"(10.177.9.11:9100|10.177.16.2:9100)",job="external-nodes"})-sum(node_memory_MemAvailable_bytes{instance=~"(10.177.9.11:9100|10.177.16.2:9100)",job="external-nodes"})-sum(node_memory_Buffers_bytes{instance=~"(10.177.9.11:9100|10.177.16.2:9100)",job="external-nodes"})-sum(node_memory_Cached_bytes{instance=~"(10.177.9.11:9100|10.177.16.2:9100)",job="external-nodes"}))/sum(node_memory_MemTotal_bytes{instance=~"(10.177.9.11:9100|10.177.16.2:9100)",job="external-nodes"})*100&time=1618918668`) //(api + param + pTime) //(`http://10.177.152.168:9090/api/v1/query?query=100*(1-sum(increase(node_cpu_seconds_total{instance=~"(10.177.9.11:9100)",mode="idle"}[5m]))/sum(increase(node_cpu_seconds_total{instance=~"(10.177.9.11:9100)"}[5m])))&time=1618918668`)

	if err != nil {
		klog.Errorf("prometheus get data  error : %s", err.Error())
		return RateTopResult{}, err
	}
	//result := ""
	//zzz := new(simple)
	var data map[string]interface{}
	//dataArr := new(RateData)
	b, er := io.ReadAll(resp.Body)
	if er != nil {
		fmt.Println(err)
	}
	e := json.Unmarshal(b, &data)
	if e != nil {
		fmt.Println(e)
	}
	//klog.Infof("GetRateData response string is: %s", string(b))
	var result RateTopResult

	//wsMap := data.(map[string]interface{})
	if vCw, ok := data["data"]; ok {
		rateData := vCw.(map[string]interface{})
		if resultData, ok := rateData["result"]; ok {
			re := resultData.([]interface{})
			if len(re) > 0 {
				for _, resultD := range re {
					var rateTop RateTop
					valu := resultD.(map[string]interface{})
					if metricData, ok := valu["metric"]; ok {
						metric := metricData.(map[string]interface{})
						if instance, ok := metric["instance"]; ok {
							res := instance.(string)
							rateTop.Instance = res
						}

						//result = res.(string)
						//fmt.Println(res)
					}
					if valueData, ok := valu["value"]; ok {
						value := valueData.([]interface{})
						res := value[1]
						//result = res.(string)
						rateTop.Value = res.(string)
						//fmt.Println(res)
					}
					if valuesData, ok := valu["values"]; ok {
						values := valuesData.([]interface{})
						rateTop.Values = values
						//fmt.Println(res)
					}
					result.Result = append(result.Result, rateTop)
				}
			}
		}

	}
	// fmt.Println(string(b))
	//fmt.Println(data)
	// fmt.Println(resp.Body)
	//fmt.Println(api + param + pTime)
	return result, err
}

func QueryPhsicalMetric(ip, start, end, step string, metrics []string) []prometheusModel.ResponseMetric {

	responseMetric := []prometheusModel.ResponseMetric{}
	rangIf := false
	if start != "" && end != "" && step != "" {
		rangIf = true
	}
	for i := 0; i < len(metrics); i++ {
		switch metrics[i] {
		case "CPULoad":
			c, _ := PrometheusQuery(rangIf, start, end, step, `1-avg(irate(node_cpu_seconds_total{mode="idle",instance="`+ip+`:9100"`+`}[5m]))`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "MemoryUse":
			c, _ := PrometheusQuery(rangIf, start, end, step, `1-node_memory_MemAvailable_bytes{instance=~"`+ip+`:9100"`+`}/node_memory_MemTotal_bytes{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskFree":
			c, _ := PrometheusQuery(rangIf, start, end, step, `1-(sum(node_filesystem_free_bytes{instance=~"`+ip+`:9100"`+`})/sum(node_filesystem_size_bytes{instance=~"`+ip+`:9100"`+`}))`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetIn":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(increase(node_network_receive_bytes_total{instance=~"`+ip+`:9100"`+`}[24h]))`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetOut":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(increase(node_network_transmit_bytes_total{instance=~"`+ip+`:9100"`+`}[24h]))`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "Disk":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_filesystem_free_bytes{fstype!~"(tmpfs|rootfs).*",instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
			//cpu
		case "CPUDetail":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum by (mode) (irate(node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`}[5m]))`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPUMode":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`})by(mode)`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPUModeIdle":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`,mode="idle"})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPUModeIowait":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`,mode="iowait"})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPUModeIrq":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`,mode="irq"})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPUModeSoftIrq":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`,mode="softirq"})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPUModeSteal":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`,mode="steal"})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPUModeSystem":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`,mode="system"})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPUModeUser":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`,mode="user"})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPUModeNice":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`,mode="nice"})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPULoad5Min":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_load5{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPUBusy": //
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum by (mode) (node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPUGuest":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_cpu_guest_seconds_total{instance=~"`+ip+`:9100"`+`})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPUSwitches":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_context_switches_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "SingleCPUIdle":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`,mode="idle"}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
			//mem
		case "MemFree":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_memory_MemAvailable_bytes{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "MemTotal":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_memory_MemTotal_bytes{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "MemSwapFree":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_memory_SwapFree_bytes{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "MemSwapTotal":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_memory_SwapTotal_bytes{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
			//network
		case "NetworkReceive":
			c, _ := PrometheusQuery(rangIf, start, end, step, `irate(node_network_receive_bytes_total{instance=~"`+ip+`:9100"`+`,device=~"(?i)^(ens|eth).+$"}[5m])  > 0`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetworkTransmit":
			c, _ := PrometheusQuery(rangIf, start, end, step, `- irate(node_network_transmit_bytes_total{instance=~"`+ip+`:9100"`+`,device=~"(?i)^(ens|eth).+$"}[5m]) < 0`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetInDrop":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_receive_drop_total{instance=~"`+ip+`:9100"`+`,device=~"(?i)^(ens|eth).+$"}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetOutDrop":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_drop_total{instance=~"`+ip+`:9100"`+`,device=~"(?i)^(ens|eth).+$"}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetInErrs":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_receive_errs_total{instance=~"`+ip+`:9100"`+`,device=~"(?i)^(ens|eth).+$"}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetOutErrs":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_errs_total{instance=~"`+ip+`:9100"`+`,device=~"(?i)^(ens|eth).+$"}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetInPackets":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_receive_packets_total{instance=~"`+ip+`:9100"`+`,device=~"(?i)^(ens|eth).+$"}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetOutPackets":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_packets_total{instance=~"`+ip+`:9100"`+`,device=~"(?i)^(ens|eth).+$"}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetInCompress":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_receive_compressed_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetOutCompress":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_compressed_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetInFifo":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_receive_fifo_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetOutFifo":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_fifo_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetInFrame":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_receive_frame_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetOutFrame":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_frame_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetInMulticast":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_receive_multicast_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetOutMulticast":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_multicast_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetOutCarrier":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_carrier_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetOutCollision":
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_colls_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetInFifoErrs": //
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_colls_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetOutFifoErrs": //
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_colls_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetInFrameErrs": //
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_colls_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetInPercent": //
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_colls_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "NetOutPercent": //
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_colls_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
			//disk
		case "DiskInodeTotal": //inode系列都没有
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_colls_total{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskInodeFree": //
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_network_transmit_colls_total{instance=~"`+ip+`:9100"`+`,device=~"(?i)^(ens|eth).+$"}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "FileSystemSizeBytes":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_filesystem_size_bytes{instance=~"`+ip+`:9100"`+`})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "FileSystemFreeBytes":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_filesystem_free_bytes{instance=~"`+ip+`:9100"`+`})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskStatisticsTotalBytes": //statistics系列都没有
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_filesystem_free_bytes{instance=~"`+ip+`:9100"`+`})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskIoAvgquSize": //
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_filesystem_free_bytes{instance=~"`+ip+`:9100"`+`})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskIoAvgrt.Listize": // await/ios/msec系列都没有
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_filesystem_free_bytes{instance=~"`+ip+`:9100"`+`})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskIoReadBytes":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_disk_read_bytes_total{instance=~"`+ip+`:9100"`+`})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskIoWriteBytes":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_disk_write_bytes_total{instance=~"`+ip+`:9100"`+`})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskIoReadMergedTotal":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_disk_read_merged_total{instance=~"`+ip+`:9100"`+`})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskIoWriteMergedTotal": //request/sectors/svctm/io.util系列没有
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(node_disk_write_merged_total{instance=~"`+ip+`:9100"`+`})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPUUseRate":
			c, _ := PrometheusQuery(rangIf, start, end, step, `1-sum(increase(node_cpu_seconds_total{instance=~"`+ip+`:9100",mode="idle"}[5m]))/sum(increase(node_cpu_seconds_total{instance=~"`+ip+`:9100"}[5m]))`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "CPUUsed":
			c, _ := PrometheusQuery(rangIf, start, end, step, `(1-sum(increase(node_cpu_seconds_total{instance=~"(`+ip+`:9100)",mode="idle"}[5m]))/sum(increase(node_cpu_seconds_total{instance=~"(`+ip+`:9100)"}[5m])))*count(node_cpu_seconds_total{instance=~"(`+ip+`:9100)",mode='system'})`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "MemoryUsed": //request/sectors/svctm/io.util系列没有
			c, _ := PrometheusQuery(rangIf, start, end, step, `node_memory_MemTotal_bytes{instance=~"`+ip+`:9100"`+`}-node_memory_MemAvailable_bytes{instance=~"`+ip+`:9100"`+`}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskUseRate":
			c, _ := PrometheusQuery(rangIf, start, end, step, `(sum(node_filesystem_size_bytes{instance=~"(`+ip+`:9100)",device=~"/dev/.*"})-sum(node_filesystem_free_bytes{instance=~"(`+ip+`:9100)",device=~"/dev/.*"}))/(sum(node_filesystem_avail_bytes{instance=~"(`+ip+`:9100)",device=~"/dev/.*"})+sum(node_filesystem_size_bytes{instance=~"(`+ip+`:9100)",device=~"/dev/.*"})-sum(node_filesystem_free_bytes{instance=~"(`+ip+`:9100)",device=~"/dev/.*"}))`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskUsed":
			c, _ := PrometheusQuery(rangIf, start, end, step, `(sum(node_filesystem_size_bytes{instance=~"(`+ip+`:9100)",device=~"/dev/.*"})-sum(node_filesystem_free_bytes{instance=~"(`+ip+`:9100)",device=~"/dev/.*"}))`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = metrics[i]
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskIoReadsCompletedTotal":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(irate(node_disk_reads_completed_total{instance=~"(`+ip+`:9100)"}[5m]))`)
			r := prometheusModel.ResponseMetric{}
			//r.Metric = "IO读次数"
			r.Metric = "读"
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskIoWritesCompletedTotal":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(irate(node_disk_writes_completed_total{instance=~"(`+ip+`:9100)"}[5m]))`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = "写"
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskIoReadtimeTotal":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(irate(node_disk_read_time_seconds_total{instance=~"(`+ip+`:9100)"}[5m]))`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = "读延时"
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "DiskIoWritetimeTotal":
			c, _ := PrometheusQuery(rangIf, start, end, step, `sum(irate(node_disk_write_time_seconds_total{instance=~"(`+ip+`:9100)"}[5m]))`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = "写延时"
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "HugePageUsage":
			c, _ := PrometheusQuery(rangIf, start, end, step, `(node_memory_HugePages_Total-node_memory_HugePages_Free )*node_memory_Hugepagesize_bytes{instance=~"(`+ip+`:9100)"}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = "大页内存使用量"
			r.Value = c
			responseMetric = append(responseMetric, r)
		case "HugePageUseRate":
			c, _ := PrometheusQuery(rangIf, start, end, step, `1 - node_memory_HugePages_Free / node_memory_HugePages_Total{instance=~"(`+ip+`:9100)"}`)
			r := prometheusModel.ResponseMetric{}
			r.Metric = "大页内存使用率"
			r.Value = c
			responseMetric = append(responseMetric, r)

		}

	}
	return responseMetric
}

func PrometheusQuery(rangeIf bool, start, end, step, query string) (interface{}, error) {
	qr := prometheusModel.QueryResponseObject{}
	body, _ := PrometheusBasicQuery(rangeIf, start, end, step, query)
	er := json.Unmarshal(body, &qr)
	if er != nil {
		return qr.Data, er
	}
	return qr.Data, nil

}

func PrometheusBasicQuery(rangeIf bool, start, end, step, query string) ([]byte, error) {
	klog.Infof("PrometheusBasicQuery queryInput:rangeIf{%v},start{%v},end{%v}, step{%v}, query{%v}", rangeIf, start, end, step, query)
	l := ""
	if rangeIf {
		l = "http://" + config.GetDefaultUrl(config.PrometheusService) + "/api/v1/query_range?query=" + url.QueryEscape(query) + "&start=" + start + "&end=" + end + "&step=" + step
	} else {
		l = "http://" + config.GetDefaultUrl(config.PrometheusService) + "/api/v1/query?query=" + url.QueryEscape(query)
	}
	klog.Infof("PrometheusBasicQuery queryInfo:query{%v}", l)
	c := http.Client{}
	resp, err := c.Get(l)
	if err != nil {
		return nil, err
	}
	body, _ := io.ReadAll(resp.Body)
	return body, nil

}

func PrometheusResultToValue(r interface{}) interface{} {
	var s interface{}
	valu := r.(map[string]interface{})
	if resultData, ok := valu["result"]; ok {
		result := resultData.([]interface{})
		if len(result) > 0 {
			resultForValue := result[0].(map[string]interface{})
			if valueData, ok := resultForValue["values"]; ok {
				return valueData
			}
			if valueData, ok := resultForValue["value"]; ok {
				return valueData
			}
		}
	}

	return s
}

func GetStateByIp(ip string) (string, error) {
	c := http.Client{}
	prome := new(Prometheus)
	resp, err := c.Get("http://" + config.GetDefaultUrl(config.PrometheusService) + "/api/v1/targets")
	if err != nil {
		return "", err
	}

	b, _ := io.ReadAll(resp.Body)
	json.Unmarshal(b, prome)

	state := ""
	for i := 0; i < len(prome.Data.ActiveTargets); i++ {

		if pp := strings.Split(prome.Data.ActiveTargets[i].Labels.Instance, ":"); pp[0] == ip {
			state = prome.Data.ActiveTargets[i].Health
			//prome.Data.ActiveTargets = append(prome.Data.ActiveTargets[:i],prome.Data.ActiveTargets[i+1:]...)
			break
		} else {
			state = "down"
		}
	}
	return state, nil
}

func PrometheusQuery2(rangeIf bool, start, end, step, query string) ([]interface{}, error) {
	klog.Infof("PrometheusQuery", query)
	queryUrl := ""
	if rangeIf {
		queryUrl = "http://" + config.GetDefaultUrl(config.PrometheusService) + "/api/v1/query_range?query=" + url.QueryEscape(query) + "&start=" + start + "&end=" + end + "&step=" + step
	} else {
		queryUrl = "http://" + config.GetDefaultUrl(config.PrometheusService) + "/api/v1/query?query=" + url.QueryEscape(query)
	}
	httpClient := http.Client{Timeout: time.Minute}
	resp, err := httpClient.Get(queryUrl)
	if err != nil {
		klog.Error(err)
	}
	//klog.Infof("PrometheusQuery2 receive query:%s", query)
	klog.Infof("PrometheusQuery2 receive query url:%s", queryUrl)
	//todo err handle {"status":"error","errorType":"bad_data","error":"exceeded maximum resolution of 11,000 points per timeseries. Try decreasing the query resolution (?step=XX)"}
	if resp.StatusCode != 200 {
		respBytes, _ := io.ReadAll(resp.Body)
		klog.Info(string(respBytes))
	}
	qr := QueryResponseObject{}
	err = json.NewDecoder(resp.Body).Decode(&qr)
	if err != nil {
		klog.Error(err)
	}
	//klog.Infof("PrometheusQuery2 response:%+v", qr)
	return qr.Data.Result, nil
}

func PrometheusResultToValue2(r interface{}) interface{} {
	valu := r.(map[string]interface{})
	if valueData, ok := valu["value"]; ok {
		value := valueData.([]interface{})
		vv, _ := strconv.ParseFloat(value[1].(string), 64)
		ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", vv), 64)

		return ss
	} else if Data, o := valu["values"]; o {
		value := Data.([]interface{})
		for i := 0; i < len(value); i++ {
			v := value[i].([]interface{})
			switch v[1].(type) {
			case string:
				vv, _ := strconv.ParseFloat(v[1].(string), 64)
				ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", vv), 64)
				v[1] = ss

			case float64:
				ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", v[1].(float64)), 64)
				v[1] = ss

			}
			value[i] = v
		}
		return value
	}
	return ""
}

func PrometheusResultToValueForPercent(r []interface{}) []interface{} {
	var s []interface{}
	if len(r) > 0 {
		for _, resultD := range r {
			var d interface{}
			valu := resultD.(map[string]interface{})
			if valueData, ok := valu["value"]; ok {
				value := valueData.([]interface{})
				vv, _ := strconv.ParseFloat(value[1].(string), 64)
				ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", vv), 64)
				//res := value[1].(string)
				//result = res.(string)
				d = ss
				//fmt.Println(res)
			} else if Data, o := valu["values"]; o {
				value := Data.([]interface{})
				for i := 0; i < len(value); i++ {
					v := value[i].([]interface{})
					switch v[1].(type) {
					case string:
						vv, _ := strconv.ParseFloat(v[1].(string), 64)
						ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", vv), 64)
						v[1] = ss
					case float64:
						ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", v[1].(float64)), 64)
						v[1] = ss
					}
				}
				//result = res.(string)
				d = value
			}
			s = append(s, d)
		}
		return s
	}
	return s
}

func PrometheusResultToValueForSize(r interface{}) interface{} {

	valu := r.(map[string]interface{})
	if valueData, ok := valu["value"]; ok {
		value := valueData.([]interface{})
		vv, _ := strconv.ParseFloat(value[1].(string), 64)
		ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", vv), 64)

		return services.FormatSize(ss)
	} else if Data, o := valu["values"]; o {
		value := Data.([]interface{})
		for i := 0; i < len(value); i++ {
			v := value[i].([]interface{})
			switch v[1].(type) {
			case string:
				vv, _ := strconv.ParseFloat(v[1].(string), 64)
				v[1] = services.Format_Size(vv)

			case float64:
				v[1] = services.Format_Size(v[1].(float64))

			}
			value[i] = v
		}
		return value
	}
	return ""
}

func FormValue(r interface{}) interface{} {
	switch r.(type) {
	case string:
		vv, _ := strconv.ParseFloat(r.(string), 64)
		ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", vv), 64)
		r = ss
		return r
	case float64:
		ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", r.(float64)), 64)
		r = ss
		return r
	}
	return ""
}

func FormPercent(r interface{}) interface{} {
	switch r.(type) {
	case string:
		vv, _ := strconv.ParseFloat(r.(string), 64)
		ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", vv), 64)
		r = ss
		return r
	case float64:
		ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", r.(float64)), 64)
		r = ss
		return r
	}
	return ""
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/prometheusmanager/model.go
```golang
package prometheusmanager

type Prometheus struct {
	Status string   `json:"status"`
	Data   DataType `json:"data"`
}

type DataType struct {
	ActiveTargets []At `json:"activeTargets"`
}

type At struct {
	DiscoveredLables DisLabels `json:"discoveredLabels"`
	Labels           Lbs       `json:"labels"`
	Health           string    `json:"health"`
}

type DisLabels struct {
	Address string `json:"__address__"`
	Job     string `json:"job"`
}

type Lbs struct {
	Instance string `json:"instance"`
	Job      string `json:"job"`
	Service  string `json:"service"`
}

type QueryResponseObject struct {
	Status string `json:"status"`
	Data   DataT  `json:"data"`
}

type DataT struct {
	ResultType string        `json:"resultType"`
	Result     []interface{} `json:"result"`
}

type ServerTop struct {
	Region string `json:"region"`
	Az     string `json:"az"`
	Lab    string `json:"lab"`
}


```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cloudproduct/handler_common.go
```golang
package cloudproduct

import (
	"sort"
	"strconv"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	vmmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cloudproduct"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"k8s.io/klog/v2"
)

var rankOrder = []string{"top1", "top2", "top3", "top4", "top5", "top6", "top7", "top8", "top9", "top10"}

type GetResourceRedisKeyParam struct {
	ResourceType string `json:"resourceType"`
	Region       string `json:"region"`
	Az           string `json:"az"`
	IntervalStr  string `json:"intervalStr"`
}

//GetResourceRedisKeyList 获取资源列表
func GetResourceRedisKeyList(param *GetResourceRedisKeyParam) (map[string][]string, error) {
	var (
		metricList   []string // 监控指标
		redisKeyList map[string][]string
	)
	switch param.ResourceType {
	case config.CloudVmResource:
		metricList = []string{"CPULoadAvg", "MemLoadAvg", "DiskUsedRange", "NetInAvg", "NetOutAvg"}
		redisKeyList = make(map[string][]string, len(metricList))
	case config.CloudRedisResource:
		metricList = []string{"RedisCpuLoad", "RedisMemoryLoad", "DiskUsedRange", "RedisIntranetInRatio",
			"RedisIntranetOutRatio", "RedisConnectionUsage", "RedisHitRate", "RedisSlowlogLen"}
		redisKeyList = make(map[string][]string, len(metricList))

		//// redis 列表region和az数据不全,特殊处理
		//param.Region = ""
		//for _, metric := range metricList {
		//	var key []string
		//	regionStr := config.CronjobPrefix + param.Region + ":" + param.ResourceType + ":" + metric + ":" + param.IntervalStr
		//	key = append(key, regionStr)
		//	//azStr := config.CronjobPrefix + param.Region + "az.AzCode" + ":" + param.ResourceType + ":" + metric + ":" + param.IntervalStr
		//	//key = append(key, azStr)
		//	redisKeyList[metric] = key
		//}
		//return redisKeyList, nil
		//if param.Region == "" {
		//	for _, metric := range metricList {
		//		var key []string
		//		regionStr := config.CronjobPrefix + param.Region + ":" + param.ResourceType + ":" + metric + ":" + param.IntervalStr
		//		key = append(key, regionStr)
		//		//azStr := config.CronjobPrefix + param.Region + "az.AzCode" + ":" + param.ResourceType + ":" + metric + ":" + param.IntervalStr
		//		//key = append(key, azStr)
		//		redisKeyList[metric] = key
		//	}
		//	return redisKeyList, nil
		//} else {
		//	if param.Az == "" {
		//		for _, metric := range metricList {
		//			var key []string
		//			redisKey := config.CronjobPrefix + param.Region + param.Region + "a" + ":" + param.ResourceType + ":" + metric + ":" + param.IntervalStr
		//			key = append(key, redisKey)
		//			redisKeyList[metric] = key
		//		}
		//		return redisKeyList, nil
		//	}
		//}
	case config.CloudBlockResource:
		metricList = []string{"BwInAvg", "BwOutAvg", "IOIn", "IOOut"}
		redisKeyList = make(map[string][]string, len(metricList))
	case config.CloudEipResource:
		metricList = []string{"EipUtilizationOut", "EipUtilizationIn", "EipPpsOut", "EipPpsIn", "EipBpsOut", "EipBpsIn"}
		redisKeyList = make(map[string][]string, len(metricList))
	case config.CloudLoadResource:
		metricList = []string{"SlbBpsIn", "SlbBpsOut", "SlbPpsIn", "SlbPpsOut", "SlbCps", "SlbActiveconn", "SlbConcurrentconn",
			"SlbInactiveconn", "EipBpsIn", "EipBpsOut", "EipPpsIn", "EipPpsOut", "EipUtilizationIn", "EipUtilizationOut"}
		redisKeyList = make(map[string][]string, len(metricList))
	case config.CloudMysqlResource:
		metricList = []string{"MysqlCpuRate", "MysqlMemRate", "MysqlIopsRead", "MysqlIopsWrite", "MysqlLinkRunning",
			"MysqlLinkConnected", "MysqlBytesReceived", "MysqlBytesSent", "MysqlOps", "MysqlTps"}
		redisKeyList = make(map[string][]string, len(metricList))
	case config.CloudNatResource:
		metricList = []string{"NatBpsIn", "NatBpsInPublic", "NatPpsIn", "NatPpsInPublic", "NatBpsOut", "NatBpsOutPublic", "NatPpsOut", "NatPpsOutPublic"}
		redisKeyList = make(map[string][]string, len(metricList))
	}
	regionList, err := cmdbmanager.ReadRegionFromCMDB() // 获取region列表

	//如果region为空 获取全部Region 与Az
	if param.Region == "" {
		if err != nil {
			klog.Errorf("get_getRegions_fail:", err)
			return redisKeyList, err
		}
		for _, region := range regionList.Data {
			for _, metric := range metricList {
				var key []string
				regionStr := config.CronjobPrefix + region.RegionCode + ":" + param.ResourceType + ":" + metric + ":" + param.IntervalStr
				key = append(key, regionStr)
				for _, az := range region.ContainAzs {
					azStr := config.CronjobPrefix + region.RegionCode + az.AzCode + ":" + param.ResourceType + ":" + metric + ":" + param.IntervalStr
					key = append(key, azStr)
				}
				if param.ResourceType == "MYSQL" || param.ResourceType == "Redis"{
					regionNull := config.CronjobPrefix + param.Region + param.Az + ":" + param.ResourceType + ":" + metric + ":" + param.IntervalStr
					key = append(key, regionNull)
				}
				redisKeyList[metric] = key
			}
		}
	} else {
		// Region存在 Az全部
		if param.Region != "" && (param.Az == "all") || (param.Az == "") {
			for _, metric := range metricList {
				for _, region := range regionList.Data {
					if region.RegionCode == param.Region { // 当前region不等于传入Region
						var key []string
						regionStr := config.CronjobPrefix + region.RegionCode + ":" + param.ResourceType + ":" + metric + ":" + param.IntervalStr
						key = append(key, regionStr)
						for _, az := range region.ContainAzs {
							redisKey := config.CronjobPrefix + param.Region + az.AzCode + ":" + param.ResourceType + ":" + metric + ":" + param.IntervalStr
							key = append(key, redisKey)
						}
						redisKeyList[metric] = key
					}
				}
			}
		} else {
			// Region存在 Az存在
			for _, metric := range metricList {
				var key []string
				redisKey := config.CronjobPrefix + param.Region + param.Az + ":" + param.ResourceType + ":" + metric + ":" + param.IntervalStr
				key = append(key, redisKey)
				redisKeyList[metric] = key
			}
		}

	}
	return redisKeyList, nil
}

//云主机排序方法
func VmValueOrder(in []vmmodel.VmValueType, code string) []vmmodel.VmValueType {
	results := alert.Bucket{}
	for i := 0; i < len(in); i++ {
		results.Slice = append(results.Slice, in[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	switch code {
	case "asc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(vmmodel.VmValueType).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(vmmodel.VmValueType).Value), 64)
			return aa < bb
		}
	case "desc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(vmmodel.VmValueType).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(vmmodel.VmValueType).Value), 64)
			return aa > bb
		}
	}

	results.By = time_by
	sort.Sort(results)
	for i := 0; i < len(in); i++ {
		in[i] = results.Slice[i].(vmmodel.VmValueType)
	}
	return in
}

func NatValueOrder(in []vmmodel.VmValueType, code string) []vmmodel.VmValueType {
	results := alert.Bucket{}
	for i := 0; i < len(in); i++ {
		results.Slice = append(results.Slice, in[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	switch code {
	case "asc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(vmmodel.VmValueType).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(vmmodel.VmValueType).Value), 64)
			return aa < bb
		}
	case "desc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(vmmodel.VmValueType).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(vmmodel.VmValueType).Value), 64)
			return aa > bb
		}
	}

	results.By = time_by
	sort.Sort(results)
	for i := 0; i < len(in); i++ {
		in[i] = results.Slice[i].(vmmodel.VmValueType)
	}
	return in
}

// MySQL排序方法
//func MysqlValueOrder(in []cloudTask.MysqlValueType, code string) []cloudTask.MysqlValueType {
//	results := alert.Bucket{}
//	for i := 0; i < len(in); i++ {
//		results.Slice = append(results.Slice, in[i])
//	}
//	time_by := func(a, b interface{}) bool {
//		return true
//	}
//
//	switch code {
//	case "asc":
//		time_by = func(a, b interface{}) bool {
//			aa, _ := strconv.ParseFloat(services.Strval(a.(cloudTask.MysqlValueType).Value), 64)
//			bb, _ := strconv.ParseFloat(services.Strval(b.(cloudTask.MysqlValueType).Value), 64)
//			return aa < bb
//		}
//	case "desc":
//		time_by = func(a, b interface{}) bool {
//			aa, _ := strconv.ParseFloat(services.Strval(a.(cloudTask.MysqlValueType).Value), 64)
//			bb, _ := strconv.ParseFloat(services.Strval(b.(cloudTask.MysqlValueType).Value), 64)
//			return aa > bb
//		}
//	}
//
//	results.By = time_by
//	sort.Sort(results)
//	for i := 0; i < len(in); i++ {
//		in[i] = results.Slice[i].(cloudTask.MysqlValueType)
//	}
//	return in
//}

// 为双柱（多柱）的Echarts按照top1、top2...进行排序
// 适用于大指标下对应多个小指标，如 流量包含入网和出网，连接数包括活跃、不活跃和拒绝连接数等
// 例子有load、nat等
func AddRankOrder(param []vmmodel.OverViewLineNew) {
	// 判断传参中元素数量：目前的overviewTop类接口返回值都为一个切片，且其只有一个元素
	if len(param) > 1 {
		return
	}
	// param[0]:参数param是一个切片且只有一个值
	res := param[0]
	// Echarts为双柱需要改 subname和name，单柱无需修改，更多柱（>2）的话设置len(res.Echarts)>1即可
	if len(res.Echarts) == 2 {
		echartsValue := res.Echarts
		for _, v := range echartsValue {
			valueList := v.Values
			if len(v.Values) > len(rankOrder) {
				klog.Errorln("valueList is more than rankOrder.")
				valueList = valueList[:len(rankOrder)]
			}
			for i, v := range valueList {
				valueList[i].SubName = v.Name
				valueList[i].Name = rankOrder[i]
			}
		}
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cloudproduct/block.go
```golang
package cloudproduct

import (
	"regexp"
	"sort"
	"strconv"

	"github.com/pkg/errors"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	block "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cloudproduct"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	kts "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/ktsmanager"
	"k8s.io/klog/v2"
)

func GetResourcePoolList(l *block.ListQuery) (block.MonitorBlocks, error) {
	klog.Info("block list")
	klog.Info(l)
	cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "post")
	klog.Info(cmdbCount)
	ms := block.MonitorBlocks{DataList: make([]block.MonitorBlock, 0, cmdbCount)}
	if l.Region == "" {
		l.Region = "all"
	}
	if len(l.Az) == 0 {
		l.Az = []string{}
	}

	cmdb, err := cmdbmanager.GetCMDBBytes(l.Region, l.Az)
	klog.Info("cmdb")
	klog.Info(cmdb)

	if err != nil {
		return ms, err
	}

	if cmdb.Code != 200 {
		return ms, errors.Errorf("get data from nova cmdb error!")
	}

	for i := 0; i < cmdbCount; i++ {

		//多选
		j := cmdb.Data.DataList[i]
		if len(l.StorageType) != 0 {
			stateIn := services.In(l.StorageType, j.ResourcePoolType)
			if !stateIn {
				continue
			}
		}
		if len(l.UseStatus) != 0 {
			stateIn := services.In(l.UseStatus, j.UseStatus)
			if !stateIn {
				continue
			}
		}

		nb, _ := regexp.MatchString(l.Name, j.Name)
		pb, _ := regexp.MatchString(l.Pool, j.ResourcePool)
		tb, _ := regexp.MatchString(l.TenantId, j.TenantId)
		if //(blockMap[l.Region] == j.Region || l.Region == "") && (services.In(l.Az, j.Az) || len(l.Az) == 0) &&
		(nb || l.Name == "") && (pb || l.Pool == "") && (tb || l.TenantId == "") {
			m := block.MonitorBlock{
				ID:          j.InstanceId,
				Name:        j.Name,
				Size:        j.Size,
				UseStatus:   j.UseStatus,
				Region:      j.Region,
				Az:          j.Az,
				TenantId:    j.TenantId,
				CreateTime:  j.CreateTime,
				StorageType: j.ResourcePoolType,
				BlockPool:   j.ResourcePool,
				AlertNumber: 0,
			}
			//多选
			if len(l.RunningStatus) != 0 {
				stateIn := services.In(l.RunningStatus, m.RunningStatus)
				if !stateIn {
					continue
				}
			}
			if j.VmId != "" && j.MountPoint != "" {
				//usepercent
				usePercent := kts.QueryVmMetric(j.VmId, "", "", []string{"DiskFree"})
				if len(usePercent) > 0 {
					use := services.Strval(usePercent[0].Value)
					m.UsePercent, _ = strconv.ParseFloat(use, 64)
				}
				rwIO := kts.QueryVmMetric(j.VmId, "", "", []string{"read", "write"})
				if len(rwIO) > 1 {
					r := services.Strval(rwIO[0].Current)
					m.RIO, _ = strconv.ParseFloat(r, 64)
					w := services.Strval(rwIO[1].Current)
					m.WIO, _ = strconv.ParseFloat(w, 64)

				}
				rwBand := kts.QueryVmMetric(j.VmId, "", "", []string{"Read", "Write"})
				if len(rwBand) > 1 {
					m.RBand = services.Strval(rwBand[0].Current)

					m.WBand = services.Strval(rwBand[1].Current)

				}

			}
			ms.DataList = append(ms.DataList, m)
		}

	}

	//order
	if l.OrderCode != "" && l.OrderType != "" {
		results := alert.Bucket{}
		for i := 0; i < len(ms.DataList); i++ {
			results.Slice = append(results.Slice, ms.DataList[i])
		}
		time_by := func(a, b interface{}) bool {
			return true
		}

		switch l.OrderCode {
		case "usePercent":

			switch l.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(block.MonitorBlock).UsePercent < b.(block.MonitorBlock).UsePercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(block.MonitorBlock).UsePercent > b.(block.MonitorBlock).UsePercent
				}
			}

		}

		results.By = time_by

		sort.Sort(results)
		for i := 0; i < len(results.Slice); i++ {
			ms.DataList[i] = results.Slice[i].(block.MonitorBlock)
		}
	}

	//分页
	low := (l.PageNo - 1) * l.PageSize
	if low > len(ms.DataList) {
		return ms, nil
	}

	hight := low + l.PageSize
	if hight > len(ms.DataList) {
		hight = len(ms.DataList)
	}

	ms.PageNo = l.PageNo
	ms.PageSize = l.PageSize

	ms.TotalCount = len(ms.DataList)
	ms.DataList = ms.DataList[low:hight]
	return ms, nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cloudproduct/bm/bm.go
```golang
package bm

import (
	"fmt"
	"github.com/jinzhu/copier"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/bm"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	kts "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/ktsmanager"
	"k8s.io/klog/v2"
	"sort"
	"strconv"
)

type IBmService interface {
	GetBmList(*bm.ListQuery) (*bm.MonitorBm, error)
}
type BmService struct {
}

func NewBmService() *BmService {
	return &BmService{}
}
func (r *BmService) GetBmList(param *bm.ListQuery) (res *bm.MonitorBm, err error) {

	size := param.PageSize

	param.PageNo = 1
	param.PageSize = int(^uint16(0))
	//获取bm裸金属列表
	cmdbRsp, err := cmdbmanager.GetBmList(*param)
	count := len(cmdbRsp.Data.DataList)
	klog.Infof("get GetBmList count :%d",count)
	if err != nil {
		klog.Errorf("get GetBmList error: %v", err)
		return
	}
	res.DataList = []bm.MonitorInfo{}

	err = copier.Copy(res.DataList, cmdbRsp.Data.DataList)
	if err != nil {
		klog.Errorf("parameter conversion error: %v", err)
		return
	}
	//批量获取监控数据
	err = setDmMetricsInfo(&res.DataList)
	if err != nil {
		klog.Errorf("parameter conversion error: %v", err)
		return
	}
	//order
	if param.OrderCode != "" && param.OrderType != "" {
		results := alert.Bucket{}
		for i := 0; i < len(res.DataList); i++ {
			results.Slice = append(results.Slice, res.DataList[i])
		}
		time_by := func(a, b interface{}) bool {
			return true
		}
		switch param.OrderCode {
		case "cpuLoad":
			if param.OrderType != "" {
				switch param.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(bm.MonitorInfo).CpuRate < b.(bm.MonitorInfo).CpuRate
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(bm.MonitorInfo).CpuRate > b.(bm.MonitorInfo).CpuRate
					}
				}
			}
		}
		results.By = time_by
		sort.Sort(results)
		for i := 0; i < len(results.Slice); i++ {
			res.DataList[i] = results.Slice[i].(bm.MonitorInfo)
		}
	}

	low := (param.PageNo - 1) * size
	if low > len(res.DataList) {
		return res, nil
	}
	hight := low + size
	if hight > len(res.DataList) {
		hight = len(res.DataList)
	}

	res.PageNo = param.PageNo
	res.PageSize = size
	res.TotalCount = len(res.DataList)
	res.DataList = res.DataList[low:hight]

	return
}


func setDmMetricsInfo(instances *[]bm.MonitorInfo) error {
	for i, inst := range *instances {
		host := fmt.Sprintf("kscrds--%s", inst.ID)
		tag := map[string]string{
			"host": host,
		}
		cpuQuery := kts.LastQuery{
			Metric: "rds.cpu_used_percent" + "." + host,
			Tags:   tag,
		}
		memQuery := kts.LastQuery{
			Metric: "rds.memory_used_percent" + "." + host,
			Tags:   tag,
		}
		diskQuery := kts.LastQuery{
			Metric: "rds.memory_used_percent" + "." + host,
			Tags:   tag,
		}
		var queries = []kts.LastQuery{cpuQuery, memQuery, diskQuery}
		metricsMap, err := kts.TSDBLastQueryBatch(queries...)
		if err != nil {
			klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", host)
		}
		cpu := metricsMap[cpuQuery.Metric].Value
		mem := metricsMap[memQuery.Metric].Value
		disk := metricsMap[memQuery.Metric].Value

		vcpu, _ := strconv.ParseFloat(cpu, 64)
		(*instances)[i].CpuRate = services.FormPercent(vcpu)
		vmem, _ := strconv.ParseFloat(mem, 64)
		(*instances)[i].MemRate = services.FormPercent(vmem)
		vdisk, _ := strconv.ParseFloat(disk, 64)
		(*instances)[i].DiskRate = services.FormPercent(vdisk)
	}
	return nil
}
```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cloudproduct/redis/redis_test.go
```golang
package redis

import (
	"reflect"
	"testing"

	"github.com/olivere/elastic"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/redis"
)

func TestRedisService_GetSlowLog(t *testing.T) {
	esAddress := "http://10.178.18.20:9200"
	client, err := elastic.NewClient(
		elastic.SetURL(esAddress),
		// elastic.SetHealthcheck(false),
		elastic.SetSniff(false),
	)
	if err != nil {
		t.Log(err.Error())
	}
	type fields struct {
		esClient *elastic.Client
	}
	type args struct {
		param *redis.LogQueryParam
	}
	tests := []struct {
		name     string
		fields   fields
		args     args
		wantData redis.LogData
		wantErr  bool
	}{
		{
			name:   "云烟",
			fields: fields{esClient: client},
			args: args{
				param: &redis.LogQueryParam{
					Id: "bd24ff31-5a20-433f-9f9a-b4e77b102d48",
				},
			},
		},
	}
	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			r := &RedisService{
				esClient: tt.fields.esClient,
			}
			gotData, err := r.GetSlowLog(tt.args.param)
			if (err != nil) != tt.wantErr {
				t.Errorf("RedisService.GetSlowLog() error = %v, wantErr %v", err, tt.wantErr)
				return
			}
			if !reflect.DeepEqual(gotData, tt.wantData) {
				t.Errorf("RedisService.GetSlowLog() = %v, want %v", gotData, tt.wantData)
			}
		})
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cloudproduct/redis/redis.go
```golang
package redis

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/dbmsservice"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct"
	"reflect"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"time"

	redisLink "github.com/go-redis/redis/v8"
	"github.com/olivere/elastic"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	vmmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cloudproduct"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/redis"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	vm "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct/vm"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/dbmsmanager"
	kts "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/ktsmanager"
	resourcepoolservice "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"k8s.io/klog/v2"
)

type IRedisService interface {
	Overview(*redis.OverviewQuery) (redis.OverView, error)
	OverviewTop(*redis.TopQuery) ([]redis.OverViewLine, error)
	OverviewTopKey(*redis.TopQuery) ([]vmmodel.OverViewLineNew, error)
	GetRedisList(*redis.ListQuery) (redis.MonitorRedisPage, error)
	GetRedisListNew(*redis.ListQuery) (redis.MonitorRedisPage, error)
	GetRedisMetricLine(*redis.MetricQuery) ([]redis.RedisOverViewLine, error)
	GetLogMsg(param *redis.LogQueryParam) (redis.LogData, error)
}

type RedisService struct {
	esClient *elastic.Client
}

func NewRedisService() *RedisService {
	client, err := elastic.NewClient(
		elastic.SetURL(config.KCSRedisLogingElasticsearchAddress),
		elastic.SetSniff(false),
	)
	if err != nil {
		klog.Errorf("KCS redis log elasticsearch connect error: %s", err)
	}
	return &RedisService{
		esClient: client,
	}
}

type Aa struct {
	Id string
}

type Database struct {
	Id          string `gorm:"column:id" json:"id"`
	Name        string `gorm:"column:name" json:"name"`
	Status      string `gorm:"column:status" json:"status"`
	TenantId    string `gorm:"column:tenant_id" json:"tenantId"`
	UserId      string `gorm:"column:uid" json:"userId"`
	UserName    string `gorm:"column:username" json:"userName"`
	ServiceType string `gorm:"column:service_type" json:"dbType"`
	DbVersion   string `gorm:"column:db_version" json:"dbVersion"`
	Ip          string `gorm:"column:ip" json:"ip"`
	Port        int    `gorm:"column:port" json:"port"`
	DeployType  string `gorm:"column:deploy_type" json:"deployType"`
	RamMb       int    `gorm:"column:ram_mb" json:"ramMb"`
	DiskGb      int    `gorm:"column:disk_gb" json:"diskGb"`
	Cpus        int    `gorm:"column:cpus" json:"cpus"`
	//Created      unixtime.UnixTime `gorm:"column:created" json:"created"`
	RegionCode   string `gorm:"column:-" json:"regionCode"`
	RegionName   string `gorm:"column:-" json:"regionName"`
	MultiAZ      bool   `json:"multiAZ"`
	MasterAzCode string `gorm:"column:area" json:"masterAzCode"`
	MasterAzName string `gorm:"column:-" json:"masterAzName"`
	SlaveAzCode  string `gorm:"column:-" json:"slaveAzCode"`
	SlaveAzName  string `gorm:"column:-" json:"slaveAzName"`
}

func (r *RedisService) Overview(param *redis.OverviewQuery) (res redis.OverView, err error) {

	klog.Info("Cloud_Redis_GetVmOverview")
	result := redis.OverView{}
	alerts := make([]resourcepoolmodel.AlertType, 0, 4)
	p0 := resourcepoolmodel.AlertType{Label: "紧急告警", Level: "p0", Kind: "error", Number: 0, Unit: "个"}

	//query mysql
	db := services.MakeMysqlClient()
	defer db.Close()
	p0Count, err := db.Exec("select count(*) from alarm_history where producttype=0")
	if err != nil {
		klog.Error(err)
	} else {
		P0, er := p0Count.LastInsertId()
		if er != nil {
			klog.Error(er)
		}
		p0.Number = P0
	}

	p1 := resourcepoolmodel.AlertType{Label: "重要告警", Level: "p1", Kind: "warn", Number: 0, Unit: "个"}
	p2 := resourcepoolmodel.AlertType{Label: "次要告警", Level: "p2", Kind: "minor", Number: 0, Unit: "个"}
	p3 := resourcepoolmodel.AlertType{Label: "提醒告警", Level: "p3", Kind: "info", Number: 0, Unit: "个"}
	alerts = append(alerts, p0, p1, p2, p3)
	result = redis.OverView{
		Region: param.Region,
		Az:     param.Az,
		Lab:    param.Lab,
		Alerts: alerts,
	}
	return result, nil
}

func (r *RedisService) OverviewTop(param *redis.TopQuery) (res []redis.OverViewLine, err error) {

	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	var nameStr string
	for _, v := range param.Name {
		nameStr += v + "_"
	}
	key := "redis_overviewTop"
	fieldKey := "name_" + nameStr + "topk_" + param.TopK + "_interval_" + intervalStr + "_region" + param.Region + "_Az" + param.Az
	klog.Infof("load OverviewTop key:%s fieldKey: %s", key, fieldKey)

	redisCon := config.RedisConfig

	var rdb *redisLink.Client
	rdb = redisLink.NewClient(&redisLink.Options{
		Addr:       redisCon["Host"].(string),
		Password:   redisCon["Password"].(string),
		DB:         redisCon["Db"].(int),
		MaxRetries: redisCon["MaxRetries"].(int),
	})
	cache, err := utils.NewRedisCache(rdb, key)
	if err != nil {
		klog.Error("get utils.NewRedisCache failed", err)
		return
	}
	result, err := rdb.Ping(context.Background()).Result()
	if err != nil {
		klog.Error("Ping redis failed", err)
		return
	}

	klog.Infof("result %s", result)
	after := time.After(time.Second * 60)

	for {
		select {
		case <-time.After(time.Second):
			data, err := cache.GetData(context.Background(), fieldKey, GetRedisTop(param), time.Minute*10)
			if err != nil {
				klog.Error("redis GetData err ", err)
			}
			if data == "" {
				continue
			}
			var list []redis.OverViewLine
			ee := json.Unmarshal([]byte(data), &list)
			if ee != nil {
				klog.Error("Parsing JSON failed", ee)
			}
			return list, nil
		case <-after:
			return
		}
	}

	return res, nil
}

// 获取redis数据
func GetRedisTop(param *redis.TopQuery) func() (data string, err error) {

	return func() (data string, err error) {
		start := strconv.FormatFloat(param.Start/1000, 'f', 3, 64)
		end := strconv.FormatFloat(param.End/1000, 'f', 3, 64)
		topk, _ := strconv.Atoi(param.TopK)

		//获取redis实例列表
		_, redisIds, err := GetRedisInstanceList(param.Region, "")

		if err != nil {
			klog.Error("get reidsids fail", err)
		}
		rst := make([]redis.OverViewLine, 0, 4)
		monitor := param.Name
		for n := 0; n < len(monitor); n++ {
			switch monitor[n] {
			case "cpu": // cpu使用率
				cpuParam := redis.GetMonitorParam{
					Start:    start,
					End:      end,
					Name:     "CPU使用率",
					Unit:     "%",
					UnitType: "percent",
					Topk:     topk,
					Ids:      redisIds,
					Metric:   []string{"RedisCpuLoad"},
				}
				result := GetMonitorTok(&cpuParam)
				rst = append(rst, result)
			case "mem": // 内存使用率
				memParam := redis.GetMonitorParam{
					Start:    start,
					End:      end,
					Name:     "内存使用率",
					Unit:     "%",
					UnitType: "percent",
					Topk:     topk,
					Ids:      redisIds,
					Metric:   []string{"RedisMemoryLoad"},
				}
				result := GetMonitorTok(&memParam)
				rst = append(rst, result)
			case "inRatio": // 入流量使用率
				inRatioParam := redis.GetMonitorParam{
					Start:    start,
					End:      end,
					Name:     "入流量使用率",
					Unit:     "%",
					UnitType: "percent",
					Topk:     topk,
					Ids:      redisIds,
					Metric:   []string{"RedisIntranetInRatio"},
				}
				result := GetMonitorTok(&inRatioParam)
				rst = append(rst, result)
			case "outRatio": // 出流量使用率
				outRatioParam := redis.GetMonitorParam{
					Start:    start,
					End:      end,
					Name:     "出流量使用率",
					Unit:     "%",
					UnitType: "percent",
					Topk:     topk,
					Ids:      redisIds,
					Metric:   []string{"RedisIntranetOutRatio"},
				}
				result := GetMonitorTok(&outRatioParam)
				rst = append(rst, result)
			case "connectionRatio": // 连接数使用率
				conParam := redis.GetMonitorParam{
					Start:    start,
					End:      end,
					Name:     "连接数使用率",
					UnitType: "percent",
					Unit:     "%",
					Topk:     topk,
					Ids:      redisIds,
					Metric:   []string{"RedisConnectionUsage"},
				}
				result := GetMonitorTok(&conParam)
				rst = append(rst, result)
			case "hitRate": // 缓存命中率
				hitRateParam := redis.GetMonitorParam{
					Start:    start,
					End:      end,
					Name:     "缓存命中率",
					Unit:     "%",
					UnitType: "percent",
					Topk:     topk,
					Ids:      redisIds,
					Metric:   []string{"RedisHitRate"},
				}
				result := GetMonitorTok(&hitRateParam)
				rst = append(rst, result)
			case "slowlogLen": // 慢查询数量
				slowParam := redis.GetMonitorParam{
					Start:    start,
					End:      end,
					Name:     "慢查询数量",
					Unit:     "个",
					UnitType: "count",
					Topk:     topk,
					Ids:      redisIds,
					Metric:   []string{"RedisSlowlogLen"},
				}
				result := GetMonitorTok(&slowParam)
				rst = append(rst, result)
			}
		}
		res, _ := json.Marshal(rst)
		return string(res), nil
	}

}

func (r *RedisService) OverviewTopKey(param *redis.TopQuery) ([]vmmodel.OverViewLineNew, error) {
	ctx, cefl := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cefl()

	//获取时间间隔
	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	topK, _ := strconv.ParseInt(param.TopK, 10, 64)

	//获取redis集合Key
	param1 := cloudproduct.GetResourceRedisKeyParam{
		ResourceType: config.CloudRedisResource,
		Region:       param.Region,
		Az:           param.Az,
		IntervalStr:  intervalStr,
	}
	redisKeyList, err := cloudproduct.GetResourceRedisKeyList(&param1)
	if err != nil {
		return []vmmodel.OverViewLineNew{}, err
	}
	klog.Infof("redisKeyList %+v", redisKeyList)

	//组装数据
	rst := make([]vmmodel.OverViewLineNew, 0)
	name := param.Name
	for i := 0; i < len(name); i++ {
		switch name[i] {
		case "cpu":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			//rr.Info.UnitType = "percent"

			values := getMetricTopValuesFromRedis(redisKeyList, "RedisCpuLoad", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "mem": // 内存使用率
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			//rr.Info.UnitType = "percent"

			values := getMetricTopValuesFromRedis(redisKeyList, "RedisMemoryLoad", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "inRatio": // 入流量使用率
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			//rr.Info.UnitType = "percent"

			values := getMetricTopValuesFromRedis(redisKeyList, "RedisIntranetInRatio", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "outRatio": // 出流量使用率
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			//rr.Info.UnitType = "percent"

			values := getMetricTopValuesFromRedis(redisKeyList, "RedisIntranetOutRatio", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "connectionRatio": // 连接数使用率
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			//rr.Info.UnitType = "percent"

			values := getMetricTopValuesFromRedis(redisKeyList, "RedisConnectionUsage", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "hitRate": // 缓存命中率
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			//rr.Info.UnitType = "percent"

			values := getMetricTopValuesFromRedis(redisKeyList, "RedisHitRate", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "slowlogLen": // 慢查询数量
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "个"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "个"
			rr.Info.UnitType = "count"

			values := getMetricTopValuesFromRedis(redisKeyList, "RedisSlowlogLen", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		}
	}

	return rst, nil
}

func getMetricTopValuesFromRedis(redisKeyList map[string][]string, metricKey string, ctx context.Context, topK int64) []vmmodel.VmValueType {
	var list []vmmodel.VmValueType
	vmCpuKeys := redisKeyList[metricKey] //获取当前metric Key
	//根据key循环获取集合数据
	for _, key := range vmCpuKeys {
		//获取集合数据
		vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
		var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
		//解析成json
		vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
		err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
		if err != nil {
			klog.Errorf("err ", err)
		}
		if len(vmlist) == 0 {
			continue
		}
		list = append(list, vmlist...)
	}

	count := len(list)
	//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
	if int64(count) > topK {
		//排序
		list = cloudproduct.VmValueOrder(list, "desc")
		if int64(len(list)) >= topK {
			list = list[:topK]
		}
	}

	return list
}

// 获取redis 监控数据
func GetMonitorTok(param *redis.GetMonitorParam) redis.OverViewLine {

	result := redis.OverViewLine{Name: param.Name, Unit: param.Unit}
	echarts := redis.EchartType{}
	echarts.Info.Name = param.Name
	echarts.Info.Unit = param.Unit
	echarts.Info.UnitType = param.UnitType
	ids := param.Ids
	for j := 0; j < len(param.Ids); j++ {
		metrics := param.Metric
		tsdbList := kts.QueryVmMetric(ids[j].ID, param.Start, param.End, metrics)
		if len(tsdbList) > 0 {
			ids[j].Value = tsdbList[0].Avg
		}
	}
	out := vm.ValueOrder(ids, "desc")
	if len(out) >= param.Topk {
		out = out[:param.Topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := redis.ValueType{Value: services.FormPercent(valueFloat / 1e2), Name: out[o].Name, VmId: out[o].ID}
		echarts.Values = append(echarts.Values, v)
	}
	result.Echarts = append(result.Echarts, echarts)

	return result
}

// 获取redis列表
func (r *RedisService) GetRedisList(q *redis.ListQuery) (res redis.MonitorRedisPage, err error) {

	if q.SearchKey != "" && q.SearchValue != "" {
		switch q.SearchKey {
		case "id":
			q.Id = q.SearchValue
		case "name":
			q.Name = q.SearchValue
		case "ip":
			q.Ip = q.SearchValue
		case "tenantId":
			q.TenantId = q.SearchValue
		case "tenantName":
			q.TenantName = q.SearchValue

		}
	}

	//获取redis实例列表
	instanceList, _, err := GetRedisInstanceList(q.Region, q.PoolId)
	if err != nil {
		klog.Error(err)
		return res, nil
	}

	rst := redis.MonitorRedisPage{}
	// 筛选
	for _, inst := range instanceList {
		if q.Id != "" {
			if match, _ := regexp.MatchString(q.Id, inst.ID); !match {
				continue
			}
		}
		if q.Name != "" {
			if match, _ := regexp.MatchString(q.Name, inst.Name); !match {
				continue
			}
		}
		if q.Ip != "" {
			if match, _ := regexp.MatchString(q.Ip, inst.Ip); !match {
				continue
			}
		}
		if q.TenantId != "" {
			if match, _ := regexp.MatchString(q.TenantId, inst.TenantId); !match {
				continue
			}
		}
		if q.TenantName != "" {
			if match, _ := regexp.MatchString(q.TenantName, inst.TenantName); !match {
				continue
			}
		}
		if len(q.Status) > 0 && !services.In(q.Status, inst.Status) {
			continue
		}
		if len(q.TenantIdList) > 0 && !services.In(q.TenantIdList, inst.TenantId) {
			continue
		}
		if len(q.TenantNameList) > 0 && !services.In(q.TenantNameList, inst.TenantName) {
			continue
		}
		if len(q.Az) > 0 && !services.In(q.Az, inst.Az) {
			continue
		}
		if len(q.PoolList) > 0 && !services.In(q.PoolList, inst.PoolName) {
			continue
		}

		rst.DataList = append(rst.DataList, inst)
	}

	//order
	if q.OrderCode != "" && q.OrderType != "" {
		orderList := alert.Bucket{}
		for i := 0; i < len(rst.DataList); i++ {
			orderList.Slice = append(orderList.Slice, rst.DataList[i])
		}
		time_by := func(a, b interface{}) bool {
			return a.(redis.MonitorRedis).CreateTime > b.(redis.MonitorRedis).CreateTime
		}

		switch q.OrderCode {
		case "createTime":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(redis.MonitorRedis).CreateTime < b.(redis.MonitorRedis).CreateTime
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(redis.MonitorRedis).CreateTime > b.(redis.MonitorRedis).CreateTime
				}
			}
		}

		orderList.By = time_by
		sort.Sort(orderList)
		for i := 0; i < len(orderList.Slice); i++ {
			rst.DataList[i] = orderList.Slice[i].(redis.MonitorRedis)
		}

	}

	low := (q.PageNo - 1) * q.PageSize
	if low > len(rst.DataList) {
		return rst, nil
	}
	hight := low + q.PageSize
	if hight > len(rst.DataList) {
		hight = len(rst.DataList)
	}

	rst.PageNo = q.PageNo
	rst.PageSize = q.PageSize
	rst.TotalCount = len(rst.DataList)
	rst.DataList = rst.DataList[low:hight]

	// 列表监控数据
	getRedisMetricsInfo(&rst.DataList)
	return rst, nil

}

func (r *RedisService) GetRedisListNew(q *redis.ListQuery) (redis.MonitorRedisPage, error) {

	var redisParam dbmsservice.RedisRequestParam

	redisParam.PageNo = q.PageNo
	redisParam.PageSize = q.PageSize
	redisParam.Region = q.Region
	redisParam.AzCodeList = q.Az
	redisParam.StatusList = q.Status
	redisParam.TenantIDList = q.TenantIdList
	redisParam.TenantNameList = q.TenantNameList
	redisParam.PoolName = q.PoolList
	redisParam.SearchKey = q.SearchKey
	redisParam.SearchValue = q.SearchValue
	redisParam.OrderCode = q.OrderCode
	redisParam.OrderType = q.OrderType

	// 获取 redis 列表
	res, err := dbmsmanager.GetDbRedisList(redisParam)
	klog.Info("get dbmsmanager.GetDbRedisList %+v", res)

	redisList := res.Data.InstanceList
	rst := redis.MonitorRedisPage{}
	for i := 0; i < len(redisList); i++ {
		info := redis.MonitorRedis{}
		info.ID = redisList[i].ID
		info.Name = redisList[i].Name
		info.Status = redisList[i].Status
		info.TenantId = redisList[i].TenantId
		info.TenantName = redisList[i].TenantName
		info.Ip = redisList[i].IP
		info.Region = redisList[i].RegionName
		info.RegionCode = redisList[i].RegionName
		info.Az = redisList[i].AzName
		info.AzCode = redisList[i].AzCode
		info.PoolId = redisList[i].ResourcePoolId
		info.PoolName = redisList[i].ResourcePool
		rst.DataList = append(rst.DataList, info)
	}
	// 获取 Metric 数据
	err = getRedisMetricsInfo(&rst.DataList)
	if err != nil {
		klog.Errorf("set Metrics Info error", err)
	}
	rst.PageNo = res.Data.PageNo
	rst.PageSize = res.Data.PageSize
	rst.TotalCount = res.Data.TotalCount

	// 列表监控数据
	return rst, nil

}

func GetRedisInstanceList(region, poolId string) (res []redis.MonitorRedis, redisIds []vmmodel.CmdbTopVm, err error) {

	const limit = int(^uint16(0))
	dbmsResult, err := dbmsmanager.GetDBResourcePoolList(region, "", []string{"redis"}, "", "", 1, limit)

	if err != nil {
		klog.Error(err)
		return res, redisIds, nil
	}
	if dbmsResult.Code != 200 {
		klog.Info("get data from dbms error!")
		return res, redisIds, nil
	}

	poolList := dbmsResult.Data.Data
	count := len(poolList)
	for i := 0; i < count; i++ {
		pool := poolList[i]
		if poolId != "" && pool.ID != poolId {
			continue
		}
		instanceParam := dbmsmanager.QueryInstanceList{
			ID:       pool.ID,
			PageNo:   1,
			PageSize: limit,
		}
		instanceList, instanceErr := dbmsmanager.GetDBInstanceList(instanceParam)
		klog.Infof("instanceListCnt %d", instanceList.Data.Total)
		if instanceErr != nil {
			return res, redisIds, errors.New("Failed to get resource pool instance")
		}
		if len(instanceList.Data.Data) == 0 {
			continue
		}
		for _, instance := range instanceList.Data.Data {
			monitorInstance := redis.MonitorRedis{}
			monitorInstance.ID = instance.ID
			monitorInstance.Name = instance.Name
			monitorInstance.Status = resourcepoolservice.DBInstanceStatusMapping[instance.Status]
			monitorInstance.TenantId = instance.TenantID
			monitorInstance.TenantName = instance.TenantName
			monitorInstance.Ip = instance.IP
			monitorInstance.Region = instance.RegionName
			monitorInstance.Az = instance.AzName
			monitorInstance.AzCode = instance.AzCode
			monitorInstance.PoolId = pool.ID
			monitorInstance.PoolName = pool.Name
			monitorInstance.CreateTime = instance.ServiceBeginTime

			redisId := vmmodel.CmdbTopVm{}
			redisId.ID = "ksckcs--" + instance.ID
			redisId.Name = instance.Name
			redisId.Region = instance.RegionCode
			redisId.Az = instance.AzCode
			redisIds = append(redisIds, redisId)

			res = append(res, monitorInstance)
		}
	}

	return

}

// 获取reids 列表监控数据
func getRedisMetricsInfo(instances *[]redis.MonitorRedis) error {

	fmt.Println("!instancesinstances", instances)
	for i, inst := range *instances {
		host := fmt.Sprintf("ksckcs--%s", inst.ID)
		tag := map[string]string{
			"host": host,
		}
		//cpu使用率
		cpuQuery := kts.LastQuery{
			Metric: "kcs.cpu_load" + "." + host,
			Tags:   tag,
		}
		// 内存使用率
		memQuery := kts.LastQuery{
			Metric: "kcs.memory_load" + "." + host,
			Tags:   tag,
		}
		////入流量是使用率
		//inputQuery := kts.LastQuery{
		//	Metric: "kcs.intranet_in_ratio" + "." + host,
		//	Tags:   tag,
		//}
		//// 出流量使用率
		//outputQuery := kts.LastQuery{
		//	Metric: "kcs.intranet_out_ratio" + "." + host,
		//	Tags:   tag,
		//}
		//缓存命中率
		hitRateQuery := kts.LastQuery{
			Metric: "kcs.hit_rate" + "." + host,
			Tags:   tag,
		}
		////连接数使用率
		//connectionQuery := kts.LastQuery{
		//	Metric: "kcs.connection_usage" + "." + host,
		//	Tags:   tag,
		//}
		////慢查询数
		//slowlogQuery := kts.LastQuery{
		//	Metric: "kcs.slowlog_len" + "." + host,
		//	Tags:   tag,
		//}
		//var queries = []kts.LastQuery{cpuQuery, memQuery, inputQuery, outputQuery, hitRateQuery, connectionQuery, slowlogQuery}
		var queries = []kts.LastQuery{cpuQuery, memQuery, hitRateQuery}
		metricsMap, err := kts.TSDBLastQueryBatch(queries...)
		if err != nil {
			klog.Errorf("redis tsdb metrics 查询错误，instanceId: %s", inst.ID)
			return err
		}

		cpu := metricsMap[cpuQuery.Metric].Value
		mem := metricsMap[memQuery.Metric].Value
		//input := metricsMap[inputQuery.Metric].Value           // 每秒入流量
		//output := metricsMap[outputQuery.Metric].Value         // 每秒出流量
		hitRate := metricsMap[hitRateQuery.Metric].Value // 缓存命中率
		//connection := metricsMap[connectionQuery.Metric].Value // 连接数使用率
		//slowlog := metricsMap[slowlogQuery.Metric].Value       // 慢查询数

		vcpu, _ := strconv.ParseFloat(cpu, 64)
		(*instances)[i].CPUUsedPercent = services.FormPercent(vcpu / 1e2)

		vmem, _ := strconv.ParseFloat(mem, 64)
		(*instances)[i].MemoryUsedPercent = services.FormPercent(vmem / 1e2)

		vHitRate, _ := strconv.ParseFloat(hitRate, 64)
		(*instances)[i].HitRate = services.FormPercent(vHitRate / 1e2) // 缓存命中率

		//vConnectionRate, _ := strconv.ParseFloat(connection, 64)
		//(*instances)[i].Connection = services.FormPercent(vConnectionRate / 1e2) // 连接数使用率
		//
		//(*instances)[i].InputKbps, _ = strconv.ParseFloat(input, 64)   // 每秒入流量
		//(*instances)[i].OutputKbps, _ = strconv.ParseFloat(output, 64) //每秒出流量
		//(*instances)[i].SlowLog, _ = strconv.ParseFloat(slowlog, 64)   // 慢查询数
	}
	return nil
}

func GetRedisSourceDataList() (redisList []Database) {
	var (
		dbIds        []string
		dbInterfaces []interface{}
	)
	ctx, cefl := context.WithTimeout(context.Background(), 5*time.Second)
	defer cefl()

	//获取资源池
	aggreKeys, err := client.HKeys(ctx, "dbms_aggregates_databases_mapping")

	for _, key := range aggreKeys {
		if ok, _ := regexp.MatchString("_redis$", key); ok {
			var idStr string
			var ids []string
			idStr, err = client.HGet(ctx, "dbms_aggregates_databases_mapping", key)
			if err != nil {
				continue
			}
			err = json.Unmarshal([]byte(idStr), &ids)
			if err != nil {
				klog.Error("dbIdStr Unmarshal error: ", err)
				continue
			}
			dbIds = append(dbIds, ids...)
		}
	}

	if len(dbIds) <= 0 {
		return
	}

	// 获取资源池下实例
	dbInterfaces, err = client.HMGet(ctx, "dbms_database_hash", dbIds)
	if err != nil {
		klog.Error("dbms_database_hash", " redis read error: ", err)
		return
	}
	for _, interfece := range dbInterfaces {
		var (
			dbStr string
			db    Database
			ok    bool
		)
		if dbStr, ok = interfece.(string); !ok {
			continue
		}
		if err = json.Unmarshal([]byte(dbStr), &db); err != nil {
			klog.Error("dbBytes Unmarshal error: ", err)
			continue
		}
		redisList = append(redisList, db)
	}

	return
}

// 获取redis监控指标
func (r *RedisService) GetRedisMetricLine(param *redis.MetricQuery) ([]redis.RedisOverViewLine, error) {
	start := strconv.FormatFloat(param.Start/1000, 'f', 3, 64)
	end := strconv.FormatFloat(param.End/1000, 'f', 3, 64)

	result := []redis.RedisOverViewLine{}

	for j := 0; j < len(param.Name); j++ {
		switch param.Name[j] {
		case "cpu":
			res := redis.RedisOverViewLine{Name: "CPU使用率", Unit: "%", UnitType: "percentage"}
			tsdbList := kts.QueryVmMetriLine("ksckcs--"+param.Id, start, end, []string{"redisCpuLoad"})
			for i := 0; i < len(tsdbList); i++ {
				echart := redis.RedisEchartType{}
				echart.Info.Name = "CPU使用率"
				echart.Info.Unit = "%"
				echart.Info.UnitType = "percentage"
				if tsdbList[i].Value != nil {
					echart.Values = services.PromeForRangeValueForms(tsdbList[i].Value)
				}
				res.Echarts = append(res.Echarts, echart)
			}
			result = append(result, res)

		case "mem":
			res := redis.RedisOverViewLine{Name: "内存使用率", Unit: "%", UnitType: "percentage"}
			tsdbList := kts.QueryVmMetriLine("ksckcs--"+param.Id, start, end, []string{"redisMemoryLoad"})
			for i := 0; i < len(tsdbList); i++ {
				echart := redis.RedisEchartType{}
				echart.Info.Name = "内存使用率"
				echart.Info.Unit = "%"
				echart.Info.UnitType = "percentage"
				if tsdbList[i].Value != nil {
					echart.Values = services.PromeForRangeValueForms(tsdbList[i].Value)
				}
				res.Echarts = append(res.Echarts, echart)
			}
			result = append(result, res)

		case "usedMem":
			res := redis.RedisOverViewLine{Name: "已使用内存", Unit: "MB", UnitType: "MB"}
			tsdbList := kts.QueryVmMetriLine("ksckcs--"+param.Id, start, end, []string{"redisUsedMemory"})
			for i := 0; i < len(tsdbList); i++ {
				echart := redis.RedisEchartType{}
				echart.Info.Name = "已使用内存"
				echart.Info.Unit = "MB"
				echart.Info.UnitType = "MB"
				if tsdbList[i].Value != nil {
					echart.Values = services.PromeForRangeValueForms(tsdbList[i].Value)
				}
				res.Echarts = append(res.Echarts, echart)
			}
			result = append(result, res)
		}
	}

	return result, nil
}

func (r *RedisService) GetLogMsg(param *redis.LogQueryParam) (data redis.LogData, err error) {
	if r.esClient == nil {
		err = errors.New("esClient is invalid")
		return
	}
	logFields := []string{"host.name", "message", "event"}
	if param.LogType == "redis.slowlog" {
		logFields = append(logFields, "redis.slowlog")
	}

	resp, err := r.getLogFromES(param, param.LogType, logFields)
	if err != nil {
		klog.Errorf("get redis instance %s log error: %s", param.Id, err)
		return
	}

	switch param.LogType {
	case "redis.slowlog":
		var slowLog redis.SlowLog
		data.Data = resp.Each(reflect.TypeOf(slowLog))
	case "redis.log":
		var runLog redis.RunLog
		data.Data = resp.Each(reflect.TypeOf(runLog))
	}
	data.Total = resp.TotalHits()
	return
}

// 从 ES 搜索日志并返回 SearchResult
// logType: redis.slowlog, redis.log
func (r *RedisService) getLogFromES(param *redis.LogQueryParam, logType string, include []string) (*elastic.SearchResult, error) {
	if param.PageSize == 0 {
		param.PageSize = 10
	}
	if param.PageNum == 0 {
		param.PageNum = 1
	}
	from := (param.PageNum - 1) * param.PageSize

	// cluster_id 对应控制台实例ID，搜索实例及对应的日志类型
	boolQuery := elastic.NewBoolQuery().Must(elastic.NewMatchQuery("cluster_id", param.Id), elastic.NewMatchQuery("event.dataset", logType))

	// 匹配日志内容
	if len(param.Context) > 0 {
		boolQuery.Must(elastic.NewMatchQuery("message", param.Context))
	}
	// 设置日志生成时间
	if param.Start != 0 && param.End != 0 {
		boolQuery.Filter(elastic.NewRangeQuery("event.created").From(param.Start).To(param.End))
	}
	// 设置 ES 返回字段, 构建请求 DSL
	includeContext := elastic.NewFetchSourceContext(true).Include(include...)
	searchSource := elastic.NewSearchSource().Query(boolQuery).Sort("event.created", false).
		From(from).Size(param.PageSize).FetchSourceContext(includeContext)
	// 打印 ES 请求DSL
	queryDSL, _ := searchSource.Source()
	klog.V(1).Infof("KCS redis instacne log query DSL: %+v", queryDSL)

	builder := elastic.NewSearchService(r.esClient).Index(config.KCSRedisLogingElasticsearchIndex)
	builder.SearchSource(searchSource)
	return builder.Do(context.Background())
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cloudproduct/vm/vm.go
```golang
package vm

import (
	"context"
	"encoding/json"
	"github.com/go-redis/redis/v8"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"io"
	"net/http"
	"sort"
	"strconv"
	"strings"
	"time"

	"github.com/pkg/errors"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	vmmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cloudproduct"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	cm "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	kts "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/ktsmanager"
	"k8s.io/klog/v2"
)

type IVmService interface {
	//GetServerHardwareMetric(string) (servermodels.HardWare, error)
	//GetSwitchMetricLine(*switchmodels.SwitchMetricLineQuery) (map[string][]switchmodels.EchartType, error)
	GetVmOverview(*vmmodel.TopQuery) (vmmodel.OverView, error)
	GetVmTop(*vmmodel.TopQuery) ([]vmmodel.OverViewLineNew, error)
	GetVmOverviewTop(*vmmodel.TopQuery) ([]vmmodel.OverViewLine, error)
	GetVmOverviewTopK(*vmmodel.TopQuery) ([]vmmodel.OverViewLine, error)
	GetVmList(*vmmodel.VmListQuery) (vmmodel.MonitorVms, error)
	GetVmList1(*vmmodel.VmListQuery) (vmmodel.MonitorVms, error)
	GetVmDiskMetric(id, start, end string) []kts.MetricResult
}

type VmService struct {
}

func NewVmService() *VmService {
	return &VmService{}
}

// 获取云主机TOP
func (s *VmService) GetVmTop(param *vmmodel.TopQuery) ([]vmmodel.OverViewLineNew, error) {

	ctx, cefl := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cefl()

	//获取时间间隔
	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	topK, _ := strconv.ParseInt(param.TopK, 10, 64)

	//获取redis集合Key
	param1 := cloudproduct.GetResourceRedisKeyParam{
		ResourceType: config.CloudVmResource,
		Region:       param.Region,
		Az:           param.Az,
		IntervalStr:  intervalStr,
	}
	redisKeyList, err := cloudproduct.GetResourceRedisKeyList(&param1)
	if err != nil {
		return []vmmodel.OverViewLineNew{}, err
	}
	klog.Infof("redisKeyList %+v", redisKeyList)
	//组装数据
	rst := make([]vmmodel.OverViewLineNew, 0, 4)
	name := param.Name
	for i := 0; i < len(name); i++ {
		switch name[i] {
		case "cpu":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			//rr.Info.UnitType = "percent"

			var vmCpuLit []vmmodel.VmValueType
			vmCpuKeys := redisKeyList["CPULoadAvg"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmCpuKeys {
				//获取集合数据
				vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				vmCpuLit = append(vmCpuLit, vmlist...)
			}
			vmCpuLit = RemoveDuplicate(vmCpuLit) // 移除重复值
			vmCpuCont := len(vmCpuLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(vmCpuCont) > topK {
				//排序
				vmCpuLit = cloudproduct.VmValueOrder(vmCpuLit, "desc")
				if int64(len(vmCpuLit)) >= topK {
					vmCpuLit = vmCpuLit[:topK]
				}
			}
			rr.Values = vmCpuLit
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "mem":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			//rr.Info.UnitType = "storage"

			var vmMemList []vmmodel.VmValueType
			vmMemKeys := redisKeyList["MemLoadAvg"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmMemKeys {
				//获取集合数据
				vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				vmMemList = append(vmMemList, vmlist...)
			}
			vmMemList = RemoveDuplicate(vmMemList) // 移除重复值
			vmMemCont := len(vmMemList)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(vmMemCont) > topK {
				//排序
				vmMemList = cloudproduct.VmValueOrder(vmMemList, "desc")
				if int64(len(vmMemList)) >= topK {
					vmMemList = vmMemList[:topK]
				}
			}
			rr.Values = vmMemList
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "disk":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			//rr.Info.UnitType = "percent"

			var vmDiskLit []vmmodel.VmValueType
			vmDiskKeys := redisKeyList["DiskUsedRange"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmDiskKeys {
				//获取集合数据
				vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				vmDiskLit = append(vmDiskLit, vmlist...)
			}
			vmDiskLit = RemoveDuplicate(vmDiskLit) // 移除重复值
			vmDiskCont := len(vmDiskLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(vmDiskCont) > topK {
				//排序
				vmDiskLit = cloudproduct.VmValueOrder(vmDiskLit, "desc")
				if int64(len(vmDiskLit)) >= topK {
					vmDiskLit = vmDiskLit[:topK]
				}
			}
			rr.Values = vmDiskLit
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "net":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			//入口流量
			rIn := vmmodel.EchartTypeNew{}
			rIn.Info.Name = name[i] + "in"
			rIn.Info.Unit = "B"
			rIn.Info.UnitType = "storage"
			var vmNatInLit []vmmodel.VmValueType
			vmNatInKeys := redisKeyList["NetInAvg"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmNatInKeys {
				//获取集合数据
				vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				vmNatInLit = append(vmNatInLit, vmlist...)
			}
			vmNatInLit = RemoveDuplicate(vmNatInLit) // 移除重复值
			vmNatInCont := len(vmNatInLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(vmNatInCont) > topK {
				//排序
				vmNatInLit = cloudproduct.VmValueOrder(vmNatInLit, "desc")
				if int64(len(vmNatInLit)) >= topK {
					vmNatInLit = vmNatInLit[:topK]
				}
			}
			for ii, vv := range vmNatInLit {
				vmNatInLit[ii].SubName = vv.Name
				vmNatInLit[ii].Name = services.GenerateTopK(ii + 1)
			}
			rIn.Values = vmNatInLit
			r.Echarts = append(r.Echarts, rIn)
			// 出口流量
			rOut := vmmodel.EchartTypeNew{}
			rOut.Info.Name = name[i] + "out"
			rOut.Info.Unit = "B"
			rOut.Info.UnitType = "storage"
			var vmNatOutLit []vmmodel.VmValueType
			vmNatOutKeys := redisKeyList["NetOutAvg"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmNatOutKeys {
				//获取集合数据
				vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				vmNatOutLit = append(vmNatOutLit, vmlist...)
			}
			vmNatOutLit = RemoveDuplicate(vmNatOutLit) // 移除重复值
			vmNatOutCont := len(vmNatOutLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(vmNatOutCont) > topK {
				//排序
				vmNatOutLit = cloudproduct.VmValueOrder(vmNatOutLit, "desc")
				if int64(len(vmNatOutLit)) >= topK {
					vmNatOutLit = vmNatOutLit[:topK]
				}
			}
			for ii, vv := range vmNatOutLit {
				vmNatOutLit[ii].SubName = vv.Name
				vmNatOutLit[ii].Name = services.GenerateTopK(ii + 1)
			}
			rOut.Values = vmNatOutLit
			r.Echarts = append(r.Echarts, rOut)

			rst = append(rst, r)
		}
	}

	return rst, nil
}

// 移除重复值
func RemoveDuplicate(slc []vmmodel.VmValueType) []vmmodel.VmValueType {
	result := []vmmodel.VmValueType{} // 存放结果
	for v := range slc {
		flag := true
		for j := range result {
			if slc[v].Id == result[j].Id {
				flag = false // 存在重复元素，标识为false
				break
			}
		}
		if flag { // 标识为false，不添加进结果
			result = append(result, slc[v])
		}
	}
	return result
}

func (s *VmService) GetVmOverview(l *vmmodel.TopQuery) (vmmodel.OverView, error) {
	klog.Info("cloud_product_vm_overview")
	cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/computePool/vm", "post")
	rst := vmmodel.OverView{}
	pppp := make([]resourcepoolmodel.AlertType, 0, 4)
	p0 := resourcepoolmodel.AlertType{Label: "紧急告警", Level: "p0", Kind: "error", Number: 0, Unit: "个"}

	//query mysql
	db := services.MakeMysqlClient()
	defer db.Close()
	p0Count, err := db.Exec("select count(*) from alarm_history where producttype=0")
	if err != nil {
		klog.Error(err)
	} else {
		P0, er := p0Count.LastInsertId()
		if er != nil {
			klog.Error(er)
		}
		p0.Number = P0
	}

	p1 := resourcepoolmodel.AlertType{Label: "重要告警", Level: "p1", Kind: "warn", Number: 0, Unit: "个"}
	p2 := resourcepoolmodel.AlertType{Label: "次要告警", Level: "p2", Kind: "minor", Number: 0, Unit: "个"}
	p3 := resourcepoolmodel.AlertType{Label: "提醒告警", Level: "p3", Kind: "info", Number: 0, Unit: "个"}
	pppp = append(pppp, p0, p1, p2, p3)

	//vm_state
	if l.Region == "" {
		l.Region = "all"
	}
	az := []string{}
	if l.Az == "all" || l.Az == "" {
		az = []string{}
	} else {
		az = append(az, l.Az)
	}

	hostUrlPost := cmdbmodel.VmListPost{
		PageNo:   1,
		PageSize: cmdbCount,
		Region:   l.Region,
		Az:       az,
	}
	cmdb, err := cm.GetCMDBVmList(hostUrlPost)
	if err != nil {
		klog.Error(err)
	}

	if cmdb.Code != 200 {
		klog.Info("get data from nova cmdb error!")
	}
	cs := cmdb.Data.DataList
	count := len(cs)
	//responseMetric := make([]OverViewLine,0,4)
	var (
		active      = 0 //运行中
		eerror      = 0 //失败
		shutdown    = 0 //关闭
		hard_reboot = 0 // 强制重启
		deleting    = 0 // 删除中
		suspended   = 0 // 挂起
	)
	for i := 0; i < count; i++ {
		switch cs[i].Status {
		case "active":
			active++
		case "error":
			eerror++
		case "shutoff":
			shutdown++
		case "hard_reboot":
			hard_reboot++
		case "deleting":
			deleting++
		case "suspended":
			suspended++
		}

	}
	chart := vmmodel.Chart{Info: vmmodel.OverInfo{Name: "云主机状态", Number: count, UnitType: "number"}}
	v1 := vmmodel.ValueType{Name: "运行中", Value: active}
	chart.Values = append(chart.Values, v1)
	v2 := vmmodel.ValueType{Name: "失败", Value: eerror}
	chart.Values = append(chart.Values, v2)
	v3 := vmmodel.ValueType{Name: "关闭", Value: shutdown}
	chart.Values = append(chart.Values, v3)
	v4 := vmmodel.ValueType{Name: "强制重启", Value: hard_reboot}
	chart.Values = append(chart.Values, v4)
	v5 := vmmodel.ValueType{Name: "删除中", Value: deleting}
	chart.Values = append(chart.Values, v5)
	v6 := vmmodel.ValueType{Name: "挂起", Value: suspended}
	chart.Values = append(chart.Values, v6)

	state := make([]vmmodel.Chart, 0, 1)
	state = append(state, chart)
	rst = vmmodel.OverView{l.Region, l.Az, l.Lab, pppp, state}
	return rst, nil
}

// GetVmOverviewTopK 监控告警 / 云资源监控 / 云产品监控 / 云主机 总览top
func (s *VmService) GetVmOverviewTopK(l *vmmodel.TopQuery) ([]vmmodel.OverViewLine, error) {
	//时间戳转换成字符串，精确到秒，精度为3
	start := strconv.FormatFloat(l.Start/1000, 'f', 3, 64)
	end := strconv.FormatFloat(l.End/1000, 'f', 3, 64)

	c := http.Client{Timeout: time.Second * 60} //每次请求60秒超时
	k, _ := strconv.Atoi(l.TopK)

	rst := make([]vmmodel.OverViewLine, 0, 4) //概览页监控项的数据
	//从cmdb中获取云主机资源总数目
	cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/computePool/vm", "post")

	klog.Infof("cmdbCount: %d", cmdbCount)
	//cmdb云主机列表数据
	cmdbData := vmmodel.CmdbTopVms{
		DataList: make([]vmmodel.CmdbTopVm, 0, cmdbCount),
	}
	cmdb := vmmodel.CMDBTopResult{Data: cmdbData}

	//确定可用区
	if l.Region == "" {
		l.Region = "all"
	}
	az := make([]string, 0)
	if l.Az == "all" || l.Az == "" {
		az = []string{}
	} else {
		az = append(az, l.Az)
	}

	//向cmdb发起请求的body数据结构
	hostUrlPost := vmmodel.VmListPost{
		PageNo:   1,
		PageSize: cmdbCount,
		Region:   l.Region,
		Az:       az,
	}
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	//从cmdb中获取 云主机 资源列表
	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/computePool/vm", "application/json", jsoninfo)

	if err != nil {
		klog.Error(err)
		return rst, nil
	}

	b, _ := io.ReadAll(resp.Body)

	err = json.Unmarshal(b, &cmdb)
	if err != nil {
		klog.Error(err)
		return rst, nil
	}
	vmDataList := cmdb.Data.DataList //从cmdb中获取到云主机数据

	//if len(vmDataList) > 100 {       //如果主机数据大于200，只取前200个实例
	//	vmDataList = vmDataList[:100]
	//}
	klog.Infof("csNum %d", len(vmDataList))

	if cmdb.Code != 200 {
		return rst, errors.Errorf("get data from nova cmdb error!")
	}
	count := len(vmDataList) //查询到的vm实例总数
	//if count > 500 {
	//	count = 500
	//}
	m := l.Name //资源类型名称, [cpu] [mem] cpu/mem/disk/net

	for i := 0; i < len(m); i++ {

		switch m[i] {
		case "cpu":
			klog.Info("csNum", "cpu")
			r := vmmodel.OverViewLine{Name: m[i], Unit: "%"} //最终查询到的topK个数据
			rr := vmmodel.EchartType{}                       //查询到的topK个数据，不包含region和az等数据
			rr.Info.Name = m[i]                              //监控项名称
			rr.Info.Unit = "%"
			rr.Info.UnitType = "percent"
			cpuLoad := []string{"CPULoadAvg"} //监控指标，cpu使用率

			//批量从tsdb中查询数据
			timer := time.NewTimer(time.Second * config.MaxVmSearchDuration)
			ctx, cancel := context.WithCancel(context.Background())
			isCmpl := make(chan struct{})

			//wg := sync.WaitGroup{}
			ids := make(chan string)
			go func() {
				for i := 0; i < count; i++ {
					ids <- cmdb.Data.DataList[i].ID
				}
				close(ids) //通道不使用时关闭
				isCmpl <- struct{}{}
			}()

			for j := 0; j < count; j++ {
				//id := vmDataList[j].ID
				//wg.Add(1)
				id := <-ids

				go func(ctx context.Context, id string, j int) {
					select {
					case <-ctx.Done():
						klog.Info("Task canceled")
						return
					default:
						metricResult := kts.QueryVmMetric(id, start, end, cpuLoad)
						if metricResult == nil {
							vmDataList[j].Value = 0
						} else {
							if len(metricResult) > 0 {
								vmDataList[j].Value = metricResult[0].Avg
							}
						}
						return
					}

				}(ctx, id, j)
			}

			select {
			case <-timer.C:
				klog.Info("Get Metric Data Timeout!")
				cancel()
			case <-isCmpl:
				klog.Info("All tasks completed !!!")
				cancel()
			}
			//wg.Wait() //等待所有的goroutine执行完成

			out := ValueOrder(vmDataList, "desc")
			klog.Infof("ordered vm list for cpu: %+v", out)
			if len(out) >= k {
				out = out[:k]
			}

			for o := 0; o < len(out); o++ {
				aa, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
				v := vmmodel.ValueType{Value: services.FormPercent(aa / 1e2), Name: out[o].Name, VmId: out[o].ID}
				rr.Values = append(rr.Values, v)
			}
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "mem":
			r := vmmodel.OverViewLine{Name: m[i], Unit: "B"}
			rr := vmmodel.EchartType{}
			rr.Info.Name = m[i]
			rr.Info.Unit = "B"
			rr.Info.UnitType = "storage"
			cpuLoad := []string{"MemLoadAvg"}

			//批量从tsdb中查询数据
			timer := time.NewTimer(time.Second * config.MaxVmSearchDuration)
			ctx, cancel := context.WithCancel(context.Background())
			isCmpl := make(chan struct{})
			//lock := sync.Mutex{}

			//wg := sync.WaitGroup{}
			ids := make(chan string)
			go func() {
				for i := 0; i < count; i++ {
					ids <- cmdb.Data.DataList[i].ID
				}
				close(ids)
				isCmpl <- struct{}{}
			}()

			for j := 0; j < count; j++ {
				id := <-ids
				//wg.Add(1)
				//id := vmDataList[j].ID
				go func(ctx context.Context, id string, j int) {
					select {
					case <-ctx.Done():
						klog.Info("Task canceled")
						return
					default:
						metricResult := kts.QueryVmMetric(id, start, end, cpuLoad)
						if metricResult == nil {
							vmDataList[j].Value = 0
						} else {
							if len(metricResult) > 0 {
								vmDataList[j].Value = metricResult[0].Avg
							}
						}
						return
					}
					//wg.Done()
				}(ctx, id, j)
			}
			//wg.Wait() //等待所有的goroutine执行完成
			select {
			case <-timer.C:
				klog.Info("Get Metric Data Timeout!")
				cancel()
			case <-isCmpl:
				klog.Info("All tasks completed !!!")
				cancel()
			}

			out := ValueOrder(vmDataList, "desc")
			klog.Infof("ordered vm list for mem: %+v", out)
			if len(out) >= k {
				out = out[:k]
			}
			for o := 0; o < len(out); o++ {
				aa, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
				v := vmmodel.ValueType{Value: aa, Name: out[o].Name, VmId: out[o].ID}
				rr.Values = append(rr.Values, v)
			}
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "disk":
			r := vmmodel.OverViewLine{Name: m[i], Unit: "%"}
			rr := vmmodel.EchartType{}
			rr.Info.Name = m[i]
			rr.Info.Unit = "B"
			rr.Info.UnitType = "storage"
			cpuLoad := []string{"DiskUsedRange"}

			//批量从tsdb中查询数据
			timer := time.NewTimer(time.Second * config.MaxVmSearchDuration)
			ctx, cancel := context.WithCancel(context.Background())
			isCmpl := make(chan struct{})
			//lock := sync.Mutex{}

			//wg := sync.WaitGroup{}
			ids := make(chan string)
			go func() {
				for i := 0; i < count; i++ {
					ids <- cmdb.Data.DataList[i].ID
				}
				close(ids) //通道不使用时关闭
				isCmpl <- struct{}{}
			}()

			for j := 0; j < count; j++ {
				id := <-ids
				//id := vmDataList[j].ID
				//wg.Add(1)
				go func(ctx context.Context, id string, j int) {
					select {
					case <-ctx.Done():
						klog.Info("Task canceled")
						return
					default:
						metricResult := kts.QueryVmMetric(id, start, end, cpuLoad)
						if metricResult == nil {
							vmDataList[j].Value = 0
						} else {
							if len(metricResult) > 0 {
								vmDataList[j].Value = metricResult[0].Avg
							}
						}

						return
					}
					//wg.Done()
				}(ctx, id, j)
			}
			//wg.Wait() //等待所有的goroutine执行完成

			select {
			case <-timer.C:
				klog.Info("Get Metric Data Timeout!")
				cancel()
			case <-isCmpl:
				klog.Info("All tasks completed !!!")
				cancel()
			}

			out := ValueOrder(vmDataList, "desc")
			klog.Infof("ordered vm list for disk: %+v", out)
			if len(out) >= k {
				out = out[:k]
			}
			for o := 0; o < len(out); o++ {
				aa, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
				v := vmmodel.ValueType{Value: aa, Name: out[o].Name, VmId: out[o].ID}
				rr.Values = append(rr.Values, v)
			}
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "net":
			r := vmmodel.OverViewLine{Name: m[i], Unit: "%"}
			rr := vmmodel.EchartType{}
			rr.Info.Name = m[i] + "in"
			rr.Info.Unit = "B"
			rr.Info.UnitType = "storage"
			cpuLoad := []string{"NetInAvg"}

			//批量从tsdb中查询数据
			timer := time.NewTimer(time.Second * config.MaxVmSearchDuration)
			ctx, cancel := context.WithCancel(context.Background())
			isCmpl := make(chan struct{})
			//lock := sync.Mutex{}

			//wg := sync.WaitGroup{}
			ids := make(chan string)
			go func() {
				for i := 0; i < count; i++ {
					ids <- cmdb.Data.DataList[i].ID
				}
				close(ids) //通道不使用时关闭
				isCmpl <- struct{}{}
			}()
			for j := 0; j < count; j++ {
				id := <-ids
				//id := vmDataList[j].ID
				//wg.Add(1)
				go func(ctx context.Context, id string, j int) {
					select {
					case <-ctx.Done():
						klog.Info("Task canceled")
						return
					default:
						metricResult := kts.QueryVmMetric(id, start, end, cpuLoad)
						if metricResult == nil {
							vmDataList[j].Value = 0
						} else {
							if len(metricResult) > 0 {
								vmDataList[j].Value = metricResult[0].Avg
							}
						}
						return
					}
					//wg.Done()
				}(ctx, id, j)
			}
			//wg.Wait() //等待所有的goroutine执行完成
			select {
			case <-timer.C:
				klog.Info("Get Metric Data Timeout!")
				cancel()
			case <-isCmpl:
				klog.Info("All tasks completed !!!")
				cancel()
			}

			out := ValueOrder(vmDataList, "desc")
			klog.Infof("ordered vm list for netIn: %+v", out)
			if len(out) >= k {
				out = out[:k]
			}
			for o := 0; o < len(out); o++ {
				aa, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
				v := vmmodel.ValueType{Value: aa, SubName: out[o].Name, Name: services.GenerateTopK(o + 1), VmId: out[o].ID}
				rr.Values = append(rr.Values, v)
			}
			r.Echarts = append(r.Echarts, rr)
			rr1 := vmmodel.EchartType{}
			rr1.Info.Name = m[i] + "out"
			rr1.Info.Unit = "B"
			rr1.Info.UnitType = "storage"
			cpuLoad = []string{"NetOutAvg"}

			//批量从tsdb中查询数据
			outLimer := time.NewTimer(time.Second * config.MaxVmSearchDuration)
			ctxOut, cancelOut := context.WithCancel(context.Background())
			isCmplOut := make(chan struct{})
			//lockOut := sync.Mutex{}

			idsOut := make(chan string)
			go func() {
				for i := 0; i < count; i++ {
					idsOut <- cmdb.Data.DataList[i].ID
				}
				close(idsOut) //通道不再使用了以后要关闭掉
				isCmplOut <- struct{}{}
			}()
			for i := 0; i < count; i++ {
				id := <-idsOut

				//id := vmDataList[i].ID
				//wg.Add(1)
				go func(ctx context.Context, id string, i int) {
					select {
					case <-ctx.Done():
						klog.Info("Task canceled")
						return
					default:
						metricResult := kts.QueryVmMetric(id, start, end, cpuLoad)
						if metricResult == nil {
							vmDataList[i].Value = 0
						} else {
							if len(metricResult) > 0 {
								vmDataList[i].Value = metricResult[0].Avg
							}
						}
						return
					}
					//wg.Done()
				}(ctxOut, id, i)
			}
			//wg.Wait() //等待所有的goroutine执行完成

			select {
			case <-outLimer.C:
				klog.Info("Get Metric Data Timeout!")
				cancelOut()
			case <-isCmplOut:
				klog.Info("All tasks completed !!!")
				cancelOut()
			}

			out1 := ValueOrder(vmDataList, "desc")
			klog.Infof("ordered vm list for netOut: %+v", out1)
			if len(out1) >= k {
				out1 = out1[:k]
			}
			for o := 0; o < len(out1); o++ {
				aa, _ := strconv.ParseFloat(services.Strval(out1[o].Value), 64)
				v := vmmodel.ValueType{Value: aa, SubName: out1[o].Name, Name: services.GenerateTopK(o + 1), VmId: out1[o].ID}
				rr1.Values = append(rr1.Values, v)
			}
			r.Echarts = append(r.Echarts, rr1)
			rst = append(rst, r)
		}
	}
	return rst, nil
}

func (s *VmService) GetVmOverviewTop(param *vmmodel.TopQuery) ([]vmmodel.OverViewLine, error) {

	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	var nameStr string
	for _, v := range param.Name {
		nameStr += v + "_"
	}

	key := "vm_overviewTop"
	fieldKey := "name_" + nameStr + "topk_" + param.TopK + "_interval_" + intervalStr + "_region" + param.Region + "_Az" + param.Az
	klog.Infof("vm OverviewTop fieldKey", fieldKey)

	redisCon := config.RedisConfig
	var rdb *redis.Client
	rdb = redis.NewClient(&redis.Options{
		Addr:       redisCon["Host"].(string),
		Password:   redisCon["Password"].(string),
		DB:         redisCon["Db"].(int),
		MaxRetries: redisCon["MaxRetries"].(int),
	})

	cache, err := utils.NewRedisCache(rdb, key)
	if err != nil {
		klog.Error("get utils.NewRedisCache failed", err)
		return []vmmodel.OverViewLine{}, nil
	}
	result, err := rdb.Ping(context.Background()).Result()
	if err != nil {
		klog.Error("Ping redis failed", err)
		return []vmmodel.OverViewLine{}, nil
	}

	klog.Infof("result %s", result)
	after := time.After(time.Second * 60)

	for {
		select {
		case <-time.After(time.Second):
			data, err := cache.GetData(context.Background(), fieldKey, GetVmTop(param), time.Minute*10)
			if err != nil {
				klog.Error("vm GetData err ", err)
			}
			if data == "" {
				continue
			}
			var list []vmmodel.OverViewLine
			ee := json.Unmarshal([]byte(data), &list)
			if ee != nil {
				klog.Error("Parsing JSON failed", ee)
			}

			klog.Infof("data:%s", list)
			return list, nil
		case <-after:
			return []vmmodel.OverViewLine{}, nil
		}
	}

	return []vmmodel.OverViewLine{}, nil
}

func GetVmTop(param *vmmodel.TopQuery) func() (data string, err error) {
	klog.Info("GetVmTop")
	return func() (data string, err error) {

		rst := make([]vmmodel.OverViewLine, 0, 4)

		start := strconv.FormatFloat(param.Start/1000, 'f', 3, 64)
		end := strconv.FormatFloat(param.End/1000, 'f', 3, 64)
		topk, _ := strconv.Atoi(param.TopK)

		if param.Region == "" {
			param.Region = "all"
		}
		az := []string{}
		if param.Az == "all" || param.Az == "" {
			az = []string{}
		} else {
			az = append(az, param.Az)
		}

		hostUrlPost := cmdbmodel.VmListPost{
			PageNo: 1,
			Region: param.Region,
			Az:     az,
		}
		cmdbRsp, err := cmdbmanager.GetCMDBVmList(hostUrlPost)
		res := cmdbRsp.Data.DataList
		count := len(cmdbRsp.Data.DataList)
		klog.Infof("csNum %d", count)
		name := param.Name
		for i := 0; i < len(name); i++ {
			switch name[i] {
			case "cpu":
				klog.Info("csNum", "cpu")
				r := vmmodel.OverViewLine{Name: name[i], Unit: "%"}
				rr := vmmodel.EchartType{}
				rr.Info.Name = name[i]
				rr.Info.Unit = "%"
				rr.Info.UnitType = "percent"
				for j := 0; j < count; j++ {
					cpuLoad := []string{"CPULoadAvg"}
					oo := kts.QueryVmMetric(res[j].ID, start, end, cpuLoad)
					if len(oo) > 0 {
						res[j].Value = oo[0].Avg
					}
				}
				out := VmValueOrder(res, "desc")
				if len(out) >= topk {
					out = out[:topk]
				}

				for o := 0; o < len(out); o++ {
					aa, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
					v := vmmodel.ValueType{Value: services.FormPercent(aa / 1e2), Name: out[o].Name, VmId: out[o].ID}
					rr.Values = append(rr.Values, v)
				}
				r.Echarts = append(r.Echarts, rr)
				rst = append(rst, r)
			case "mem":
				r := vmmodel.OverViewLine{Name: name[i], Unit: "B"}
				rr := vmmodel.EchartType{}
				rr.Info.Name = name[i]
				rr.Info.Unit = "B"
				rr.Info.UnitType = "storage"
				for j := 0; j < count; j++ {
					cpuLoad := []string{"MemLoadAvg"}
					oo := kts.QueryVmMetric(res[j].ID, start, end, cpuLoad)
					if len(oo) > 0 {
						res[j].Value = oo[0].Avg
					}
				}
				out := VmValueOrder(res, "desc")
				if len(out) >= topk {
					out = out[:topk]
				}
				for o := 0; o < len(out); o++ {
					aa, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
					v := vmmodel.ValueType{Value: aa, Name: out[o].Name, VmId: out[o].ID}
					rr.Values = append(rr.Values, v)
				}
				r.Echarts = append(r.Echarts, rr)
				rst = append(rst, r)
			case "disk":
				r := vmmodel.OverViewLine{Name: name[i], Unit: "%"}
				rr := vmmodel.EchartType{}
				rr.Info.Name = name[i]
				rr.Info.Unit = "B"
				rr.Info.UnitType = "storage"
				for j := 0; j < count; j++ {
					cpuLoad := []string{"DiskUsedRange"}
					oo := kts.QueryVmMetric(res[j].ID, start, end, cpuLoad)
					if len(oo) > 0 {
						res[j].Value = oo[0].Avg
					}
				}
				out := VmValueOrder(res, "desc")
				if len(out) >= topk {
					out = out[:topk]
				}
				for o := 0; o < len(out); o++ {
					aa, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
					v := vmmodel.ValueType{Value: aa, Name: out[o].Name, VmId: out[o].ID}
					rr.Values = append(rr.Values, v)
				}
				r.Echarts = append(r.Echarts, rr)
				rst = append(rst, r)
			case "net":
				r := vmmodel.OverViewLine{Name: name[i], Unit: "%"}
				rr := vmmodel.EchartType{}
				rr.Info.Name = name[i] + "in"
				rr.Info.Unit = "B"
				rr.Info.UnitType = "storage"
				for j := 0; j < count; j++ {
					cpuLoad := []string{"NetInAvg"}
					oo := kts.QueryVmMetric(res[j].ID, start, end, cpuLoad)
					if len(oo) > 0 {
						res[j].Value = oo[0].Avg
					}
				}
				out := VmValueOrder(res, "desc")
				if len(out) >= topk {
					out = out[:topk]
				}
				for o := 0; o < len(out); o++ {
					aa, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
					v := vmmodel.ValueType{Value: aa, SubName: out[o].Name, Name: services.GenerateTopK(o + 1), VmId: out[o].ID}
					rr.Values = append(rr.Values, v)
				}
				r.Echarts = append(r.Echarts, rr)
				rr1 := vmmodel.EchartType{}
				rr1.Info.Name = name[i] + "out"
				rr1.Info.Unit = "B"
				rr1.Info.UnitType = "storage"
				for j1 := 0; j1 < count; j1++ {
					cpuLoad := []string{"NetOutAvg"}
					oo := kts.QueryVmMetric(res[j1].ID, start, end, cpuLoad)
					if len(oo) > 0 {
						res[j1].Value = oo[0].Avg
					}
				}
				out1 := VmValueOrder(res, "desc")
				if len(out1) >= topk {
					out1 = out1[:topk]
				}
				for o := 0; o < len(out1); o++ {
					aa, _ := strconv.ParseFloat(services.Strval(out1[o].Value), 64)
					v := vmmodel.ValueType{Value: aa, SubName: out1[o].Name, Name: services.GenerateTopK(o + 1), VmId: out1[o].ID}
					rr1.Values = append(rr1.Values, v)
				}
				r.Echarts = append(r.Echarts, rr1)
				rst = append(rst, r)
			}
		}

		resq, _ := json.Marshal(rst)
		return string(resq), nil
	}
}

func (s *VmService) GetVmListNew(param *vmmodel.VmListQuery) (res vmmodel.MonitorVms, err error) {
	klog.Info("service_vm_list")

	if param.Region == "" {
		param.Region = "all"
	}
	if len(param.Az) == 0 {
		param.Az = []string{}
	}
	//请求cmdb获取云主机列表
	hostUrlPost := cmdbmodel.VmListPost{
		PageNo: 1,
		Region: param.Region,
		Az:     param.Az,
	}
	cmdb, err := cm.GetCMDBVmList(hostUrlPost)
	if err != nil {
		klog.Error(err)
		return res, nil
	}
	cs := cmdb.Data

	if cmdb.Code != 200 {
		return res, errors.Errorf("get data from nova cmdb error!")
	}
	count := len(cs.DataList)
	klog.Infof("vm_count: %d", count)

	return vmmodel.MonitorVms{}, nil
}

func (s *VmService) GetVmList1(l *vmmodel.VmListQuery) (vmmodel.MonitorVms, error) {
	klog.Info("service_vm_list")

	if l.Region == "" {
		l.Region = "all"
	}
	if len(l.Az) == 0 {
		l.Az = []string{}
	}
	//获取云主机列表
	hostUrlPost := cmdbmodel.VmListPost{
		PageNo:     l.PageNo,
		PageSize:   l.PageSize,
		Region:     l.Region,
		Az:         l.Az,
		Name:       l.Name,
		Status:     l.RunList,      // 运行状态
		TenantId:   l.TenantId,     //租户ID
		Hypervisor: l.PhysicalHost, //所属服务器
		InnerIp:    l.InnerIp,      // 内网ip
		PublicIp:   l.OuterIp,      //外网ip
	}
	if l.Pool != "" {
		hostUrlPost.Aggregate = &l.Pool //所属资源池
	}
	cmdb, err := cm.GetCMDBVmList(hostUrlPost)
	if err != nil {
		klog.Error("get_GetCMDBVmList_fail:", err)
		return vmmodel.MonitorVms{}, nil
	}

	ms := vmmodel.MonitorVms{DataList: make([]vmmodel.MonitorVm, 0, len(cmdb.Data.DataList))}
	var queries []kts.LastQuery
	for _, v := range cmdb.Data.DataList {
		//cpu使用率
		cpuQuery := kts.LastQuery{
			Metric: "cpu.utilizition.total" + "." + v.ID,
			Tags: map[string]string{
				"host": v.ID,
			},
		}
		//总内存
		memTotalQuery := kts.LastQuery{
			Metric: "vm.memory.size" + "." + v.ID,
			Tags: map[string]string{
				"host": v.ID,
				"p1":   "total",
			},
		}
		//已使用内存
		memUsedQuery := kts.LastQuery{
			Metric: "vm.memory.size" + "." + v.ID,
			Tags: map[string]string{
				"host": v.ID,
				"p1":   "used",
			},
		}
		//内存使用率
		memQuery := kts.LastQuery{
			Metric: "memory.utilizition.total" + "." + v.ID,
			Tags: map[string]string{
				"host": v.ID,
			},
		}
		queries = []kts.LastQuery{cpuQuery, memTotalQuery, memUsedQuery, memQuery}
	}

	now := time.Now()
	klog.Infof("DEBUG GetVmList1  start: %v", now)
	//批量获取数据
	metrics, err := kts.TSDBLastQueryBatchBase(queries...)
	if err != nil {
		klog.Errorf("DEBUG GetVmList1 TSDBLastQueryBatchBase error: %s", err.Error())
	}
	klog.Infof("DEBUG GetVmList1  end: %v", time.Since(now))

	klog.Infof("DEBUG GetVmList1  metrics: %+v", metrics)

	ms.PageNo = l.PageNo
	ms.PageSize = l.PageSize
	ms.TotalCount = cmdb.Data.TotalCount
	return ms, nil
}

func (s *VmService) GetVmList(l *vmmodel.VmListQuery) (vmmodel.MonitorVms, error) {
	klog.Info("service_vm_list")

	if l.Region == "" {
		l.Region = "all"
	}
	if len(l.Az) == 0 {
		l.Az = []string{}
	}
	//获取云主机列表
	hostUrlPost := cmdbmodel.VmListPost{
		PageNo:     l.PageNo,
		PageSize:   l.PageSize,
		Region:     l.Region,
		Az:         l.Az,
		Name:       l.Name,
		Status:     l.RunList,      // 运行状态
		TenantId:   l.TenantId,     //租户ID
		Hypervisor: l.PhysicalHost, //所属服务器
		InnerIp:    l.InnerIp,      // 内网ip
		PublicIp:   l.OuterIp,      //外网ip
	}
	if l.Pool != "" {
		hostUrlPost.Aggregate = &l.Pool //所属资源池
	}
	cmdb, err := cm.GetCMDBVmList(hostUrlPost)
	if err != nil {
		klog.Error("get_GetCMDBVmList_fail:", err)
		return vmmodel.MonitorVms{}, nil
	}

	ms := vmmodel.MonitorVms{DataList: make([]vmmodel.MonitorVm, 0, len(cmdb.Data.DataList))}
	for _, v := range cmdb.Data.DataList {
		//cpu使用率
		cpuQuery := kts.LastQuery{
			Metric: "cpu.utilizition.total" + "." + v.ID,
			Tags: map[string]string{
				"host": v.ID,
			},
		}
		//总内存
		memTotalQuery := kts.LastQuery{
			Metric: "vm.memory.size" + "." + v.ID,
			Tags: map[string]string{
				"host": v.ID,
				"p1":   "total",
			},
		}
		//已使用内存
		memUsedQuery := kts.LastQuery{
			Metric: "vm.memory.size" + "." + v.ID,
			Tags: map[string]string{
				"host": v.ID,
				"p1":   "used",
			},
		}
		//内存使用率
		memQuery := kts.LastQuery{
			Metric: "memory.utilizition.total" + "." + v.ID,
			Tags: map[string]string{
				"host": v.ID,
			},
		}
		var queries = []kts.LastQuery{cpuQuery, memTotalQuery, memUsedQuery, memQuery}
		//批量获取数据
		metrics, err := kts.TSDBLastQueryBatchBase(queries...)
		if err != nil {
			klog.Errorf("TSDBLastQueryBatchBase error: %s", err.Error())
		}
		cpu, memTotal, memUsed, mem := "0", "0", "0", "0"
		if len(metrics) == 4 {
			cpu = metrics[0].Value
			memTotal = metrics[1].Value
			memUsed = metrics[2].Value
			mem = metrics[3].Value
		}

		vcpu, _ := strconv.ParseFloat(cpu, 64)
		vmemTotal, _ := strconv.ParseFloat(memTotal, 64)
		vmemUsed, _ := strconv.ParseFloat(memUsed, 64)
		vmem, _ := strconv.ParseFloat(mem, 64)

		createTime := strconv.Itoa(v.CreateTime * 1e3)
		info := vmmodel.MonitorVm{
			ID:            v.ID,
			Name:          v.Name,
			VmType:        v.Flavor,
			Status:        v.Status,
			ComputePool:   v.Aggregate,
			Region:        v.Region,
			Az:            v.Az,
			TenantId:      v.TenantId,
			TenantName:    v.TenantName,
			PhysicalHost:  v.Hypervisor,
			InnerIP:       v.InnerIP,
			OuterIP:       v.PublicIP,
			CreateTime:    createTime,
			Flavor:        v.Flavor,
			CPUUseRate:    services.FormPercent(vcpu),
			MemoryTotal:   services.FormatSize(vmemTotal),
			MemoryUse:     services.FormatSize(vmemUsed),
			MemoryUseRate: services.FormPercent(vmem),
		}
		ms.DataList = append(ms.DataList, info)
	}
	ms.PageNo = l.PageNo
	ms.PageSize = l.PageSize
	ms.TotalCount = cmdb.Data.TotalCount
	return ms, nil

	//cs := cmdb.Data
	//
	//if cmdb.Code != 200 {
	//	return ms, errors.Errorf("get data from nova cmdb error!")
	//}
	//count := len(cs.DataList)
	//klog.Infof("vm_count: %d", count)
	//for i := 0; i < count; i++ {
	//
	//	j := cs.DataList[i]
	//	//多选
	//	if len(l.RunList) != 0 {
	//		stateIn := services.In(l.RunList, j.Status)
	//		if !stateIn {
	//			continue
	//		}
	//	}
	//
	//	nb, _ := regexp.MatchString(l.Name, j.Name)
	//	pb, _ := regexp.MatchString(l.PhysicalHost, j.Hypervisor)
	//	tb, _ := regexp.MatchString(l.TenantId, j.TenantId)
	//	if (pb || l.PhysicalHost == "") &&
	//		(l.Pool == j.Aggregate || l.Pool == "") &&
	//		(l.InnerIp == j.InnerIP || l.InnerIp == "") &&
	//		(l.OuterIp == j.PublicIP || l.OuterIp == "") &&
	//		(nb || l.Name == "") &&
	//		(tb || l.TenantId == "") {
	//		createTime := strconv.Itoa(j.CreateTime * 1e3)
	//		m := vmmodel.MonitorVm{
	//			ID:           j.ID,
	//			Name:         j.Name,
	//			VmType:       j.Flavor,
	//			Status:       j.Status,
	//			ComputePool:  j.Aggregate,
	//			Region:       j.Region,
	//			Az:           j.Az,
	//			TenantId:     j.TenantId,
	//			TenantName:   j.TenantName,
	//			PhysicalHost: j.Hypervisor,
	//			InnerIP:      j.InnerIP,
	//			OuterIP:      j.PublicIP,
	//			CreateTime:   createTime,
	//			Flavor:       j.Flavor,
	//		}
	//
	//		ms.DataList = append(ms.DataList, m)
	//	}
	//
	//}
	//
	//low := (l.PageNo - 1) * l.PageSize
	//if low > len(ms.DataList) {
	//	return ms, nil
	//}
	//
	//hight := low + l.PageSize
	//if hight > len(ms.DataList) {
	//	hight = len(ms.DataList)
	//}
	//
	//ms.PageNo = l.PageNo
	//ms.PageSize = l.PageSize
	//ms.TotalCount = len(ms.DataList)
	//ms.DataList = ms.DataList[low:hight]
	// TODO 列表监控数据获取暂时取消
	//for j := 0; j < len(ms.DataList); j++ {
	//	m := &ms.DataList[j]
	//	//cpu使用率
	//	tag1 := map[string]string{
	//		"host": m.ID,
	//	}
	//	cpuLast := kts.LastQuery{
	//		Metric: "cpu.utilizition.total" + "." + m.ID,
	//		Tags:   tag1,
	//	}
	//
	//	c, _ := kts.TSDBLastQuery(cpuLast)
	//	if len(c) > 0 {
	//		cc, _ := strconv.ParseFloat(c[0].Value, 64)
	//		m.CPUUseRate = services.FormPercent(cc / 100)
	//	}
	//
	//	//memory 内存使用量/内存总量
	//	mem1Tag := map[string]string{
	//		"host": m.ID,
	//		"p1":   "total",
	//	}
	//	mem1Last := kts.LastQuery{
	//		Metric: "vm.memory.size" + "." + m.ID,
	//		Tags:   mem1Tag,
	//	}
	//	mem1, _ := kts.TSDBLastQuery(mem1Last)
	//	if len(mem1) > 0 {
	//		cc, _ := strconv.ParseInt(mem1[0].Value, 10, 64)
	//		m.MemoryTotal = services.FormatFileSize(cc)
	//	}
	//
	//	mem2Tag := map[string]string{
	//		"host": m.ID,
	//		"p1":   "used",
	//	}
	//	mem2Last := kts.LastQuery{
	//		Metric: "vm.memory.size" + "." + m.ID,
	//		Tags:   mem2Tag,
	//	}
	//	mem2, _ := kts.TSDBLastQuery(mem2Last)
	//	if len(mem2) > 0 {
	//		cc, _ := strconv.ParseInt(mem1[0].Value, 10, 64)
	//		m.MemoryUse = services.FormatFileSize(cc)
	//	}
	//
	//	// 内存利用率
	//	mem3tag := map[string]string{
	//		"host": m.ID,
	//	}
	//	mem3Last := kts.LastQuery{
	//		Metric: "memory.utilizition.total" + "." + m.ID,
	//		Tags:   mem3tag,
	//	}
	//	mem3, _ := kts.TSDBLastQuery(mem3Last)
	//	if len(mem3) > 0 {
	//		cc, _ := strconv.ParseFloat(mem3[0].Value, 64)
	//		m.MemoryUseRate = services.FormPercent(cc / 100)
	//	}
	//	//disk 磁盘使用总量/磁盘使用量
	//	//disk1Tag := map[string]string{
	//	//	"host": m.ID,
	//	//	"p1":   "/",
	//	//	"p2":   "total",
	//	//}
	//	//disk1Last := kts.LastQuery{
	//	//	Metric: "vfs.fs.size" + "." + m.ID,
	//	//	Tags:   disk1Tag,
	//	//}
	//	//disk1, _ := kts.TSDBLastQuery(disk1Last)
	//	//if len(disk1) > 0 {
	//	//	cc, _ := strconv.ParseFloat(disk1[0].Value, 64)
	//	//	m.DiskTotal = cc
	//	//}
	//	//
	//	//disk2Tag := map[string]string{
	//	//	"host": m.ID,
	//	//	"p1":   "/",
	//	//	"p2":   "pused",
	//	//}
	//	//disk2Last := kts.LastQuery{
	//	//	Metric: "vfs.fs.size" + "." + m.ID,
	//	//	Tags:   disk2Tag,
	//	//}
	//	//disk2, _ := kts.TSDBLastQuery(disk2Last)
	//	//if len(disk2) > 0 {
	//	//	cc, _ := strconv.ParseFloat(disk2[0].Value, 64)
	//	//	m.DiskUse = cc
	//	//}
	//
	//	// 磁盘使用率
	//	disk3tag := map[string]string{
	//		"host": m.ID,
	//		"p1":   "/",
	//		"p2":   "pused",
	//	}
	//	disk3Last := kts.LastQuery{
	//		Metric: "vfs.fs.size" + "." + m.ID,
	//		Tags:   disk3tag,
	//	}
	//	disk3, _ := kts.TSDBLastQuery(disk3Last)
	//	if len(disk3) > 0 {
	//		cc, _ := strconv.ParseFloat(disk3[0].Value, 64)
	//		m.DiskUseRate = services.FormPercent(cc / 100)
	//	}
	//
	//}

	return ms, nil
}

func (s *VmService) GetVmDiskMetric(id, start, end string) []kts.MetricResult {
	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBK(end1 - start1) //降采样

	result := make([]kts.MetricResult, 0)
	vmDetail, err := cm.GetCMDBVmDetail(id)
	if err != nil {
		return result
	}
	if vmDetail.Code != 200 {
		return result
	}
	metricDir := vmDetail.Data.MetricDir
	if len(metricDir) == 0 {
		metricDir = append(metricDir, "/")
	}

	//id = "5b09313e-052e-4bf3-bd8c-1b63a5b69fac"

	for _, dir := range metricDir {
		r := kts.MetricResult{Name: dir}
		tag1 := map[string]string{
			"host": id,
			"p1":   dir,
			"p2":   "pused",
		}
		last := kts.RangeQuery{
			Aggregator: "sum",
			Metric:     "vfs.fs.size" + "." + id,
			Tags:       tag1,
			Downsample: step,
		}
		p, _ := kts.TSDBRangeQuery(start, end, last)
		if len(p) > 0 {
			r.Value = kts.KtsResultToValue(p[0].Dps)
			ss := kts.KtsGetSlice(p[0].Dps)
			//r.Max = services.FormatSize(getMax(ss))
			//r.Min = services.FormatSize(getMin(ss))
			r.Current = ss[0]

		}
		result = append(result, r)
	}
	return result
}

func ValueOrder(in []vmmodel.CmdbTopVm, code string) []vmmodel.CmdbTopVm {
	results := alert.Bucket{}
	for i := 0; i < len(in); i++ {
		results.Slice = append(results.Slice, in[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	switch code {
	case "asc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(vmmodel.CmdbTopVm).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(vmmodel.CmdbTopVm).Value), 64)
			return aa < bb
		}
	case "desc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(vmmodel.CmdbTopVm).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(vmmodel.CmdbTopVm).Value), 64)
			return aa > bb
		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(in); i++ {
		in[i] = results.Slice[i].(vmmodel.CmdbTopVm)
	}
	return in
}

func VmValueOrder(in []cmdbmodel.CmdbVm, code string) []cmdbmodel.CmdbVm {
	results := alert.Bucket{}
	for i := 0; i < len(in); i++ {
		results.Slice = append(results.Slice, in[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	switch code {
	case "asc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(cmdbmodel.CmdbVm).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(cmdbmodel.CmdbVm).Value), 64)
			return aa < bb
		}
	case "desc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(cmdbmodel.CmdbVm).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(cmdbmodel.CmdbVm).Value), 64)
			return aa > bb
		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(in); i++ {
		in[i] = results.Slice[i].(cmdbmodel.CmdbVm)
	}
	return in
}

//func makeMysqlClient() *sqlx.DB {
//	db, err := sqlx.Open("mysql", "root:Kingsoft123@tcp(10.178.224.65:8306)/luban?charset=utf8")
//	if err != nil {
//		panic("failed to connect database,err:" + err.Error())
//	}
//	return db
//}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cloudproduct/vm/vm_test.go
```golang
package vm

import (
	"encoding/json"
	vmmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cloudproduct"
	"testing"
)

func TestVmService_GetVmOverviewTop(t *testing.T) {
	vms := NewVmService()

	data := `{"region":"cn-shanghai-2","az":"cn-shanghai-2b","topK":"5","name":["cpu"],"loading":false,"start":1651991541959,"end":1651993341959}`
	//data := `{"region":"cn-shanghai-2","az":"all","topK":"5","name":["mem"],"loading":false,"start":1651989726841,"end":1651991526841}`
	//data := `{"region":"cn-shanghai-2","az":"all","topK":"5","name":["disk"],"loading":false,"start":1651989726841,"end":1651991526841}`
	//data := `{"region":"cn-shanghai-2","az":"all","topK":"5","name":["net"],"loading":false,"start":1651989726841,"end":1651991526842}`
	tq := new(vmmodel.TopQuery)
	err := json.Unmarshal([]byte(data), tq)
	if err != nil {
		t.Logf("Errorf: %s", err)
	}
	resp, err := vms.GetVmOverviewTopK(tq)
	if err != nil {
		t.Logf("Errorf: %s", err)
	}
	t.Logf("Final result : %+v", resp)
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cloudproduct/load/load_test.go
```golang
package load

import (
	"strconv"
	"testing"
	"time"
)

func Test_metric(t *testing.T) {
	id := "73156bab-eaa5-496a-9ff6-d75dd731efac"
	start := strconv.FormatInt(time.Now().Add(-time.Hour*5).Unix(), 10)
	end := strconv.FormatInt(time.Now().Unix(), 10)
	step := "60s-avg-zero"
	cl, _ := DropbpsLine(id, start, end, step)
	t.Logf("%+v", cl)

	cr, _ := DropppsLine(id, start, end, step)
	t.Logf("%+v", cr)

	ml, _ := BpsLine(id, start, end, step)
	t.Logf("%+v", ml)

	mr, _ := PpsLine(id, start, end, step)
	t.Logf("%+v", mr)

	pn, _ := CpsLine(id, start, end, step)
	t.Logf("%+v", pn)

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cloudproduct/load/load.go
```golang
package load

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"time"

	"github.com/go-redis/redis/v8"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	vmmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cloudproduct"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	eipmodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/eip"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/load"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct"
	cm "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/eip"
	kts "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/ktsmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"k8s.io/klog/v2"
)

const (
	load_overview    = "load_overview"
	load_overviewTop = "load_overviewTop"
)

//slbBps 负载均衡流量
//slbPps 负载均衡每秒收发包次数
//slbCps  每秒新建连接数
//slbActiveconn 链接数
//eipBps 弹性IP带宽
//eipPps 弹性IP每秒收发包次数
// eipPps 出入带宽百分比
var LoadOverviewTopMapK = map[string]func(list []load.LoadTopVm, name, start, end string, k int) ([]load.OverViewLine, error){
	"slbBps":         QueryTopSlbBps,
	"slbPps":         QueryTopSlbPps,
	"slbCps":         QueryTopSlbCps,
	"slbActiveconn":  QueryTopSlbActiveconn,
	"eipBps":         QueryTopLoagEipBps,
	"eipPps":         QueryTopLoagEipPps,
	"eipUtilization": QueryTopLoagEipUtilization,
}

type ILoadService interface {
	Overview(*load.OverviewQuery) (load.OverView, error)
	OverviewTop(*load.OverviewTopQuery) ([]load.OverViewLine, error)
	OverviewTopK(*load.OverviewTopQuery) ([]vmmodel.OverViewLineNew, error)
	GetLBList(*load.ListQuery) (load.MonitorPage, error)
	GetMetricLine(*load.LoadMetricQuery) (load.LoadMetricRsp, error)
}

type LoadService struct {
}

func NewLoadService() *LoadService {
	return &LoadService{}
}

//概览页
func (r *LoadService) Overview(param *load.OverviewQuery) (load.OverView, error) {

	klog.Infof("get load overview ,region: %s, azs: %q", param.Region, param.Az)

	alerts := make([]models.AlertType, 0, 4)
	p0 := models.AlertType{Name: "紧急告警", Level: "p0", Kind: "error", Number: 0, Unit: "个"}
	p1 := models.AlertType{Name: "重要告警", Level: "p1", Kind: "warn", Number: 0, Unit: "个"}
	p2 := models.AlertType{Name: "次要告警", Level: "p2", Kind: "minor", Number: 0, Unit: "个"}
	p3 := models.AlertType{Name: "提醒告警", Level: "p3", Kind: "info", Number: 0, Unit: "个"}
	alerts = append(alerts, p0, p1, p2, p3)

	//// 获取负载均衡个数
	//loadCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/lb/cloudProduct/lbList", "post")
	//klog.Infof("loadCount", loadCount)
	//获取负载均衡列表
	hostUrlPost := cmdbmodel.GetLoadListParam{
		PageNo:   1,
		PageSize: int(^uint16(0)),
		Region:   param.Region,
	}

	list, err := cm.GetLbList(hostUrlPost)
	if err != nil {
		klog.Errorf("get GetLbList err ", err)
	}

	cs := list.Data.DataList
	count := len(cs)
	var (
		active   = 0 //运行中
		shutdown = 0 //已停止
	)
	for i := 0; i < count; i++ {
		switch cs[i].State {
		case "active":
			active++
		default:
			shutdown++
		}
	}

	chart := load.Chart{Info: load.OverInfo{Name: "实例状态", Number: count, UnitType: "number"}}
	v1 := load.ValueType{Name: "运行中", Value: active}
	chart.Values = append(chart.Values, v1)
	v2 := load.ValueType{Name: "已停止", Value: shutdown}
	chart.Values = append(chart.Values, v2)
	state := make([]load.Chart, 0, 1)
	state = append(state, chart)
	rst := load.OverView{param.Region, param.Az, alerts, state}

	return rst, nil
}

//概览页top
func (r *LoadService) OverviewTop(param *load.OverviewTopQuery) (rst []load.OverViewLine, err error) {

	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	var nameStr string
	for _, v := range param.Name {
		nameStr += v + "_"
	}

	key := "load_overviewTop"
	fieldKey := "name_" + nameStr + "topk_" + param.TopK + "_interval_" + intervalStr + "_region" + param.Region + "_Az" + param.Az
	klog.Infof("load OverviewTop fieldKey", fieldKey)

	redisCon := config.RedisConfig
	var rdb *redis.Client
	rdb = redis.NewClient(&redis.Options{
		Addr:       redisCon["Host"].(string),
		Password:   redisCon["Password"].(string),
		DB:         redisCon["Db"].(int),
		MaxRetries: redisCon["MaxRetries"].(int),
	})

	cache, err := utils.NewRedisCache(rdb, key)
	if err != nil {
		klog.Error("get utils.NewRedisCache failed", err)
		return
	}
	result, err := rdb.Ping(context.Background()).Result()
	if err != nil {
		klog.Error("Ping redis failed", err)
		return
	}

	klog.Infof("result %s", result)
	after := time.After(time.Second * 60)

	for {
		select {
		case <-time.After(time.Second):
			data, err := cache.GetData(context.Background(), fieldKey, GetLoadTop(param), time.Minute*10)
			if err != nil {
				klog.Error("load GetData err ", err)
			}
			if data == "" {
				continue
			}
			var list []load.OverViewLine
			ee := json.Unmarshal([]byte(data), &list)
			if ee != nil {
				klog.Error("Parsing JSON failed", ee)
			}

			klog.Infof("data:%s", list)
			return list, nil
		case <-after:
			return
		}
	}

	return rst, nil
}

func (r *LoadService) OverviewTopK(param *load.OverviewTopQuery) ([]vmmodel.OverViewLineNew, error) {
	ctx, cefl := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cefl()

	//获取时间间隔
	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	topK, _ := strconv.ParseInt(param.TopK, 10, 64)

	//获取redis集合Key
	param1 := cloudproduct.GetResourceRedisKeyParam{
		ResourceType: config.CloudLoadResource,
		Region:       param.Region,
		Az:           param.Az,
		IntervalStr:  intervalStr,
	}
	redisKeyList, err := cloudproduct.GetResourceRedisKeyList(&param1)
	if err != nil {
		return []vmmodel.OverViewLineNew{}, err
	}
	klog.Infof("redisKeyList %+v", redisKeyList)

	//组装数据
	rst := make([]vmmodel.OverViewLineNew, 0)
	name := param.Name
	for i := 0; i < len(name); i++ {
		switch name[i] {
		case "slbBps":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "bps"}
			//入口流量
			rIn := vmmodel.EchartTypeNew{}
			rIn.Info.Name = "入网带宽"
			rIn.Info.Unit = "bps"
			rIn.Info.UnitType = "number"
			values := getMetricTopValuesFromRedis(redisKeyList, "SlbBpsIn", ctx, topK)
			rIn.Values = values
			r.Echarts = append(r.Echarts, rIn)

			// 出口流量
			rOut := vmmodel.EchartTypeNew{}
			rOut.Info.Name = "出网带宽"
			rOut.Info.Unit = "bps"
			rOut.Info.UnitType = "number"

			values = getMetricTopValuesFromRedis(redisKeyList, "SlbBpsOut", ctx, topK)
			rOut.Values = values
			r.Echarts = append(r.Echarts, rOut)

			rst = append(rst, r)
		case "slbPps":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "pps"}
			//入口流量
			rIn := vmmodel.EchartTypeNew{}
			rIn.Info.Name = "每秒流入包数"
			rIn.Info.Unit = "pps"
			rIn.Info.UnitType = "number"
			values := getMetricTopValuesFromRedis(redisKeyList, "SlbPpsIn", ctx, topK)
			rIn.Values = values
			r.Echarts = append(r.Echarts, rIn)

			// 出口流量
			rOut := vmmodel.EchartTypeNew{}
			rOut.Info.Name = "每秒流出包数"
			rOut.Info.Unit = "pps"
			rOut.Info.UnitType = "number"

			values = getMetricTopValuesFromRedis(redisKeyList, "SlbPpsOut", ctx, topK)
			rOut.Values = values
			r.Echarts = append(r.Echarts, rOut)

			rst = append(rst, r)
		case "slbCps":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "cps"}
			rIn := vmmodel.EchartTypeNew{}
			rIn.Info.Name = "每秒新建连接数"
			rIn.Info.Unit = "个"
			rIn.Info.UnitType = "number"
			values := getMetricTopValuesFromRedis(redisKeyList, "SlbCps", ctx, topK)
			rIn.Values = values
			r.Echarts = append(r.Echarts, rIn)

			rst = append(rst, r)
		case "slbActiveconn":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "个"}
			rIn := vmmodel.EchartTypeNew{}
			rIn.Info.Name = "活跃连接数"
			rIn.Info.Unit = "个"
			rIn.Info.UnitType = "number"
			values := getMetricTopValuesFromRedis(redisKeyList, "SlbActiveconn", ctx, topK)
			rIn.Values = values
			r.Echarts = append(r.Echarts, rIn)

			rOut := vmmodel.EchartTypeNew{}
			rOut.Info.Name = "并发连接数"
			rOut.Info.Unit = "个"
			rOut.Info.UnitType = "number"

			values = getMetricTopValuesFromRedis(redisKeyList, "SlbConcurrentconn", ctx, topK)
			rOut.Values = values
			r.Echarts = append(r.Echarts, rOut)

			rst = append(rst, r)
		case "eipBps":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "Mbps"}
			rIn := vmmodel.EchartTypeNew{}
			rIn.Info.Name = "入网带宽"
			rIn.Info.Unit = "bps"
			rIn.Info.UnitType = "number"
			values := getMetricTopValuesFromRedis(redisKeyList, "EipBpsIn", ctx, topK)
			rIn.Values = values
			r.Echarts = append(r.Echarts, rIn)

			rOut := vmmodel.EchartTypeNew{}
			rOut.Info.Name = "出网带宽"
			rOut.Info.Unit = "bps"
			rOut.Info.UnitType = "number"

			values = getMetricTopValuesFromRedis(redisKeyList, "EipBpsOut", ctx, topK)
			rOut.Values = values
			r.Echarts = append(r.Echarts, rOut)

			rst = append(rst, r)
		case "eipPps":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "pps"}
			rIn := vmmodel.EchartTypeNew{}
			rIn.Info.Name = "每秒流入包数"
			rIn.Info.Unit = "pps"
			rIn.Info.UnitType = "number"
			values := getMetricTopValuesFromRedis(redisKeyList, "EipPpsIn", ctx, topK)
			rIn.Values = values
			r.Echarts = append(r.Echarts, rIn)

			rOut := vmmodel.EchartTypeNew{}
			rOut.Info.Name = "每秒流出包数"
			rOut.Info.Unit = "pps"
			rOut.Info.UnitType = "number"

			values = getMetricTopValuesFromRedis(redisKeyList, "EipPpsOut", ctx, topK)
			rOut.Values = values
			r.Echarts = append(r.Echarts, rOut)

			rst = append(rst, r)
		case "eipUtilization":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rIn := vmmodel.EchartTypeNew{}
			rIn.Info.Name = "入带宽百分比"
			rIn.Info.Unit = "%"
			values := getMetricTopValuesFromRedis(redisKeyList, "EipUtilizationIn", ctx, topK)
			rIn.Values = values
			r.Echarts = append(r.Echarts, rIn)

			rOut := vmmodel.EchartTypeNew{}
			rOut.Info.Name = "出带宽百分比"
			rOut.Info.Unit = "%"

			values = getMetricTopValuesFromRedis(redisKeyList, "EipUtilizationOut", ctx, topK)
			rOut.Values = values
			r.Echarts = append(r.Echarts, rOut)

			rst = append(rst, r)
		}
	}
	cloudproduct.AddRankOrder(rst) // 为双柱的Echarts设置排序
	return rst, nil
}

func getMetricTopValuesFromRedis(redisKeyList map[string][]string, metricKey string, ctx context.Context, topK int64) []vmmodel.VmValueType {
	var list []vmmodel.VmValueType
	vmCpuKeys := redisKeyList[metricKey] //获取当前metric Key
	//根据key循环获取集合数据
	for _, key := range vmCpuKeys {
		//获取集合数据
		vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
		var loadlist = make([]vmmodel.LoadValueType, len(vmListStr))
		var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
		//解析成json
		vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
		err := json.Unmarshal([]byte(vmSliceStr), &loadlist)
		if err != nil {
			klog.Errorf("err ", err)
		}
		if len(loadlist) == 0 {
			continue
		}
		// LoadValueType和VmValueType字段不一致，将LoadValueType的值迁移给VmValueType（VmValueType的反序列化是前端需要的）
		for k, v := range loadlist {
			vmlist[k].Value = v.Value
			vmlist[k].Id = v.Id
			vmlist[k].Name = v.Name
			vmlist[k].RegionCode = v.RegionCode
		}
		list = append(list, vmlist...)
	}

	count := len(list)
	//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
	if int64(count) > topK {
		//排序
		list = cloudproduct.VmValueOrder(list, "desc")
		if int64(len(list)) >= topK {
			list = list[:topK]
		}
	}

	return list
}

func GetLoadTop(param *load.OverviewTopQuery) func() (data string, err error) {

	return func() (data string, err error) {
		var rst []load.OverViewLine
		start := strconv.FormatFloat(param.Start/1000, 'f', 3, 64)
		end := strconv.FormatFloat(param.End/1000, 'f', 3, 64)
		topk, _ := strconv.Atoi(param.TopK)

		//获取负载均衡列表
		hostUrlPost := cmdbmodel.GetLoadListParam{
			PageNo:   1,
			PageSize: int(^uint16(0)),
			Region:   param.Region,
		}
		list, err := cm.GetLbList(hostUrlPost)
		if err != nil {
			klog.Errorf("get GetLbList err ", err)
		}
		klog.Infof("load list count", len(list.Data.DataList))

		var ipList = map[string]cmdbmodel.LoadDataList{}
		for _, val := range list.Data.DataList {
			if val.Eip != "" {
				ipList[val.Eip] = val
			}
		}

		var loadsList []load.LoadTopVm
		var eipList []eipmodels.CmdbEip

		if param.FlowType == 0 { // 全部
			lists := list.Data.DataList
			for _, v := range lists {
				if v.ListenerNum > 0 {
					loadInfo := load.LoadTopVm{}
					loadInfo.ID = "ksclb---" + v.InstanceID
					loadInfo.Name = v.InstanceName
					loadsList = append(loadsList, loadInfo)
				}
			}
		} else { // 公网
			eipParam := eipmodels.EipListQuery{}
			eipParam.BoundType = []string{"lb"}
			eip, err := eip.GetCmdbEipList(eipParam)
			if err != nil {
				klog.Error("get eip list fail")
			}
			eipList = eip.Data.DataList
			for _, v := range eipList {
				eips, ok := ipList[v.IpAddr]
				if !ok {
					continue
				}
				loadInfo := load.LoadTopVm{}
				loadInfo.ID = eips.InstanceID      // 负载id
				loadInfo.EipId = "ksceip--" + v.Id // eip id
				loadInfo.Name = eips.InstanceName  // 负载名称
				loadsList = append(loadsList, loadInfo)
			}
			// 数据如果未匹配上
			if len(loadsList) == 0 {
				count := len(list.Data.DataList)
				var aa []cmdbmodel.LoadDataList
				if count >= topk && count > 0 {
					aa = list.Data.DataList[0:topk]
				} else {
					aa = list.Data.DataList[0:count]
				}
				for _, vv := range aa {
					loadInfo := load.LoadTopVm{}
					loadInfo.ID = vv.InstanceID     // 负载id
					loadInfo.Name = vv.InstanceName // 负载名称
					loadsList = append(loadsList, loadInfo)
				}

			}
		}

		klog.Infof("loads conut", len(loadsList))

		//var lists []load.LoadTopVm
		//test := load.LoadTopVm{
		//	ID: "209ac436-1507-44e1-b6d5-21b4d92fbd44",
		//	EipId: "ksceip--7ce465dd-3fef-4411-8e84-8b6b2ce29d77",
		//}
		//lists = append(lists,test)

		for _, name := range param.Name {
			if op, ok := LoadOverviewTopMapK[name]; ok {
				result, errOp := op(loadsList, name, start, end, topk)
				if errOp != nil {
					klog.Error(errOp)
					continue
				}
				rst = append(rst, result...)
			}
		}
		res, _ := json.Marshal(rst)
		return string(res), nil
	}
}

func LoadValueOrder(in []load.LoadTopVm, code string) []load.LoadTopVm {
	results := alert.Bucket{}
	for i := 0; i < len(in); i++ {
		results.Slice = append(results.Slice, in[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	switch code {
	case "asc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(load.LoadTopVm).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(load.LoadTopVm).Value), 64)
			return aa < bb
		}
	case "desc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(load.LoadTopVm).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(load.LoadTopVm).Value), 64)
			return aa > bb
		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(in); i++ {
		in[i] = results.Slice[i].(load.LoadTopVm)
	}
	return in
}

//topk 负载均衡流量
func QueryTopSlbBps(list []load.LoadTopVm, name, start, end string, topk int) ([]load.OverViewLine, error) {
	klog.Info("SlbBps", "负载均衡流量")

	rst := make([]load.OverViewLine, 0, 4)
	result := load.OverViewLine{Name: name, Unit: "bps"}

	// in
	inEcharts := load.EchartType{}
	inEcharts.Info.Name = "入网带宽"
	inEcharts.Info.Unit = "bps"
	inEcharts.Info.UnitType = "bps"
	for j := 0; j < len(list); j++ {
		metric := []string{"SlbBpsIn"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	in := LoadValueOrder(list, "desc")
	if len(in) >= topk {
		in = in[:topk]
	}
	for o := 0; o < len(in); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(in[o].Value), 64)
		v := load.ValueType{Value: valueFloat, SubName: in[o].Name, Name: services.GenerateTopK(o + 1), VmId: in[o].ID}
		inEcharts.Values = append(inEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, inEcharts)

	// out
	outEcharts := load.EchartType{}
	outEcharts.Info.Name = "出网带宽"
	outEcharts.Info.Unit = "bps"
	outEcharts.Info.UnitType = "bps"
	for j := 0; j < len(list); j++ {
		metric := []string{"SlbBpsOut"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := LoadValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := load.ValueType{Value: valueFloat, SubName: out[o].Name, Name: services.GenerateTopK(o + 1), VmId: out[o].ID}
		outEcharts.Values = append(outEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, outEcharts)

	rst = append(rst, result)

	return rst, nil
}

//topk 负载均衡每秒收发包次数
func QueryTopSlbPps(list []load.LoadTopVm, name, start, end string, topk int) ([]load.OverViewLine, error) {
	klog.Info("SlbPps", "负载均衡每秒收发包次数")

	rst := make([]load.OverViewLine, 0, 4)
	result := load.OverViewLine{Name: name, Unit: "数/秒"}

	// in
	inEcharts := load.EchartType{}
	inEcharts.Info.Name = "每秒流入包数"
	inEcharts.Info.Unit = "次"
	inEcharts.Info.UnitType = "次"
	for j := 0; j < len(list); j++ {
		metric := []string{"SlbPpsIn"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	in := LoadValueOrder(list, "desc")
	if len(in) >= topk {
		in = in[:topk]
	}
	for o := 0; o < len(in); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(in[o].Value), 64)
		v := load.ValueType{Value: valueFloat, SubName: in[o].Name, Name: services.GenerateTopK(o + 1), VmId: in[o].ID}
		inEcharts.Values = append(inEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, inEcharts)

	// out
	outEcharts := load.EchartType{}
	outEcharts.Info.Name = "每秒流出包数"
	outEcharts.Info.Unit = "次"
	outEcharts.Info.UnitType = "次"
	for j := 0; j < len(list); j++ {
		metric := []string{"SlbPpsOut"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := LoadValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := load.ValueType{Value: valueFloat, SubName: out[o].Name, Name: services.GenerateTopK(o + 1), VmId: out[o].ID}
		outEcharts.Values = append(outEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, outEcharts)

	rst = append(rst, result)

	return rst, nil
}

//topk 负载均衡每秒新建连接数
func QueryTopSlbCps(list []load.LoadTopVm, name, start, end string, topk int) ([]load.OverViewLine, error) {
	klog.Info("SlbCps", "负载均衡每秒新建连接数")

	rst := make([]load.OverViewLine, 0, 4)
	result := load.OverViewLine{Name: name, Unit: "次/秒"}

	echarts := load.EchartType{}
	echarts.Info.Name = "每秒新建连接数"
	echarts.Info.Unit = "次"
	echarts.Info.UnitType = "次"
	for j := 0; j < len(list); j++ {
		metric := []string{"SlbCps"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := LoadValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := load.ValueType{Value: valueFloat, Name: out[o].Name, VmId: out[o].ID}
		echarts.Values = append(echarts.Values, v)
	}
	result.Echarts = append(result.Echarts, echarts)

	rst = append(rst, result)

	return rst, nil
}

//topk 负载均衡链接数
func QueryTopSlbActiveconn(list []load.LoadTopVm, name, start, end string, topk int) ([]load.OverViewLine, error) {
	klog.Info("SlbActiveconn", "负载均负载均衡链接数衡每秒新建连接数")

	rst := make([]load.OverViewLine, 0, 4)
	result := load.OverViewLine{Name: name, Unit: "个"}

	// SlbActiveconn
	actEcharts := load.EchartType{}
	actEcharts.Info.Name = "活跃连接数"
	actEcharts.Info.Unit = "次"
	actEcharts.Info.UnitType = "次"
	for j := 0; j < len(list); j++ {
		metric := []string{"SlbActiveconn"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	actOut := LoadValueOrder(list, "desc")
	if len(actOut) >= topk {
		actOut = actOut[:topk]
	}
	for o := 0; o < len(actOut); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(actOut[o].Value), 64)
		v := load.ValueType{Value: valueFloat, SubName: actOut[o].Name, Name: services.GenerateTopK(o + 1), VmId: actOut[o].ID}
		actEcharts.Values = append(actEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, actEcharts)

	// SlbConcurrentconn
	conEcharts := load.EchartType{}
	conEcharts.Info.Name = "并发连接数"
	conEcharts.Info.Unit = "次"
	conEcharts.Info.UnitType = "次"
	for j := 0; j < len(list); j++ {
		metric := []string{"SlbConcurrentconn"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	conOut := LoadValueOrder(list, "desc")
	if len(conOut) >= topk {
		conOut = conOut[:topk]
	}
	for o := 0; o < len(conOut); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(conOut[o].Value), 64)
		v := load.ValueType{Value: valueFloat, SubName: conOut[o].Name, Name: services.GenerateTopK(o + 1), VmId: conOut[o].ID}
		conEcharts.Values = append(conEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, conEcharts)

	// SlbInactiveconn
	inaEcharts := load.EchartType{}
	inaEcharts.Info.Name = "不活跃连接数"
	inaEcharts.Info.Unit = "次"
	inaEcharts.Info.UnitType = "次"
	for j := 0; j < len(list); j++ {
		metric := []string{"SlbInactiveconn"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	inaOut := LoadValueOrder(list, "desc")
	if len(inaOut) >= topk {
		inaOut = inaOut[:topk]
	}
	for o := 0; o < len(inaOut); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(inaOut[o].Value), 64)
		v := load.ValueType{Value: valueFloat, SubName: inaOut[o].Name, Name: services.GenerateTopK(o + 1), VmId: inaOut[o].ID}
		inaEcharts.Values = append(inaEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, inaEcharts)

	rst = append(rst, result)

	return rst, nil
}

//topk 负载均衡 弹性ip带宽
func QueryTopLoagEipBps(list []load.LoadTopVm, name, start, end string, topk int) ([]load.OverViewLine, error) {
	klog.Info("EipBps", "负载均衡弹性ip带宽")

	rst := make([]load.OverViewLine, 0, 4)
	result := load.OverViewLine{Name: name, Unit: "Mbps"}

	// in
	inEcharts := load.EchartType{}
	inEcharts.Info.Name = "入网带宽"
	inEcharts.Info.Unit = "bps"
	inEcharts.Info.UnitType = "bps"
	for j := 0; j < len(list); j++ {
		metric := []string{"EipBpsIn"}
		oo := kts.QueryVmMetric(list[j].EipId, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	in := LoadValueOrder(list, "desc")
	if len(in) >= topk {
		in = in[:topk]
	}
	for o := 0; o < len(in); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(in[o].Value), 64)
		v := load.ValueType{Value: valueFloat, SubName: in[o].Name, Name: services.GenerateTopK(o + 1), VmId: in[o].ID}
		inEcharts.Values = append(inEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, inEcharts)

	// out
	outEcharts := load.EchartType{}
	outEcharts.Info.Name = "出网带宽"
	outEcharts.Info.Unit = "bps"
	outEcharts.Info.UnitType = "bps"
	for j := 0; j < len(list); j++ {
		metric := []string{"EipBpsOut"}
		oo := kts.QueryVmMetric(list[j].EipId, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := LoadValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := load.ValueType{Value: valueFloat, SubName: out[o].Name, Name: services.GenerateTopK(o + 1), VmId: out[o].ID}
		outEcharts.Values = append(outEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, outEcharts)

	rst = append(rst, result)

	return rst, nil
}

//topk 负载均衡 弹性IP每秒收发包次数
func QueryTopLoagEipPps(list []load.LoadTopVm, name, start, end string, topk int) ([]load.OverViewLine, error) {
	klog.Info("EipPps", "弹性IP每秒收发包次数")

	rst := make([]load.OverViewLine, 0, 4)
	result := load.OverViewLine{Name: name}

	// in
	inEcharts := load.EchartType{}
	inEcharts.Info.Name = "每秒流入包数"
	inEcharts.Info.Unit = "	次"
	inEcharts.Info.UnitType = "次"
	for j := 0; j < len(list); j++ {
		metric := []string{"EipPpsIn"}
		oo := kts.QueryVmMetric(list[j].EipId, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	in := LoadValueOrder(list, "desc")
	if len(in) >= topk {
		in = in[:topk]
	}
	for o := 0; o < len(in); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(in[o].Value), 64)
		v := load.ValueType{Value: valueFloat, SubName: in[o].Name, Name: services.GenerateTopK(o + 1), VmId: in[o].ID}
		inEcharts.Values = append(inEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, inEcharts)

	// out
	outEcharts := load.EchartType{}
	outEcharts.Info.Name = "每秒流出包数"
	outEcharts.Info.Unit = "	次"
	outEcharts.Info.Unit = "	次"
	for j := 0; j < len(list); j++ {
		metric := []string{"EipPpsOut"}
		oo := kts.QueryVmMetric(list[j].EipId, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := LoadValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := load.ValueType{Value: valueFloat, SubName: out[o].Name, Name: services.GenerateTopK(o + 1), VmId: out[o].ID}
		outEcharts.Values = append(outEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, outEcharts)

	rst = append(rst, result)

	return rst, nil
}

//topk 负载均衡 弹性IP出入带宽百分比
func QueryTopLoagEipUtilization(list []load.LoadTopVm, name, start, end string, topk int) ([]load.OverViewLine, error) {
	klog.Info("EipUtilization", "弹性IP出入带宽百分比")

	rst := make([]load.OverViewLine, 0, 4)
	result := load.OverViewLine{Name: name, Unit: "%"}

	// in
	inEcharts := load.EchartType{}
	inEcharts.Info.Name = "入带宽百分比"
	inEcharts.Info.Unit = "%"
	inEcharts.Info.UnitType = "%"
	for j := 0; j < len(list); j++ {
		metric := []string{"EipUtilizationIn"}
		oo := kts.QueryVmMetric(list[j].EipId, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	in := LoadValueOrder(list, "desc")
	if len(in) >= topk {
		in = in[:topk]
	}
	for o := 0; o < len(in); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(in[o].Value), 64)
		v := load.ValueType{Value: valueFloat, SubName: in[o].Name, Name: services.GenerateTopK(o + 1), VmId: in[o].ID}
		inEcharts.Values = append(inEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, inEcharts)

	// out
	outEcharts := load.EchartType{}
	outEcharts.Info.Name = "出带宽百分比"
	outEcharts.Info.Unit = "%"
	outEcharts.Info.UnitType = "%"
	for j := 0; j < len(list); j++ {
		metric := []string{"EipUtilizationOut"}
		oo := kts.QueryVmMetric(list[j].EipId, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := LoadValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := load.ValueType{Value: valueFloat, SubName: out[o].Name, Name: services.GenerateTopK(o + 1), VmId: out[o].ID}
		outEcharts.Values = append(outEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, outEcharts)

	rst = append(rst, result)

	return rst, nil
}

func (s *LoadService) GetLBList(q *load.ListQuery) (load.MonitorPage, error) {
	rst := load.MonitorPage{}
	cmdbParam := cmdbmodel.GetLoadListParam{
		PageNo:           1,
		PageSize:         int(^uint16(0)),
		Region:           q.Region,
		InstanceType:     []string{q.InstanceType},
		ResourcePoolName: q.ResourcePoolName,
	}
	instances, err := getLBInstanceList(cmdbParam)
	if err != nil {
		klog.Error(err)
		return rst, err
	}
	poolNameMap := make(map[string]string)
	tenantIdMap := make(map[string]string)
	tenantNameMap := make(map[string]string)
	projectNameMap := make(map[string]string)
	for _, inst := range *instances {
		if q.InstanceType != "" && q.InstanceType != inst.InstanceType {
			continue
		}
		if q.State != "" && q.State != inst.State {
			continue
		}
		if q.LineType != "" && q.LineType != inst.LineType {
			continue
		}
		if q.NetType != "" && q.NetType != inst.NetType {
			continue
		}
		if len(q.PoolList) > 0 && !services.In(q.PoolList, inst.ResourcePoolName) {
			continue
		}
		if len(q.TenantIdList) > 0 && !services.In(q.TenantIdList, inst.TenantId) {
			continue
		}
		if len(q.TenantNameList) > 0 && !services.In(q.TenantNameList, inst.TenantName) {
			continue
		}
		if len(q.ProjectNameList) > 0 && !services.In(q.ProjectNameList, inst.ProjectName) {
			continue
		}
		//模糊搜索
		if q.SearchKey == "instanceName" && q.SearchValue != "" {
			if match, _ := regexp.MatchString(q.SearchValue, inst.InstanceName); !match {
				continue
			}
		}
		rst.DataList = append(rst.DataList, inst)
		//添加Item
		if _, ok := poolNameMap[inst.ResourcePoolName]; !ok && inst.ResourcePoolName != "" {
			poolNameMap[inst.ResourcePoolName] = inst.ResourcePoolName
			rst.Item.PoolList = append(rst.Item.PoolList, inst.ResourcePoolName)
		}
		if _, ok := tenantIdMap[inst.TenantId]; !ok && inst.TenantId != "" {
			tenantIdMap[inst.TenantId] = inst.TenantId
			rst.Item.TenantIdList = append(rst.Item.TenantIdList, inst.TenantId)
		}
		if _, ok := tenantNameMap[inst.TenantName]; !ok && inst.TenantName != "" {
			tenantNameMap[inst.TenantName] = inst.TenantName
			rst.Item.TenantNameList = append(rst.Item.TenantNameList, inst.TenantName)
		}
		if _, ok := projectNameMap[inst.ProjectName]; !ok && inst.ProjectName != "" {
			projectNameMap[inst.ProjectName] = inst.ProjectName
			rst.Item.ProjectNameList = append(rst.Item.ProjectNameList, inst.ProjectName)
		}
	}

	setOrderMetricsInfo(&rst.DataList, q.OrderCode)

	//order
	if q.OrderCode != "" && q.OrderType != "" {
		orderList := alert.Bucket{}
		for i := 0; i < len(rst.DataList); i++ {
			orderList.Slice = append(orderList.Slice, rst.DataList[i])
		}

		time_by := func(a, b interface{}) bool {
			return a.(load.MonitorInfo).CreateTime > b.(load.MonitorInfo).CreateTime
		}

		switch q.OrderCode {
		case "bpsOut":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(load.MonitorInfo).BPSOut < b.(load.MonitorInfo).BPSOut
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(load.MonitorInfo).BPSOut > b.(load.MonitorInfo).BPSOut
				}
			}
		case "bpsIn":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(load.MonitorInfo).BPSIn < b.(load.MonitorInfo).BPSIn
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(load.MonitorInfo).BPSIn > b.(load.MonitorInfo).BPSIn
				}
			}
		case "ppsIn":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(load.MonitorInfo).PPSIn < b.(load.MonitorInfo).PPSIn
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(load.MonitorInfo).PPSIn > b.(load.MonitorInfo).PPSIn
				}
			}

		case "ppsOut":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(load.MonitorInfo).PPSOut < b.(load.MonitorInfo).PPSOut
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(load.MonitorInfo).PPSOut > b.(load.MonitorInfo).PPSOut
				}
			}

		case "cps":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(load.MonitorInfo).CPS < b.(load.MonitorInfo).CPS
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(load.MonitorInfo).CPS > b.(load.MonitorInfo).CPS
				}
			}

		case "concurrentConn":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(load.MonitorInfo).ConcurrentConn < b.(load.MonitorInfo).ConcurrentConn
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(load.MonitorInfo).ConcurrentConn > b.(load.MonitorInfo).ConcurrentConn
				}
			}

		case "createTime":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(load.MonitorInfo).CreateTime < b.(load.MonitorInfo).CreateTime
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(load.MonitorInfo).CreateTime > b.(load.MonitorInfo).CreateTime
				}
			}

		}

		orderList.By = time_by
		sort.Sort(orderList)
		for i := 0; i < len(orderList.Slice); i++ {
			rst.DataList[i] = orderList.Slice[i].(load.MonitorInfo)
		}

	}

	low := (q.PageNo - 1) * q.PageSize
	if low > len(rst.DataList) {
		return rst, nil
	}
	hight := low + q.PageSize
	if hight > len(rst.DataList) {
		hight = len(rst.DataList)
	}
	rst.PageNo = q.PageNo
	rst.PageSize = q.PageSize
	rst.TotalCount = len(rst.DataList)
	rst.DataList = rst.DataList[low:hight]
	setMetricsInfo(&rst.DataList)
	return rst, nil
}

func getLBInstanceList(param cmdbmodel.GetLoadListParam) (*[]load.MonitorInfo, error) {
	result := make([]load.MonitorInfo, 0)
	cmdbRst, err := cm.GetLbList(param)
	if err != nil {
		klog.Error(err)
		return &result, err
	}
	if cmdbRst.Code != 200 {
		klog.Info("get data from cmdb error!")
		return &result, errors.New("get data from cmdb error")
	}

	//klog.Info("cmdb load balance Data")
	//klog.Info(cmdbRst.Data)
	regionList, _ := cm.GetAllRegions()
	for _, instance := range cmdbRst.Data.DataList {
		monitorInstance := load.MonitorInfo{}
		monitorInstance.ResourcePoolType = instance.ResourcePoolType
		monitorInstance.ResourcePoolName = instance.ResourcePoolName
		monitorInstance.Region = instance.Region
		monitorInstance.RegionName = cm.GetRegion(instance.Region, regionList).RegionName
		monitorInstance.InstanceName = instance.InstanceName
		monitorInstance.InstanceId = instance.InstanceID
		monitorInstance.State = instance.State
		monitorInstance.TenantId = instance.TenantID
		monitorInstance.TenantName = instance.TenantName
		monitorInstance.InstanceType = instance.InstanceType
		monitorInstance.IpVersion = instance.IPVersion
		monitorInstance.NetType = instance.NetType

		monitorInstance.ProjectName = instance.ProjectName
		monitorInstance.VPCInstanceName = instance.VpcInstanceName
		monitorInstance.Eip = instance.Eip
		monitorInstance.LineType = instance.LineType
		monitorInstance.ListenerNum = instance.ListenerNum
		monitorInstance.CreateTime = instance.CreateTime
		result = append(result, monitorInstance)
	}

	return &result, nil
}

func setMetricsInfo(instances *[]load.MonitorInfo) error {
	for i, inst := range *instances {
		host := fmt.Sprintf("ksclb---%s", inst.InstanceId)
		//host = "kscrds--aa1411ef-571e-41cc-a46f-b68d9c2da638"
		tag := map[string]string{
			"host": host,
		}
		bpsInQuery := kts.LastQuery{
			Metric: "slb.bps.in" + "." + host,
			Tags:   tag,
		}
		bpsOutQuery := kts.LastQuery{
			Metric: "slb.bps.out" + "." + host,
			Tags:   tag,
		}
		ppsInQuery := kts.LastQuery{
			Metric: "slb.pps.in" + "." + host,
			Tags:   tag,
		}
		ppsOutQuery := kts.LastQuery{
			Metric: "slb.pps.out" + "." + host,
			Tags:   tag,
		}
		cpsQuery := kts.LastQuery{
			Metric: "slb.cps" + "." + host,
			Tags:   tag,
		}
		concurrentConnQuery := kts.LastQuery{
			Metric: "slb.concurrentconn" + "." + host,
			Tags:   tag,
		}

		var queries = []kts.LastQuery{bpsInQuery, bpsOutQuery, ppsInQuery, ppsOutQuery, cpsQuery, concurrentConnQuery}
		//批量获取数据
		metrics, err := kts.TSDBLastQueryBatchBase(queries...)
		if err != nil {
			klog.Errorf("SDBLastQueryBatchBase load balance tsdb metrics 查询错误，instanceId: %s", inst.InstanceId)
		}

		var vBPSIn, vBPSOut, vPPSIn, vPPSOut, vCPS, vConcurrentConn int64 = 0, 0, 0, 0, 0, 0
		if len(metrics) == 6 {
			vBPSIn, _ = strconv.ParseInt(metrics[0].Value, 10, 64)
			vBPSOut, _ = strconv.ParseInt(metrics[1].Value, 10, 64)
			vPPSIn, _ = strconv.ParseInt(metrics[2].Value, 10, 64)
			vPPSOut, _ = strconv.ParseInt(metrics[3].Value, 10, 64)
			vCPS, _ = strconv.ParseInt(metrics[4].Value, 10, 64)
			vConcurrentConn, _ = strconv.ParseInt(metrics[5].Value, 10, 64)
		}

		(*instances)[i].BPSIn = vBPSIn
		(*instances)[i].BPSOut = vBPSOut
		(*instances)[i].PPSIn = vPPSIn
		(*instances)[i].PPSOut = vPPSOut
		(*instances)[i].CPS = vCPS
		(*instances)[i].ConcurrentConn = vConcurrentConn
	}
	return nil
}

func setOrderMetricsInfo(instances *[]load.MonitorInfo, orderField string) error {
	if orderField == "createTime" || orderField == "" {
		return nil
	}

	for i, inst := range *instances {
		//inst.InstanceId = "73156bab-eaa5-496a-9ff6-d75dd731efac"
		host := fmt.Sprintf("ksclb---%s", inst.InstanceId)

		tag := map[string]string{
			"host": host,
		}

		switch orderField {
		case "bpsOut":
			bpsOutQuery := kts.LastQuery{
				Metric: "slb.bps.out" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{bpsOutQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.InstanceId)
			} else {
				(*instances)[i].BPSOut, _ = strconv.ParseInt(metricsMap[bpsOutQuery.Metric].Value, 10, 64)
			}
		case "bpsIn":
			bpsInQuery := kts.LastQuery{
				Metric: "slb.bps.in" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{bpsInQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.InstanceId)
			} else {
				(*instances)[i].BPSIn, _ = strconv.ParseInt(metricsMap[bpsInQuery.Metric].Value, 10, 64)
			}
		case "ppsIn":
			ppsInQuery := kts.LastQuery{
				Metric: "slb.pps.in" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{ppsInQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.InstanceId)
			} else {
				(*instances)[i].PPSIn, _ = strconv.ParseInt(metricsMap[ppsInQuery.Metric].Value, 10, 64)
			}
		case "ppsOut":
			ppsOutQuery := kts.LastQuery{
				Metric: "slb.bps.out" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{ppsOutQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.InstanceId)
			} else {
				(*instances)[i].PPSOut, _ = strconv.ParseInt(metricsMap[ppsOutQuery.Metric].Value, 10, 64)
			}
		case "cps":
			cpsQuery := kts.LastQuery{
				Metric: "slb.cps" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{cpsQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.InstanceId)
			} else {
				(*instances)[i].CPS, _ = strconv.ParseInt(metricsMap[cpsQuery.Metric].Value, 10, 64)
			}
		case "concurrentConn":
			concurrentConnQuery := kts.LastQuery{
				Metric: "slb.concurrentconn" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{concurrentConnQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.InstanceId)
			} else {
				(*instances)[i].ConcurrentConn, _ = strconv.ParseInt(metricsMap[concurrentConnQuery.Metric].Value, 10, 64)
			}
		}

	}
	return nil
}

//dropbps  丢弃流量
//droppps  丢弃数据包
//bps    负载均衡流量
//pps   负载均衡每秒收发包次数
//cps      每秒新建连接数
//conn    负载均衡连接数
//reqrate      7层协议QPS
var LoadMetricLineMap = map[string]queryFunc{
	"dropbps": DropbpsLine,
	"droppps": DropppsLine,
	"bps":     BpsLine,
	"pps":     PpsLine,
	"cps":     CpsLine,
	"conn":    ConnLine,
	"reqrate": ReqRateLine,
}

type queryFunc func(id, start, end, step string) (load.LoadMetricRsp, error)

func DropbpsLine(id, start, end, step string) (load.LoadMetricRsp, error) {
	rst := load.LoadMetricRsp{Name: "丢弃流量", Unit: "bps", UnitType: "number"}
	//丢弃入流量
	echart1 := load.LineType{}
	echart1.Info = load.InfoType{
		Name:     "丢弃入流量",
		Unit:     "bps",
		UnitType: "number",
	}
	host := "ksclb---" + id
	tags := map[string]string{
		"host": host,
	}
	rangeQ := kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.drop.bps.in" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart1.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart1)

	//丢弃出流量
	echart2 := load.LineType{}
	echart2.Info = load.InfoType{
		Name:     "丢弃出流量",
		Unit:     "bps",
		UnitType: "number",
	}
	rangeQ = kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.drop.bps.out" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ = kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart2.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart2)

	//ACL丢弃流量
	echart3 := load.LineType{}
	echart3.Info = load.InfoType{
		Name:     "ACL丢弃流量",
		Unit:     "bps",
		UnitType: "number",
	}
	rangeQ = kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.drop.bps.acl" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ = kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart3.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart3)

	return rst, nil
}

func DropppsLine(id, start, end, step string) (load.LoadMetricRsp, error) {
	rst := load.LoadMetricRsp{Name: "丢弃数据包数", Unit: "pps", UnitType: "number"}
	//丢弃流入数据包
	echart1 := load.LineType{}
	echart1.Info = load.InfoType{
		Name:     "丢弃流入数据包",
		Unit:     "pps",
		UnitType: "number",
	}
	host := "ksclb---" + id
	tags := map[string]string{
		"host": host,
	}
	rangeQ := kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.drop.pps.in" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart1.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart1)

	//丢弃流出数据包
	echart2 := load.LineType{}
	echart2.Info = load.InfoType{
		Name:     "丢弃流出数据包",
		Unit:     "pps",
		UnitType: "number",
	}
	rangeQ = kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.drop.pps.out" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ = kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart2.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart2)

	//ACL丢弃数据包
	echart3 := load.LineType{}
	echart3.Info = load.InfoType{
		Name:     "ACL丢弃数据包",
		Unit:     "pps",
		UnitType: "number",
	}
	rangeQ = kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.drop.pps.acl" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ = kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart3.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart3)

	return rst, nil
}
func BpsLine(id, start, end, step string) (load.LoadMetricRsp, error) {
	rst := load.LoadMetricRsp{Name: "负载均衡流量", Unit: "bps", UnitType: "number"}
	//入网带宽
	echart := load.LineType{}
	echart.Info = load.InfoType{
		Name:     "入网带宽",
		Unit:     "bps",
		UnitType: "number",
	}

	host := "ksclb---" + id
	tags := map[string]string{
		"host": host,
	}
	rangeQ := kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.bps.in" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart)

	//出网带宽
	echart1 := load.LineType{}
	echart1.Info = load.InfoType{
		Name:     "入网带宽",
		Unit:     "bps",
		UnitType: "number",
	}
	rangeQ = kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.bps.out" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ = kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart1.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart1)
	return rst, nil
}

func PpsLine(id, start, end, step string) (load.LoadMetricRsp, error) {
	rst := load.LoadMetricRsp{Name: "负载均衡每秒收发包次数", Unit: "次", UnitType: "number"}
	//每秒流入包数
	echart := load.LineType{}
	echart.Info = load.InfoType{
		Name:     "每秒流入包数",
		Unit:     "pps",
		UnitType: "number",
	}

	host := "ksclb---" + id
	tags := map[string]string{
		"host": host,
	}
	rangeQ := kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.pps.in" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart)

	//每秒流出包数
	echart1 := load.LineType{}
	echart1.Info = load.InfoType{
		Name:     "每秒流出包数",
		Unit:     "次",
		UnitType: "number",
	}
	rangeQ = kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.pps.out" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ = kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart1.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart1)
	return rst, nil
}

func CpsLine(id, start, end, step string) (load.LoadMetricRsp, error) {
	rst := load.LoadMetricRsp{Name: "每秒新建连接数", Unit: "个", UnitType: "number"}
	echart := load.LineType{}
	echart.Info = load.InfoType{
		Name:     "每秒新建连接数",
		Unit:     "个",
		UnitType: "number",
	}

	//query
	host := "ksclb---" + id
	tags := map[string]string{
		"host": host,
	}
	rangeQ := kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.cps" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart)
	return rst, nil
}

func ConnLine(id, start, end, step string) (load.LoadMetricRsp, error) {
	rst := load.LoadMetricRsp{Name: "负载均衡连接数", Unit: "个", UnitType: "number"}
	//活跃连接数
	echart := load.LineType{}
	echart.Info = load.InfoType{
		Name:     "每秒新建连接数",
		Unit:     "个",
		UnitType: "number",
	}

	//query
	host := "ksclb---" + id
	tags := map[string]string{
		"host": host,
	}
	rangeQ := kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.activeconn" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart)

	//并发连接数
	echart1 := load.LineType{}
	echart1.Info = load.InfoType{
		Name:     "并发连接数",
		Unit:     "个",
		UnitType: "number",
	}

	//query
	rangeQ = kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.concurrentconn" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ = kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart1.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart1)

	//不活跃连接数
	echart2 := load.LineType{}
	echart2.Info = load.InfoType{
		Name:     "不活跃连接数",
		Unit:     "个",
		UnitType: "number",
	}
	rangeQ = kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.inactiveconn" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ = kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart2.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart2)

	return rst, nil
}

func ReqRateLine(id, start, end, step string) (load.LoadMetricRsp, error) {
	rst := load.LoadMetricRsp{Name: "7层协议QPS", Unit: "qps", UnitType: "number"}
	echart := load.LineType{}
	echart.Info = load.InfoType{
		Name:     "7层协议QPS",
		Unit:     "qps",
		UnitType: "number",
	}

	//query
	host := "ksclb---" + id
	tags := map[string]string{
		"host": host,
	}
	rangeQ := kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "slb.req_rate" + "." + host,
		Tags:       tags,
		Downsample: step,
	}
	rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart)
	return rst, nil
}

func (r *LoadService) GetMetricLine(query *load.LoadMetricQuery) (ld load.LoadMetricRsp, err error) {
	start := strconv.FormatFloat(query.Start, 'f', 3, 64)
	end := strconv.FormatFloat(query.End, 'f', 3, 64)
	step := services.TimeToStepForTSDBK(query.End - query.Start)
	fmt.Println("start", start, "end", end, "step", step)
	name := query.Name
	if op, ok := LoadMetricLineMap[name]; !ok {
		return
	} else {
		result, errOp := op(query.Id, start, end, step)
		if errOp != nil {
			klog.Error(errOp)
			return
		}
		return result, nil
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cloudproduct/object/object.go
```golang
package object

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"sort"
	"strconv"
	"strings"
	"time"

	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	objectmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/object"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/esmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	"k8s.io/klog/v2"
)

type IObjectService interface {
	GetObjectMetric(string) ([]objectmodel.MetricT, error)
	//GetServerHardwareMetric(string) (servermodels.HardWare, error)
	//GetSwitchMetricLine(*switchmodels.SwitchMetricLineQuery) (map[string][]switchmodels.EchartType, error)
	GetObjectOverview(*objectmodel.BucketQuery) (objectmodel.OverviewBucket, error)
	GetObjectOverviewTop(*objectmodel.BucketQuery) ([]objectmodel.OverviewTopType, error)
	GetObjectList(*objectmodel.ListQuery) (objectmodel.MonitorBuckets, error)
	//GetObjectPoolUsageList(*resourcepoolmodel.ObjectStorageUsageQuery) (resourcepoolmodel.ObjectStoragePoolUsageResult, error)
}

type ObjectService struct {
}

func NewObjectService() *ObjectService {
	return &ObjectService{}
}

func (s *ObjectService) GetObjectOverview(bq *objectmodel.BucketQuery) (objectmodel.OverviewBucket, error) {
	klog.Infof("GetBucketOverview BucketQuery:%+v", bq)
	rst := objectmodel.OverviewBucket{}
	pppp := make([]resourcepoolmodel.AlertType, 0, 4)
	p0 := resourcepoolmodel.AlertType{Label: "紧急告警", Level: "p0", Kind: "error", Number: 0, Unit: "个"}
	//cloud_monitor
	db := services.MakeMysqlClient()
	defer db.Close()
	p0Count, err := db.Exec("select count(*) from alarm_history where producttype=1")
	if err != nil {
		klog.Error(err)
	} else {
		P0, er := p0Count.LastInsertId()
		if er != nil {
			klog.Error(er)
		}
		p0.Number = P0
	}

	pppp = append(pppp, p0)

	p1 := resourcepoolmodel.AlertType{Label: "重要告警", Level: "p1", Kind: "warn", Number: 0, Unit: "个"}
	p2 := resourcepoolmodel.AlertType{Label: "次要告警", Level: "p2", Kind: "minor", Number: 0, Unit: "个"}
	p3 := resourcepoolmodel.AlertType{Label: "提醒告警", Level: "p3", Kind: "info", Number: 0, Unit: "个"}
	pppp = append(pppp, p1, p2, p3)
	rst.Alert = pppp
	var charts []objectmodel.Chart
	/*
	  1、存储总容量
	*/
	//storageChart, err := GetBucketStorage(bq)
	//storageChart, err := GetBucketStorageFromES(bq)

	storageChart := objectmodel.Chart{}
	//
	//if err != nil {
	//	klog.Error(err)
	//	return rst, nil
	//}
	charts = append(charts, storageChart)
	/*
	 2、总流入流量
	*/
	// wideUpChart, err := GetBucketWide(bq, true)
	// if err != nil {
	// 	klog.Error(err)
	// 	return rst, nil
	// }
	// charts = append(charts, wideUpChart)

	// /*
	//   3、总流出流量
	// */
	// wideDownChart, err := GetBucketWide(bq, false)
	// if err != nil {
	// 	klog.Error(err)
	// 	return rst, nil
	// }
	// charts = append(charts, wideDownChart)
	wild, err := GetBucketWideAll(bq)
	if err != nil {
		klog.Error(err)
		return rst, nil
	}
	charts = append(charts, wild...)

	/*
	  4、总体API请求
	*/
	APIRequestChart, err := GetAPIRequestTimes(bq)
	if err != nil {
		klog.Error(err)
	}
	charts = append(charts, APIRequestChart)

	/*
	 5、存储空间(Bucket)数量
	*/
	bucketCountChart, err := GetBucketStorageCount(bq)
	if err != nil {
		klog.Error(err)
		return rst, nil
	}
	charts = append(charts, bucketCountChart)
	rst.Echarts = charts
	return rst, nil
}

const (
	//存储类型
	STORAGETYPE_STANDARD    = "STANDARD"    //标准存储
	STORAGETYPE_ARCHIVE     = "ARCHIVE"     //归档存储
	STORAGETYPE_STANDARD_IA = "STANDARD_IA" //低频存储

	//单位类型 storage:存储的、percent:百分比的、number:数值的

	UNIT_TYPE_STORAGE = "storage"
	UNIT_TYPE_PERCENT = "percent"
	UNIT_TYPE_NUMBER  = "number"
)

func GetBucketStorage(bq *objectmodel.BucketQuery) (objectmodel.Chart, error) {
	chart := objectmodel.Chart{}
	/*
	  1、存储总容量
	*/
	storageOverInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "存储总容量",
		Name:     "存储总容量",
		Total:    0,
		Unit:     "byte",
		UnitType: UNIT_TYPE_STORAGE,
	}
	//标准存储
	standardValue := objectmodel.ValueType{
		Name:  "标准存储",
		Value: 0,
	}
	//归档存储
	archiveValue := objectmodel.ValueType{
		Name:  "归档存储",
		Value: 0,
	}
	//低频存储
	standardIAValue := objectmodel.ValueType{
		Name:  "低频存储",
		Value: 0,
	}
	storageMetric := prometheusmanager.GetBucketOverview(bq.Region, bq.StorageType, "BucketStore")
	prometheusStoreInfo := objectmodel.PrometheusStoreInfo{}
	err := json.Unmarshal(storageMetric, &prometheusStoreInfo)
	if err != nil {
		return chart, err
	}
	var total float64
	var value float64
	if len(prometheusStoreInfo.Data.Result) > 0 {
		for _, data := range prometheusStoreInfo.Data.Result {
			if len(data.Value) > 0 {
				valueString := data.Value[1].(string)
				result, err := strconv.ParseFloat(valueString, 64)
				if err != nil {
					return chart, err
				}
				//总和累加
				total = total + result
				value = result
			}
			switch data.Metric.Storageclass {
			case STORAGETYPE_STANDARD:
				if value > 0 {
					standardValue.Value = value
				}
			case STORAGETYPE_STANDARD_IA:
				if value > 0 {
					standardIAValue.Value = value
				}
			case STORAGETYPE_ARCHIVE:
				if value > 0 {
					archiveValue.Value = value
				}
			}
		}
		if total > 0 {
			storageOverInfo.Total = total
		}
	}
	//具体监控项
	var values []objectmodel.ValueType
	values = append(values, standardValue, archiveValue, standardIAValue)
	chart.Info = storageOverInfo
	chart.Values = values
	return chart, nil
}

func GetBucketStorageFromES(bq *objectmodel.BucketQuery) (objectmodel.Chart, error) {
	chart := objectmodel.Chart{}
	/*
	  1、存储总容量
	*/
	storageOverInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "存储总容量",
		Name:     "存储总容量",
		Total:    0,
		Unit:     "byte",
		UnitType: UNIT_TYPE_STORAGE,
	}
	//标准存储
	standardValue := objectmodel.ValueType{
		Name:  "标准存储",
		Value: 0,
	}
	//归档存储
	archiveValue := objectmodel.ValueType{
		Name:  "归档存储",
		Value: 0,
	}
	//低频存储
	standardIAValue := objectmodel.ValueType{
		Name:  "低频存储",
		Value: 0,
	}
	storeMap := esmanager.GetStorageTypeCapacityMap(bq.Region)
	if len(storeMap) > 0 {
		var tt int64
		for k, v := range storeMap {
			t, _ := strconv.ParseInt(fmt.Sprintf("%1.0f", v), 10, 64)
			tt += t
			switch k {
			case STORAGETYPE_STANDARD:
				if v > 0 {
					standardValue.Value = v
				}
			case STORAGETYPE_STANDARD_IA:
				if v > 0 {
					standardIAValue.Value = v
				}
			case STORAGETYPE_ARCHIVE:
				if v > 0 {
					archiveValue.Value = v
				}
			}
		}
		if tt > 0 {
			storageOverInfo.Total = tt
		}
	}

	//具体监控项
	var values []objectmodel.ValueType
	values = append(values, standardValue, archiveValue, standardIAValue)
	chart.Info = storageOverInfo
	chart.Values = values
	return chart, nil
}

// func GetBucketWide(bq *BucketQuery, isUp bool) (Chart, error) {
// 	chart := Chart{}
// 	/*
// 	  2、总流入流量/总流出流量
// 	*/
// 	wideOverInfo := OverInfo{
// 		Region:   bq.Region,
// 		Label:    utils.If(isUp, "总流入流量", "总流出流量").(string),
// 		Name:     utils.If(isUp, "总流入流量", "总流出流量").(string),
// 		Total:    0,
// 		Unit:     "byte",
// 		UnitType: UNIT_TYPE_STORAGE,
// 	}
// 	//公网
// 	publicNetworkValue := ValueType{
// 		Name:  "公网",
// 		Value: 0,
// 	}
// 	//内网
// 	intranetValue := ValueType{
// 		Name:  "内网",
// 		Value: 0,
// 	}
// 	//低频存储
// 	cdnValue := ValueType{
// 		Name:  "CDN",
// 		Value: 0,
// 	}
// 	wideMetric := prometheusmanager.GetBucketOverview(bq.Region, bq.StorageType, utils.If(isUp, "WideUp", "WideDown").(string))
// 	prometheusWideInfo := PrometheusWideInfo{}
// 	err := json.Unmarshal(wideMetric, &prometheusWideInfo)
// 	if err != nil {
// 		return chart, err
// 	}
// 	var total float64
// 	var value float64
// 	if len(prometheusWideInfo.Data.Result) > 0 {
// 		for _, data := range prometheusWideInfo.Data.Result {
// 			if len(data.Value) > 0 {
// 				valueString := data.Value[1].(string)
// 				result, err := strconv.ParseFloat(valueString, 64)
// 				if err != nil {
// 					return chart, err
// 				}
// 				//总和累加
// 				total = total + result
// 				value = result
// 			}
// 			//CDN
// 			if data.Metric.Cdn != "-" {
// 				cdnValue.Value = value
// 			} else {
// 				//外网
// 				if data.Metric.Isinner == "false" {
// 					intranetValue.Value = value
// 					//内网
// 				} else {
// 					publicNetworkValue.Value = value
// 				}
// 			}

// 		}
// 		if total > 0 {
// 			wideOverInfo.Total = total
// 		}
// 	}
// 	//具体监控项
// 	var values []ValueType
// 	values = append(values, publicNetworkValue, intranetValue, cdnValue)
// 	chart.Info = wideOverInfo
// 	chart.Values = values
// 	return chart, nil
// }

func GetBucketWideAll(bq *objectmodel.BucketQuery) ([]objectmodel.Chart, error) {
	chart := []objectmodel.Chart{}
	/*
	  2、总流入流量/总流出流量
	*/
	wideOverInfo1 := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "总流入流量",
		Name:     "总流入流量",
		Total:    0,
		Unit:     "byte",
		UnitType: UNIT_TYPE_STORAGE,
	}
	wideOverInfo2 := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "总流出流量",
		Name:     "总流出流量",
		Total:    0,
		Unit:     "byte",
		UnitType: UNIT_TYPE_STORAGE,
	}
	//公网流入
	//publicNetworkValue1 := objectmodel.ValueType{
	//	Name:  "公网",
	//	Value: 0,
	//}
	//内网
	//intranetValue1 := objectmodel.ValueType{
	//	Name:  "内网",
	//	Value: 0,
	//}
	//低频存储
	//cdnValue1 := objectmodel.ValueType{
	//	Name:  "CDN",
	//	Value: 0,
	//}
	//公网流出
	//publicNetworkValue2 := objectmodel.ValueType{
	//	Name:  "公网",
	//	Value: 0,
	//}
	//内网
	//intranetValue2 := objectmodel.ValueType{
	//	Name:  "内网",
	//	Value: 0,
	//}
	//低频存储
	//cdnValue2 := objectmodel.ValueType{
	//	Name:  "CDN",
	//	Value: 0,
	//}
	// wideMetric := prometheusmanager.GetBucketOverview(bq.Region, bq.StorageType, utils.If(isUp, "WideUp", "WideDown").(string))
	// prometheusWideInfo := PrometheusWideInfo{}
	// err := json.Unmarshal(wideMetric, &prometheusWideInfo)
	// if err != nil {
	// 	return chart, err
	// }
	// var total float64
	// var value float64
	// if len(prometheusWideInfo.Data.Result) > 0 {
	// 	for _, data := range prometheusWideInfo.Data.Result {
	// 		if len(data.Value) > 0 {
	// 			valueString := data.Value[1].(string)
	// 			result, err := strconv.ParseFloat(valueString, 64)
	// 			if err != nil {
	// 				return chart, err
	// 			}
	// 			//总和累加
	// 			total = total + result
	// 			value = result
	// 		}
	// 		//CDN
	// 		if data.Metric.Cdn != "-" {
	// 			cdnValue.Value = value
	// 		} else {
	// 			//外网
	// 			if data.Metric.Isinner == "false" {
	// 				intranetValue.Value = value
	// 				//内网
	// 			} else {
	// 				publicNetworkValue.Value = value
	// 			}
	// 		}

	// 	}
	// 	if total > 0 {
	// 		wideOverInfo.Total = total
	// 	}
	// }
	/*
		codeMap := map[string]int64{
			"公网上传":  0,
			"公网下载":  0,
			"内网上传":  0,
			"内网下载":  0,
			"CDN上传": 0,
			"CDN下载": 0,
		}
	*/
	//detailMap := esmanager.GetFlowById("")
	//klog.Infof("flow data: %+v", detailMap)
	//for k, v := range detailMap {
	//	switch k {
	//	case "外网流入流量":
	//		publicNetworkValue1.Value = float64(v)
	//		wideOverInfo1.Total += float64(v)
	//	case "内网流入流量":
	//		intranetValue1.Value = float64(v)
	//		wideOverInfo1.Total += float64(v)
	//	case "CDN流入流量":
	//		cdnValue1.Value = float64(v)
	//		wideOverInfo1.Total += float64(v)
	//	case "外网流出流量":
	//		publicNetworkValue2.Value = float64(v)
	//		wideOverInfo2.Total += float64(v)
	//	case "内网流出流量":
	//		intranetValue2.Value = float64(v)
	//		wideOverInfo2.Total += float64(v)
	//	case "CDN流出流量":
	//		cdnValue2.Value = float64(v)
	//		wideOverInfo2.Total += float64(v)
	//	}
	//}

	//非归档存储 就是特指 标准存储
	//innerFlowMap := esmanager.GetFlowInnerByEsSum(strings.ToUpper(bq.Region), bq.StorageType) //内网
	//outerFlow := esmanager.GetFlowOuterByEsSum(strings.ToUpper(bq.Region), bq.StorageType)    // 外网
	//cdnFlow := GetCdnTraffic(strings.ToUpper(bq.Region), bq.StorageType)                      //cdn
	//
	//intranetValue1.Value = innerFlowMap["up"]   //内网流入总量
	//intranetValue2.Value = innerFlowMap["down"] // 内网流出总量
	//cdnValue1.Value = cdnFlow["inner_up"] + cdnFlow["outer_up"]
	//cdnValue2.Value = cdnFlow["inner_down"] + cdnFlow["outer_down"]
	//
	//publicNetworkValue1.Value = outerFlow["up"]   //外网流入总量
	//publicNetworkValue2.Value = outerFlow["down"] // 外网流出总量
	//
	//wideOverInfo1.Total = intranetValue1.Value + publicNetworkValue1.Value //总流入量
	//wideOverInfo2.Total = intranetValue2.Value + publicNetworkValue2.Value // 总流出量
	//
	//chartchart1 := objectmodel.Chart{Info: wideOverInfo1, Values: []objectmodel.ValueType{publicNetworkValue1, intranetValue1, cdnValue1}}
	//chartchart2 := objectmodel.Chart{Info: wideOverInfo2, Values: []objectmodel.ValueType{publicNetworkValue2, intranetValue2, cdnValue2}}
	//去掉cdn与外网流量，只展示总流量 bq.Region
	wideOverInfo1.Total, _ = esmanager.GetTrafficSum(bq.Region, bq.StorageType, "", "", esmanager.GetDateIndex(-1), esmanager.TrafficUp)   //总流入量
	wideOverInfo2.Total, _ = esmanager.GetTrafficSum(bq.Region, bq.StorageType, "", "", esmanager.GetDateIndex(-1), esmanager.TrafficDown) // 总流出量
	chartchart1 := objectmodel.Chart{Info: wideOverInfo1}
	chartchart2 := objectmodel.Chart{Info: wideOverInfo2}

	chart = append(chart, chartchart1, chartchart2)
	return chart, nil
}

func GetCdnTraffic(region, storageType string) map[string]float64 {
	cndMap := map[string]float64{
		"inner_up":   0,
		"inner_down": 0,
		"outer_up":   0,
		"outer_down": 0,
	}
	Ago := time.Now().Add(time.Duration(-24 * time.Hour)).Format(esmanager.EsIndexDateFormat)
	AgoDate := strings.Split(Ago, ".")
	Index := AgoDate[0]
	aggr, err := esmanager.GetTrafficAggrFromEs(region, storageType, Index)
	if err != nil {
		klog.Errorf("esmanager GetTrafficAggrFromEs error: %s", err.Error())
		return cndMap
	}

	for _, userTypeBucket := range aggr.Aggregations.Usertype.UsertypeBuckets {
		if userTypeBucket.Key != "-" {
			if userTypeBucket.Key != "crr" {
				for _, isInnerBucket := range userTypeBucket.IsInner.IsInnerBuckets {
					if isInnerBucket.Key == "true" {
						cndMap["inner_up"] += isInnerBucket.Up.Value
						cndMap["inner_down"] += isInnerBucket.Down.Value
					} else {
						cndMap["outer_up"] += isInnerBucket.Up.Value
						cndMap["outer_down"] += isInnerBucket.Down.Value
					}
				}
			}
		}
	}
	return cndMap
}

func GetAPIRequestTimes(bq *objectmodel.BucketQuery) (objectmodel.Chart, error) {
	chart := objectmodel.Chart{}
	/*
	  4、总体API请求
	*/
	APIRequestInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "总体API请求",
		Name:     "总体API请求",
		Total:    0,
		Unit:     "次",
		UnitType: UNIT_TYPE_NUMBER,
	}
	//GET请求
	getValue := objectmodel.ValueType{
		Name:  "GET请求",
		Value: 0,
	}
	//PUT请求
	putValue := objectmodel.ValueType{
		Name:  "PUT请求",
		Value: 0,
	}
	//detail := esmanager.GetBucketApiNumDetailById("")
	detail := esmanager.GetBucketApiNumDetail(strings.ToUpper(bq.Region), bq.StorageType)
	klog.Infof("api number : %+v", detail)
	APIRequestInfo.Total = services.FormatFloat64(detail.Info.Total)
	chart.Info = APIRequestInfo
	for _, v := range detail.Values {
		switch v.Name {
		case "GET":
			getValue.Value = services.FormatFloat64(v.Value)
		case "PUT":
			putValue.Value = services.FormatFloat64(v.Value)
		}
	}
	chart.Values = append(chart.Values, getValue, putValue)
	return chart, nil
}

func GetBucketStorageCount(bq *objectmodel.BucketQuery) (objectmodel.Chart, error) {
	chart := objectmodel.Chart{}
	/*
	  5、存储空间(Bucket)数量
	*/
	APIRequestInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "存储空间(Bucket)数量",
		Name:     "存储空间(Bucket)数量",
		Total:    0,
		Unit:     "个",
		UnitType: UNIT_TYPE_NUMBER,
	}

	/* query */
	bucket := cmdbmodel.BucketRequest{Region: bq.Region, PageStruct: cmdbmodel.PageStruct{PageNo: 1, PageSize: 10}}
	if bq.StorageType != "" {
		bucket.StorageType = []string{bq.StorageType}
	}
	cmdbRst, err := cmdbmanager.GetBucketList(bucket)
	if err != nil {
		klog.Error(err)
		return chart, err
	}
	//APIRequestInfo.Total = float64(len(cmdbRst.DataList))
	APIRequestInfo.Total = cmdbRst.TotalCount

	//get请求
	// storeCountMetric := prometheusmanager.GetBucketOverview(bq.Region, bq.StorageType, "StoreCount")
	// storeCountInfo := PrometheusSumInfo{}
	// err := json.Unmarshal(storeCountMetric, &storeCountInfo)
	// if err != nil {
	// 	return chart, err
	// }
	// var total float64
	// if len(storeCountInfo.Data.Result) > 0 {
	// 	for _, data := range storeCountInfo.Data.Result {
	// 		if len(data.Value) > 0 {
	// 			valueString := data.Value[1].(string)
	// 			result, err := strconv.ParseFloat(valueString, 64)
	// 			if err != nil {
	// 				return chart, err
	// 			}
	// 			//总和累加
	// 			total = total + result
	// 		}
	// 	}
	// }
	// if total > 0 {
	// 	APIRequestInfo.Total = total
	// }
	chart.Info = APIRequestInfo
	return chart, nil
}

const (
	/**
	  1、监控图表类型
	*/
	TOTALFLOW       = "totalFlow"       //总流量监控
	TOTALREQUEST    = "totalRequest"    //总请求监控
	CAPACITY        = "capacity"        //空间容量
	CAPACITYERR     = "capacityErr"     //空间异常
	CAPACITYSUCCESS = "capacitySuccess" //存储空间成功率
	CAPACITYREQUEST = "capacityRequest" //存储空间请求
	CAPACITYFLOW    = "capacityFlow"    //存储空间流量
	CAPACITYBRAND   = "capacityBrand"   //存储空间带宽
	/*
		2、图表查询下拉选项
	*/
	CDN = "cdn"
	OUT = "out"
	IN  = "in"
)

func (s *ObjectService) GetObjectOverviewTop(bq *objectmodel.BucketQuery) ([]objectmodel.OverviewTopType, error) {
	klog.Infof("GetBucketOverviewTop BucketQuery:%+v", bq)
	//总的返回结构
	var rst []objectmodel.OverviewTopType
	//echart结构
	if len(bq.Name) <= 0 || bq.TopK == "" || bq.Start == "" || bq.End == "" {
		return rst, errors.New("对象存储概览参数入参错误")
	}
	//计算时间范围:
	start, startE := strconv.ParseFloat(bq.Start, 64)
	if startE != nil {
		return rst, errors.New("时间范围错误")
	}
	end, endE := strconv.ParseFloat(bq.End, 64)
	if endE != nil {
		return rst, errors.New("时间范围错误")
	}
	queryTime := services.FormatTime(end/1000 - start/1000)
	for _, name := range bq.Name {
		//处理name参数,示例:totalFlow:cdn/out/in
		nameSplit := strings.Split(name, ":")
		if len(nameSplit) <= 0 {
			return rst, errors.New("chart类型错误")
		}

		//图表名称
		chartName := nameSplit[0]
		//流量下拉选项
		flowSelect := ""
		if len(nameSplit) > 1 {
			flowSelect = nameSplit[1]
		}
		switch chartName {
		case TOTALFLOW: //总流量监控
			totalFlowTop, totalFlowErr := GetTotalFlowTop(bq, flowSelect, queryTime)
			if totalFlowErr != nil {
				return rst, errors.New("获取数据错误")
			}
			totalFlowTop.Name = "总流量监控"
			totalFlowTop.Region = bq.Region
			rst = append(rst, totalFlowTop)
		case TOTALREQUEST: //总请求监控
			totalRequestTop, totalRequestErr := GetTotalRequestTop(bq)
			if totalRequestErr != nil {
				return rst, errors.New("获取数据错误")
			}
			totalRequestTop.Name = "总请求监控"
			totalRequestTop.Region = bq.Region
			rst = append(rst, totalRequestTop)
		case CAPACITY: //空间容量
			totalCapacityTop, totalCapacityErr := GetTotalCapacityTop(bq, queryTime)
			if totalCapacityErr != nil {
				return rst, errors.New("获取数据错误")
			}
			totalCapacityTop.Name = "存储空间容量"
			totalCapacityTop.Region = bq.Region
			rst = append(rst, totalCapacityTop)
		case CAPACITYERR: //空间异常
			totalCapacityErrTop, totalCapacityErrErr := GetTotalCapacityErrTop(bq, queryTime)
			if totalCapacityErrErr != nil {
				return rst, errors.New("获取数据错误")
			}
			totalCapacityErrTop.Name = "存储空间异常返回排名"
			totalCapacityErrTop.Region = bq.Region
			rst = append(rst, totalCapacityErrTop)
		case CAPACITYSUCCESS: //存储空间成功率
			//capacitySuccessTop, capacitySuccessErr := GetCapacitySuccessTop(bq, queryTime)
			capacitySuccessTop, capacitySuccessErr := GetBucketSuccessTop(bq) //上面注释的是没改之前的逻辑，仿照之前的计算方法优化
			if capacitySuccessErr != nil {
				return rst, errors.New("获取数据错误")
			}
			capacitySuccessTop.Name = "存储空间成功率"
			capacitySuccessTop.Region = bq.Region
			rst = append(rst, capacitySuccessTop)
		case CAPACITYREQUEST: //存储空间请求，代码复制的 TOTALREQUEST: 总请求监控
			capacityRequestTop, capacityRequestErr := GetCapacityRequestTop(bq, queryTime)
			if capacityRequestErr != nil {
				return rst, errors.New("获取数据错误")
			}
			capacityRequestTop.Name = "存储空间请求"
			capacityRequestTop.Region = bq.Region
			rst = append(rst, capacityRequestTop)
		case CAPACITYFLOW:
			capacityFlowTop, capacityFlowErr := GetCapacityFlowTop(bq, queryTime)
			if capacityFlowErr != nil {
				return rst, errors.New("获取数据错误")
			}
			capacityFlowTop.Name = "存储空间总流量"
			capacityFlowTop.Region = bq.Region
			rst = append(rst, capacityFlowTop)
		case CAPACITYBRAND:
			capacityBandTop, capacityBandErr := GetCapacityBandTop(bq, queryTime)
			if capacityBandErr != nil {
				return rst, errors.New("获取数据错误")
			}
			capacityBandTop.Name = "存储空间带宽"
			capacityBandTop.Region = bq.Region
			rst = append(rst, capacityBandTop)
		}

	}

	return rst, nil
}

func GetTotalFlowTop(bq *objectmodel.BucketQuery, flowSelect, queryTime string) (objectmodel.OverviewTopType, error) {
	totalFlowTop := objectmodel.OverviewTopType{
		Name:   "总流量监控",
		Region: bq.Region,
	}
	//echart结构
	var echarts []objectmodel.ChartType
	//每个info name信息
	infoUpName := ""
	infoDownName := ""
	bucketMapKeyUp := ""
	bucketMapKeyDown := ""
	switch flowSelect {
	case CDN:
		infoUpName = "CDN流入流量"
		infoDownName = "CDN流出流量"
		bucketMapKeyUp = "CDNTrafficUp"
		bucketMapKeyDown = "CDNTrafficDown"
	case OUT:
		infoUpName = "内外网流入流量" //”外网流入流量“改为”内外网流入流量“
		infoDownName = "内外网流出流量"
		bucketMapKeyUp = "outNetTrafficUp"
		bucketMapKeyDown = "outNetTrafficDown"
	case IN:
		infoUpName = "内网流入流量"
		infoDownName = "内网流出流量"
		bucketMapKeyUp = "innerNetTrafficUp"
		bucketMapKeyDown = "innerNetTrafficDown"
	}
	//总流量监控流入流量
	totalFlowUpInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    infoUpName,
		Name:     infoUpName,
		Total:    0,
		Unit:     "byte",
		UnitType: UNIT_TYPE_STORAGE,
	}
	//var flowUpValues []objectmodel.ValueType
	flowUpValues := GetTopBuckets(bucketMapKeyUp)
	k, _ := strconv.Atoi(bq.TopK)
	//流入组装数据
	if len(flowUpValues) >= k {
		flowUpValues = flowUpValues[:k]
	}

	flowUpChartType := objectmodel.ChartType{
		Info:   totalFlowUpInfo,
		Values: flowUpValues,
	}
	echarts = append(echarts, flowUpChartType)

	//总流量监控流出流量
	totalFlowDownInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    infoDownName,
		Name:     infoDownName,
		Total:    0,
		Unit:     "byte",
		UnitType: UNIT_TYPE_STORAGE,
	}

	flowDownValues := GetTopBuckets(bucketMapKeyDown)

	//流入组装数据
	if len(flowDownValues) >= k {
		flowDownValues = flowDownValues[:k]
	}
	for i := 0; i < len(flowDownValues); i++ {
		p := flowDownValues[i]
		p.Name = fmt.Sprintf("top%d", i+1)
		flowDownValues[i] = p
	}
	flowDownChartType := objectmodel.ChartType{
		Info:   totalFlowDownInfo,
		Values: flowDownValues,
	}
	echarts = append(echarts, flowDownChartType)
	totalFlowTop.Echarts = echarts
	return totalFlowTop, nil
}

func GetTopBuckets(field string) []objectmodel.ValueType {
	topValues := make([]objectmodel.ValueType, 0)
	ctx, cefl := context.WithTimeout(context.Background(), 3*time.Minute)
	defer cefl()
	key := "bucket_charge_top:" + esmanager.GetDateIndex(-1)
	rs, err := client.HGet(ctx, key, field)
	if err != nil {
		req := cmdbmodel.BucketRequest{Region: "all", PageStruct: cmdbmodel.PageStruct{PageNo: 1, PageSize: 10000}}
		cmdbRst, err := cmdbmanager.GetBucketList(req)
		if err != nil {
			klog.Error(err)
			return topValues
		}

		if len(cmdbRst.DataList) > 0 {
			for index, d := range cmdbRst.DataList {
				chargeInfoMap := esmanager.GetBucketChargeInfoCache(d.ID)
				var v float64
				if field == "rok" {
					if chargeInfoMap["rTotal"] != 0 {
						v = services.FormPercent(float64(chargeInfoMap["rOK"] / chargeInfoMap["rTotal"]))
					}
				} else if field == "wok" {
					if chargeInfoMap["wTotal"] != 0 {
						v = services.FormPercent(float64(chargeInfoMap["wOK"] / chargeInfoMap["wTotal"]))
					}
				} else {
					v = float64(chargeInfoMap[field])
				}
				flowValue := objectmodel.ValueType{
					Name:       fmt.Sprintf("top%d", index+1),
					Value:      v,
					BucketId:   d.ID,
					BucketName: d.Name,
				}
				topValues = append(topValues, flowValue)
			}
		}
		rankValues := ValueOrder(topValues, "desc")
		//流入组装数据
		if len(rankValues) >= 20 {
			topValues = rankValues[:20]
		} else {
			topValues = rankValues
		}
		for i := 0; i < len(topValues); i++ {
			topValues[i].Name = fmt.Sprintf("top%d", i+1)
		}
		valueJson, _ := json.Marshal(topValues)
		client.HSet(ctx, key, field, valueJson)
		client.Expire(ctx, key, 24*7*3600)
	} else {
		err = json.Unmarshal([]byte(rs), &topValues)
	}
	return topValues
}

func GetTotalRequestTop(bq *objectmodel.BucketQuery) (objectmodel.OverviewTopType, error) {
	totalRequestTop := objectmodel.OverviewTopType{
		Name:   "总请求监控",
		Region: bq.Region,
	}
	//echart结构
	var echarts []objectmodel.ChartType
	//总put请求监控
	totalPutRequestInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "PUT请求",
		Name:     "PUT请求",
		Total:    0,
		Unit:     "次",
		UnitType: UNIT_TYPE_NUMBER,
	}

	totalPutRequestValues := GetTopBuckets("PUT")

	k, _ := strconv.Atoi(bq.TopK)
	//流入组装数据
	if len(totalPutRequestValues) >= k {
		totalPutRequestValues = totalPutRequestValues[:k]
	}

	totalPutRequestChartType := objectmodel.ChartType{
		Info:   totalPutRequestInfo,
		Values: totalPutRequestValues,
	}
	echarts = append(echarts, totalPutRequestChartType)

	//总get监控
	totalGetRequestInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "GET请求",
		Name:     "GET请求",
		Total:    0,
		Unit:     "次",
		UnitType: UNIT_TYPE_NUMBER,
	}
	totalGetRequestValues := GetTopBuckets("GET")

	if len(totalGetRequestValues) >= k {
		totalGetRequestValues = totalGetRequestValues[:k]
	}
	totalGetRequestChartType := objectmodel.ChartType{
		Info:   totalGetRequestInfo,
		Values: totalGetRequestValues,
	}
	echarts = append(echarts, totalGetRequestChartType)
	totalRequestTop.Echarts = echarts
	return totalRequestTop, nil
}

func GetTotalCapacityTop(bq *objectmodel.BucketQuery, queryTime string) (objectmodel.OverviewTopType, error) {
	totalCapacityTop := objectmodel.OverviewTopType{
		Name:   "存储空间容量",
		Region: bq.Region,
	}
	//var value float64
	//存储空间容量
	totalCapacityInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "存储空间容量",
		Name:     "存储空间容量",
		Total:    0,
		Unit:     "byte",
		UnitType: UNIT_TYPE_STORAGE,
	}
	var totalCapacityValues []objectmodel.ValueType

	/* query */
	bucket := cmdbmodel.BucketRequest{Region: "all", PageStruct: cmdbmodel.PageStruct{PageNo: 1, PageSize: 1000}}
	cmdbRst, err := cmdbmanager.GetBucketList(bucket)
	if err != nil {
		klog.Error(err)
		return totalCapacityTop, err
	}
	if len(cmdbRst.DataList) > 0 {
		for _, d := range cmdbRst.DataList {

			totalPutValue := objectmodel.ValueType{
				Name:       d.Name,
				Value:      float64(d.Size),
				BucketId:   d.ID,
				BucketName: d.Name,
			}
			totalCapacityValues = append(totalCapacityValues, totalPutValue)
		}
	}
	dateRst := ValueOrder(totalCapacityValues, "desc")
	k, _ := strconv.Atoi(bq.TopK)
	//流入组装数据
	if len(dateRst) >= k {
		totalCapacityValues = dateRst[:k]
	} else {
		totalCapacityValues = dateRst
	}
	totalCapacityChartType := objectmodel.ChartType{
		Info:   totalCapacityInfo,
		Values: totalCapacityValues,
	}
	totalCapacityTop.Echarts = append(totalCapacityTop.Echarts, totalCapacityChartType)
	return totalCapacityTop, nil
}

func GetTotalCapacityErrTop(bq *objectmodel.BucketQuery, queryTime string) (objectmodel.OverviewTopType, error) {
	totalCapacityErrTop := objectmodel.OverviewTopType{
		Name:   "存储空间异常返回排名",
		Region: bq.Region,
	}
	//echart结构
	var echarts []objectmodel.ChartType
	//存储空间容量
	totalCapacityErrInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "存储空间异常返回排名",
		Name:     "存储空间异常返回排名",
		Total:    0,
		Unit:     "次",
		UnitType: UNIT_TYPE_NUMBER,
	}

	totalCapacityErrValues := GetTopBuckets("codeErr")

	k, _ := strconv.Atoi(bq.TopK)
	//流入组装数据
	if len(totalCapacityErrValues) >= k {
		totalCapacityErrValues = totalCapacityErrValues[:k]
	}
	for i, v := range totalCapacityErrValues {
		totalCapacityErrValues[i].Name = v.BucketName
	}
	totalCapacityChartType := objectmodel.ChartType{
		Info:   totalCapacityErrInfo,
		Values: totalCapacityErrValues,
	}
	echarts = append(echarts, totalCapacityChartType)
	totalCapacityErrTop.Echarts = echarts
	return totalCapacityErrTop, nil
}

func GetCapacitySuccessTop(bq *objectmodel.BucketQuery, queryTime string) (objectmodel.OverviewTopType, error) {
	capacitySuccessTop := objectmodel.OverviewTopType{
		Name:   "存储空间成功率",
		Region: bq.Region,
	}
	//echart结构
	var echarts []objectmodel.ChartType

	//存储空间读成功率
	readSuccessInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "读成功率",
		Name:     "读成功率",
		Total:    0,
		Unit:     "%",
		UnitType: UNIT_TYPE_PERCENT,
	}
	top, cErr := strconv.Atoi(bq.TopK)
	if cErr != nil {
		return capacitySuccessTop, cErr
	}
	var readSuccessValues []objectmodel.ValueType

	//设置精度为2位 四舍五入的精度
	type capacityPercent struct {
		Bucketid   string
		BucketName string
		Percent    float64
	}

	/* query */
	bucket := cmdbmodel.BucketRequest{Region: "all", PageStruct: cmdbmodel.PageStruct{PageNo: 1, PageSize: 1000}}
	cmdbRst, err := cmdbmanager.GetBucketList(bucket)
	if err != nil {
		klog.Error(err)
		return capacitySuccessTop, err
	}

	if len(cmdbRst.DataList) > 0 {
		/*
		  1、计算出所有的读成功率
		*/
		var readSucessList []capacityPercent
		for _, d := range cmdbRst.DataList {

			rwOKMap := esmanager.GetRWOKById(d.ID)
			readSucessList = append(readSucessList, capacityPercent{
				Bucketid:   d.ID,
				BucketName: d.Name,
				Percent:    rwOKMap["读成功率"],
			})
		}
		/*
		  2、对读成功率排序
		*/
		sort.Slice(readSucessList, func(i, j int) bool {
			return readSucessList[i].Percent > readSucessList[j].Percent
		})
		/*
		   3、对读成功率赋值
		*/
		var readSuccessLength int
		if len(readSucessList) >= top {
			readSuccessLength = top
		} else {
			readSuccessLength = len(readSucessList)
		}

		for i := 0; i < readSuccessLength; i++ {
			readSucess := readSucessList[i]
			readSuccessValue := objectmodel.ValueType{
				Name:       fmt.Sprintf("top%d", i+1),
				BucketId:   readSucess.Bucketid,
				BucketName: readSucess.BucketName,
				Value:      readSucess.Percent,
			}
			readSuccessValues = append(readSuccessValues, readSuccessValue)
		}
	}
	//读成功率组装数据
	readChartType := objectmodel.ChartType{
		Info:   readSuccessInfo,
		Values: readSuccessValues,
	}
	echarts = append(echarts, readChartType)

	//存储空间写成功率
	writeSuccessInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "写成功率",
		Name:     "写成功率",
		Total:    0,
		Unit:     "%",
		UnitType: UNIT_TYPE_PERCENT,
	}
	var writeSuccessValues []objectmodel.ValueType

	writeSuccessMetric := prometheusmanager.GetBucketOverviewTop(bq.Region, bq.StorageType, "", "", "write", "capacitySuccess", queryTime, "", "code=\"200\"")
	prometheusWriteSuccessInfo := objectmodel.PrometheusBucketIdInfo{}
	wsErr := json.Unmarshal(writeSuccessMetric, &prometheusWriteSuccessInfo)
	if wsErr != nil {
		return capacitySuccessTop, wsErr
	}
	// //查询写总数

	if len(cmdbRst.DataList) > 0 {
		/*
		  1、计算出所有写的成功率
		*/
		var writeSucessList []capacityPercent
		for _, d := range cmdbRst.DataList {

			rwOKMap := esmanager.GetRWOKById(d.ID)
			writeSucessList = append(writeSucessList, capacityPercent{
				Bucketid:   d.ID,
				BucketName: d.Name,
				Percent:    rwOKMap["写成功率"],
			})
		}
		/*
		  2、对写成功率排序
		*/
		sort.Slice(writeSucessList, func(i, j int) bool {
			return writeSucessList[i].Percent > writeSucessList[j].Percent
		})
		/*
		   3、对写成功率赋值
		*/
		var writeSuccessLength int
		if len(writeSucessList) >= top {
			writeSuccessLength = top
		} else {
			writeSuccessLength = len(writeSucessList)
		}

		for i := 0; i < writeSuccessLength; i++ {
			writeSucess := writeSucessList[i]
			writeSuccessValue := objectmodel.ValueType{
				Name:       fmt.Sprintf("top%d", i+1),
				BucketId:   writeSucess.Bucketid,
				BucketName: writeSucess.BucketName,
				Value:      writeSucess.Percent,
			}
			writeSuccessValues = append(writeSuccessValues, writeSuccessValue)
		}
	}
	//写成功率组装数据
	writeChartType := objectmodel.ChartType{
		Info:   writeSuccessInfo,
		Values: writeSuccessValues,
	}
	echarts = append(echarts, writeChartType)
	capacitySuccessTop.Echarts = echarts
	return capacitySuccessTop, nil
}

func GetBucketSuccessTop(bq *objectmodel.BucketQuery) (objectmodel.OverviewTopType, error) {
	capacitySuccessTop := objectmodel.OverviewTopType{
		Name:   "存储空间成功率",
		Region: bq.Region,
	}
	//echart结构
	var echarts []objectmodel.ChartType

	//存储空间读成功率
	readSuccessInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "读成功率",
		Name:     "读成功率",
		Total:    0,
		Unit:     "%",
		UnitType: UNIT_TYPE_PERCENT,
	}
	top, cErr := strconv.Atoi(bq.TopK)
	if cErr != nil {
		return capacitySuccessTop, cErr
	}

	readSuccessValues := GetTopBuckets("rok")

	if len(readSuccessValues) >= top {
		readSuccessValues = readSuccessValues[:top]
	}

	//读成功率组装数据
	readChartType := objectmodel.ChartType{
		Info:   readSuccessInfo,
		Values: readSuccessValues,
	}
	echarts = append(echarts, readChartType)

	//存储空间写成功率
	writeSuccessInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "写成功率",
		Name:     "写成功率",
		Total:    0,
		Unit:     "%",
		UnitType: UNIT_TYPE_PERCENT,
	}
	writeSuccessValues := GetTopBuckets("wok")

	if len(writeSuccessValues) >= top {
		writeSuccessValues = writeSuccessValues[:top]
	}
	//写成功率组装数据
	writeChartType := objectmodel.ChartType{
		Info:   writeSuccessInfo,
		Values: writeSuccessValues,
	}
	echarts = append(echarts, writeChartType)
	capacitySuccessTop.Echarts = echarts
	return capacitySuccessTop, nil
}

func GetCapacityRequestTop(bq *objectmodel.BucketQuery, queryTime string) (objectmodel.OverviewTopType, error) {
	capacityRequestTop := objectmodel.OverviewTopType{
		Name:   "存储空间请求",
		Region: bq.Region,
	}
	var value float64
	//echart结构
	var echarts []objectmodel.ChartType
	//总put请求监控
	putRequestInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "PUT请求",
		Name:     "PUT请求",
		Total:    0,
		Unit:     "次",
		UnitType: UNIT_TYPE_NUMBER,
	}
	var putRequestValues []objectmodel.ValueType

	/* query */
	bucket := cmdbmodel.BucketRequest{Region: "all", PageStruct: cmdbmodel.PageStruct{PageNo: 1, PageSize: 1000}}
	cmdbRst, err := cmdbmanager.GetBucketList(bucket)
	if err != nil {
		klog.Error(err)
		return capacityRequestTop, err
	}
	if len(cmdbRst.DataList) > 0 {
		for index, d := range cmdbRst.DataList {

			putValue := objectmodel.ValueType{
				Name:       fmt.Sprintf("top%d", index+1),
				Value:      value,
				BucketId:   d.ID,
				BucketName: d.Name,
			}
			esdetail := esmanager.GetBucketApiNumDetailById(d.ID) //取的是前一天的请求方法数据
			for _, v := range esdetail.Values {
				if v.Name.(string) == "PUT" {
					putValue.Value = float64(v.Value.(int64))
				}
			}
			putRequestValues = append(putRequestValues, putValue)
		}
	}
	dateRst := ValueOrder(putRequestValues, "desc")
	k, _ := strconv.Atoi(bq.TopK)
	//流入组装数据
	if len(dateRst) >= k {
		putRequestValues = dateRst[:k]
	} else {
		putRequestValues = dateRst
	}
	for i := 0; i < len(putRequestValues); i++ {
		p := putRequestValues[i]
		p.Name = fmt.Sprintf("top%d", i+1)
		putRequestValues[i] = p
	}
	totalPutRequestChartType := objectmodel.ChartType{
		Info:   putRequestInfo,
		Values: putRequestValues,
	}
	echarts = append(echarts, totalPutRequestChartType)

	//总get监控
	totalGetRequestInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "GET请求",
		Name:     "GET请求",
		Total:    0,
		Unit:     "次",
		UnitType: UNIT_TYPE_NUMBER,
	}
	var totalGetRequestValues []objectmodel.ValueType

	if len(cmdbRst.DataList) > 0 {
		for index, d := range cmdbRst.DataList {

			totalGetValue := objectmodel.ValueType{
				Name:       fmt.Sprintf("top%d", index+1),
				Value:      value,
				BucketId:   d.ID,
				BucketName: d.Name,
			}
			esdetail := esmanager.GetBucketApiNumDetailById(d.ID)
			for _, v := range esdetail.Values {
				if v.Name.(string) == "GET" {
					totalGetValue.Value = float64(v.Value.(int64))
				}
			}
			totalGetRequestValues = append(totalGetRequestValues, totalGetValue)
		}
	}
	//流入组装数据
	dateRst = ValueOrder(totalGetRequestValues, "desc")
	if len(dateRst) >= k {
		totalGetRequestValues = dateRst[:k]
	} else {
		totalGetRequestValues = dateRst
	}
	for i := 0; i < len(totalGetRequestValues); i++ {
		p := totalGetRequestValues[i]
		p.Name = fmt.Sprintf("top%d", i+1)
		totalGetRequestValues[i] = p
	}
	totalGetRequestChartType := objectmodel.ChartType{
		Info:   totalGetRequestInfo,
		Values: totalGetRequestValues,
	}
	echarts = append(echarts, totalGetRequestChartType)
	capacityRequestTop.Echarts = echarts
	return capacityRequestTop, nil
}

func GetCapacityFlowTop(bq *objectmodel.BucketQuery, queryTime string) (objectmodel.OverviewTopType, error) {
	capacityFlowTop := objectmodel.OverviewTopType{
		Name:   "存储空间总流出流量",
		Region: bq.Region,
	}
	var value float64
	//echart结构
	var echarts []objectmodel.ChartType
	//总流出量监控
	flowOutInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "总流出量",
		Name:     "总流出量",
		Total:    0,
		Unit:     "B",
		UnitType: UNIT_TYPE_NUMBER,
	}
	var flowOutValues []objectmodel.ValueType

	/* query */
	bucket := cmdbmodel.BucketRequest{Region: "all", PageStruct: cmdbmodel.PageStruct{PageNo: 1, PageSize: 1000}}
	cmdbRst, err := cmdbmanager.GetBucketList(bucket)
	if err != nil {
		klog.Error(err)
		return capacityFlowTop, err
	}
	if len(cmdbRst.DataList) > 0 {
		for index, d := range cmdbRst.DataList {

			flowOutValue := objectmodel.ValueType{
				Name:       fmt.Sprintf("top%d", index+1),
				Value:      value,
				BucketId:   d.ID,
				BucketName: d.Name,
			}
			flowMap := esmanager.GetFlowById(d.ID) //取的是前一天的数据
			for k, v := range flowMap {
				if k == "外网流出流量" || k == "内网流出流量" {
					flowOutValue.Value += float64(v)
				}
			}
			flowOutValues = append(flowOutValues, flowOutValue)
		}
	}
	dateRst := ValueOrder(flowOutValues, "desc")
	k, _ := strconv.Atoi(bq.TopK)
	//流入组装数据
	if len(dateRst) >= k {
		flowOutValues = dateRst[:k]
	} else {
		flowOutValues = dateRst
	}
	for i := 0; i < len(flowOutValues); i++ {
		p := flowOutValues[i]
		p.Name = fmt.Sprintf("top%d", i+1)
		flowOutValues[i] = p
	}
	flowOutChartType := objectmodel.ChartType{
		Info:   flowOutInfo,
		Values: flowOutValues,
	}
	echarts = append(echarts, flowOutChartType)

	//总get监控
	flowInInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "总流入量",
		Name:     "总流入量",
		Total:    0,
		Unit:     "B",
		UnitType: UNIT_TYPE_NUMBER,
	}
	var flowInValues []objectmodel.ValueType

	if len(cmdbRst.DataList) > 0 {
		for index, d := range cmdbRst.DataList {

			flowInValue := objectmodel.ValueType{
				Name:       fmt.Sprintf("top%d", index+1),
				Value:      value,
				BucketId:   d.ID,
				BucketName: d.Name,
			}
			flowMap := esmanager.GetFlowById(d.ID) //取的是前一天的数据
			for k, v := range flowMap {
				if k == "外网流入流量" || k == "内网流入流量" {
					flowInValue.Value += float64(v)
				}
			}
			flowInValues = append(flowInValues, flowInValue)
		}
	}
	//流入组装数据
	dateRst = ValueOrder(flowInValues, "desc")
	if len(dateRst) >= k {
		flowInValues = dateRst[:k]
	} else {
		flowInValues = dateRst
	}
	for i := 0; i < len(flowInValues); i++ {
		p := flowInValues[i]
		p.Name = fmt.Sprintf("top%d", i+1)
		flowInValues[i] = p
	}
	totalGetRequestChartType := objectmodel.ChartType{
		Info:   flowInInfo,
		Values: flowInValues,
	}
	echarts = append(echarts, totalGetRequestChartType)
	capacityFlowTop.Echarts = echarts
	return capacityFlowTop, nil
}

func GetCapacityBandTop(bq *objectmodel.BucketQuery, queryTime string) (objectmodel.OverviewTopType, error) {
	capacityBandTop := objectmodel.OverviewTopType{
		Name:   "存储空间上传带宽",
		Region: bq.Region,
	}
	var value float64
	//echart结构
	var echarts []objectmodel.ChartType
	//上传带宽
	bandUpInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "上传带宽",
		Name:     "上传带宽",
		Total:    0,
		Unit:     "Bps",
		UnitType: UNIT_TYPE_NUMBER,
	}
	var bandUpValues []objectmodel.ValueType

	/* query */
	bucket := cmdbmodel.BucketRequest{Region: "all", PageStruct: cmdbmodel.PageStruct{PageNo: 1, PageSize: 1000}}
	cmdbRst, err := cmdbmanager.GetBucketList(bucket)
	if err != nil {
		klog.Error(err)
		return capacityBandTop, err
	}
	if len(cmdbRst.DataList) > 0 {
		for index, d := range cmdbRst.DataList {

			bandUpValue := objectmodel.ValueType{
				Name:       fmt.Sprintf("top%d", index+1),
				Value:      value,
				BucketId:   d.ID,
				BucketName: d.Name,
			}
			flowMap := esmanager.GetFlowById(d.ID) //取的是前一天的数据
			for k, v := range flowMap {
				if k == "外网流入流量" || k == "内网流入流量" {
					bandUpValue.Value += float64(v / 86400)
				}
			}
			bandUpValues = append(bandUpValues, bandUpValue)
		}
	}
	dateRst := ValueOrder(bandUpValues, "desc")
	k, _ := strconv.Atoi(bq.TopK)
	//流入组装数据
	if len(dateRst) >= k {
		bandUpValues = dateRst[:k]
	} else {
		bandUpValues = dateRst
	}
	for i := 0; i < len(bandUpValues); i++ {
		p := bandUpValues[i]
		p.Name = fmt.Sprintf("top%d", i+1)
		bandUpValues[i] = p
	}
	bandUpChartType := objectmodel.ChartType{
		Info:   bandUpInfo,
		Values: bandUpValues,
	}
	echarts = append(echarts, bandUpChartType)

	//下载带宽
	bandDownInfo := objectmodel.OverInfo{
		Region:   bq.Region,
		Label:    "下载带宽",
		Name:     "下载带宽",
		Total:    0,
		Unit:     "Bps",
		UnitType: UNIT_TYPE_NUMBER,
	}
	var bandDownValues []objectmodel.ValueType

	if len(cmdbRst.DataList) > 0 {
		for index, d := range cmdbRst.DataList {

			bandDownValue := objectmodel.ValueType{
				Name:       fmt.Sprintf("top%d", index+1),
				Value:      value,
				BucketId:   d.ID,
				BucketName: d.Name,
			}
			flowMap := esmanager.GetFlowById(d.ID) //取的是前一天的数据
			for k, v := range flowMap {
				if k == "外网流出流量" || k == "内网流出流量" {
					bandDownValue.Value += float64(v / 86400)
				}
			}
			bandDownValues = append(bandDownValues, bandDownValue)
		}
	}
	//流入组装数据
	dateRst = ValueOrder(bandDownValues, "desc")
	if len(dateRst) >= k {
		bandDownValues = dateRst[:k]
	} else {
		bandDownValues = dateRst
	}
	for i := 0; i < len(bandDownValues); i++ {
		p := bandDownValues[i]
		p.Name = fmt.Sprintf("top%d", i+1)
		bandDownValues[i] = p
	}
	bandDownChartType := objectmodel.ChartType{
		Info:   bandDownInfo,
		Values: bandDownValues,
	}
	echarts = append(echarts, bandDownChartType)
	capacityBandTop.Echarts = echarts
	return capacityBandTop, nil
}
func (s *ObjectService) GetObjectMetric(id string) (metric []objectmodel.MetricT, err error) {
	//bucketTotalSize, _ := prometheusmanager.PrometheusQuery2(false, "", "", "", `sum(sum_over_time(bucket_total_size{bucket=~"`+id+`"}[10m]))`)
	//const unitTypeStorage = "storage"
	//const unitTypePercent = "percent"
	//const unitTypeNumber = "number"
	//
	////1.当前存储容量
	//total := 0.
	//for _, me := range bucketTotalSize {
	//	i := me.(map[string]interface{})["value"]
	//	i2 := i.([]interface{})[1]
	//	signalTotal, _ := strconv.ParseFloat(i2.(string), 64)
	//	total += signalTotal
	//}

	cm, _ := esmanager.GetStoreLineById(id)
	total := cm["总量"]
	currentCap := objectmodel.MetricT{
		HealthyState: "success",
		ID:           id,
		Total:        fmt.Sprintf("%f", total),
		Value:        fmt.Sprintf("%d", int64(total)),
		UsePercent:   "",
		UseState:     "",
		Used:         "",
		Name:         "当前总存储量",
		Unit:         "B",
		UnitType:     UNIT_TYPE_STORAGE,
	}
	metric = append(metric, currentCap)

	//2.近30天下载总量

	_, down, err := esmanager.Get30DownloadById(id)
	if err != nil {
		klog.Info(err)
	}
	currentCap = objectmodel.MetricT{
		HealthyState: "success",
		ID:           id,
		Total:        fmt.Sprintf("%f", float64(down)),
		Value:        fmt.Sprintf("%d", down),
		UsePercent:   "",
		UseState:     "",
		Used:         "",
		Unit:         "B",
		UnitType:     UNIT_TYPE_STORAGE,
		Name:         "近30天下载总量",
	}
	metric = append(metric, currentCap)

	//3.近30天apiRequests

	times, errr := esmanager.Get30ApiNumById(id)
	if errr != nil {
		klog.Info(errr)
	}
	currentCap = objectmodel.MetricT{
		HealthyState: "success",
		ID:           id,
		Total:        fmt.Sprintf("%f", float64(times)),
		Value:        fmt.Sprintf("%d", times),
		UsePercent:   "",
		UseState:     "",
		Used:         "",
		Unit:         "次",
		UnitType:     UNIT_TYPE_NUMBER,
		Name:         "近30天API请求数",
	}
	metric = append(metric, currentCap)

	idUp, idDown := esmanager.GetBucketFlowById(id)
	currentCap = objectmodel.MetricT{
		HealthyState: "success",
		ID:           id,
		Total:        fmt.Sprintf("%f", idUp),
		Value:        fmt.Sprintf("%d", int64(idUp)),
		UsePercent:   "",
		UseState:     "",
		Used:         "",
		Unit:         "B",
		UnitType:     UNIT_TYPE_STORAGE,
		Name:         "总流入流量",
	}
	metric = append(metric, currentCap)

	currentCap = objectmodel.MetricT{
		HealthyState: "success",
		ID:           id,
		Total:        fmt.Sprintf("%f", idDown),
		Value:        fmt.Sprintf("%d", int64(idDown)),
		UsePercent:   "",
		UseState:     "",
		Used:         "",
		Unit:         "B",
		UnitType:     UNIT_TYPE_STORAGE,
		Name:         "总流出流量",
	}
	metric = append(metric, currentCap)
	return metric, nil
}

var objectMap = map[string]string{
	"cn-shanghai-2": "上海二区",       //上海2区(VPC)
	"cn-beijing-6":  "TJWQRegion", //北京6区
}

func (s *ObjectService) GetObjectList(l *objectmodel.ListQuery) (objectmodel.MonitorBuckets, error) {
	klog.Infof("get Object GetObjectList param :%v", l)

	req := cmdbmodel.BucketRequest{Region: l.Region, PageStruct: cmdbmodel.PageStruct{PageNo: 1, PageSize: 10000}}
	cmdb, err := cmdbmanager.GetBucketList(req)
	fmt.Printf("GetBucketListCount %+d", len(cmdb.DataList))

	if err != nil {
		klog.Info("Get_GetBucketList_Error!")
		return objectmodel.MonitorBuckets{}, nil
	}
	//sort.Slice(cmdb.DataList, func(i, j int) bool {
	//	return cmdb.DataList[i].Name < cmdb.DataList[j].Name
	//})
	cs := cmdb.DataList
	res := objectmodel.MonitorBuckets{DataList: make([]objectmodel.MonitorBucket, 0, len(cs))}

	for i := 0; i < len(cs); i++ {
		j := cs[i]
		//多选
		if len(l.StorageType) != 0 {
			stateIn := services.In(l.StorageType, j.StorageType)
			if !stateIn {
				continue
			}
		}
		if len(l.SearchValue) > 0 {
			key := l.SearchKey
			// 按名字模糊查询
			if key == "name" {
				if !strings.Contains(j.Name, l.SearchValue) {
					continue
				}
			}
			if key == "tenantId" {
				if !strings.Contains(j.TenantID, l.SearchValue) {
					continue
				}
			}

			if key == "pool" {
				if !strings.Contains(j.ResourcePoolName, l.SearchValue) {
					continue
				}
			}

		}
		if (l.Region == j.Region || l.Region == "") &&
			(l.Az == j.AzCode || l.Az == "") &&
			(l.Pool == j.ResourcePoolName || l.Pool == "") && (l.TenantId == j.TenantID || l.TenantId == "") {
			create := services.Strval(j.CreateTime)
			intCreate, _ := strconv.Atoi(create + "000")
			m := objectmodel.MonitorBucket{
				ID:            j.ID,
				Name:          j.Name,
				Region:        j.Region,
				Az:            j.AzCode,
				TenantId:      j.TenantID,
				TenantName:    j.TenantName,
				CreateTime:    intCreate,
				StorageType:   j.StorageType,
				ObjectPool:    j.ResourcePoolName,
				CapacityTotal: j.Size,
				AlertNumber:   0,
			}

			//多选
			if len(l.MonitorStatus) != 0 {
				stateIn := services.In(l.MonitorStatus, m.MonitorStatus)
				if !stateIn {
					continue
				}
			}
			// if j.ID != "" {
			// 	outFlow, _ := prometheusmanager.PrometheusQuery2(false, "", "", "", `sum(sum_over_time(bucket_wide_down{bucketid="`+j.ID+`"}[10m]))`)

			// 	if len(outFlow) > 0 {
			// 		v := prometheusmanager.PrometheusResultToValueForSize(outFlow[0])
			// 		m.OutFlow = v.(string)
			// 	}

			// 	inFlow, _ := prometheusmanager.PrometheusQuery2(false, "", "", "", `sum(sum_over_time(bucket_wide_up{bucketid="`+j.ID+`"}[10m]))`)
			// 	if len(inFlow) > 0 {
			// 		v := prometheusmanager.PrometheusResultToValueForSize(inFlow[0])
			// 		m.InFlow = v.(string)
			// 	}

			// 	num := esmanager.GetBucketApiNumByid(j.ID)
			// 	m.APIRequestNumber = float64(num)

			// 	_, downLoad := esmanager.Get30DownloadById(j.ID)
			// 	m.DownLoad = services.FormatSize(float64(downLoad))

			// }
			res.DataList = append(res.DataList, m)
		}
	}

	low := (l.PageNo - 1) * l.PageSize
	if low > len(res.DataList) {
		return res, nil
	}

	hight := low + l.PageSize
	if hight > len(res.DataList) {
		hight = len(res.DataList)
	}

	res.PageNo = l.PageNo
	res.PageSize = l.PageSize
	res.TotalCount = len(res.DataList)
	res.DataList = res.DataList[low:hight]
	for o := 0; o < len(res.DataList); o++ {
		j := res.DataList[o]
		if j.ID != "" {
			chargeInfoMap := esmanager.GetBucketChargeInfoCache(j.ID)
			//up, down := esmanager.GetBucketFlowById(j.ID)
			j.InFlow = services.FormatSize(float64(chargeInfoMap["trafficUp"]))
			j.OutFlow = services.FormatSize(float64(chargeInfoMap["trafficDown"]))
			j.APIRequestNumber = float64(chargeInfoMap["requestTimes"])
			j.DownLoad = services.FormatSize(float64(chargeInfoMap["30trafficDown"]))
			j.TotalCount = chargeInfoMap["totalCount"]
			j.PutCount = chargeInfoMap["putCount"]
			j.DeleteCount = chargeInfoMap["deleteCount"]
		}
		res.DataList[o] = j
	}

	return res, nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cloudproduct/object/util.go
```golang
package object

import (
	"encoding/json"
	"fmt"
	"sort"
	"strconv"

	objectmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/object"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	cmdb "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"k8s.io/klog/v2"
)

func MakeTimeStamp(start, end, step string) []string {
	sl := make([]string, 0)
	start1, _ := strconv.ParseFloat(start, 64)
	end1, _ := strconv.ParseFloat(end, 64)
	step1, _ := strconv.ParseFloat(step, 64)
	for {
		ss := strconv.FormatFloat(start1, 'f', -1, 64)
		sl = append(sl, ss)
		start1 += step1
		if start1 > end1 {
			break
		}
	}

	return sl
}

//func GetStateByIp(ip string) (string, error) {
//	c := http.Client{}
//	prome := new(Prometheus)
//	resp, err := c.Get("http://" + config.GetDefaultUrl(config.PrometheusService) + "/api/v1/targets")
//	if err != nil {
//		return "", err
//	}
//
//	b, _ := io.ReadAll(resp.Body)
//	json.Unmarshal(b, prome)
//
//	state := ""
//	for i := 0; i < len(prome.Data.ActiveTargets); i++ {
//		fmt.Printf("instance= %s\n", prome.Data.ActiveTargets[i].Labels.Instance)
//		if pp := strings.Split(prome.Data.ActiveTargets[i].Labels.Instance, ":"); pp[0] == ip {
//			fmt.Printf("%s, health: %s", pp[0], prome.Data.ActiveTargets[i].Health)
//			state = strings.ToUpper(prome.Data.ActiveTargets[i].Health)
//			break
//		} else {
//			state = "DOWN"
//		}
//	}
//	return state, nil
//}

//func rTOs(s string, l interface{}) ResponseMetric {
//	r := ResponseMetric{}
//	r.Metric = s
//	ll := prom.PrometheusResultToValue2(l)
//	fmt.Printf("ll: %v\n", ll)
//
//	r.Value = ll
//	return r
//}

func getIpSlice(hosts []cmdb.PhysicalHostData) []string {
	s := []string{}
	for i := 0; i < len(hosts); i++ {
		s = append(s, hosts[i].ManagementIP)
	}

	return s
}

func getMax(vals []float64) float64 {
	var max = vals[0]
	for _, val := range vals {
		if val > max {
			max = val
		}
	}
	return max
}

func getMin(vals []float64) float64 {
	var min = vals[0]
	for _, val := range vals {
		if val < min {
			min = val
		}
	}
	return min
}

func getAvg(vals []float64) float64 {
	l := len(vals)
	sum := 0.0
	for _, val := range vals {
		sum += val / float64(l)
	}
	return sum
}

func getSlice(r interface{}) []float64 {
	var result []float64

	valu := r.(map[string]interface{})
	if Data, o := valu["values"]; o {
		value := Data.([]interface{})
		for i := 0; i < len(value); i++ {
			v := value[i].([]interface{})
			switch v[1].(type) {
			case string:
				vv, _ := strconv.ParseFloat(v[1].(string), 64)
				//ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", vv), 64)
				//sss := services.FormatSize(ss)
				//v[1] = sss
				result = append(result, vv)
			case float64:
				ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", v[1].(float64)), 64)
				//sss := services.FormatSize(ss)
				//v[1] = sss
				result = append(result, ss)
			}
		}
		//result = res.(string)
	}

	return result
}

func proDataConvEchart(label, id string, start string, end string, data []interface{}) objectmodel.MetricEcharts {
	dataMap := data[0].(map[string]interface{})
	bucketTotalDownLabel := dataMap["metric"].(map[string]interface{})
	klog.Infof("proLabel: %#v", bucketTotalDownLabel)
	values := dataMap["values"] //fixed 不接收下来直接assert有概率直接报错，怀疑是ssa无法处理的原因
	dataMapValue := values.([]interface{})
	dataMapValueEcharts := objectmodel.MetricEcharts{}
	dataMapValueEcharts.Info.ID = id
	dataMapValueEcharts.Info.Start = start
	dataMapValueEcharts.Info.End = end
	dataMapValueEcharts.Info.Label = label
	dataMapValueEcharts.Info.Name = label
	//bucketTotalDownEcharts.Info.SubName = bucketTotalDownLabel["bucketname"].(string)
	dataMapValues := objectmodel.MetricValues{}
	for _, item := range dataMapValue {
		dataMapValues.Value = json.Number(item.([]interface{})[1].(string))
		dataMapValues.Timestamep = json.Number(fmt.Sprintf("%f", item.([]interface{})[0].(float64)))
		dataMapValues.Name = json.Number(fmt.Sprintf("%f", item.([]interface{})[0].(float64)*1000))
		dataMapValueEcharts.Values = append(dataMapValueEcharts.Values, dataMapValues)
	}
	return dataMapValueEcharts
}
func proDataConvEchartPercent(label, id string, start string, end string, data []interface{}) objectmodel.MetricEcharts {
	dataMap := data[0].(map[string]interface{})
	bucketTotalDownLabel := dataMap["metric"].(map[string]interface{})
	klog.Infof("proLabel: %#v", bucketTotalDownLabel)
	values := dataMap["values"] //fixed 不接收下来直接assert有概率直接报错，怀疑是ssa无法处理的原因
	dataMapValue := values.([]interface{})
	dataMapValueEcharts := objectmodel.MetricEcharts{}
	dataMapValueEcharts.Info.ID = id
	dataMapValueEcharts.Info.Start = start
	dataMapValueEcharts.Info.End = end
	dataMapValueEcharts.Info.Label = label
	dataMapValueEcharts.Info.Name = label
	//bucketTotalDownEcharts.Info.SubName = bucketTotalDownLabel["bucketname"].(string)
	dataMapValues := objectmodel.MetricValues{}
	total := 0.
	for _, item := range dataMapValue {
		parseFloat, err := strconv.ParseFloat(item.([]interface{})[1].(string), 64)
		if err != nil {
			continue
		}
		total += parseFloat
	}
	dataMapValues.Value = json.Number(fmt.Sprintf("%f", total))
	dataMapValues.Name = label
	dataMapValueEcharts.Values = append(dataMapValueEcharts.Values, dataMapValues)
	return dataMapValueEcharts
}

func ValueOrder(in []objectmodel.ValueType, code string) []objectmodel.ValueType {
	results := alert.Bucket{}
	for i := 0; i < len(in); i++ {
		results.Slice = append(results.Slice, in[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	switch code {
	case "asc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(objectmodel.ValueType).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(objectmodel.ValueType).Value), 64)
			return aa < bb
		}
	case "desc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(objectmodel.ValueType).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(objectmodel.ValueType).Value), 64)
			return aa > bb
		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(in); i++ {
		in[i] = results.Slice[i].(objectmodel.ValueType)
	}
	return in
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cloudproduct/mysql/mysql.go
```golang
package mysql

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"github.com/go-redis/redis/v8"
	redisLink "github.com/go-redis/redis/v8"
	"github.com/ks3sdklib/aws-sdk-go/service/s3"
	client2 "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	alertmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	vmmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cloudproduct"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/dbmsservice"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/mysql"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct"
	vm "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct/vm"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/dbmsmanager"
	kts "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/ktsmanager"
	resourcepoolservice "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/resourcepool"
	mysqltemp "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/mysql"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"k8s.io/klog/v2"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"time"
)

type IMysqlService interface {
	GetMysqlList(*mysql.ListQuery) (mysql.MonitorMysqlPage, error)
	GetMysqlListDisorder(*mysql.ListQuery) (mysql.MonitorMysqlPage, error)
	GetMysqlListNew(*mysql.ListQuery) (mysql.MonitorMysqlPage, error)
	GetVmOverview(*mysql.OverviewQuery) (mysql.OverView, error)
	GetOverviewTop(*mysql.TopQuery) ([]mysql.OverViewLine, error)
	GetOverviewTopK(query *mysql.TopQuery) ([]vmmodel.OverViewLineNew, error)
	GetBlockMetricLine(*mysql.MetricQuery) ([]mysql.MysqlOverViewLine, error)
	GetBlockMetricLogsList(*mysql.LogsListMetricQuery) (mysql.LogsListSuccess, error)
	GetBlockMetricLogs(*mysql.MetricQuery) ([]byte, error)
	GetItems(region, dbType, poolId string) (mysql.Filter, error)
}

type MysqlService struct {
}

func NewMysqlService() *MysqlService {
	return &MysqlService{}
}

func (s *MysqlService) GetMysqlListDisorder(q *mysql.ListQuery) (mysql.MonitorMysqlPage, error) {
	// 筛选功能
	if q.SearchKey != "" && q.SearchValue != "" {
		switch q.SearchKey {
		case "id":
			q.Id = q.SearchValue
		case "name":
			q.Name = q.SearchValue
		case "ip":
			q.Ip = q.SearchValue
		case "tenantId":
			q.TenantId = q.SearchValue
		case "tenantName":
			q.TenantName = q.SearchValue

		}
	}
	if len(q.Az) == 0 {
		q.Az = []string{}
	}
	// 获取 mysql 列表
	rst := mysql.MonitorMysqlPage{}
	instanceList, err := getMysqlInstanceList(q.Region, "mysql", q.PoolId)
	if err != nil {
		klog.Error("get Mysql Instance List failed", err)
		return rst, nil
	}
	// 循环完成删选
	for _, inst := range instanceList {
		if q.Id != "" {
			if match, _ := regexp.MatchString(q.Id, inst.ID); !match {
				continue
			}
		}
		if q.Name != "" {
			if match, _ := regexp.MatchString(q.Name, inst.Name); !match {
				continue
			}
		}
		if q.Ip != "" {
			if match, _ := regexp.MatchString(q.Ip, inst.Ip); !match {
				continue
			}
		}
		if q.TenantId != "" {
			if match, _ := regexp.MatchString(q.TenantId, inst.TenantId); !match {
				continue
			}
		}
		if q.TenantName != "" {
			if match, _ := regexp.MatchString(q.TenantName, inst.TenantName); !match {
				continue
			}
		}
		if len(q.Status) > 0 && !services.In(q.Status, inst.Status) {
			continue
		}
		if len(q.TenantIdList) > 0 && !services.In(q.TenantIdList, inst.TenantId) {
			continue
		}
		if len(q.TenantNameList) > 0 && !services.In(q.TenantNameList, inst.TenantName) {
			continue
		}
		if len(q.Az) > 0 && !services.In(q.Az, inst.Az) {
			continue
		}
		if len(q.PoolName) > 0 && !services.In(q.PoolName, inst.PoolName) {
			continue
		}

		rst.DataList = append(rst.DataList, inst)
	}

	low := (q.PageNo - 1) * q.PageSize
	if low > len(rst.DataList) {
		return rst, nil
	}
	hight := low + q.PageSize
	if hight > len(rst.DataList) {
		hight = len(rst.DataList)
	}
	rst.PageNo = q.PageNo
	rst.PageSize = q.PageSize
	rst.TotalCount = len(rst.DataList)
	rst.DataList = rst.DataList[low:hight]
	// 获取 Metric 数据
	err = setMetricsInfo(&rst.DataList)
	if err != nil {
		klog.Errorf("set Metrics Info error", err)
	}
	return rst, err
}

func (s *MysqlService) GetMysqlListNew(q *mysql.ListQuery) (mysql.MonitorMysqlPage, error) {

	var mysqlParam dbmsservice.MysqlRequestParam

	mysqlParam.PageNo = q.PageNo
	mysqlParam.PageSize = q.PageSize
	mysqlParam.Region = q.Region
	mysqlParam.AzCodeList = q.Az
	mysqlParam.StatusList = q.Status
	mysqlParam.TenantIDList = q.TenantIdList
	mysqlParam.TenantNameList = q.TenantNameList
	mysqlParam.PoolName = q.PoolName
	mysqlParam.SearchKey = q.SearchKey
	mysqlParam.SearchValue = q.SearchValue
	mysqlParam.OrderCode = q.OrderCode
	mysqlParam.OrderType = q.OrderType

	// 获取 mysql 列表
	res, err := dbmsmanager.GetDbMysqlList(mysqlParam)
	klog.Info("get dbmsmanager.GetDbMysqlList %+v", res)

	mysqlList := res.Data.DataList
	rst := mysql.MonitorMysqlPage{}
	for i := 0; i < len(mysqlList); i++ {
		info := mysql.MonitorMysql{}
		info.ID = mysqlList[i].ID
		info.Name = mysqlList[i].Name
		info.Status = mysqlList[i].Status
		info.TenantId = mysqlList[i].TenantId
		info.TenantName = mysqlList[i].TenantName
		info.Ip = mysqlList[i].IP
		info.Region = mysqlList[i].RegionName
		info.RegionCode = mysqlList[i].RegionName
		info.Az = mysqlList[i].AzName
		info.AzCode = mysqlList[i].AzCode
		info.PoolId = mysqlList[i].ResourcePoolId
		info.PoolName = mysqlList[i].ResourcePool
		rst.DataList = append(rst.DataList, info)
	}
	// 获取 Metric 数据
	err = setMetricsInfo(&rst.DataList)
	if err != nil {
		klog.Errorf("set Metrics Info error", err)
	}
	rst.PageNo = res.Data.PageNo
	rst.PageSize = res.Data.PageSize
	rst.TotalCount = res.Data.TotalCount

	return rst, err
}

func (s *MysqlService) GetMysqlList(q *mysql.ListQuery) (mysql.MonitorMysqlPage, error) {
	if q.SearchKey != "" && q.SearchValue != "" {
		switch q.SearchKey {
		case "id":
			q.Id = q.SearchValue
		case "name":
			q.Name = q.SearchValue
		case "ip":
			q.Ip = q.SearchValue
		case "tenantId":
			q.TenantId = q.SearchValue
		case "tenantName":
			q.TenantName = q.SearchValue

		}
	}
	rst := mysql.MonitorMysqlPage{}
	instanceList, err := getMysqlInstanceList(q.Region, "mysql", q.PoolId)
	if err != nil {
		klog.Error(err)
		return rst, nil
	}

	//listMatch := make([]mysql.MonitorMysql, 0)
	for _, inst := range instanceList {
		if q.Id != "" {
			if match, _ := regexp.MatchString(q.Id, inst.ID); !match {
				continue
			}
		}
		if q.Name != "" {
			if match, _ := regexp.MatchString(q.Name, inst.Name); !match {
				continue
			}
		}
		if q.Ip != "" {
			if match, _ := regexp.MatchString(q.Ip, inst.Ip); !match {
				continue
			}
		}
		if q.TenantId != "" {
			if match, _ := regexp.MatchString(q.TenantId, inst.TenantId); !match {
				continue
			}
		}
		if q.TenantName != "" {
			if match, _ := regexp.MatchString(q.TenantName, inst.TenantName); !match {
				continue
			}
		}
		if len(q.Status) > 0 && !services.In(q.Status, inst.Status) {
			continue
		}
		if len(q.TenantIdList) > 0 && !services.In(q.TenantIdList, inst.TenantId) {
			continue
		}
		if len(q.TenantNameList) > 0 && !services.In(q.TenantNameList, inst.TenantName) {
			continue
		}
		if len(q.Az) > 0 && !services.In(q.Az, inst.Az) {
			continue
		}
		if len(q.PoolName) > 0 && !services.In(q.PoolName, inst.PoolName) {
			continue
		}

		rst.DataList = append(rst.DataList, inst)
	}

	setOrderMetricsInfo(&rst.DataList, q.OrderCode)

	//order
	if q.OrderCode != "" && q.OrderType != "" {
		orderList := alert.Bucket{}
		for i := 0; i < len(rst.DataList); i++ {
			orderList.Slice = append(orderList.Slice, rst.DataList[i])
		}
		time_by := func(a, b interface{}) bool {
			return a.(mysql.MonitorMysql).CreateTime > b.(mysql.MonitorMysql).CreateTime
		}

		switch q.OrderCode {
		case "cpuUsedPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).CPUUsedPercent < b.(mysql.MonitorMysql).CPUUsedPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).CPUUsedPercent > b.(mysql.MonitorMysql).CPUUsedPercent
				}
			}

		case "memoryUsedPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).MemoryUsedPercent < b.(mysql.MonitorMysql).MemoryUsedPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).MemoryUsedPercent > b.(mysql.MonitorMysql).MemoryUsedPercent
				}
			}

		case "iops":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).IOPS < b.(mysql.MonitorMysql).IOPS
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).IOPS > b.(mysql.MonitorMysql).IOPS
				}
			}

		case "netInput":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).NetInput < b.(mysql.MonitorMysql).NetInput
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).NetInput > b.(mysql.MonitorMysql).NetInput
				}
			}

		case "netOutput":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).NetOutput < b.(mysql.MonitorMysql).NetOutput
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).NetOutput > b.(mysql.MonitorMysql).NetOutput
				}
			}

		case "connect":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).Connect < b.(mysql.MonitorMysql).Connect
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).Connect > b.(mysql.MonitorMysql).Connect
				}
			}

		case "qps":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).QPS < b.(mysql.MonitorMysql).QPS
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).QPS > b.(mysql.MonitorMysql).QPS
				}
			}

		case "tps":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).TPS < b.(mysql.MonitorMysql).TPS
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).TPS > b.(mysql.MonitorMysql).TPS
				}
			}

		case "createTime":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).CreateTime < b.(mysql.MonitorMysql).CreateTime
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(mysql.MonitorMysql).CreateTime > b.(mysql.MonitorMysql).CreateTime
				}
			}

		}

		orderList.By = time_by
		sort.Sort(orderList)
		for i := 0; i < len(orderList.Slice); i++ {
			rst.DataList[i] = orderList.Slice[i].(mysql.MonitorMysql)
		}

	}

	low := (q.PageNo - 1) * q.PageSize
	if low > len(rst.DataList) {
		return rst, nil
	}
	hight := low + q.PageSize
	if hight > len(rst.DataList) {
		hight = len(rst.DataList)
	}
	rst.PageNo = q.PageNo
	rst.PageSize = q.PageSize
	rst.TotalCount = len(rst.DataList)
	rst.DataList = rst.DataList[low:hight]
	setMetricsInfo(&rst.DataList)
	return rst, nil
}

func setMetricsInfo(instances *[]mysql.MonitorMysql) error {
	for i, inst := range *instances {
		host := fmt.Sprintf("kscrds--%s", inst.ID)
		//host = "kscrds--aa1411ef-571e-41cc-a46f-b68d9c2da638"
		tag := map[string]string{
			"host": host,
		}
		cpuQuery := kts.LastQuery{
			Metric: "rds.cpu_used_percent" + "." + host,
			Tags:   tag,
		}
		memQuery := kts.LastQuery{
			Metric: "rds.memory_used_percent" + "." + host,
			Tags:   tag,
		}
		riopsQuery := kts.LastQuery{
			Metric: "rds.riops" + "." + host,
			Tags:   tag,
		}
		wiopsQuery := kts.LastQuery{
			Metric: "rds.wiops" + "." + host,
			Tags:   tag,
		}
		recQuery := kts.LastQuery{
			Metric: "rds.bytes_received" + "." + host,
			Tags:   tag,
		}
		sentQuery := kts.LastQuery{
			Metric: "rds.bytes_sent" + "." + host,
			Tags:   tag,
		}
		connQuery := kts.LastQuery{
			Metric: "rds.threads_connected" + "." + host,
			Tags:   tag,
		}
		qpsQuery := kts.LastQuery{
			Metric: "rds.qps" + "." + host,
			Tags:   tag,
		}
		tpsQuery := kts.LastQuery{
			Metric: "rds.tps" + "." + host,
			Tags:   tag,
		}
		var queries = []kts.LastQuery{cpuQuery, memQuery, riopsQuery, wiopsQuery, recQuery, sentQuery, connQuery, qpsQuery, tpsQuery}
		metricsMap, err := kts.TSDBLastQueryBatch(queries...)
		if err != nil {
			klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", host)
		}
		cpu := metricsMap[cpuQuery.Metric].Value
		mem := metricsMap[memQuery.Metric].Value
		riops := metricsMap[riopsQuery.Metric].Value
		wiops := metricsMap[wiopsQuery.Metric].Value

		rec := metricsMap[recQuery.Metric].Value
		sent := metricsMap[sentQuery.Metric].Value
		conn := metricsMap[connQuery.Metric].Value
		qps := metricsMap[qpsQuery.Metric].Value
		tps := metricsMap[tpsQuery.Metric].Value

		vcpu, _ := strconv.ParseFloat(cpu, 64)
		(*instances)[i].CPUUsedPercent = services.FormPercent(vcpu)
		vmem, _ := strconv.ParseFloat(mem, 64)
		(*instances)[i].MemoryUsedPercent = services.FormPercent(vmem)

		//vriops, _ := strconv.Atoi(riops)
		//vwiops, _ := strconv.Atoi(wiops)
		//(*instances)[i].IOPS = int64(vriops + vwiops)
		if riops == "" {
			riops = "0"
		}
		if wiops == "" {
			wiops = "0"
		}
		(*instances)[i].IOPS = riops + "/" + wiops

		(*instances)[i].NetInput, _ = strconv.ParseFloat(rec, 64)
		(*instances)[i].NetOutput, _ = strconv.ParseFloat(sent, 64)
		(*instances)[i].Connect, _ = strconv.ParseInt(conn, 10, 64)
		(*instances)[i].QPS, _ = strconv.ParseInt(qps, 10, 64)
		(*instances)[i].TPS, _ = strconv.ParseInt(tps, 10, 64)
	}
	return nil
}

func setOrderMetricsInfo(instances *[]mysql.MonitorMysql, orderField string) error {
	if orderField == "createTime" || orderField == "" {
		return nil
	}

	for i, inst := range *instances {
		host := fmt.Sprintf("kscrds--%s", inst.ID)
		//host = "kscrds--aa1411ef-571e-41cc-a46f-b68d9c2da638"
		tag := map[string]string{
			"host": host,
		}

		switch orderField {
		case "cpuUsedPercent":
			cpuQuery := kts.LastQuery{
				Metric: "rds.cpu_used_percent" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{cpuQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				vcpu, _ := strconv.ParseFloat(metricsMap[cpuQuery.Metric].Value, 64)
				(*instances)[i].CPUUsedPercent = services.FormPercent(vcpu / 1e2)
			}

		case "memoryUsedPercent":
			memQuery := kts.LastQuery{
				Metric: "rds.memory_used_percent" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{memQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				vmem, _ := strconv.ParseFloat(metricsMap[memQuery.Metric].Value, 64)
				(*instances)[i].MemoryUsedPercent = services.FormPercent(vmem / 1e2)
			}

		case "iops":
			riopsQuery := kts.LastQuery{
				Metric: "rds.riops" + "." + host,
				Tags:   tag,
			}
			wiopsQuery := kts.LastQuery{
				Metric: "rds.wiops" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{riopsQuery, wiopsQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				//vriops, _ := strconv.Atoi(metricsMap[riopsQuery.Metric].Value)
				//vwiops, _ := strconv.Atoi(metricsMap[wiopsQuery.Metric].Value)
				//(*instances)[i].IOPS = int64(vriops + vwiops)
				vriops, vwiops := "0", "0"
				if metricsMap[riopsQuery.Metric].Value != "" {
					vriops = metricsMap[riopsQuery.Metric].Value
				}
				if metricsMap[wiopsQuery.Metric].Value != "" {
					vwiops = metricsMap[wiopsQuery.Metric].Value
				}
				(*instances)[i].IOPS = vriops + "/" + vwiops
			}

		case "netInput":
			recQuery := kts.LastQuery{
				Metric: "rds.bytes_received" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{recQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				(*instances)[i].NetInput, _ = strconv.ParseFloat(metricsMap[recQuery.Metric].Value, 64)
			}

		case "netOutput":
			sentQuery := kts.LastQuery{
				Metric: "rds.bytes_sent" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{sentQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				(*instances)[i].NetOutput, _ = strconv.ParseFloat(metricsMap[sentQuery.Metric].Value, 64)
			}

		case "connect":
			connQuery := kts.LastQuery{
				Metric: "rds.threads_connected" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{connQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				(*instances)[i].Connect, _ = strconv.ParseInt(metricsMap[connQuery.Metric].Value, 10, 64)
			}

		case "qps":
			qpsQuery := kts.LastQuery{
				Metric: "rds.qps" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{qpsQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				(*instances)[i].QPS, _ = strconv.ParseInt(metricsMap[qpsQuery.Metric].Value, 10, 64)
			}

		case "tps":
			tpsQuery := kts.LastQuery{
				Metric: "rds.tps" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{tpsQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				(*instances)[i].TPS, _ = strconv.ParseInt(metricsMap[tpsQuery.Metric].Value, 10, 64)
			}

		}

	}
	return nil
}

func getMysqlInstanceList(region, dbType, poolId string) ([]mysql.MonitorMysql, error) {
	result := make([]mysql.MonitorMysql, 0)
	const limit = int(^uint16(0))
	dbmsResult, err := dbmsmanager.GetDBResourcePoolList(region, "", []string{dbType}, "", "", 1, limit)
	if err != nil {
		klog.Error(err)
		return result, nil
	}
	if dbmsResult.Code != 200 {
		klog.Info("get data from dbms error!")
		return result, nil
	}

	klog.Info("dbmsResult.Data")
	klog.Info(dbmsResult.Data)
	poolList := dbmsResult.Data.Data
	count := len(poolList)
	for i := 0; i < count; i++ {
		pool := poolList[i]
		if poolId != "" && pool.ID != poolId {
			continue
		}
		instanceParam := dbmsmanager.QueryInstanceList{
			ID:       pool.ID,
			PageNo:   1,
			PageSize: limit,
		}
		instanceList, instanceErr := dbmsmanager.GetDBInstanceList(instanceParam)
		klog.Infof("instanceListCnt %d", instanceList.Data.Total)
		if instanceErr != nil {
			return result, errors.New("Failed to get resource pool instance")
		}
		if len(instanceList.Data.Data) == 0 {
			continue
		}
		for _, instance := range instanceList.Data.Data {
			monitorInstance := mysql.MonitorMysql{}
			monitorInstance.ID = instance.ID
			monitorInstance.Name = instance.Name
			monitorInstance.Status = resourcepoolservice.DBInstanceStatusMapping[instance.Status]
			monitorInstance.TenantId = instance.TenantID
			monitorInstance.TenantName = instance.TenantName
			monitorInstance.Ip = instance.IP
			monitorInstance.Region = instance.RegionName
			monitorInstance.Az = instance.AzName
			monitorInstance.AzCode = instance.AzCode
			monitorInstance.PoolId = pool.ID
			monitorInstance.PoolName = pool.Name
			monitorInstance.CreateTime = instance.ServiceBeginTime
			result = append(result, monitorInstance)
		}
	}

	return result, nil
}

// 监控概览
func (s *MysqlService) GetVmOverview(param *mysql.OverviewQuery) (mysql.OverView, error) {
	klog.Info("Cloud_Mysql_GetVmOverview")
	result := mysql.OverView{}
	alerts := make([]resourcepoolmodel.AlertType, 0, 4)
	p0 := resourcepoolmodel.AlertType{Label: "紧急告警", Level: "p0", Kind: "error", Number: 0, Unit: "个"}

	//query mysql
	db := services.MakeMysqlClient()
	defer db.Close()
	p0Count, err := db.Exec("select count(*) from alarm_history where producttype=0")
	if err != nil {
		klog.Error(err)
	} else {
		P0, er := p0Count.LastInsertId()
		if er != nil {
			klog.Error(er)
		}
		p0.Number = P0
	}
	p1 := resourcepoolmodel.AlertType{Label: "重要告警", Level: "p1", Kind: "warn", Number: 0, Unit: "个"}
	p2 := resourcepoolmodel.AlertType{Label: "次要告警", Level: "p2", Kind: "minor", Number: 0, Unit: "个"}
	p3 := resourcepoolmodel.AlertType{Label: "提醒告警", Level: "p3", Kind: "info", Number: 0, Unit: "个"}
	alerts = append(alerts, p0, p1, p2, p3)
	result = mysql.OverView{
		Region: param.Region,
		Az:     param.Az,
		Lab:    param.Lab,
		Alerts: alerts,
	}
	return result, nil
}

func (s *MysqlService) GetOverviewTopK(param *mysql.TopQuery) (res []vmmodel.OverViewLineNew, err error) {
	ctx, cefl := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cefl()

	//获取时间间隔
	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	topK, _ := strconv.ParseInt(param.TopK, 10, 64)

	//获取redis集合Key
	param1 := cloudproduct.GetResourceRedisKeyParam{
		ResourceType: config.CloudMysqlResource,
		Region:       param.Region,
		Az:           param.Az,
		IntervalStr:  intervalStr,
	}
	redisKeyList, err := cloudproduct.GetResourceRedisKeyList(&param1)
	if err != nil {
		return []vmmodel.OverViewLineNew{}, err
	}
	klog.Infof("redisKeyList %+v", redisKeyList)

	//组装数据
	rst := make([]vmmodel.OverViewLineNew, 0, 4)

	name := param.Name
	for i := 0; i < len(name); i++ {
		switch name[i] {
		case "cpu":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			rr.Info.UnitType = ""

			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlCpuRate", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "mem": // 内存使用率
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			rr.Info.UnitType = ""

			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlMemRate", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "iops":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "次/秒"}
			// iops 读
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i] + "_read"
			rr.Info.Unit = "次/秒"
			rr.Info.UnitType = "count"
			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlIopsRead", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			// iops 写
			ww := vmmodel.EchartTypeNew{}
			ww.Info.Name = name[i] + "_wright"
			ww.Info.Unit = "次/秒"
			ww.Info.UnitType = "count"
			values = getMetricTopValuesFromRedis(redisKeyList, "MysqlIopsWrite", ctx, topK)
			ww.Values = values
			r.Echarts = append(r.Echarts, ww)

			rst = append(rst, r)
		case "link":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "个"}
			// Running 当前活跃连接数
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i] + "_running"
			rr.Info.Unit = "个"
			rr.Info.UnitType = "count"
			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlLinkRunning", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			// Connected 当前连接数
			rc := vmmodel.EchartTypeNew{}
			rc.Info.Name = name[i] + "_connected"
			rc.Info.Unit = "个"
			rc.Info.UnitType = "count"
			values = getMetricTopValuesFromRedis(redisKeyList, "MysqlLinkConnected", ctx, topK)
			rc.Values = values
			r.Echarts = append(r.Echarts, rc)

			rst = append(rst, r)
		case "input": // todo 网络输入吞吐量
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "Kbps"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "Kbps"
			rr.Info.UnitType = "count"
			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlBytesReceived", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)

			rst = append(rst, r)
		case "output": // todo 网络输出吞吐量
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "Kbps"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "Kbps"
			rr.Info.UnitType = "count"
			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlBytesSent", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)

			rst = append(rst, r)
		case "ops": // qps
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "次/秒"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "次/秒"
			rr.Info.UnitType = "count"
			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlOps", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)

			rst = append(rst, r)
		case "tps": // tps
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "次/秒"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "次/秒"
			rr.Info.UnitType = "count"
			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlTps", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)

			rst = append(rst, r)
		}
	}
	cloudproduct.AddRankOrder(rst) // 为双柱的Echarts设置排序
	return rst, nil
}

// 监控概览top
func (s *MysqlService) GetOverviewTop(param *mysql.TopQuery) (res []mysql.OverViewLine, err error) {

	klog.Info("Cloud_Mysql_GetOverviewTop")

	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	var nameStr string
	for _, v := range param.Name {
		nameStr += v + "_"
	}
	key := "mysql_overviewTop"
	fieldKey := "name_" + nameStr + "topk_" + param.TopK + "_interval_" + intervalStr + "_region" + param.Region + "_Az" + param.Az
	klog.Infof("load OverviewTop key:%s fieldKey: %s", key, fieldKey)

	redisCon := config.RedisConfig

	var rdb *redisLink.Client
	rdb = redisLink.NewClient(&redisLink.Options{
		Addr:       redisCon["Host"].(string),
		Password:   redisCon["Password"].(string),
		DB:         redisCon["Db"].(int),
		MaxRetries: redisCon["MaxRetries"].(int),
	})
	cache, err := utils.NewRedisCache(rdb, key)
	if err != nil {
		klog.Error("get utils.NewRedisCache failed", err)
		return
	}
	result, err := rdb.Ping(context.Background()).Result()
	if err != nil {
		klog.Error("Ping redis failed", err)
		return
	}

	klog.Infof("result %s", result)
	after := time.After(time.Second * 60)

	for {
		select {
		case <-time.After(time.Second):
			data, err := cache.GetData(context.Background(), fieldKey, GetMysqlTop(param), time.Minute*10)
			if err != nil {
				klog.Error("mysql GetData err ", err)
			}
			if data == "" {
				continue
			}
			var list []mysql.OverViewLine
			ee := json.Unmarshal([]byte(data), &list)
			if ee != nil {
				klog.Error("Parsing JSON failed", ee)
			}
			return list, nil
		case <-after:
			return
		}
	}

	return res, nil
}

func GetMysqlTop(param *mysql.TopQuery) func() (data string, err error) {

	return func() (data string, err error) {

		start := strconv.FormatFloat(param.Start/1000, 'f', 3, 64)
		end := strconv.FormatFloat(param.End/1000, 'f', 3, 64)
		topk, _ := strconv.Atoi(param.TopK)
		fmt.Println("start", start, "end", end, "topk", topk)

		//获取mysql资源池列表
		dbType := []string{"mysql"}
		total, _ := dbmsmanager.GetDBResourcePoolList(param.Region, "", dbType, "", "", 1, 1)
		totalCnt := int(total.Data.Total)
		klog.Infof("totalCnt %d", totalCnt)
		if totalCnt == 0 {
			res, _ := json.Marshal([]mysql.OverViewLine{})
			return string(res), nil
		}
		dbmsResult, err := dbmsmanager.GetDBResourcePoolList(param.Region, "", dbType, "", "", 1, totalCnt)
		if err != nil || dbmsResult.Data.Total == 0 {
			klog.Errorf("Failed to get database list", err)
			res, _ := json.Marshal([]mysql.OverViewLine{})
			return string(res), nil
		}

		// 获取资源池下数据库列表
		mysqlIds := []vmmodel.CmdbTopVm{}
		for i := 0; i < len(dbmsResult.Data.Data); i++ {
			poolInfo := dbmsResult.Data.Data[i]
			instanceCountParam := dbmsmanager.QueryInstanceList{
				ID:       poolInfo.ID,
				PageNo:   1,
				PageSize: 1,
			}
			instanceTotal, _ := dbmsmanager.GetDBInstanceList(instanceCountParam) // 获取数据库总数
			instanceTotalCnt := instanceTotal.Data.Total
			klog.Infof("instanceTotalCnt %d", instanceTotalCnt)

			if instanceTotalCnt == 0 {
				continue
			}
			instanceParam := dbmsmanager.QueryInstanceList{
				ID:       poolInfo.ID,
				PageNo:   1,
				PageSize: instanceTotalCnt,
			}
			instance, _ := dbmsmanager.GetDBInstanceList(instanceParam) // 获取数据列表

			if instance.Data.Total == 0 {
				continue
			}

			for j := 0; j < len(instance.Data.Data); j++ {
				instanceInfo := instance.Data.Data[j]
				mysqlIds = append(mysqlIds, vmmodel.CmdbTopVm{
					ID:   "kscrds--" + instanceInfo.ID,
					Name: instanceInfo.Name,
				})
			}
		}
		count := len(mysqlIds)
		if count == 0 {
			res, _ := json.Marshal([]mysql.OverViewLine{})
			return string(res), nil
		}

		rst := make([]mysql.OverViewLine, 0, 4)
		monitor := param.Name
		for n := 0; n < len(monitor); n++ {
			switch monitor[n] {
			case "cpu": // cpu使用率
				result := mysql.OverViewLine{Name: monitor[n], Unit: "%"}
				echarts := mysql.EchartType{}
				echarts.Info.Name = monitor[n]
				echarts.Info.Unit = "%"
				echarts.Info.UnitType = "percent"
				for j := 0; j < count; j++ {
					metrics := []string{"MysqlCpuRate"}
					tsdbList := kts.QueryVmMetric(mysqlIds[j].ID, start, end, metrics)
					if len(tsdbList) > 0 {
						mysqlIds[j].Name = mysqlIds[j].Name
						mysqlIds[j].Value = tsdbList[0].Avg
					}
				}
				out := vm.ValueOrder(mysqlIds, "desc")
				if len(out) >= topk {
					out = out[:topk]
				}
				for o := 0; o < len(out); o++ {
					valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
					v := mysql.ValueType{Value: services.FormPercent(valueFloat / 1e2), Name: out[o].Name, VmId: out[o].ID}
					echarts.Values = append(echarts.Values, v)
				}
				result.Echarts = append(result.Echarts, echarts)
				rst = append(rst, result)
			case "mem": // 内存使用率
				result := mysql.OverViewLine{Name: monitor[n], Unit: "%"}
				echarts := mysql.EchartType{}
				echarts.Info.Name = monitor[n]
				echarts.Info.Unit = "%"
				echarts.Info.UnitType = "percent"
				for j := 0; j < count; j++ {
					metrics := []string{"MysqlMemRate"}
					tsdbList := kts.QueryVmMetric(mysqlIds[j].ID, start, end, metrics)
					if len(tsdbList) > 0 {
						mysqlIds[j].Name = mysqlIds[j].Name
						mysqlIds[j].Value = tsdbList[0].Avg
					}
				}
				out := vm.ValueOrder(mysqlIds, "desc")
				if len(out) >= topk {
					out = out[:topk]
				}
				for o := 0; o < len(out); o++ {
					valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
					v := mysql.ValueType{Value: services.FormPercent(valueFloat / 1e2), Name: out[o].Name, VmId: out[o].ID}
					echarts.Values = append(echarts.Values, v)
				}
				result.Echarts = append(result.Echarts, echarts)
				rst = append(rst, result)
			case "iops": //iops
				//Read
				result := mysql.OverViewLine{Name: monitor[n], Unit: "%"}
				readEcharts := mysql.EchartType{}
				readEcharts.Info.Name = monitor[n] + "Read"
				readEcharts.Info.Unit = "次/秒"
				readEcharts.Info.UnitType = "Times/second"
				for j := 0; j < count; j++ {
					cpuLoad := []string{"MysqlIopsRead"}
					oo := kts.QueryVmMetric(mysqlIds[j].ID, start, end, cpuLoad)
					if len(oo) > 0 {
						mysqlIds[j].Value = oo[0].Avg
					}
				}
				readOut := vm.ValueOrder(mysqlIds, "desc")
				if len(readOut) >= topk {
					readOut = readOut[:topk]
				}
				for o := 0; o < len(readOut); o++ {
					valueFloat, _ := strconv.ParseFloat(services.Strval(readOut[o].Value), 64)
					v := mysql.ValueType{Value: valueFloat, SubName: readOut[o].Name, Name: services.GenerateTopK(o + 1), VmId: readOut[o].ID}
					readEcharts.Values = append(readEcharts.Values, v)
				}
				//Write
				result.Echarts = append(result.Echarts, readEcharts)
				writeEcharts := mysql.EchartType{}
				writeEcharts.Info.Name = monitor[n] + "Write"
				writeEcharts.Info.Unit = "次/秒"
				writeEcharts.Info.UnitType = "Times/second"
				for j1 := 0; j1 < count; j1++ {
					cpuLoad := []string{"MysqlIopsWrite"}
					oo := kts.QueryVmMetric(mysqlIds[j1].ID, start, end, cpuLoad)
					if len(oo) > 0 {
						mysqlIds[j1].Value = oo[0].Avg
					}
				}
				writeOut := vm.ValueOrder(mysqlIds, "desc")
				if len(writeOut) >= topk {
					writeOut = writeOut[:topk]
				}
				for o := 0; o < len(writeOut); o++ {
					valueFloat, _ := strconv.ParseFloat(services.Strval(writeOut[o].Value), 64)
					//services.GenerateTopK(o + 1)
					v := mysql.ValueType{Value: valueFloat, SubName: writeOut[o].Name, Name: services.GenerateTopK(o + 1), VmId: writeOut[o].ID}
					writeEcharts.Values = append(writeEcharts.Values, v)
				}
				result.Echarts = append(result.Echarts, writeEcharts)
				rst = append(rst, result)

			case "link": // 链接数
				//Running 当前活跃连接数
				result := mysql.OverViewLine{Name: monitor[n], Unit: "个"}
				readEcharts := mysql.EchartType{}
				readEcharts.Info.Name = monitor[n] + "Running"
				readEcharts.Info.Unit = "个"
				readEcharts.Info.UnitType = "individual"
				for j := 0; j < count; j++ {
					metrics := []string{"MysqlLinkRunning"}
					oo := kts.QueryVmMetric(mysqlIds[j].ID, start, end, metrics)
					if len(oo) > 0 {
						mysqlIds[j].Value = oo[0].Avg
					}
				}
				runningOut := vm.ValueOrder(mysqlIds, "desc")
				if len(runningOut) >= topk {
					runningOut = runningOut[:topk]
				}
				for o := 0; o < len(runningOut); o++ {
					valueFloat, _ := strconv.ParseFloat(services.Strval(runningOut[o].Value), 64)
					v := mysql.ValueType{Value: valueFloat, SubName: runningOut[o].Name, Name: services.GenerateTopK(o + 1), VmId: runningOut[o].ID}
					readEcharts.Values = append(readEcharts.Values, v)
				}

				// Connected 当前连接数
				result.Echarts = append(result.Echarts, readEcharts)
				writeEcharts := mysql.EchartType{}
				writeEcharts.Info.Name = monitor[n] + "Connected"
				writeEcharts.Info.Unit = "个"
				writeEcharts.Info.UnitType = "individual"
				for j1 := 0; j1 < count; j1++ {
					metrics := []string{"MysqlLinkConnected"}
					oo := kts.QueryVmMetric(mysqlIds[j1].ID, start, end, metrics)
					if len(oo) > 0 {
						mysqlIds[j1].Value = oo[0].Avg
					}
				}
				connectedOut := vm.ValueOrder(mysqlIds, "desc")
				if len(connectedOut) >= topk {
					connectedOut = connectedOut[:topk]
				}
				for o := 0; o < len(connectedOut); o++ {
					valueFloat, _ := strconv.ParseFloat(services.Strval(connectedOut[o].Value), 64)
					v := mysql.ValueType{Value: valueFloat, SubName: connectedOut[o].Name, Name: services.GenerateTopK(o + 1), VmId: connectedOut[o].ID}
					writeEcharts.Values = append(writeEcharts.Values, v)
				}
				result.Echarts = append(result.Echarts, writeEcharts)
				rst = append(rst, result)
			case "input": //todo 网络输入吞吐量
				//monitor[n]
				result := mysql.OverViewLine{Name: "网络输入吞吐量", Unit: "%"}
				echarts := mysql.EchartType{}
				echarts.Info.Name = monitor[n]
				echarts.Info.Unit = "kbps"
				echarts.Info.UnitType = "kbps"
				for j := 0; j < count; j++ {
					metrics := []string{"MysqlBytesreceived"}
					tsdbList := kts.QueryVmMetric(mysqlIds[j].ID, start, end, metrics)
					if len(tsdbList) > 0 {
						mysqlIds[j].Name = mysqlIds[j].Name
						mysqlIds[j].Value = tsdbList[0].Avg
					}
				}
				out := vm.ValueOrder(mysqlIds, "desc")
				if len(out) >= topk {
					out = out[:topk]
				}
				for o := 0; o < len(out); o++ {
					valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
					v := mysql.ValueType{Value: services.FormPercent(valueFloat / 1e2), Name: out[o].Name, VmId: out[o].ID}
					echarts.Values = append(echarts.Values, v)
				}
				result.Echarts = append(result.Echarts, echarts)
				rst = append(rst, result)

			case "output": //todo 网络输出吞吐量

				result := mysql.OverViewLine{Name: "网络输出吞吐量", Unit: "%"}
				echarts := mysql.EchartType{}
				echarts.Info.Name = monitor[n]
				echarts.Info.Unit = "kbps"
				echarts.Info.UnitType = "kbps"
				for j := 0; j < count; j++ {
					metrics := []string{"MysqlBytesSent"}
					tsdbList := kts.QueryVmMetric(mysqlIds[j].ID, start, end, metrics)
					if len(tsdbList) > 0 {
						mysqlIds[j].Name = mysqlIds[j].Name
						mysqlIds[j].Value = tsdbList[0].Avg
					}
				}
				out := vm.ValueOrder(mysqlIds, "desc")
				if len(out) >= topk {
					out = out[:topk]
				}
				for o := 0; o < len(out); o++ {
					valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
					v := mysql.ValueType{Value: services.FormPercent(valueFloat / 1e2), Name: out[o].Name, VmId: out[o].ID}
					echarts.Values = append(echarts.Values, v)
				}
				result.Echarts = append(result.Echarts, echarts)
				rst = append(rst, result)

			case "ops": // ops
				result := mysql.OverViewLine{Name: monitor[n], Unit: "%"}
				echarts := mysql.EchartType{}
				echarts.Info.Name = monitor[n]
				echarts.Info.Unit = "次/秒"
				echarts.Info.UnitType = "times/second"
				for j := 0; j < count; j++ {
					metrics := []string{"MysqlOps"}
					tsdbList := kts.QueryVmMetric(mysqlIds[j].ID, start, end, metrics)
					if len(tsdbList) > 0 {
						mysqlIds[j].Name = mysqlIds[j].Name
						mysqlIds[j].Value = tsdbList[0].Avg
					}
				}
				out := vm.ValueOrder(mysqlIds, "desc")
				if len(out) >= topk {
					out = out[:topk]
				}
				for o := 0; o < len(out); o++ {
					valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
					v := mysql.ValueType{Value: services.FormPercent(valueFloat / 1e2), Name: out[o].Name, VmId: out[o].ID}
					echarts.Values = append(echarts.Values, v)
				}
				result.Echarts = append(result.Echarts, echarts)
				rst = append(rst, result)

			case "tps": // tps
				result := mysql.OverViewLine{Name: monitor[n], Unit: "%"}
				echarts := mysql.EchartType{}
				echarts.Info.Name = monitor[n]
				echarts.Info.Unit = "次/秒"
				echarts.Info.UnitType = "times/second"
				for j := 0; j < count; j++ {
					metrics := []string{"MysqlTps"}
					tsdbList := kts.QueryVmMetric(mysqlIds[j].ID, start, end, metrics)
					if len(tsdbList) > 0 {
						mysqlIds[j].Name = mysqlIds[j].Name
						mysqlIds[j].Value = tsdbList[0].Avg
					}
				}
				out := vm.ValueOrder(mysqlIds, "desc")
				if len(out) >= topk {
					out = out[:topk]
				}
				for o := 0; o < len(out); o++ {
					valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
					v := mysql.ValueType{Value: services.FormPercent(valueFloat / 1e2), Name: out[o].Name, VmId: out[o].ID}
					echarts.Values = append(echarts.Values, v)
				}
				result.Echarts = append(result.Echarts, echarts)
				rst = append(rst, result)
			}
		}
		res, _ := json.Marshal(rst)
		return string(res), nil
	}
}

func (s *MysqlService) OverviewTopKey(param *mysql.TopQuery) ([]vmmodel.OverViewLineNew, error) {
	ctx, cefl := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cefl()

	//获取时间间隔
	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	topK, _ := strconv.ParseInt(param.TopK, 10, 64)

	//获取redis集合Key
	param1 := cloudproduct.GetResourceRedisKeyParam{
		ResourceType: config.CloudMysqlResource,
		Region:       param.Region,
		Az:           param.Az,
		IntervalStr:  intervalStr,
	}
	redisKeyList, err := cloudproduct.GetResourceRedisKeyList(&param1)
	if err != nil {
		return []vmmodel.OverViewLineNew{}, err
	}
	klog.Infof("redisKeyList %+v", redisKeyList)

	//组装数据
	rst := make([]vmmodel.OverViewLineNew, 0)
	name := param.Name
	for i := 0; i < len(name); i++ {
		switch name[i] {
		case "cpu":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			rr.Info.UnitType = "percent"

			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlCpuRate", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "mem": // 内存使用率
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			rr.Info.UnitType = "percent"

			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlMemRate", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "iopsRead": // 每秒io输出量
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			rr.Info.UnitType = "percent"

			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlIopsRead", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "iopsWrite": // 每秒io输入量
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			rr.Info.UnitType = "percent"

			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlIopsWrite", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "linkRunning": // 当前活跃连接数
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			rr.Info.UnitType = "percent"

			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlLinkRunning", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "linkConnected": // 当前连接数
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "%"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			rr.Info.UnitType = "percent"

			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlLinkConnected", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "bytesReceived": // 网络输入吞吐量
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "个"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "个"
			rr.Info.UnitType = "count"

			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlBytesReceived", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "bytesSent": // 网络输出吞吐量
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "个"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "个"
			rr.Info.UnitType = "count"

			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlBytesSent", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "ops": // MysqlQps
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "个"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "个"
			rr.Info.UnitType = "count"

			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlOps", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "tps": // MysqlTps
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "个"}
			rr := vmmodel.EchartTypeNew{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "个"
			rr.Info.UnitType = "count"

			values := getMetricTopValuesFromRedis(redisKeyList, "MysqlTps", ctx, topK)
			rr.Values = values
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		}
	}
	cloudproduct.AddRankOrder(rst)
	return rst, nil
}

func getMetricTopValuesFromRedis(redisKeyList map[string][]string, metricKey string, ctx context.Context, topK int64) []vmmodel.VmValueType {
	var list []vmmodel.VmValueType
	metricKeys := redisKeyList[metricKey] //获取当前metric Key

	//根据key循环获取集合数据
	for _, key := range metricKeys {
		//获取集合数据
		mysqlListStr, _ := client2.ZRevRange(ctx, key, 0, topK-1)
		var mysqlList = make([]vmmodel.VmValueType, len(mysqlListStr))
		//解析成json
		vmSliceStr := "[" + strings.Join(mysqlListStr, ",") + "]"
		err := json.Unmarshal([]byte(vmSliceStr), &mysqlList)
		if err != nil {
			klog.Errorf("err ", err)
		}
		if len(mysqlList) == 0 {
			continue
		}
		list = append(list, mysqlList...)
	}

	count := len(list)
	//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
	if int64(count) > topK {
		//排序
		list = cloudproduct.VmValueOrder(list, "desc")
		if int64(len(list)) >= topK {
			list = list[:topK]
		}
	}
	return list
}

// 监控指标
func (s *MysqlService) GetBlockMetricLine(param *mysql.MetricQuery) ([]mysql.MysqlOverViewLine, error) {

	klog.Info("Cloud_Mysql_GetBlockMetricLine")
	start := strconv.FormatFloat(param.Start/1000, 'f', 3, 64)
	end := strconv.FormatFloat(param.End/1000, 'f', 3, 64)
	fmt.Println("start", start, "end", end)

	//todo 连接数据库
	//db := services.MakeMysqlYunyanClient()
	//defer db.Close()
	//
	//rows, err := db.Query("select id from vnis where id = '001c7d5d-06fe-406a-8e0a-68a1773b796a'")
	//if err != nil {
	//	fmt.Println("fetech data failed:", err.Error())
	//	return
	//}
	//defer rows.Close()
	//for rows.Next() {
	//	var id string
	//	errrr :=rows.Scan(&id)
	//	fmt.Println("errrr",errrr)
	//	fmt.Println("id:", id)
	//}
	klog.Info(param.IndexType)
	var metricInfoList []mysql.MetricInfoType
	if param.IndexType != "" && param.Name == "" { // 分类下全部
		indexType := mysqltemp.MysqlMonitorIndexMaps[param.IndexType]
		indexList := indexType.List
		for _, v := range indexList {
			namrs := mysqltemp.MysqlMonitorIndexMap[v]
			if namrs == nil {
				klog.Info("The corresponding template was not obtained")
				continue
			}
			metricInfo := mysql.MetricInfoType{
				Metric:      namrs.Metric,
				Name:        namrs.Name,
				Unit:        namrs.Unit,
				UnitType:    namrs.UnitType,
				Copywriting: namrs.Copywriting,
			}
			metricInfoList = append(metricInfoList, metricInfo)

		}
	} else if param.Name != "" { // 分类下某个
		namrs := mysqltemp.MysqlMonitorIndexMap[param.Name]
		metricInfo := mysql.MetricInfoType{
			Metric:      namrs.Metric,
			Name:        namrs.Name,
			Unit:        namrs.Unit,
			UnitType:    namrs.UnitType,
			Copywriting: namrs.Copywriting,
		}
		metricInfoList = append(metricInfoList, metricInfo)
	}
	result := []mysql.MysqlOverViewLine{}
	for _, value := range metricInfoList {
		res := mysql.MysqlOverViewLine{Name: value.Name, Unit: value.Unit, UnitType: value.UnitType, Copywriting: value.Copywriting}

		tsdbList := kts.QueryVmMetriLine("kscrds--"+param.Id, start, end, value.Metric)
		for i := 0; i < len(tsdbList); i++ {
			echart := mysql.MysqlEchartType{}
			echart.Info.Name = tsdbList[i].Name.(string)
			echart.Info.Unit = value.Unit
			echart.Info.UnitType = value.UnitType
			if tsdbList[i].Value != nil {
				echart.Values = services.PromeForRangeValueForms(tsdbList[i].Value)
			}
			res.Echarts = append(res.Echarts, echart)
		}

		result = append(result, res)
	}

	return result, nil
}

type Catalogue struct {
	LogsClass string `json:"logs_class"` // 日志分类
	TenantId  string `json:"tenant_id"`  // 租户ID
	DateTime  string `json:"date_time"`  // 日期
	GroupId   string `json:"group_id"`   // 分组ID
	GuestId   string `json:"guest_id"`   // GuestId
}

func GetRdsList(BucketName, Prefix, Marker string, MaxKeys int64) []s3.Object {

	resp, _ := client2.ListObjects(BucketName, Prefix, Marker, MaxKeys)

	var contents = []s3.Object{}

	for i := 0; i < len(resp.Contents); i++ {
		jj := resp.Contents[i]

		if strings.Contains(*jj.Key, ".gz") {
			contents = append(contents, *jj)
		}

		if *resp.IsTruncated == true && i == len(resp.Contents)-1 {
			rdsLogList := GetRdsList(BucketName, Prefix, *jj.Key, MaxKeys)
			contents = append(contents, rdsLogList...)
		}
	}

	return contents
}

// 日志列表
func (s *MysqlService) GetBlockMetricLogsList(param *mysql.LogsListMetricQuery) (mysql.LogsListSuccess, error) {
	start := param.Start
	end := param.End

	var redisKey string
	if param.DbLogType == "ErrorLog" { // 错误日志
		redisKey = client2.DbmsRdsLogsErrlog
	} else if param.DbLogType == "SlowLog" { // 慢日志
		redisKey = client2.DbmsRdsLogsSlowQuery
	} else {
		redisKey = client2.DbmsRdsLogsBinlog // binlog
	}

	ctx, cefl := context.WithTimeout(context.Background(), 3*time.Minute)
	defer cefl()
	rst := HGetRdsLogListRedis(ctx, redisKey, param.ID)

	klog.Infof("log num", len(rst))

	if len(rst) == 0 {
		return mysql.LogsListSuccess{}, nil
	}

	list := []mysql.LogsListData{}

	for _, v := range rst {
		//if (start != 0 && end != 0)&& (float64(v.FileCreateTime) >= start)&&(float64(v.Created) <= end){}
		info := mysql.LogsListData{}

		var stateTime string
		var endTime string
		var stateobj time.Time
		if param.DbLogType == "ErrorLog" || param.DbLogType == "SlowLog" {
			//时间范围筛选 开始结束时间不为空 创建时间小于开始时间
			if (start != 0 && end != 0) && ((float64(v.FileCreateTime) < start) || (float64(v.Created) > end)) {
				continue
			}
			stateobj = time.Unix(v.FileCreateTime/1000, 0)
			stateTime = stateobj.Format("2006-01-02 15:04:05")
			endobj := time.Unix(v.Created/1000, 0)
			endTime = endobj.Format("2006-01-02 15:04:05")
		} else {
			if (start != 0 && end != 0) && ((float64(v.FistEventTime) < start) || (float64(v.LastEventTime) > end)) {
				continue
			}
			stateobj = time.Unix(v.FistEventTime/1000, 0)
			stateTime = stateobj.Format("2006-01-02 15:04:05")
			endobj := time.Unix(v.LastEventTime/1000, 0)
			endTime = endobj.Format("2006-01-02 15:04:05")
		}

		info.ID = v.InstanceID
		info.Name = param.Name
		info.LogFileName = v.LogURL
		info.StartTime = stateTime
		info.EndTime = endTime
		info.Size = services.FormatFileSize(int64(v.Size))
		info.TimeStr = stateobj.Format("2006010215")

		list = append(list, info)
	}

	rst1 := mysql.LogsListSuccess{}

	low := (param.PageNo - 1) * param.PageSize
	if low > len(list) {
		return rst1, nil
	}
	hight := low + param.PageSize
	if hight > len(list) {
		hight = len(list)
	}
	rst1.PageNo = param.PageNo
	rst1.PageSize = param.PageSize
	rst1.TotalCount = len(list)
	rst1.Data = list[low:hight]

	for kk, vv := range rst1.Data {
		fileName := param.Name + "_" + param.DbLogType + "_" + vv.TimeStr + ".log.gz"

		if param.DbLogType == "BinLog" {
			position := strings.Index(vv.LogFileName, ".")
			suffix := vv.LogFileName[position:]
			fileName = param.Name + "_" + param.DbLogType + "_" + vv.TimeStr + suffix
		}
		rst1.Data[kk].LogFileName = client2.GetObjectInput(vv.LogFileName, fileName)
	}

	return rst1, nil
}

func HGetRdsLogListRedis(ctx context.Context, k, field string) []mysql.LogsList {

	var res []mysql.LogsList
	rs, err := client2.HGet(ctx, k, field)

	if err == redis.Nil {
		return res
		klog.Error("gredis.HGet Unmarshal failure:", err.Error())
	}
	if err != nil {
		klog.Error("gredis.HGet read from redis failure:", err.Error())
	}
	err = json.Unmarshal([]byte(rs), &res)
	if err != nil {
		klog.Error("gredis.HGet Unmarshal failure:", err.Error())
	}
	return res
}

// 日志下载
func (s *MysqlService) GetBlockMetricLogs(param *mysql.MetricQuery) ([]byte, error) {
	//client2.GetObjectInput()
	//res := client2.GetObject()
	return []byte{}, nil
}

func (s *MysqlService) GetItems(region, dbType, poolId string) (mysql.Filter, error) {
	filters := mysql.Filter{}
	filters.Tenant = make([]map[string]string, 0)
	filters.ResourcePool = make([]map[string]string, 0)
	tenantMap := make(map[string]string)
	poolMap := make(map[string]string)

	instanceList, err := getMysqlInstanceList(region, dbType, poolId)
	if err != nil {
		klog.Error(err)
		return filters, nil
	}
	for _, inst := range instanceList {
		if _, ok := tenantMap[inst.TenantId]; !ok {
			tenantMap[inst.TenantId] = inst.TenantName
			filters.Tenant = append(filters.Tenant, map[string]string{"tenantId": inst.TenantId, "tenantName": inst.TenantName})
		}
		if _, ok := poolMap[inst.PoolId]; !ok {
			poolMap[inst.PoolId] = inst.PoolName
			filters.ResourcePool = append(filters.ResourcePool, map[string]string{"poolId": inst.PoolId, "poolName": inst.PoolName})
		}
	}
	return filters, nil
}

func GetAlertNum(region string) string {
	queryParam := alertmodel.AlertQuery{
		Filter: "",
	}

	if region != "" && region != "all" {
		queryParam.Filter = queryParam.Filter + "&filter=region=%22" + region + "%22"
	}
	queryParam.ResourceTypeCode = []string{"resourcePool"}
	queryParam.ResourceSubTypeCode = []string{"ks3"}
	res, err := alert.GetAlertsDataListPage(queryParam)
	if err != nil {
		return ""
	}
	return strconv.Itoa(len(res.DataList))
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cloudproduct/block/block.go
```golang
package block

import (
	"bytes"
	"context"
	"encoding/json"
	"io"
	"io/ioutil"
	"net/http"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"time"

	"github.com/go-redis/redis/v8"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"

	"github.com/pkg/errors"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/block"
	blockmodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/block"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	kts "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/ktsmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/physicalSwitch"
	"k8s.io/klog/v2"
)

type IBlockService interface {
	GetBlockMetric(string) ([]block.MetricInfo, error)
	GetBlockMetricLine(string, *block.MetricQuery) ([]block.MetricLineType, error)
	//GetServerHardwareMetric(string) (servermodels.HardWare, error)
	//GetSwitchMetricLine(*switchmodels.SwitchMetricLineQuery) (map[string][]switchmodels.EchartType, error)
	//GetVmOverview(*resourcepoolmodel.ObjectOverviewLineQuery) (resourcepoolmodel.ObjectOverView, error)
	GetBlockOverviewTopK(*block.TopQuery) ([]block.OverViewLine, error)
	GetBlockOverviewTop(*block.TopQuery) ([]block.OverViewLine, error)
	GetBlockList(*block.ListQuery) (block.MonitorBlocks, error)
	//GetObjectPoolUsageList(*resourcepoolmodel.ObjectStorageUsageQuery) (resourcepoolmodel.ObjectStoragePoolUsageResult, error)
	GetBlockTopNew(*blockmodels.BlockOverviewLineQuery) ([]blockmodels.OverviewLineData, error)
}

type BlockService struct {
}

func NewBlockService() *BlockService {
	return &BlockService{}
}

type commonPageQuery struct {
	PageNo     int      `json:"pageNo,omitempty"`
	PageSize   int      `json:"pageSize,omitempty"`
	AzCode     []string `json:"az,omitempty"`
	RegionCode string   `json:"region,omitempty"`
}

type cloudDiskListQueryParameter struct {
	PageNo     int      `json:"pageNo,omitempty"`
	PageSize   int      `json:"pageSize,omitempty"`
	AzCode     []string `json:"az,omitempty"`
	RegionCode string   `json:"region,omitempty"`
	DiskType   []string `json:"diskType,omitempty"`
}

var UseStatusMap = map[string]string{
	"creating":        "创建中",
	"available":       "待挂载",
	"attaching":       "挂载中",
	"in-use":          "使用中",
	"detaching":       "卸载中",
	"extending":       "扩容中",
	"deleting":        "删除中",
	"error":           "错误",
	"error_attaching": "挂载失败",
	"error_detaching": "卸载失败",
	"error_deleting":  "删除失败",
	"error_extending": "扩容失败",
	"deleted":         "已删除",
	"recycling":       "回收中",
	"rollbacking":     "回滚中",
}

func (s *BlockService) GetBlockTopNew(param *blockmodels.BlockOverviewLineQuery) ([]blockmodels.OverviewLineData, error) {
	ctx, cefl := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cefl()

	//获取时间间隔
	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	topK, _ := strconv.ParseInt(param.TopK, 10, 64)

	//获取redis集合Key
	param1 := cloudproduct.GetResourceRedisKeyParam{
		ResourceType: config.CloudBlockResource,
		Region:       param.Region,
		Az:           param.Az,
		IntervalStr:  intervalStr,
	}
	if param.Region == "" {
		param1.Region = "cn-shanghai-2"
	}
	if param.Az == "" {
		param1.Az = "cn-shanghai-2a"
	}
	redisKeyList, err := cloudproduct.GetResourceRedisKeyList(&param1)
	if err != nil {
		return []blockmodels.OverviewLineData{}, err
	}
	klog.Infof("redisKeyList %+v", redisKeyList)

	rst := make([]blockmodels.OverviewLineData, 0, 4)
	name := param.Name
	for i := 0; i < len(name); i++ {
		switch name[i] {
		case "band":
			r := blockmodels.OverviewLineData{Name: name[i], Unit: "bps"}
			rr := blockmodels.BlockEchart{}
			rr.Info.Name = "读带宽"
			rr.Info.Unit = "bps"
			rr.Info.UnitType = "storage"
			var blockOutBandLit []services.BlockValueType
			vmCpuKeys := redisKeyList["BwOutAvg"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmCpuKeys {
				//获取集合数据
				blockListStr, _ := client.ZRevRange(ctx, key, 0, 50)
				var vmlist = make([]services.BlockValueType, len(blockListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(blockListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				filterList := make([]services.BlockValueType, 0)
				k := 0
				for _, v := range vmlist {
					if v.ResourceType == param.DiskType {
						v.SubName = v.Name
						k += 1
						v.Name = "top" + strconv.Itoa(k)
						filterList = append(filterList, v)
					}
					if k == int(topK) {
						break
					}
				}
				vmlist = filterList
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				blockOutBandLit = append(blockOutBandLit, vmlist...)
			}

			blockOutBandCont := len(blockOutBandLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(blockOutBandCont) > topK {
				//排序
				blockOutBandLit = physicalSwitch.BlockInterfaceValueOrder(blockOutBandLit, "desc")
				if int64(len(blockOutBandLit)) >= topK {
					blockOutBandLit = blockOutBandLit[:topK]
				}
			}
			rr.Values = blockOutBandLit
			r.Echarts = append(r.Echarts, rr)
			// write
			rr1 := blockmodels.BlockEchart{}
			rr1.Info.Name = "写带宽"
			rr1.Info.Unit = "bps"
			rr1.Info.UnitType = "storage"
			var blockInBandLit []services.BlockValueType
			bandInKeys := redisKeyList["BwInAvg"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range bandInKeys {
				//获取集合数据
				blockListStr, _ := client.ZRevRange(ctx, key, 0, 50)
				var vmlist = make([]services.BlockValueType, len(blockListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(blockListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				filterList := make([]services.BlockValueType, 0)
				k := 0
				for _, v := range vmlist {
					if v.ResourceType == param.DiskType {
						v.SubName = v.Name
						k += 1
						v.Name = "top" + strconv.Itoa(k)
						filterList = append(filterList, v)
					}
					if k == int(topK) {
						break
					}
				}
				vmlist = filterList
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				blockInBandLit = append(blockInBandLit, vmlist...)
			}

			blockInBandCont := len(blockInBandLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(blockInBandCont) > topK {
				//排序
				blockInBandLit = physicalSwitch.BlockInterfaceValueOrder(blockInBandLit, "desc")
				if int64(len(blockInBandLit)) >= topK {
					blockInBandLit = blockInBandLit[:topK]
				}
			}
			rr1.Values = blockInBandLit
			r.Echarts = append(r.Echarts, rr1)
			rst = append(rst, r)
		case "io":
			r := blockmodels.OverviewLineData{Name: name[i], Unit: "次"}
			rr := blockmodels.BlockEchart{}
			rr.Info.Name = "read"
			rr.Info.Unit = "次/秒"
			rr.Info.UnitType = "number"
			var blockOutBandLit []services.BlockValueType
			vmCpuKeys := redisKeyList["IOOut"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmCpuKeys {
				//获取集合数据
				blockListStr, _ := client.ZRevRange(ctx, key, 0, 50)
				var vmlist = make([]services.BlockValueType, len(blockListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(blockListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				filterList := make([]services.BlockValueType, 0)
				k := 0
				for _, v := range vmlist {
					if v.ResourceType == param.DiskType {
						v.SubName = v.Name
						k += 1
						v.Name = "top" + strconv.Itoa(k)
						filterList = append(filterList, v)
					}
					if k == int(topK) {
						break
					}
				}
				vmlist = filterList
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				blockOutBandLit = append(blockOutBandLit, vmlist...)
			}

			blockOutBandCont := len(blockOutBandLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(blockOutBandCont) > topK {
				//排序
				blockOutBandLit = physicalSwitch.BlockInterfaceValueOrder(blockOutBandLit, "desc")
				if int64(len(blockOutBandLit)) >= topK {
					blockOutBandLit = blockOutBandLit[:topK]
				}
			}
			rr.Values = blockOutBandLit
			r.Echarts = append(r.Echarts, rr)
			// write
			rr1 := blockmodels.BlockEchart{}
			rr1.Info.Name = "write"
			rr1.Info.Unit = "次/秒"
			rr1.Info.UnitType = "number"
			var blockInBandLit []services.BlockValueType
			bandInKeys := redisKeyList["IOIn"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range bandInKeys {
				//获取集合数据
				blockListStr, _ := client.ZRevRange(ctx, key, 0, 50)
				var vmlist = make([]services.BlockValueType, len(blockListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(blockListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				filterList := make([]services.BlockValueType, 0)
				k := 0
				for _, v := range vmlist {
					if v.ResourceType == param.DiskType {
						v.SubName = v.Name
						k += 1
						v.Name = "top" + strconv.Itoa(k)
						filterList = append(filterList, v)
					}
					if k == int(topK) {
						break
					}
				}
				vmlist = filterList
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				blockInBandLit = append(blockInBandLit, vmlist...)
			}

			blockInBandCont := len(blockInBandLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(blockInBandCont) > topK {
				//排序
				blockInBandLit = physicalSwitch.BlockInterfaceValueOrder(blockInBandLit, "desc")
				if int64(len(blockInBandLit)) >= topK {
					blockInBandLit = blockInBandLit[:topK]
				}
			}
			rr1.Values = blockInBandLit
			r.Echarts = append(r.Echarts, rr1)
			rst = append(rst, r)
		}

	}
	return rst, nil
}
func (s *BlockService) GetBlockOverviewTop(param *block.TopQuery) (rst []block.OverViewLine, err error) {

	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	var nameStr string
	for _, v := range param.Name {
		nameStr += v + "_"
	}

	key := "block_overviewTop"
	fieldKey := "name_" + nameStr + "topk_" + param.TopK + "_interval_" + intervalStr + "_region" + param.Region + "_Az" + param.Az
	klog.Infof("block OverviewTop fieldKey", fieldKey)

	redisCon := config.RedisConfig
	var rdb *redis.Client
	rdb = redis.NewClient(&redis.Options{
		Addr:       redisCon["Host"].(string),
		Password:   redisCon["Password"].(string),
		DB:         redisCon["Db"].(int),
		MaxRetries: redisCon["MaxRetries"].(int),
	})

	cache, err := utils.NewRedisCache(rdb, key)
	if err != nil {
		klog.Error("get utils.NewRedisCache failed", err)
		return
	}
	result, err := rdb.Ping(context.Background()).Result()
	if err != nil {
		klog.Error("Ping redis failed", err)
		return
	}

	klog.Infof("result %s", result)
	after := time.After(time.Second * 60)

	for {
		select {
		case <-time.After(time.Second):
			data, err := cache.GetData(context.Background(), fieldKey, GetBlockTop(param), time.Minute*10)
			if err != nil {
				klog.Error("block GetData err ", err)
			}
			if data == "" {
				continue
			}
			var list []block.OverViewLine
			ee := json.Unmarshal([]byte(data), &list)
			if ee != nil {
				klog.Error("Parsing JSON failed", ee)
			}

			klog.Infof("data:%s", list)
			return list, nil
		case <-after:
			return rst, nil
		}
	}

	return rst, nil

}

func GetBlockTop(param *block.TopQuery) func() (data string, err error) {
	klog.Info("GetblockTop")
	return func() (data string, err error) {
		start := strconv.FormatFloat(param.Start/1000, 'f', 3, 64)
		end := strconv.FormatFloat(param.End/1000, 'f', 3, 64)
		k, _ := strconv.Atoi(param.TopK)

		if param.Region == "" {
			param.Region = "all"
		}
		az := []string{}
		if param.Az == "all" || param.Az == "" {
			az = []string{}
		} else {
			az = append(az, param.Az)
		}

		diskType := []string{}
		if param.DiskType == "all" || param.DiskType == "" {
			diskType = []string{}
		} else {
			diskType = append(diskType, param.DiskType)
		}

		queryParam := cloudDiskListQueryParameter{
			PageNo:     1,
			PageSize:   10000,
			AzCode:     az,
			RegionCode: param.Region,
			DiskType:   diskType,
		}
		res, err := queryCloudDiskList(queryParam)

		if err != nil {
			klog.Error("Failed to get list:", err)
			//return []block.OverViewLine{}, nil
		}
		dataList := res.Data.DataList

		blockList := []block.CmdbTopBlock{}
		for _, v := range dataList {
			if v.VmId == "" {
				continue
			}
			blockInfo := block.CmdbTopBlock{}
			blockInfo.ID = v.VmId
			blockInfo.Name = v.Name
			blockList = append(blockList, blockInfo)
		}
		count := len(blockList)
		klog.Infof("count: %d", count)

		rst := make([]block.OverViewLine, 0, 2)

		m := param.Name
		for i := 0; i < len(m); i++ {
			switch m[i] {
			case "band": // 磁盘读写带宽
				r := block.OverViewLine{Name: m[i], Unit: "%"}

				read := block.Echart{}
				read.Info.Name = "read"
				read.Info.Unit = "Bps"
				read.Info.UnitType = "storage"

				for j := 0; j < count; j++ {
					block := blockList[j]
					oo := kts.QueryVmMetric(block.ID, start, end, []string{"BLockBpsRead"})
					if len(oo) > 0 {
						dataList[j].Value = oo[0].Avg
					}
				}
				readOut := ValueOrder(dataList, "desc")
				if len(readOut) >= k {
					readOut = readOut[:k]
				}
				for o := 0; o < len(readOut); o++ {
					aa, _ := strconv.ParseFloat(services.Strval(readOut[o].Value), 64)
					readV := services.ValueType{Value: aa, SubName: readOut[o].Name, Name: services.GenerateTopK(o + 1), Id: readOut[o].InstanceId}
					read.Values = append(read.Values, readV)
				}
				r.Echarts = append(r.Echarts, read)

				//write
				write := block.Echart{}
				write.Info.Name = "write"
				write.Info.Unit = "Bps"
				write.Info.UnitType = "storage"

				for j := 0; j < count; j++ {
					block := blockList[j]
					oo := kts.QueryVmMetric(block.ID, start, end, []string{"BLockBpsWrite"})
					if len(oo) > 0 {
						dataList[j].Value = oo[0].Avg
					}
				}
				writeOut := ValueOrder(dataList, "desc")
				if len(writeOut) >= k {
					writeOut = writeOut[:k]
				}
				for o := 0; o < len(writeOut); o++ {
					aa, _ := strconv.ParseFloat(services.Strval(writeOut[o].Value), 64)
					writeV := services.ValueType{Value: aa, SubName: writeOut[o].Name, Name: services.GenerateTopK(o + 1), Id: writeOut[o].InstanceId}
					write.Values = append(write.Values, writeV)
				}
				r.Echarts = append(r.Echarts, write)
				rst = append(rst, r)
			case "io": // 磁盘每秒读写次数
				r := block.OverViewLine{Name: m[i], Unit: "%"}

				read := block.Echart{}
				read.Info.Name = "read"
				read.Info.Unit = "Ops"
				read.Info.UnitType = "storage"

				for j := 0; j < count; j++ {
					block := blockList[j]
					oo := kts.QueryVmMetric(block.ID, start, end, []string{"BLockOpsRead"})
					if len(oo) > 0 {
						dataList[j].Value = oo[0].Avg
					}
				}
				readOut := ValueOrder(dataList, "desc")
				if len(readOut) >= k {
					readOut = readOut[:k]
				}
				for o := 0; o < len(readOut); o++ {
					aa, _ := strconv.ParseFloat(services.Strval(readOut[o].Value), 64)
					readV := services.ValueType{Value: aa, SubName: readOut[o].Name, Name: services.GenerateTopK(o + 1), Id: readOut[o].InstanceId}
					read.Values = append(read.Values, readV)
				}
				r.Echarts = append(r.Echarts, read)

				//write
				write := block.Echart{}
				write.Info.Name = "write"
				write.Info.Unit = "Ops"
				write.Info.UnitType = "storage"

				for j := 0; j < count; j++ {
					block := blockList[j]
					oo := kts.QueryVmMetric(block.ID, start, end, []string{"BLockOpsWrite"})
					if len(oo) > 0 {
						dataList[j].Value = oo[0].Avg
					}
				}
				writeOut := ValueOrder(dataList, "desc")
				if len(writeOut) >= k {
					writeOut = writeOut[:k]
				}
				for o := 0; o < len(writeOut); o++ {
					aa, _ := strconv.ParseFloat(services.Strval(writeOut[o].Value), 64)
					writeV := services.ValueType{Value: aa, SubName: writeOut[o].Name, Name: services.GenerateTopK(o + 1), Id: writeOut[o].InstanceId}
					write.Values = append(write.Values, writeV)
				}
				r.Echarts = append(r.Echarts, write)
				rst = append(rst, r)
			}
		}
		resq, _ := json.Marshal(rst)
		return string(resq), nil
	}
}

func (s *BlockService) GetBlockOverviewTopK(l *block.TopQuery) ([]block.OverViewLine, error) {
	start := strconv.FormatFloat(l.Start/1000, 'f', 3, 64)
	end := strconv.FormatFloat(l.End/1000, 'f', 3, 64)
	rst := make([]block.OverViewLine, 0, 2)

	k, _ := strconv.Atoi(l.TopK)

	if l.Region == "" {
		l.Region = "all"
	}
	az := []string{}
	if l.Az == "all" || l.Az == "" {
		az = []string{}
	} else {
		az = append(az, l.Az)
	}

	diskType := []string{}
	if l.DiskType == "all" || l.DiskType == "" {
		diskType = []string{}
	} else {
		diskType = append(diskType, l.DiskType)
	}

	queryParam := cloudDiskListQueryParameter{
		PageNo:     1,
		PageSize:   10000,
		AzCode:     az,
		RegionCode: l.Region,
		DiskType:   diskType,
	}
	// get total size
	res, err := queryCloudDiskList(queryParam)

	//cmdb, err := cmdbmanager.GetCMDBBytes(l.Region, az)
	if err != nil {
		klog.Error(err)
		return rst, nil
	}

	dataList := res.Data.DataList
	if len(dataList) > 100 {
		dataList = dataList[:100]
	}

	count := len(dataList)
	if count > 100 {
		count = 100
	}

	klog.Infof("count: %d", count)
	m := l.Name

	for i := 0; i < len(m); i++ {
		switch m[i] {
		case "band":
			r := block.OverViewLine{Name: m[i], Unit: "%"}
			rr := block.Echart{}
			rr1 := block.Echart{}
			rr.Info.Name = "read"
			rr.Info.Unit = "B"
			rr.Info.UnitType = "storage"
			rr1.Info.Name = "write"
			rr1.Info.Unit = "B"
			rr1.Info.UnitType = "storage"

			//批量从tsdb中查询数据
			timer := time.NewTimer(time.Second * config.MaxBlockSearchDuration)
			ctx, cancel := context.WithCancel(context.Background())

			for j := 0; j < count; j++ {
				id := dataList[j].VmId
				if id != "" && dataList[j].MountPoint != "" {
					go func(ctx context.Context, id string, j int) {
						select {
						case <-ctx.Done():
							klog.Info("Task canceled")
							return
						default:
							oo := kts.QueryVmMetric(id, start, end, []string{"Read"})
							if len(oo) > 0 {
								dataList[j].Value = oo[0].Avg
							}
						}
					}(ctx, id, j)
				}
			}
			select {
			case <-timer.C:
				klog.Info("Get Metric Data Timeout!")
				cancel()
			}

			out := ValueOrder(dataList, "desc")
			if len(out) >= k {
				out = out[:k]
			}
			for o := 0; o < len(out); o++ {
				aa, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
				v := services.ValueType{Value: aa, SubName: out[o].Name, Name: services.GenerateTopK(o + 1), Id: out[o].InstanceId}

				rr.Values = append(rr.Values, v)
			}
			r.Echarts = append(r.Echarts, rr)

			//write

			//批量从tsdb中查询数据
			timer = time.NewTimer(time.Second * config.MaxBlockSearchDuration)
			ctx, cancel = context.WithCancel(context.Background())

			for j := 0; j < count; j++ {
				id := dataList[j].VmId
				if id != "" && dataList[j].MountPoint != "" {
					go func(ctx context.Context, id string, j int) {
						select {
						case <-ctx.Done():
							klog.Info("Task canceled")
							return
						default:
							oo := kts.QueryVmMetric(id, start, end, []string{"Write"})
							if len(oo) > 0 {
								dataList[j].Value = oo[0].Avg
							}
						}
					}(ctx, id, j)
				}
			}
			select {
			case <-timer.C:
				klog.Info("Get Metric Data Timeout!")
				cancel()
			}

			out1 := ValueOrder(dataList, "desc")
			if len(out1) >= k {
				out1 = out1[:k]
			}
			for o := 0; o < len(out1); o++ {
				aa, _ := strconv.ParseFloat(services.Strval(out1[o].Value), 64)
				v := services.ValueType{Value: aa, SubName: out1[o].Name, Id: out1[o].InstanceId, Name: services.GenerateTopK(o + 1)}

				rr1.Values = append(rr1.Values, v)
			}
			r.Echarts = append(r.Echarts, rr1)
			rst = append(rst, r)
		case "io":
			r := block.OverViewLine{Name: m[i]}
			rr := block.Echart{}
			rr1 := block.Echart{}
			rr.Info.Name = "read"
			rr.Info.Unit = "次"
			rr.Info.UnitType = "number"
			rr1.Info.Name = "write"
			rr1.Info.Unit = "次"
			rr1.Info.UnitType = "number"

			//批量从tsdb中查询数据
			timer := time.NewTimer(time.Second * config.MaxBlockSearchDuration)
			ctx, cancel := context.WithCancel(context.Background())

			for j := 0; j < count; j++ {
				id := dataList[j].VmId
				go func(ctx context.Context, id string, j int) {
					select {
					case <-ctx.Done():
						klog.Info("Task canceled")
						return
					default:
						oo := kts.QueryVmMetric(id, start, end, []string{"read"})
						if len(oo) > 0 {
							dataList[j].Value = oo[0].Avg
						}
					}
				}(ctx, id, j)
			}
			select {
			case <-timer.C:
				klog.Info("Get Metric Data Timeout!")
				cancel()
			}

			out := ValueOrder(dataList, "desc")
			if len(out) >= k {
				out = out[:k]
			}
			for o := 0; o < len(out); o++ {
				aa, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
				v := services.ValueType{Value: aa, SubName: out[o].Name, Id: out[o].InstanceId, Name: services.GenerateTopK(o + 1)}

				rr.Values = append(rr.Values, v)
			}
			r.Echarts = append(r.Echarts, rr)

			//write

			//批量从tsdb中查询数据
			timer = time.NewTimer(time.Second * config.MaxBlockSearchDuration)
			ctx, cancel = context.WithCancel(context.Background())

			for j := 0; j < count; j++ {
				id := dataList[j].VmId
				go func(ctx context.Context, id string, j int) {
					select {
					case <-ctx.Done():
						klog.Info("Task canceled")
						return
					default:
						oo := kts.QueryVmMetric(id, start, end, []string{"write"})
						if len(oo) > 0 {
							dataList[j].Value = oo[0].Avg
						}
					}
				}(ctx, id, j)
			}
			select {
			case <-timer.C:
				klog.Info("Get Metric Data Timeout!")
				cancel()
			}

			out1 := ValueOrder(dataList, "desc")
			if len(out1) >= k {
				out1 = out1[:k]
			}
			for o := 0; o < len(out1); o++ {
				aa, _ := strconv.ParseFloat(services.Strval(out1[o].Value), 64)

				v := services.ValueType{Value: aa, SubName: out1[o].Name, Name: services.GenerateTopK(o + 1), Id: out1[o].InstanceId}
				rr1.Values = append(rr1.Values, v)
			}
			r.Echarts = append(r.Echarts, rr1)
			rst = append(rst, r)
		}
	}

	return rst, nil
}

func (s *BlockService) GetBlockList(l *block.ListQuery) (block.MonitorBlocks, error) {
	klog.Info("GetBlockList - block  - 1")
	klog.Info(l)
	cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "post")
	klog.Info("GetBlockList - block  - 2")
	klog.Info(cmdbCount)
	if l.Region == "" {
		l.Region = "all"
	}
	if len(l.Az) == 0 {
		l.Az = []string{}
	}
	//获取云产品块存储列表
	cmdb, err := cmdbmanager.GetCMDBBytes(l.Region, l.Az)
	klog.Info("GetBlockList - block  - 3")

	ms := block.MonitorBlocks{DataList: make([]block.MonitorBlock, 0, cmdbCount)}
	if err != nil {
		klog.Error(err)
		return ms, nil
	}
	if cmdb.Code != 200 {
		return ms, errors.Errorf("get data from nova cmdb error!")
	}
	cmdbList := cmdb.Data.DataList
	// 按时间倒叙排列
	sort.Slice(cmdb.Data.DataList, func(i, j int) bool {
		return cmdb.Data.DataList[i].CreateTime > cmdb.Data.DataList[j].CreateTime
	})
	////TODO 临时处理，分页前置，排序失效
	////order
	//if l.OrderCode != "" && l.OrderType != "" {
	//	results := alert.Bucket{}
	//	for i := 0; i < len(cmdb.DataList); i++ {
	//		results.Slice = append(results.Slice, ms.DataList[i])
	//	}
	//	time_by := func(a, b interface{}) bool {
	//		return true
	//	}
	//
	//	switch l.OrderCode {
	//	case "usePercent":
	//
	//		switch l.OrderType {
	//		case "asc":
	//			time_by = func(a, b interface{}) bool {
	//				return a.(block.MonitorBlock).UsePercent < b.(block.MonitorBlock).UsePercent
	//			}
	//		case "desc":
	//			time_by = func(a, b interface{}) bool {
	//				return a.(block.MonitorBlock).UsePercent > b.(block.MonitorBlock).UsePercent
	//			}
	//		}
	//
	//	}
	//
	//	results.By = time_by
	//
	//	klog.Info("GetBlockList - block  - 5")
	//
	//	sort.Sort(results)
	//	for i := 0; i < len(results.Slice); i++ {
	//		ms.DataList[i] = results.Slice[i].(block.MonitorBlock)
	//	}
	//}

	for i := 0; i < len(cmdbList); i++ {

		//多选
		j := cmdbList[i]
		if len(l.StorageType) != 0 {
			stateIn := services.In(l.StorageType, j.ResourcePoolType)
			if !stateIn {
				continue
			}
		}
		if len(l.UseStatus) != 0 {
			stateIn := services.In(l.UseStatus, j.UseStatus)
			if !stateIn {
				continue
			}
		}

		nb, _ := regexp.MatchString(l.Name, j.Name)
		pb, _ := regexp.MatchString(l.Pool, j.ResourcePool)
		tb, _ := regexp.MatchString(l.TenantId, j.TenantId)
		if //(blockMap[l.Region] == j.Region || l.Region == "") && (services.In(l.Az, j.Az) || len(l.Az) == 0) &&
		(nb || l.Name == "") && (pb || l.Pool == "") && (tb || l.TenantId == "") {
			m := block.MonitorBlock{
				ID:          j.InstanceId,
				Name:        j.Name,
				Size:        j.Size,
				UseStatus:   j.UseStatus,
				Region:      j.Region,
				Az:          j.Az,
				TenantId:    j.TenantId,
				TenantName:  j.TenantName,
				CreateTime:  j.CreateTime,
				StorageType: j.ResourcePoolType,
				BlockPool:   j.ResourcePool,
				VmId:        j.VmId,
				MountPoint:  j.MountPoint,
				AlertNumber: 0,
			}
			//多选
			if len(l.RunningStatus) != 0 {
				stateIn := services.In(l.RunningStatus, m.RunningStatus)
				if !stateIn {
					continue
				}
			}
			if j.VmId != "" && j.MountPoint != "" {
				// TODO 获取监控数据太慢，先取消
				////usepercent
				//usePercent := kts.QueryVmMetric(j.VmId, "", "", []string{"DiskFree"})
				//if len(usePercent) > 0 {
				//	use := services.Strval(usePercent[0].Value)
				//	m.UsePercent, _ = strconv.ParseFloat(use, 64)
				//}
				//klog.Info("GetBlockList - block  - 3 . 1")
				//rwIO := kts.QueryVmMetric(j.VmId, "", "", []string{"read", "write"})
				//if len(rwIO) > 1 {
				//	r := services.Strval(rwIO[0].Current)
				//	m.RIO, _ = strconv.ParseFloat(r, 64)
				//	w := services.Strval(rwIO[1].Current)
				//	m.WIO, _ = strconv.ParseFloat(w, 64)
				//
				//}
				//klog.Info("GetBlockList - block  - 3 . 2")
				//
				//rwBand := kts.QueryVmMetric(j.VmId, "", "", []string{"Read", "Write"})
				//if len(rwBand) > 1 {
				//	m.RBand = services.Strval(rwBand[0].Current)
				//
				//	m.WBand = services.Strval(rwBand[1].Current)
				//
				//}
				//klog.Info("GetBlockList - block  - 3 . 3")

			}
			ms.DataList = append(ms.DataList, m)
		}

	}
	klog.Info("GetBlockList - block  - 4")

	//分页
	low := (l.PageNo - 1) * l.PageSize
	if low > len(ms.DataList) {
		return ms, nil
	}

	hight := low + l.PageSize
	if hight > len(ms.DataList) {
		hight = len(ms.DataList)
	}

	ms.PageNo = l.PageNo
	ms.PageSize = l.PageSize

	ms.TotalCount = len(ms.DataList)
	ms.DataList = ms.DataList[low:hight]
	setMetricsInfo(&ms.DataList)
	return ms, nil
}

func setMetricsInfo(instances *[]block.MonitorBlock) error {
	start := time.Now().Unix()
	klog.Info("GetBlockList - block  - start:" + strconv.FormatInt(start, 10))
	for i, inst := range *instances {
		//usepercent
		usePercent := kts.QueryVmMetric(inst.VmId, "", "", []string{"DiskFree"})
		if len(usePercent) > 0 {
			use := services.Strval(usePercent[0].Value)
			(*instances)[i].UsePercent, _ = strconv.ParseFloat(use, 64)
		}

		rwIO := kts.QueryVmMetric(inst.VmId, "", "", []string{"read", "write"})
		if len(rwIO) > 1 {
			r := services.Strval(rwIO[0].Current)
			(*instances)[i].RIO, _ = strconv.ParseFloat(r, 64)
			w := services.Strval(rwIO[1].Current)
			(*instances)[i].WIO, _ = strconv.ParseFloat(w, 64)
		}

		rwBand := kts.QueryVmMetric(inst.VmId, "", "", []string{"Read", "Write"})
		if len(rwBand) > 1 {
			rband := services.Strval(rwBand[0].Current)
			wband := services.Strval(rwBand[1].Current)
			if rband != "" {
				(*instances)[i].RBand = rband + "ps"
			}
			if wband != "" {
				(*instances)[i].WBand = wband + "ps"
			}
		}
		//大于40s返回，防止页面无响应
		if time.Now().Unix()-start > 40 {
			return nil
		}
	}
	return nil
}

func (s *BlockService) GetBlockMetric(id string) (metric []block.MetricInfo, err error) {

	result := make([]block.MetricInfo, 0, 4)
	r1 := block.MetricInfo{Label: "云硬盘总容量", Unit: "B", Type: "info", Kind: "info"}
	//r2 := block.MetricInfo{Label: "已使用量", Unit: "B", Type: "info", Kind: "error", Number: "0"}
	//r3 := block.MetricInfo{Label: "云硬盘使用率", Unit: "%", Type: "info", Kind: "error", Number: "0"}
	r4 := block.MetricInfo{Label: "硬盘使用状态", StatusText: "使用中", Type: "status", Kind: "success"}
	r5 := block.MetricInfo{Label: "硬盘健康状态", StatusText: "正常", Type: "status", Kind: "success"}

	cmdbCount := services.GetTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "post")
	//ms := MonitorBlocks{DataList: make([]MonitorBlock, 0, cmdbCount)}
	cmdb, err := cmdbmanager.GetCMDBBytes("all", []string{})
	if cmdb.Code != 200 || err != nil {
		klog.Info("get data from nova cmdb error!")
		return result, nil
	}

	dataList := cmdb.Data.DataList
	for i := 0; i < cmdbCount; i++ {
		if id == dataList[i].InstanceId {
			if status, ok := UseStatusMap[dataList[i].UseStatus]; ok {
				r4.StatusText = status
			}
			if dataList[i].VmId != "" && dataList[i].MountPoint != "" {
				//总容量
				//r1 := block.MetricInfo{Label: "云硬盘总容量", Unit: "B", Type: "info", Kind: "info"}
				capacity := kts.QueryVmMetric(dataList[i].VmId, "", "", []string{"DiskCapacity"})
				if len(capacity) > 0 {
					//r1.Number = services.Strval(capacity[0].Value)
					r1.Number = strconv.Itoa(dataList[i].Size)
					r1.Unit = "GB"
				}

				//result = append(result, r1)
				//已使用量
				//r2 := block.MetricInfo{Label: "已使用量", Unit: "B", Type: "info", Kind: "error", Number: "0"}
				//used := kts.QueryVmMetric(dataList[i].VmId, "", "", []string{"DiskUsed"})
				//if len(used) > 0 {
				//	r2.Number = services.Strval(used[0].Value)
				//}
				////result = append(result, r2)
				////使用率
				////r3 := block.MetricInfo{Label: "云硬盘使用率", Unit: "%", Type: "info", Kind: "error", Number: "0"}
				//usePercent := kts.QueryVmMetric(dataList[i].VmId, "", "", []string{"DiskFree"})
				//if len(usePercent) > 0 {
				//	r3.Number = services.Strval(usePercent[0].Value)
				//}
				//result = append(result, r3)
				//使用状态
				//r4 := block.MetricInfo{Label: "硬盘使用状态", StatusText: "使用中", Type: "status", Kind: "success"}
				//result = append(result, r4)
				//usePercent:= kts.QueryVmMetric(dataList[i].InstanceId, "", "", []string{"DiskFree"})
				//if len(capacity) > 0 {
				//	r1.Name = usePercent[0].Value.(string)
				//	result = append(result, r4)
				//}
				//健康状态
				//r5 := block.MetricInfo{Label: "硬盘健康状态", StatusText: "正常", Type: "status", Kind: "success"}
				//result = append(result, r5)
			}
		}
	}
	result = append(result, r1)
	//result = append(result, r2)
	//result = append(result, r3)
	result = append(result, r4)
	result = append(result, r5)
	return result, nil
}

func (s *BlockService) GetBlockMetricLine(id string, t *block.MetricQuery) (metric []block.MetricLineType, err error) {
	start := strconv.FormatFloat(t.Start/1000, 'f', 3, 64)
	end := strconv.FormatFloat(t.End/1000, 'f', 3, 64)

	result := make([]block.MetricLineType, 0, 4)
	//获取块存储详情
	cmdb, err := cmdbmanager.GetCMDBCloudDiskDetail(id)
	if cmdb.Code != 200 || err != nil {
		klog.Info("get data from nova cmdb error!")
		return result, nil
	}
	data := cmdb.Data
	//if data.VmId != "" && data.MountPoint != "" {
	for j := 0; j < len(t.Name); j++ {
		switch t.Name[j] {
		case "capacity":
			r1 := block.MetricLineType{Label: "存储容量监控", Name: "capacity"}
			capacity := kts.QueryVmMetric(data.VmId, start, end, []string{"DiskCapacityRange", "DiskUsedRange", "DiskFreeRange"})
			if len(capacity) > 0 {
				for o := 0; o < len(capacity); o++ {
					e := block.Echart{}
					e.Info.Name = capacity[o].Name.(string)
					e.Info.Unit = "Byte"
					e.Info.UnitType = "storage"
					if capacity[o].Value != nil {
						e.Values = services.PromeForRangeValueForms(capacity[o].Value)
					}
					r1.Echarts = append(r1.Echarts, e)
				}
			}
			result = append(result, r1)
		case "band":
			r1 := block.MetricLineType{Label: "带宽监控", Name: "band"}
			capacity := kts.QueryVmMetric(data.VmId, start, end, []string{"Read", "Write"})
			if len(capacity) > 0 {
				for o := 0; o < len(capacity); o++ {
					e := block.Echart{}
					e.Info.Name = capacity[o].Name.(string)
					e.Info.Unit = "Mb/s"
					e.Info.UnitType = "number"
					//e.Info.UnitType = "storage"
					if capacity[o].Value != nil {
						e.Values = services.PromeForRangeValueForms(capacity[o].Value)
					}
					r1.Echarts = append(r1.Echarts, e)
				}
			}
			result = append(result, r1)
		case "iops":
			r1 := block.MetricLineType{Label: "IOPS监控", Name: "iops"}
			capacity := kts.QueryVmMetric(data.VmId, start, end, []string{"read", "write"})
			if len(capacity) > 0 {
				for o := 0; o < len(capacity); o++ {
					e := block.Echart{}
					e.Info.Name = capacity[o].Name.(string)
					e.Info.Unit = "次/秒"
					e.Info.UnitType = "number"
					if capacity[o].Value != nil {
						e.Values = services.PromeForRangeValueForms(capacity[o].Value)
					}
					r1.Echarts = append(r1.Echarts, e)
				}
			}
			result = append(result, r1)
		case "ioDelay":
			r1 := block.MetricLineType{Label: "IO延时", Name: "ioDelay"}
			capacity := kts.QueryVmMetric(data.VmId, start, end, []string{"readAwait", "writeAwait"})
			if len(capacity) > 0 {
				for o := 0; o < len(capacity); o++ {
					e := block.Echart{}
					e.Info.Name = capacity[o].Name.(string)
					if capacity[o].Value != nil {
						e.Values = services.PromeForRangeValueForms(capacity[o].Value)
					}
					r1.Echarts = append(r1.Echarts, e)
				}
			}
			result = append(result, r1)
		}
	}
	//}

	return result, nil
}

func GetCMDBResult(l *block.ListQuery) (cmdbmodel.BlockCMDBResult, error) {
	c := http.Client{}
	cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "post")
	cmdb := cmdbmodel.BlockCMDBResult{}
	hostUrlPost := cmdbmodel.BlockListPost{
		PageNo:   1,
		PageSize: cmdbCount,
		Region:   l.Region,
		Az:       l.Az,

		//cmdb.Data.TotalCount = services.GetTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "post")
	}
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "application/json", jsoninfo)

	if err != nil {
		return cmdb, err
	}

	b, _ := io.ReadAll(resp.Body)

	err = json.Unmarshal(b, &cmdb)
	if err != nil {
		return cmdb, err
	}
	return cmdb, nil
}

func ValueOrder(in []cmdbmodel.CloudDiskData, code string) []cmdbmodel.CloudDiskData {
	results := alert.Bucket{}
	for i := 0; i < len(in); i++ {
		results.Slice = append(results.Slice, in[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	switch code {
	case "asc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(cmdbmodel.CloudDiskData).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(cmdbmodel.CloudDiskData).Value), 64)
			return aa < bb
		}
	case "desc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(cmdbmodel.CloudDiskData).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(cmdbmodel.CloudDiskData).Value), 64)
			return aa > bb
		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(in); i++ {
		in[i] = results.Slice[i].(cmdbmodel.CloudDiskData)
	}
	return in
}

type CloudDiskPageResult struct {
	Code    int             `json:"code,omitempty"`
	Message string          `json:"message"`
	Data    CloudDiskResult `json:"data"`
}
type CommonListPagination struct {
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
	TotalCount int `json:"totalCount"`
}

type CloudDiskResult struct {
	CommonListPagination
	DataList []cmdbmodel.CloudDiskData `json:"dataList"`
}

func queryCloudDiskList(parameter cloudDiskListQueryParameter) (*CloudDiskPageResult, error) {
	res := &CloudDiskPageResult{}
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/clouddisk"
	err := PostUrl(url, parameter, res)
	if err != nil {
		return nil, err
	}
	return res, nil
}

func PostUrl(url string, data interface{}, result interface{}) error {
	jsonStr, _ := json.Marshal(data)
	req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonStr))
	req.Header.Add("content-type", "application/json")
	if err != nil {
		panic(err)
	}
	defer req.Body.Close()
	client := &http.Client{Timeout: 300 * time.Second}
	resp, err := client.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()
	respBytes, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		return err
	}
	err = json.Unmarshal(respBytes, result)
	if err != nil {
		return err
	}
	return nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/physicalServer/util.go
```golang
package physicalServer

import (
	"fmt"
	"strconv"

	servermodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/physicalServer"
	cmdb "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	prom "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
)

func MakeTimeStamp(start, end, step string) []string {
	sl := make([]string, 0)
	start1, _ := strconv.ParseFloat(start, 64)
	end1, _ := strconv.ParseFloat(end, 64)
	step1, _ := strconv.ParseFloat(step, 64)
	for {
		ss := strconv.FormatFloat(start1, 'f', -1, 64)
		sl = append(sl, ss)
		start1 += step1
		if start1 > end1 {
			break
		}
	}

	return sl
}

//func GetStateByIp(ip string) (string, error) {
//	c := http.Client{}
//	prome := new(Prometheus)
//	resp, err := c.Get("http://" + config.GetDefaultUrl(config.PrometheusService) + "/api/v1/targets")
//	if err != nil {
//		return "", err
//	}
//
//	b, _ := io.ReadAll(resp.Body)
//	json.Unmarshal(b, prome)
//
//	state := ""
//	for i := 0; i < len(prome.Data.ActiveTargets); i++ {
//		fmt.Printf("instance= %s\n", prome.Data.ActiveTargets[i].Labels.Instance)
//		if pp := strings.Split(prome.Data.ActiveTargets[i].Labels.Instance, ":"); pp[0] == ip {
//			fmt.Printf("%s, health: %s", pp[0], prome.Data.ActiveTargets[i].Health)
//			state = strings.ToUpper(prome.Data.ActiveTargets[i].Health)
//			break
//		} else {
//			state = "DOWN"
//		}
//	}
//	return state, nil
//}

func rTOs(s string, l interface{}) servermodels.ResponseMetric {
	r := servermodels.ResponseMetric{}
	r.Metric = s
	ll := prom.PrometheusResultToValue2(l)
	fmt.Printf("ll: %v\n", ll)

	r.Value = ll
	return r
}

func getIpSlice(hosts []cmdb.PhysicalHostData) []string {
	s := []string{}
	for i := 0; i < len(hosts); i++ {
		s = append(s, hosts[i].ManagementIP)
	}

	return s
}

func getMax(vals []float64) float64 {
	var max = vals[0]
	for _, val := range vals {
		if val > max {
			max = val
		}
	}
	return max
}

func getMin(vals []float64) float64 {
	var min = vals[0]
	for _, val := range vals {
		if val < min {
			min = val
		}
	}
	return min
}

func getAvg(vals []float64) float64 {
	l := len(vals)
	sum := 0.0
	for _, val := range vals {
		sum += val / float64(l)
	}
	return sum
}

func getSlice(r interface{}) []float64 {
	var result []float64

	valu := r.(map[string]interface{})
	if Data, o := valu["values"]; o {
		value := Data.([]interface{})
		for i := 0; i < len(value); i++ {
			v := value[i].([]interface{})
			switch v[1].(type) {
			case string:
				vv, _ := strconv.ParseFloat(v[1].(string), 64)
				//ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", vv), 64)
				//sss := services.FormatSize(ss)
				//v[1] = sss
				result = append(result, vv)
			case float64:
				ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", v[1].(float64)), 64)
				//sss := services.FormatSize(ss)
				//v[1] = sss
				result = append(result, ss)
			}
		}
		//result = res.(string)
	}

	return result
}

//func getMetric (l []interface{}) []MetricResult {
//	responseMetric := []MetricResult{}
//	for j := 0; j < len(l); j++ {
//		r := MetricResult{}
//
//		ll := l[j].(map[string]interface{})
//		lll := ll["metric"].(map[string]interface{})
//
//		s := getSlice(l[j])
//
//
//		r.Name = "r:" + lll["device"].(string)
//
//		r.Min = services.FormatSize(getMin(s))
//		r.Avg = services.FormatSize(getAvg(s))
//		r.Max = services.FormatSize(getMax(s))
//		llll := prom.PrometheusResultToValueForSize(l)
//		r.Value = llll[j]
//		responseMetric = append(responseMetric, r)
//	}
//	return responseMetric
//}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/physicalServer/physicalServer.go
```golang
package physicalServer

import (
	"errors"
	"fmt"
	"github.com/prometheus/common/model"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	alertmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	servermodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/physicalServer"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	cmdb "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/dgraphmanager"
	prom "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	temp "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/physicalServer"
	"k8s.io/klog/v2"
	"math"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"time"
)

type IPhysicalServer interface {
	GetServerMetric(*servermodels.QueryList) (interface{}, error)
	GetServerMetricWorkDropDownList(ip string) ([]string, error)
	GetServerHardwareMetric(string) (servermodels.HardWare, error)
	//GetSwitchMetricLine(*switchmodels.SwitchMetricLineQuery) (map[string][]switchmodels.EchartType, error)
	GetServerOverview(*servermodels.ListQuery) (servermodels.OverView, error)
	GetServerOverviewTop(*servermodels.TopKQueryList) ([]servermodels.OverviewTopType, error)
	GetServerOverviewTopNew(*servermodels.TopKQueryList) ([]servermodels.OverviewTopType, error)
	GetServerList(*servermodels.PhyListQuery) (servermodels.ListResult, error)
}

type PhysicalServerService struct {
	PromClient *client.PromClient
}

func NewPhysicalServerService() *PhysicalServerService {
	return &PhysicalServerService{
		PromClient: client.NewPromClient(),
	}
}

func (s *PhysicalServerService) GetServerOverview(q *servermodels.ListQuery) (rst servermodels.OverView, err error) {
	klog.Infoln("get physical overview")

	if q.Region == "" {
		q.Region = "all"
	}
	az := []string{}
	if q.Az == "all" || q.Az == "" {
		az = []string{}
	} else {
		az = append(az, q.Az)
	}

	lab := []string{}
	if q.Lab == "all" || q.Lab == "" {
		lab = []string{}
	} else {
		lab = append(lab, q.Lab)
	}

	//获取服务器列表
	serverList, err := cmdb.GetAllPhysicalHostList("", q.Region, az, lab)
	if err != nil {
		return rst, err
	}
	klog.Infof("total_physical_server_num: %d", len(serverList.Data.DataList))

	UP := servermodels.StateType{Prefix: "监控中", Unit: "个"}
	DOWN := servermodels.StateType{Prefix: "监控异常", Unit: "个"}

	for _, v := range serverList.Data.DataList {
		query := temp.NewServerMetics(v.ManagementIP+":9100", "", 0).ToString("server_up")
		up, err := client.VectorQuery(query)
		if err != nil {
			klog.Info(err)
		}
		if len(up) > 0 {
			if math.IsNaN(float64(up[0].Value)) {
				up[0].Value = 0
			}
			if float64(up[0].Value) == 1 {
				UP.Number++
			} else {
				DOWN.Number++
			}
		} else {
			DOWN.Number++
		}
	}
	// 获取服务器告警数据
	alertPpram := alertmodel.AlertQuery{
		Module: "server",
		Az:     az,
	}
	alertList, err := alert.GetCommonAlertOverviewNum(alertPpram)
	if err != nil {
		return rst, err
	}
	cpuFaultNum, cpulables := GetCPUFaultNum()
	memFaultNum, memlables := GetMemoryFaultNum()
	diskFaultNum, disklables := GetDiskFaultNum()
	cpuErrNum := servermodels.StateType{Prefix: "CPU故障数量", Unit: "个", Value: float64(cpuFaultNum), Lables: cpulables}
	memErrNum := servermodels.StateType{Prefix: "内存故障数量", Unit: "个", Value: float64(memFaultNum), Lables: memlables}
	diskErrNum := servermodels.StateType{Prefix: "硬盘故障数量", Unit: "个", Value: float64(diskFaultNum), Lables: disklables}

	rst.Alerts = append(rst.Alerts, alertList...)
	rst.State = append(rst.State, DOWN, UP)
	rst.HardwareState = append(rst.HardwareState, cpuErrNum, memErrNum, diskErrNum)

	return rst, nil
}

func GetCPUFaultNum() (int, []model.Metric) {
	labelSetSlice := make([]model.Metric, 0)
	num := 0
	pml := `ipmi_sensor_state{name=~"^CPU.*State|^CPU.*Status",service="ipmi-exporter",type="Processor"}`
	cpuMetrics, err := client.VectorQuery(pml)
	if err != nil {
		klog.Info(err)
		return 0, labelSetSlice
	}

	for _, v := range cpuMetrics {
		if math.IsNaN(float64(v.Value)) {
			continue
		}
		if float64(v.Value) > 1 {
			num += 1
			labelSetSlice = append(labelSetSlice, v.Metric)
		}
	}
	return num, labelSetSlice
}

func GetMemoryFaultNum() (int, []model.Metric) {
	labelSetSlice := make([]model.Metric, 0)
	num := 0
	pml := `ipmi_sensor_state{name!="Memory Usage",service="ipmi-exporter",type="Memory"}`
	memoryMetrics, err := client.VectorQuery(pml)
	if err != nil {
		klog.Info(err)
		return 0, labelSetSlice
	}

	for _, v := range memoryMetrics {
		if math.IsNaN(float64(v.Value)) {
			continue
		}
		if float64(v.Value) > 1 {
			num += 1
			labelSetSlice = append(labelSetSlice, v.Metric)
		}
	}
	return num, labelSetSlice
}

func GetDiskFaultNum() (int, []model.Metric) {
	labelSetSlice := make([]model.Metric, 0)
	num := 0
	pml := `ipmi_sensor_state{service="ipmi-exporter",type="Drive Slot"}`
	diskMetrics, err := client.VectorQuery(pml)
	if err != nil {
		klog.Info(err)
		return 0, labelSetSlice
	}

	for _, v := range diskMetrics {
		if math.IsNaN(float64(v.Value)) {
			continue
		}
		if float64(v.Value) > 1 {
			num += 1
			labelSetSlice = append(labelSetSlice, v.Metric)
		}
	}
	return num, labelSetSlice
}

func (s *PhysicalServerService) GetServerOverviewTop(q *servermodels.TopKQueryList) ([]servermodels.OverviewTopType, error) {

	if q.Step == "" {
		q.Step = "30"
	}
	if q.Region == "" {
		q.Region = "all"
	}
	az := []string{}
	if q.Az == "all" || q.Az == "" {
		az = []string{}
	} else {
		az = append(az, q.Az)
	}

	lab := []string{}
	if q.Lab == "all" || q.Lab == "" {
		lab = []string{}
	} else {
		lab = append(lab, q.Lab)
	}

	ss, _ := cmdb.GetAllPhysicalHostList("", q.Region, az, lab)
	ips := strings.Join(getIpSlice(ss.Data.DataList), ":9100|")
	ips = ips + ":9100"

	allTopK := QueryPhysicalTopK(ips, q.TopK, q.Start, q.End, q.Name)
	return allTopK, nil

}

func (s *PhysicalServerService) GetServerOverviewTopNew(q *servermodels.TopKQueryList) ([]servermodels.OverviewTopType, error) {

	if q.Step == "" {
		q.Step = "30"
	}
	paramLabel := &prom.ServerTop{
		Region: q.Region,
		Az:     q.Az,
		Lab:    q.Lab,
	}
	label := ServerbuildCommonCondition(paramLabel)
	klog.Infof("label :%s", label)
	metrics := q.Name
	allServer, err := cmdb.GetAllPhysicalHostList("", "all", []string{}, []string{})
	if err != nil {
		klog.Error(err)
	}
	allList := allServer.Data.DataList
	t := services.FormatTime(float64(q.End/1000 - q.Start/1000))
	responseMetric := []servermodels.OverviewTopType{}
	for i := 0; i < len(metrics); i++ {
		switch metrics[i] {
		case "cpuPercent":
			r := servermodels.OverviewTopType{Name: metrics[i], Unit: "%"}
			rr := servermodels.EchartType{}
			rr.Info.Name = metrics[i]
			rr.Info.Unit = "%"
			cpuTop, _ := prom.GetCpuRateTopKNew(q.TopK, label, t, time.Now())
			c := dgraphmanager.String2int(cpuTop.Result, allList)
			for j := 0; j < len(c); j++ {
				v := servermodels.ValueType{Value: services.Form2(c[j].Percent), Name: c[j].Name, Ip: c[j].Ip}
				rr.Values = append(rr.Values, v)
			}
			r.Echarts = append(r.Echarts, rr)
			responseMetric = append(responseMetric, r)
		case "memPercent":
			r := servermodels.OverviewTopType{Name: metrics[i], Unit: "%"}
			rr := servermodels.EchartType{}
			rr.Info.Name = metrics[i]
			rr.Info.Unit = "%"
			memTop, _ := prom.GetMemoryRateTopKNew(q.TopK, label, t, time.Now())

			c := dgraphmanager.String2int(memTop.Result, allList)
			for j := 0; j < len(c); j++ {
				cc, _ := strconv.ParseFloat(c[j].Percent, 64)
				v := servermodels.ValueType{Value: services.Form2(cc * 100), Name: c[j].Name, Ip: c[j].Ip}
				rr.Values = append(rr.Values, v)
			}
			r.Echarts = append(r.Echarts, rr)
			responseMetric = append(responseMetric, r)
		case "diskPercent":
			r := servermodels.OverviewTopType{Name: metrics[i], Unit: "%"}
			rr := servermodels.EchartType{}
			rr.Info.Name = metrics[i]
			rr.Info.Unit = "%"
			diskTop, _ := prom.GetDiskRateTopKNew(q.TopK, label, t, time.Now())
			c := dgraphmanager.String2int(diskTop.Result, allList)
			for j := 0; j < len(c); j++ {
				cc, _ := strconv.ParseFloat(c[j].Percent, 64)
				v := servermodels.ValueType{Value: services.Form2(cc * 100), Name: c[j].Name, Ip: c[j].Ip}
				rr.Values = append(rr.Values, v)
			}
			r.Echarts = append(r.Echarts, rr)
			responseMetric = append(responseMetric, r)
		case "netIn":
			r := servermodels.OverviewTopType{Name: metrics[i], Unit: ""}
			rr := servermodels.EchartType{}
			rr.Info.Name = metrics[i]
			rr.Info.UnitType = "storage"
			netInTop, _ := prom.GetNetworkReceiveRateTopKNew(q.TopK, label, t, time.Now())
			c := dgraphmanager.String2int(netInTop.Result, allList)
			for j := 0; j < len(c); j++ {
				cc, _ := strconv.ParseFloat(c[j].Percent, 64)
				v := servermodels.ValueType{Value: services.Form2(cc), Name: c[j].Name, Ip: c[j].Ip}
				rr.Values = append(rr.Values, v)
			}
			r.Echarts = append(r.Echarts, rr)
			responseMetric = append(responseMetric, r)
		case "netOut":
			r := servermodels.OverviewTopType{Name: metrics[i], Unit: ""}
			rr := servermodels.EchartType{}
			rr.Info.Name = metrics[i]
			rr.Info.UnitType = "storage"
			netOutTop, _ := prom.GetNetworkTransmitRateTopKNew(q.TopK, label, t, time.Now())
			c := dgraphmanager.String2int(netOutTop.Result, allList)
			for j := 0; j < len(c); j++ {
				cc, _ := strconv.ParseFloat(c[j].Percent, 64)
				v := servermodels.ValueType{Value: services.Form2(cc), Name: c[j].Name, Ip: c[j].Ip}
				rr.Values = append(rr.Values, v)
			}
			r.Echarts = append(r.Echarts, rr)
			responseMetric = append(responseMetric, r)
		}
	}

	return responseMetric, nil

}

func ServerbuildCommonCondition(parameter *prom.ServerTop, extConditions ...string) string {
	var conditions []string
	if len(extConditions) > 0 {
		conditions = append(conditions, extConditions...)
	}

	conditions = append(conditions, "job !=\""+"node-exporter"+"\"")
	if parameter.Region != "" {
		conditions = append(conditions, "region=\""+parameter.Region+"\"")
	}

	if parameter.Az != "" {
		conditions = append(conditions, "az=\""+parameter.Az+"\"")
	}

	if parameter.Lab != "" {
		conditions = append(conditions, "lab=\""+parameter.Lab+"\"")
	}

	var conditionStr string
	if len(conditions) > 0 {
		conditionStr = strings.Join(conditions, ",")
	}
	return conditionStr
}

func (s *PhysicalServerService) GetServerList(t *servermodels.PhyListQuery) (servermodels.ListResult, error) {

	result := servermodels.ListResult{}
	if t.SearchKey != "" && t.SearchValue != "" {
		switch t.SearchKey {
		case "sn":
			t.Sn = t.SearchValue
		case "name":
			t.Name = t.SearchValue
		case "ip":
			t.Ip = t.SearchValue
		case "label":
			t.Label = t.SearchValue
		case "pool":
			t.Pool = t.SearchValue
		}

	}

	//fmt.Println("t.Pool",t.Pool)
	//switch t.Pool { // 计算资源池
	//case "poolComputer":
	//	klog.Infof("IsAggragate_poolComputer")
	//	list, _ := cmdb.GetComputerPoolNameList("all", []string{}, "", "1", "1000") // 获取计算资源池所有名称
	//	klog.Infof("poolComputer_count",len(list))
	//	klog.Infof("poolComputer_name_list %+v",list)
	//	t.Pools = list // 计算资源池列表
	//	// case "name":
	//	// 	t.Name = t.SearchValue
	//	// case "ip":
	//	// 	t.Ip = t.SearchValue
	//	// case "label":
	//	// 	t.Label = t.SearchValue
	//}

	//cmdbCount := services.GetTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/physicalHost", "post")
	hosts := make([]servermodels.PhysicalServer, 0, 10)
	cmdbAll, err := cmdb.GetAllPhysicalHostList("", t.Region, t.Az, []string{})
	if err != nil {
		klog.Info(err)
	}
	count := len(cmdbAll.Data.DataList)
	for i := 0; i < count; i++ {
		j := cmdbAll.Data.DataList[i]

		//if t.Pool == "poolComputer" { // 计算资源池
		//	klog.Infof("ResourcePool",j.ResourcePool)
		//	stateIn := services.In(t.Pools, j.ResourcePool)
		//	if !stateIn {
		//		continue
		//	}
		//}
		//单选 pool
		if t.Pool != "" {
			rp := strings.Split(j.ResourcePool, ",") //XGW-LB,XGW-EIP 混合部署的存在这种情况
			if !services.IsValueInList(rp, t.Pool) {
				continue
			}
			//stateIn := services.In(rp, t.Pool)
			//if !stateIn {
			//	continue
			//}
		}
		//fuzzy search
		nb, _ := regexp.MatchString(t.Name, j.Name)
		sb, _ := regexp.MatchString(t.Sn, j.Sn)
		if (strings.Contains(j.ManagementIP, t.Ip) || t.Ip == "") && (sb || t.Sn == "") && (nb || t.Name == "") &&
			(t.Region == j.HostRegionCode || t.Region == "") && (services.In(t.Az, j.HostAzCode) || len(t.Az) == 0) &&
			(services.In(t.Lab, j.HostLabCode) || len(t.Lab) == 0) {
			host := servermodels.PhysicalServer{
				Name:     j.Name,
				Pool:     j.ResourcePool,
				PoolType: j.ResourcePoolType,
				Region:   j.HostRegionName,
				Az:       j.HostAzName,
				Lab:      j.HostLabName,
				Sn:       j.Sn,
				IP:       j.ManagementIP,
				Node:     j.Node,
			}
			//获取服务器运行状态
			upQuery := temp.NewServerMetics(j.ManagementIP+":9100", "", 0).ToString("server_up")
			up, err := client.VectorQuery(upQuery)
			if err != nil {
				klog.Info(err)
			}
			host.State = "down"
			for _, v := range up {
				if math.IsNaN(float64(v.Value)) {
					v.Value = 0
				}
				if float64(v.Value) == 1 {
					host.State = "up"
				} else {
					host.State = "down"
				}
			}
			//多选 运行状态
			if len(t.RunList) != 0 {
				stateIn := services.In(t.RunList, host.State)
				if !stateIn {
					continue
				}
			}
			//多选 资源池类型
			if len(t.PoolType) != 0 {
				//poolTypeIn := services.In(t.PoolType, j.ResourcePoolType)
				poolTypeIn := poolTypeExist(t.PoolType, j.ResourcePoolType)
				if !poolTypeIn {
					continue
				}
			}

			//多选 节点类型
			if len(t.Node) != 0 {
				nodeIn := poolTypeExist(t.Node, j.Node)
				if !nodeIn {
					continue
				}
			}

			//获取监控数据
			if t.OrderType == "cpuLoad" || t.OrderType == "memLoad" || t.OrderType == "diskLoad" {
				monitor := GetSevreMonitor(j.ManagementIP)
				host.CpuLoad = monitor.CpuLoad
				host.MemLoad = monitor.MemLoad
				host.DiskLoad = monitor.DiskLoad
			}
			host.CpuErrNum = 0
			host.MemErrNum = 0
			host.DiskErrNum = 0
			if t.CpuErrNum == "zero" && host.CpuErrNum > 0 { //筛选cpu故障数等于0的
				continue
			}
			if t.MemErrNum == "zero" && host.MemErrNum > 0 { //筛选mem故障数等于0的
				continue
			}
			if t.DiskErrNum == "zero" && host.DiskErrNum > 0 { //筛选硬盘故障数等于0的
				continue
			}
			if t.CpuErrNum == "nozero" && host.CpuErrNum == 0 { //筛选mem故障数大于0的
				continue
			}
			if t.MemErrNum == "nozero" && host.MemErrNum == 0 { //筛选cpu故障数大于0的
				continue
			}
			if t.DiskErrNum == "nozero" && host.DiskErrNum == 0 { //筛选硬盘故障数大于0的
				continue
			}
			hosts = append(hosts, host)
		}
	}
	timeUnix2 := time.Now().Unix()
	fmt.Println("rangeEndTime", timeUnix2)

	//order 排序
	if t.OrderCode != "" && t.OrderType != "" {
		results := alert.Bucket{}
		for i := 0; i < len(hosts); i++ {
			results.Slice = append(results.Slice, hosts[i])
		}
		time_by := func(a, b interface{}) bool {
			return true
		}
		switch t.OrderCode {
		case "cpuLoad":
			if t.OrderType != "" {
				switch t.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(servermodels.PhysicalServer).CpuLoad < b.(servermodels.PhysicalServer).CpuLoad
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(servermodels.PhysicalServer).CpuLoad > b.(servermodels.PhysicalServer).CpuLoad
					}
				}
			}
		case "memLoad":
			if t.OrderType != "" {
				switch t.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(servermodels.PhysicalServer).MemLoad < b.(servermodels.PhysicalServer).MemLoad
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(servermodels.PhysicalServer).MemLoad > b.(servermodels.PhysicalServer).MemLoad
					}
				}
			}
		case "diskLoad":
			if t.OrderType != "" {
				switch t.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(servermodels.PhysicalServer).DiskLoad < b.(servermodels.PhysicalServer).DiskLoad
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(servermodels.PhysicalServer).DiskLoad > b.(servermodels.PhysicalServer).DiskLoad
					}
				}
			}
		}
		results.By = time_by
		sort.Sort(results)
		for i := 0; i < len(results.Slice); i++ {
			hosts[i] = results.Slice[i].(servermodels.PhysicalServer)
		}
	}
	//分页
	low := (t.PageNo - 1) * t.PageSize
	if low > len(hosts) {
		klog.Info("PageSize is too large")
	}

	hight := low + t.PageSize
	if hight > len(hosts) {
		hight = len(hosts)
	}

	result.PageSize = t.PageSize
	result.PageNo = t.PageNo
	result.TotalCount = len(hosts)
	result.DataList = hosts[low:hight]
	//告警数量
	for k, v := range result.DataList {
		result.DataList[k].AlertNumber = alert.GetResourcePoolAlertNum(v.Region, v.Az, "physicalResource", "physicalServer", v.IP+`:9100`)
		//监控数据
		if t.OrderType == "" {
			monitor := GetSevreMonitor(v.IP)
			result.DataList[k].CpuLoad = monitor.CpuLoad
			result.DataList[k].MemLoad = monitor.MemLoad
			result.DataList[k].DiskLoad = monitor.DiskLoad
		}
	}
	return result, nil
}

type MonitorRes struct {
	CpuLoad  float64
	MemLoad  float64
	DiskLoad float64
}

func GetSevreMonitor(ip string) (res MonitorRes) {
	//monitor
	cpuQuery := temp.NewServerMetics(ip+":9100", "", 0).ToString("server_cpu_usage_rate_new")
	cpu, err := client.VectorQuery(cpuQuery)
	if err != nil {
		klog.Info(err)
	}
	for _, v := range cpu {
		if math.IsNaN(float64(v.Value)) {
			v.Value = 0
		}
		res.CpuLoad = services.FormPercent(float64(v.Value))
	}
	memQuery := temp.NewServerMetics(ip+":9100", "", 0).ToString("server_memory_usage_rate")
	mem, err := client.VectorQuery(memQuery)
	if err != nil {
		klog.Info(err)
	}
	for _, v := range mem {
		if math.IsNaN(float64(v.Value)) {
			v.Value = 0
		}
		res.MemLoad = services.FormPercent(float64(v.Value))
	}
	diskQuery := temp.NewServerMetics(ip+":9100", "", 0).ToString("server_disk_usage_rate")
	disk, err := client.VectorQuery(diskQuery)
	if err != nil {
		klog.Info(err)
	}
	for _, v := range disk {
		if math.IsNaN(float64(v.Value)) {
			v.Value = 0
		}
		res.DiskLoad = services.FormPercent(float64(v.Value))
	}
	return res
}

func poolTypeExist(searchType []string, poolTypeJoins string) bool {

	poolTypes := strings.Split(poolTypeJoins, ",")
	for _, poolType := range poolTypes {
		poolTypeIn := services.In(searchType, poolType)
		if poolTypeIn {
			return true
		}
	}
	return false
}

var MetricMap = map[string]struct{}{
	//disk
	"file": struct{}{},
	//"Disk":  struct{}{},
	"read":  struct{}{},
	"write": struct{}{},
	"Read":  struct{}{},
	"Write": struct{}{},
	//network
	"Receive":     struct{}{},
	"Transmit":    struct{}{},
	"ErrDropIn":   struct{}{},
	"ErrDropOut":  struct{}{},
	"LoseDropIn":  struct{}{},
	"LoseDropOut": struct{}{},

	//mem
	"Free":      struct{}{},
	"Total":     struct{}{},
	"Available": struct{}{},
	//cpu
	"CPUMode":    struct{}{},
	"CPUAvgMode": struct{}{},
}

func (s *PhysicalServerService) GetServerMetric(q *servermodels.QueryList) (interface{}, error) {

	klog.Info("GetServerMetric")
	start1, _ := strconv.ParseFloat(q.Start, 64)
	end1, _ := strconv.ParseFloat(q.End, 64)
	step := services.TimeToStep(end1 - start1)

	var result interface{}
	for i := 0; i < len(q.List); i++ {
		if _, ok := MetricMap[q.List[i]]; ok {
			klog.Info("ling")
			if _, ok := MetricWorkMap[q.List[i]]; ok { // 网络监控验证参数
				if len(q.WorkName) <= 0 {
					return result, errors.New("workName Parameter not passed")
				}
			}
			result = QueryNetworkAndDisk(q.Ip, q.Start, q.End, step, q.WorkName, q.List)
		} else {
			klog.Info("overview")
			result = QueryPhysicalMetric(q.Ip, "", "", "", q.List)
		}
	}
	if q.Start != "" && q.End != "" && step != "" {
		ss := MakeTimeStamp(q.Start, q.End, step)
		op := make([]servermodels.MetricResult, 0)
		op = result.([]servermodels.MetricResult)
		res := []servermodels.MetricResult{}
		klog.Infof("getQueryNetworkAndDiskCount", len(op))
		for _, v := range op {
			value := v.Value.([]interface{})
			startTime := value[0].([]interface{}) //第一条的开始时间
			repairFirstTime := strconv.FormatFloat(startTime[0].(float64), 'f', -1, 64)
			firstStep, _ := strconv.ParseFloat(step, 64)
			start, _ := strconv.ParseFloat(q.Start, 64)
			var vvv []interface{}
			klog.Errorf("start: %v; repairFirstTime: %v; firstStep: %v", ss, repairFirstTime, firstStep)
			for n := start; n < startTime[0].(float64); n += firstStep { // 补充日期
				vvv = append(vvv, []interface{}{n, 0})
			}
			for _, vv := range value {
				tt := vv
				vvv = append(vvv, tt)
			}
			var resInfoValue interface{}
			resInfoValue = vvv

			resInfo := servermodels.MetricResult{}
			resInfo.Name = v.Name
			resInfo.Current = v.Current
			resInfo.Min = v.Min
			resInfo.Max = v.Max
			resInfo.Avg = v.Avg
			resInfo.Value = resInfoValue
			res = append(res, resInfo)
		}
		result = res
		tt := servermodels.TimeResult{
			TimeStamp: ss,
			Result:    result,
		}
		return tt, nil
	} else {
		return result, nil
	}

}

func (s *PhysicalServerService) GetServerMetricWorkDropDownList(ip string) ([]string, error) {
	sql := `count(node_network_receive_packets_total{instance="` + ip + `:9100"` + `,device=~"(?i)^(en|eth|em|x|bond).+$"})by (instance,device)`
	res, _ := prom.PrometheusQuery2(false, "", "", "", sql)
	var names []string
	for j := 0; j < len(res); j++ {
		ll := res[j].(map[string]interface{})
		lll := ll["metric"].(map[string]interface{})
		name := lll["device"].(string)
		names = append(names, name)

	}
	sort.Strings(names)
	return names, nil
}

var StateMap = map[string]string{
	"0":   "正常",
	"1":   "告警",
	"2":   "故障",
	"NaN": "未知",
}

func typeToRealSize(size string) (res int64) {
	idx := strings.Index(size, "bytes")
	for i := 0; i < idx; i++ {
		if size[i] >= '0' && size[i] <= '9' {
			res *= 10
			res += int64(size[i] - '0')
		}
	}
	return
}

// 服务器硬件监控概览 带外ip连通状态
func ServerHardwareOverviewOutBandIpStatus(outBandIp string) (res []servermodels.StateType) {
	ipmiStatus := servermodels.StateType{Name: "带外连通状态", Value: 0}
	ipmi := temp.NewServerMetics(outBandIp, "", 0).ToString("ipmi_up")
	ipmitRst, _ := client.VectorQuery(ipmi)
	if len(ipmitRst) != 0 { //  Intlet Temp 有值
		if !math.IsNaN(float64(ipmitRst[0].Value)) {
			ipmiStatus.Value = float64(ipmitRst[0].Value)
		}
	}
	res = append(res, ipmiStatus)
	return res
}

// 服务器硬件监控概览 进风口温度
func ServerHardwareOverviewInTempStatus(outBandIp string) (res []servermodels.StateType) {
	//获取进风口温度
	inTemp := servermodels.StateType{Name: "进风口", Value: 0}
	inlet := temp.NewServerMetics(outBandIp, "", 0).ToString("ipmi_temperature_celsius_inlet")
	inletRst, err := client.VectorQuery(inlet)
	if err != nil {
		klog.Info(err)
	}
	if len(inletRst) != 0 { //  Intlet Temp 有值
		if !math.IsNaN(float64(inletRst[0].Value)) {
			inTemp.Value = float64(inletRst[0].Value)
		}
	} else { // Intlet Temp 无值
		inletTwo := temp.NewServerMetics(outBandIp, "", 0).ToString("ipmi_temperature_celsius_inlet_two")
		inletRstTwo, _ := client.VectorQuery(inletTwo)
		if len(inletRstTwo) != 0 { // Intlet_Temp 有值
			if !math.IsNaN(float64(inletRstTwo[0].Value)) {
				inTemp.Value = float64(inletRstTwo[0].Value)
			}
		}
	}
	res = append(res, inTemp) // 进风口温度
	return res
}

// 服务器硬件监控概览 出风口温度
func ServerHardwareOverviewOutTempStatus(outBandIp string) (res []servermodels.StateType) {
	//获取进风口温度
	outTemp := servermodels.StateType{Name: "出风口", Value: 0}
	outlet := temp.NewServerMetics(outBandIp, "", 0).ToString("ipmi_temperature_celsius_outlet")
	outletRst, err := client.VectorQuery(outlet)
	if err != nil {
		klog.Error(err)
	}
	if len(outletRst) != 0 {
		if !math.IsNaN(float64(outletRst[0].Value)) {
			outTemp.Value = float64(outletRst[0].Value)
		}
	} else {
		outletTwo := temp.NewServerMetics(outBandIp, "", 0).ToString("ipmi_temperature_celsius_outlet_two")
		outletRstTwo, _ := client.VectorQuery(outletTwo)
		if len(outletRstTwo) != 0 { // Intlet_Temp 有值
			if !math.IsNaN(float64(outletRstTwo[0].Value)) {
				outTemp.Value = float64(outletRstTwo[0].Value)
			}
		}
	}
	res = append(res, outTemp) // 出风口温度
	return res
}

//状态列表
var stateSlice = []servermodels.State{
	servermodels.State{
		State: "0",
		Name:  "正常",
	},
	servermodels.State{
		State: "1",
		Name:  "告警",
	},
	servermodels.State{
		State: "2",
		Name:  "故障",
	},
	servermodels.State{
		State: "NaN",
		Name:  "未知",
	},
}

// 服务器硬件监控概览 cpu状态
func ServerHardwareOverviewCpuStatus(outBandIp string, cpuNum int) (res []servermodels.StateType) {
	//cpu 健康状态
	cpuStateList := []float64{}
	cpuQuery := temp.NewServerMetics(outBandIp, "", 0).ToString("ipmi_sensor_state_cpu_count_values_new")
	cRst, _ := client.VectorQuery(cpuQuery)
	for _, v := range cRst {
		if math.IsNaN(float64(v.Value)) {
			continue
		}
		name := string(v.Metric["name"])
		if strings.Contains(name, "CPU") && strings.Contains(name, "Status") {
			cpuStateList = append(cpuStateList, float64(v.Value))
		} else if strings.Contains(name, "Status") {
			cpuStateList = append(cpuStateList, float64(v.Value))
		}
	}
	klog.Infof("cpuStateList", cpuStateList)
	if len(cpuStateList) > 0 {
		var stateMapCpu = map[float64]int{}
		for _, vvv := range cpuStateList {
			if v, ok := stateMapCpu[vvv]; ok {
				stateMapCpu[vvv] = v + 1
			} else {
				stateMapCpu[vvv] = 1
			}
		}
		for _, vv := range stateSlice {
			aa, _ := strconv.ParseFloat(vv.State, 64)
			rr, ok := stateMapCpu[aa]
			if ok {
				info := servermodels.StateType{Name: vv.Name, Value: float64(rr)}
				res = append(res, info)
			} else {
				info := servermodels.StateType{Name: vv.Name, Value: float64(0)}
				res = append(res, info)
			}
		}
	} else {
		for _, vv := range stateSlice {
			var info servermodels.StateType
			if vv.Name == "正常" {
				info = servermodels.StateType{Name: "正常", Value: float64(cpuNum), Remarks: "列表数据"}
			} else {
				info = servermodels.StateType{Name: vv.Name, Value: float64(0)}
			}
			res = append(res, info)
		}
	}
	return res
}

// 服务器硬件监控概览 mem状态
func ServerHardwareOverviewMemStatus(outBandIp, manufacturer string, memoryInfo []cmdb.MemoryDeviceInfo) (res []servermodels.StateType) {
	memStateList := []float64{}
	memQuery := temp.NewServerMetics(outBandIp, "", 0).ToString("ipmi_sensor_state_memory_count_values")
	mRst, err := client.VectorQuery(memQuery)
	if err != nil {
		klog.Infof("get_ipmi_sensor_state_memory_count_values_fail", err)
	}
	for _, vv := range memoryInfo { // 循环内存列表
		klog.Infof("out_ip %s mem_deviceLocator_name %s", outBandIp, vv.DeviceLocator)
		for _, v := range mRst { // 匹配数据
			if math.IsNaN(float64(v.Value)) {
				continue
			}
			name := string(v.Metric["name"]) //ipmi返回名称
			klog.Infof("out_ip %s mem_metric_name %s", outBandIp, name)
			if name == vv.DeviceLocator { // ipmi返回名称与agent名称相同
				memStateList = append(memStateList, float64(v.Value))
			} else {
				klog.Infof("SysInfo_Manufacturer", manufacturer)
				switch manufacturer { //服务器型号
				case "Huawei": // 华为
					deviceLocator := strings.Split(vv.DeviceLocator, " ")
					if name == deviceLocator[0] {
						memStateList = append(memStateList, float64(v.Value))
					}
				case "Sugon": // 中科曙光
					if strings.Contains(name, "Status") { //ipmi返回名称包括Status
						deviceLocator := strings.Split(vv.DeviceLocator, "_")
						metricName := strings.Split(name, "_")
						m := metricName[0] + "_" + metricName[1]
						d := deviceLocator[0] + "_" + deviceLocator[2]
						if m == d {
							memStateList = append(memStateList, float64(v.Value))
						}
					} else if strings.Contains(name, "Stat") { // ipmi返回名称包括Stat
						//
						m := name[0 : len(name)-5]
						if m == vv.DeviceLocator {
							memStateList = append(memStateList, float64(v.Value))
						}
					} else {
						// ipmi CPU2_A1  agent CPU0_DIMM_A0
						//deviceLocator := strings.Split(vv.DeviceLocator, "_")

						//d := deviceLocator[0] + "_" + deviceLocator[2]
						if name == vv.DeviceLocator {
							memStateList = append(memStateList, float64(v.Value))
						}
					}
				case "Inspur":
					//浪潮 ipmi CPU1_C4D0   agent CPU1_CH4_DIMM0
					d1 := strings.Replace(vv.DeviceLocator, "H", "", -1)
					d2 := strings.Replace(d1, "IMM", "", -1)
					d3 := strings.Split(d2, "_")
					if len(d3) != 3 {
						continue
					}
					deviceLocator := d3[0] + "_" + d3[1] + d3[2]
					if name == deviceLocator {
						memStateList = append(memStateList, float64(v.Value))
					}
				case "H3C":
					//ipmi CPU1_DIMM_A1  agent Processor1 Ch1 DIMM A1
					if strings.Contains(vv.DeviceLocator, "DIMM") {
						d1 := strings.Replace("Processor1 Ch1 DIMM A1", "Processor", "CPU", -1)
						d2 := strings.Replace(d1, " Ch1 ", "_", -1)
						deviceLocator := strings.Replace(d2, " ", "_", -1)
						if name == deviceLocator {
							memStateList = append(memStateList, float64(v.Value))
						}
					} else {
						//ipmi CPU2_A1  agent CPU1_CH1_D0(A0)
						if len(vv.DeviceLocator) > 12 {
							d1 := vv.DeviceLocator
							d2 := d1[:5] + d1[12:]
							deviceLocator := strings.Trim(d2, ")")
							if name == deviceLocator {
								memStateList = append(memStateList, float64(v.Value))
							}
						}
					}

				}
			}
		}
	}
	klog.Infof("memStateList", memStateList)
	if len(memStateList) > 0 { // 有匹配数据

		var stateMapMem = map[float64]int{}
		for _, vvv := range memStateList {
			if v, ok := stateMapMem[vvv]; ok {
				stateMapMem[vvv] = v + 1
			} else {
				stateMapMem[vvv] = 1
			}
		}
		for _, vv := range stateSlice {
			aa, _ := strconv.ParseFloat(vv.State, 64)
			rr, ok := stateMapMem[aa]
			if ok {
				info := servermodels.StateType{Name: vv.Name, Value: float64(rr)}
				res = append(res, info)
			} else {
				info := servermodels.StateType{Name: vv.Name, Value: float64(0)}
				res = append(res, info)
			}
		}
	} else {
		for _, vv := range stateSlice {
			var info servermodels.StateType
			if vv.Name == "正常" {
				info = servermodels.StateType{Name: "正常", Value: float64(len(memoryInfo)), Remarks: "列表数据"}
			} else {
				info = servermodels.StateType{Name: vv.Name, Value: float64(0)}
			}
			res = append(res, info)
		}
	}

	return res
}

// 服务器硬件监控概览 disk状态
func ServerHardwareOverviewDiskStatus(outBandIp string, diskNum int) (res []servermodels.StateType) {

	////硬盘健康状态
	//rst.DiskState = []servermodels.StateType{}
	//stateMapDisk := map[string]servermodels.StateType{}
	//diskQuery := temp.NewServerMetics(ipip, "", 0).ToString("ipmi_sensor_state_disk_count_values")
	//dRst, err := client.VectorQuery(diskQuery)
	//klog.Infof("硬盘 dRst", dRst)
	//if err != nil {
	//	klog.Info(err)
	//}
	//for _, v := range dRst {
	//	if math.IsNaN(float64(v.Value)) {
	//		v.Value = 0
	//	}
	//	vv := servermodels.StateType{Name: StateMap[string(v.Metric["state"])], Value: float64(v.Value)}
	//	stateMapDisk[string(v.Metric["state"])] = vv
	//	//rst.DiskState = append(rst.DiskState, vv)
	//}
	//for _, vv := range stateSlice {
	//	rr, ok := stateMapDisk[vv.State]
	//	if ok {
	//		rst.DiskState = append(rst.DiskState, rr)
	//	} else {
	//		vvv := servermodels.StateType{Name: vv.Name, Value: float64(0)}
	//		rst.DiskState = append(rst.DiskState, vvv)
	//	}
	//}
	//

	//硬盘健康状态 写死
	for _, vv := range stateSlice {
		if vv.Name == "正常" {
			vvv := servermodels.StateType{Name: vv.Name, Value: float64(diskNum)}
			res = append(res, vvv)
		} else {
			vvv := servermodels.StateType{Name: vv.Name, Value: float64(0)}
			res = append(res, vvv)
		}
	}
	return res
}

// 服务器硬件监控概览 power状态
func ServerHardwareOverviewPowerStatus(outBandIp string) (res []servermodels.StateType) {
	stateMapPower := map[string]servermodels.StateType{}
	powerQuery := temp.NewServerMetics(outBandIp, "", 0).ToString("ipmi_sensor_state_power_count_values")
	pRst, err := client.VectorQuery(powerQuery)
	klog.Infof("电池 pRst", pRst)
	if err != nil {
		klog.Info(err)
	}
	for _, v := range pRst {
		if math.IsNaN(float64(v.Value)) {
			v.Value = 0
		}
		vv := servermodels.StateType{Name: StateMap[string(v.Metric["state"])], Value: float64(v.Value)}
		stateMapPower[string(v.Metric["state"])] = vv
	}

	for _, vv := range stateSlice {
		rr, ok := stateMapPower[vv.State]
		if ok {
			res = append(res, rr)
		} else {
			vvv := servermodels.StateType{Name: vv.Name, Value: float64(0)}
			res = append(res, vvv)
		}
	}

	return res
}

// 服务器硬件监控概览 fan状态
func ServerHardwareOverviewFanStatus(outBandIp string) (res []servermodels.StateType) {
	stateMapFan := map[string]servermodels.StateType{}
	fanQuery := temp.NewServerMetics(outBandIp, "", 0).ToString("ipmi_sensor_state_fan_count_values_new")
	fRst, err := client.VectorQuery(fanQuery)
	klog.Infof("风扇 fRst", fRst)
	if err != nil {
		klog.Info(err)
	}
	for _, v := range fRst {
		if math.IsNaN(float64(v.Value)) {
			v.Value = 0
		}
		vv := servermodels.StateType{Name: StateMap[string(v.Metric["state"])], Value: float64(v.Value)}
		stateMapFan[string(v.Metric["state"])] = vv
	}

	for _, vv := range stateSlice {
		rr, ok := stateMapFan[vv.State]
		if ok {
			res = append(res, rr)
		} else {
			vvv := servermodels.StateType{Name: vv.Name, Value: float64(0)}
			res = append(res, vvv)
		}
	}

	return res
}

func (s *PhysicalServerService) GetServerHardwareMetric(ip string) (rst servermodels.HardWare, err error) {
	klog.Info("GetServerMetric")
	var outBandIp, sn string
	//获取服务器详情
	res, err := cmdb.GetAllPhysicalHostInfo(cmdb.GetPhysicalHostInfo{
		IP: ip,
	})

	if len(res.Data.DataList) == 0 {
		klog.Error("GetAllPhysicalHostInfo_Fail", err)
		return rst, err
	}

	for _, v := range res.Data.DataList {
		if v.Ip == ip {
			sn = v.Sn
			outBandIp = v.OutbandIP
		}
	}

	// 获取服务器硬件数据
	hardware, err := cmdb.GetphysicalHostHardware(sn)
	if err != nil || len(hardware.SysInfo) == 0 {
		klog.Error(err)
		return
	}
	manufacturer := hardware.SysInfo[0].Manufacturer // 服务器型号

	rst.IpmiStatus = ServerHardwareOverviewOutBandIpStatus(outBandIp)
	rst.InTemp = ServerHardwareOverviewInTempStatus(outBandIp)
	rst.OutTemp = ServerHardwareOverviewOutTempStatus(outBandIp)
	rst.CpuState = ServerHardwareOverviewCpuStatus(outBandIp, len(hardware.CpuInfo))
	rst.MemState = ServerHardwareOverviewMemStatus(outBandIp, manufacturer, hardware.MemoryInfo)
	rst.DiskState = ServerHardwareOverviewDiskStatus(outBandIp, len(hardware.DiskInfo))
	rst.PowerState = ServerHardwareOverviewPowerStatus(outBandIp)
	rst.FanState = ServerHardwareOverviewFanStatus(outBandIp)

	//cpu列表
	for _, v := range hardware.CpuInfo {
		rst.Cpu.Cores += int(v.CoreCount)
		rst.Cpu.Sum++
		vv := servermodels.Cpu{Name: v.SocketDesignation, Model: v.Model, ClockSpeed: v.CurrentSpeed, MaxClock: v.MaxSpeed, Cores: v.CoreCount, Threads: v.ThreadCount, L1Cache: v.L1iCache + v.L1dCache, L2Cache: v.L2Cache, L3Cache: v.L3Cache}
		rst.Cpu.CpuList = append(rst.Cpu.CpuList, vv)
	}
	//内存列表
	var memCapTotal int
	for _, v := range hardware.MemoryInfo {
		memCapTotal += int(v.Size)
		rst.Mem.Sum++
		vv := servermodels.Memory{Position: v.DeviceLocator, Model: v.PartNumber, Width: int(v.TotalWidth), MaxClock: int(v.Speed), Capacity: services.FormCMDBStorageM(int(v.Size)), Tech: v.FormFactor, Sn: v.SerialNumber, ProducFactory: v.Manufacturer}
		rst.Mem.MemList = append(rst.Mem.MemList, vv)
	}
	rst.Mem.Capacity = services.FormCMDBStorageM(memCapTotal)
	//硬盘列表
	var diskCapTotal int64
	for _, v := range hardware.DiskInfo {
		vSize := typeToRealSize(v.Size)
		diskCapTotal += vSize
		rst.Disk.Sum++
		var diskType string
		if v.DiskType == "0" {
			diskType = "sdd"
		} else if v.DiskType == "" {
			diskType = "hdd"
		}
		vv := servermodels.Disk{
			Name:          v.DiskName,
			ProducFactory: v.Vendor,
			DiskType:      diskType,
			UsedRate:      v.DiskRate,
			Model:         v.Model,
			Sn:            v.SerialNumber,
			Capacity:      services.FormatSizeForHardware(float64(vSize)),
		}
		rst.Disk.DiskList = append(rst.Disk.DiskList, vv)
	}
	rst.Disk.Capacity = services.FormatSizeForHardware(float64(diskCapTotal))

	// 主板
	for _, v := range hardware.BaseboardInfo {
		mainBoard := servermodels.MainBoard{Name: v.Model, State: 0, ProducFactory: v.Manufacturer, Sn: v.SerialNumber}
		rst.MainBoardList = append(rst.MainBoardList, mainBoard)
	}
	//电源
	rst.PowerList = make([]servermodels.Power, 0)
	powerList := temp.NewServerMetics(outBandIp, "", 0).ToString("ipmi_sensor_state_power")
	plRst, err := client.VectorQuery(powerList)
	if err != nil {
		klog.Info(err)
	}
	for _, v := range plRst {
		if math.IsNaN(float64(v.Value)) {
			v.Value = 0
		}
		vv := servermodels.Power{Id: string(v.Metric["id"]), State: float64(v.Value)}
		rst.PowerList = append(rst.PowerList, vv)
	}
	//风扇
	rst.FanList = make([]servermodels.Fan, 0)
	fanList := temp.NewServerMetics(outBandIp, "", 0).ToString("ipmi_fan_speed_rpm")
	flRst, err := client.VectorQuery(fanList)
	if err != nil {
		klog.Info(err)
	}
	for _, v := range flRst {
		if math.IsNaN(float64(v.Value)) {
			v.Value = 0
		}
		vv := servermodels.Fan{Name: string(v.Metric["name"]), Speed: float64(v.Value)}
		rst.FanList = append(rst.FanList, vv)
	}

	//work列表
	for _, v := range hardware.WorkInfo {
		speed := services.FormatSizePerSecond(float64(v.Size))
		pattern := "en|eth|em|x"
		match, err1 := regexp.MatchString(pattern, v.Name)
		if err1 != nil {
			fmt.Println("正则匹配出错:", err)
			return
		}
		if !match {
			continue
		}
		vv := servermodels.Work{Name: v.Name, HealthStatus: v.HealthStatus,
			Product: v.Product, Vendor: v.Vendor, Speed: speed}
		rst.Work = append(rst.Work, vv)
	}

	//
	return

}

func QueryPhysicalMetric(ip, start, end, step string, metrics []string) []servermodels.ResponseMetric {

	responseMetric := []servermodels.ResponseMetric{}

	for i := 0; i < len(metrics); i++ {
		switch metrics[i] {
		case "Up":
			r := servermodels.ResponseMetric{Metric: metrics[i]}
			upQuery := temp.NewServerMetics(ip+":9100", "", 0).ToString("server_up")
			up, err := client.VectorQuery(upQuery)
			if err != nil {
				klog.Info(err)
			}
			for _, v := range up {
				if math.IsNaN(float64(v.Value)) {
					v.Value = 0
				}
				if float64(v.Value) == 1 {
					r.Value = "up"
				} else {
					r.Value = "down"
				}
			}
			responseMetric = append(responseMetric, r)
		case "CPULoad":
			r := servermodels.ResponseMetric{Metric: metrics[i]}
			cpuQuery := temp.NewServerMetics(ip+":9100", "", 0).ToString("server_cpu_usage_rate_new")
			cpu, err := client.VectorQuery(cpuQuery)
			if err != nil {
				klog.Info(err)
			}
			for _, v := range cpu {
				if math.IsNaN(float64(v.Value)) {
					v.Value = 0
				}
				klog.Info(v.Value)
				r.Value = services.FormPercent(float64(v.Value))
			}
			responseMetric = append(responseMetric, r)
		case "MemoryUse":
			r := servermodels.ResponseMetric{Metric: metrics[i]}
			cpuQuery := temp.NewServerMetics(ip+":9100", "", 0).ToString("server_memory_usage_rate")
			cpu, err := client.VectorQuery(cpuQuery)
			if err != nil {
				klog.Info(err)
			}
			for _, v := range cpu {
				if math.IsNaN(float64(v.Value)) {
					v.Value = 0
				}
				r.Value = services.FormPercent(float64(v.Value))
			}
			responseMetric = append(responseMetric, r)
		case "DiskFree":
			r := servermodels.ResponseMetric{Metric: metrics[i]}
			cpuQuery := temp.NewServerMetics(ip+":9100", "", 0).ToString("server_disk_usage_rate")
			cpu, err := client.VectorQuery(cpuQuery)
			if err != nil {
				klog.Info(err)
			}
			for _, v := range cpu {
				if math.IsNaN(float64(v.Value)) {
					v.Value = 0
				}
				r.Value = services.FormPercent(float64(v.Value))
			}
			responseMetric = append(responseMetric, r)
		case "NetIn":
			r := servermodels.ResponseMetric{Metric: metrics[i]}
			cpuQuery := temp.NewServerMetics(ip+":9100", "", 0).ToString("server_network_receive_24h")
			cpu, err := client.VectorQuery(cpuQuery)
			if err != nil {
				klog.Info(err)
			}
			for _, v := range cpu {
				if math.IsNaN(float64(v.Value)) {
					v.Value = 0
				}
				r.Value = services.FormPercent(float64(v.Value))
			}
			responseMetric = append(responseMetric, r)
		case "NetOut":
			r := servermodels.ResponseMetric{Metric: metrics[i]}
			cpuQuery := temp.NewServerMetics(ip+":9100", "", 0).ToString("server_network_transmit_24h")
			cpu, err := client.VectorQuery(cpuQuery)
			if err != nil {
				klog.Info(err)
			}
			for _, v := range cpu {
				if math.IsNaN(float64(v.Value)) {
					v.Value = 0
				}
				r.Value = services.FormPercent(float64(v.Value))
			}
			responseMetric = append(responseMetric, r)
		case "Disk":
			r := servermodels.ResponseMetric{}
			cpuQuery := temp.NewServerMetics(ip+":9100", "", 0).ToString("server_disk_avail_every")
			cpu, err := client.VectorQuery(cpuQuery)
			if err != nil {
				klog.Info(err)
			}
			// for _, v := range cpu {
			// 	if math.IsNaN(float64(v.Value)) {
			// 		v.Value = 0
			// 	}
			// 	r.Value = services.FormPercent(v.Value)
			// }
			r.Metric = metrics[i]
			r.Value = cpu
			responseMetric = append(responseMetric, r)
		}
	}
	return responseMetric
}

//func resultHandler (r []prometheusModel.ResponseMetric) []ResponseMetric {
//	res := []ResponseMetric{}
//	for i := 0; i < len(r); i++ {
//		for j := 0; j < len(r[i].Value.Result); j++ {
//			re := ResponseMetric{}
//			re.Metric = r[i].Metric
//			re.Value = r[i].Value.Result[j].Value
//			res = append(res,re)
//		}
//	}
//	return res
//}

//func NewQueryNetworkAndDisk(ip, start, end, step string, metrics []string) []servermodels.MetricResult {
//	responseMetric := []servermodels.MetricResult{}
//	step1 := services.TimeToStepForInt(1660619027 - 1658027027)
//	for i := 0; i < len(metrics); i++ {
//		switch metrics[i] {
//		case "CPUMode":
//			values, err := client.MatrixQuery(network.NewNetworkMetics(ip+":9100").ToString("node_cpu_seconds_total"), v1.Range{
//				Start: time.Unix(1658027027, 0),
//				End:   time.Unix(1660619027, 0),
//				Step:  time.Duration(step1) * time.Second,
//			})
//			if err != nil {
//				klog.Errorf("Failed to get %s usage: %s", err.Error())
//				continue
//			}
//
//
//			//			for j := 0; j < len(l); j++ {
//			//				r := servermodels.MetricResult{}
//			//
//			//				ll := l[j].(map[string]interface{})
//			//				lll := ll["metric"].(map[string]interface{})
//			//
//			//				for o := 0; o < len(c); o++ {
//			//					oo := c[o].(map[string]interface{})
//			//					ooo := oo["metric"].(map[string]interface{})
//			//					if ooo["mode"] == lll["mode"] {
//			//						r.Current = prom.PrometheusResultToValue2(c[o])
//			//					}
//			//				}
//			//				//r.Current = prom.PrometheusResultToValue2(c[j])
//			//
//			//				//aa := prom.PrometheusResultToValue2(a)
//			//				r.Name = lll["mode"]
//			//
//			//				//r.Current = cc[j]
//			//				s := getSlice(l[j])
//			//				r.Avg = prom.FormValue(getAvg(s))
//			//				r.Value = prom.PrometheusResultToValue2(l[j])
//			//				//r.Value = llll[j]
//			//				responseMetric = append(responseMetric, r)
//			//			}
//
//
//
//			// 实际数据
//			for _, ii := range values {
//				r := servermodels.MetricResult{}
//				r.Name = ii.Metric
//
//				for _, j := range ii.Values {
//					timeStr := time.Unix(j.Timestamp.Unix(), 0).Format("2006-01-02 15:04:05")
//					r.Value := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: services.FormPercent(j.Value.String()), IsForecast: false, Day: timeStr}
//					responseMetric = append(responseMetric, r)
//				}
//			}
//		}
//	}
//	return responseMetric
//}

var MetricWorkMap = map[string]struct{}{
	//network
	"Receive":     struct{}{},
	"Transmit":    struct{}{},
	"ErrDropIn":   struct{}{},
	"ErrDropOut":  struct{}{},
	"LoseDropIn":  struct{}{},
	"LoseDropOut": struct{}{},
}

func QueryNetworkAndDisk(ip, start, end, step, workName string, metrics []string) []servermodels.MetricResult {

	responseMetric := []servermodels.MetricResult{}

	for i := 0; i < len(metrics); i++ {
		switch metrics[i] {
		case "file":
			r := []servermodels.MetricResult{}
			l, _ := prom.PrometheusQuery2(true, start, end, step, `node_filesystem_avail_bytes{instance=~"`+ip+`:9100"`+`,fstype!~"(tmpfs|rootfs)"}`)
			c, _ := prom.PrometheusQuery2(false, "", "", "", `node_filesystem_avail_bytes{instance=~"`+ip+`:9100"`+`,fstype!~"(tmpfs|rootfs)"}`)
			for j := 0; j < len(l); j++ {
				rr := servermodels.MetricResult{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				for o := 0; o < len(c); o++ {
					oo := c[o].(map[string]interface{})
					ooo := oo["metric"].(map[string]interface{})
					if ooo["mountpoint"] == lll["mountpoint"] {
						rr.Current = prom.PrometheusResultToValueForSize(c[o])
					}
				}

				//rr.Current = prom.PrometheusResultToValueForSize(c[j])

				rr.Name = lll["mountpoint"].(string)

				rr.Value = prom.PrometheusResultToValue2(l[j])

				r = append(r, rr)
			}
			responseMetric = append(responseMetric, r...)
		case "Read":
			//min, _ := prom.PrometheusQuery2(false, "", "", "", `min_over_time(node_disk_read_bytes_total{instance=~"`+ip+`:9100"`+`}[1h])`)
			//max, _ := prom.PrometheusQuery2(false, "", "", "", `max_over_time(node_disk_read_bytes_total{instance=~"`+ip+`:9100"`+`}[1h])`)
			l, _ := prom.PrometheusQuery2(true, start, end, step, `irate(node_disk_read_bytes_total{instance=~"`+ip+`:9100"`+`}[5m])`)
			for j := 0; j < len(l); j++ {
				r := servermodels.MetricResult{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				s := getSlice(l[j])

				r.Name = "Read:" + lll["device"].(string)

				r.Min = services.FormatSizePerSecond(getMin(s))
				r.Max = services.FormatSizePerSecond(getMax(s))
				r.Value = prom.PrometheusResultToValue2(l[j])
				//r.Value = llll[j]
				responseMetric = append(responseMetric, r)
			}
		case "Write":
			//min, _ := prom.PrometheusQuery2(false, "", "", "", `min_over_time(node_disk_written_bytes_total{instance=~"`+ip+`:9100"`+`}[1h])`)
			//max, _ := prom.PrometheusQuery2(false, "", "", "", `max_over_time(node_disk_written_bytes_total{instance=~"`+ip+`:9100"`+`}[1h])`)
			l, _ := prom.PrometheusQuery2(true, start, end, step, `irate(node_disk_written_bytes_total{instance=~"`+ip+`:9100"`+`}[5m])`)
			for j := 0; j < len(l); j++ {
				r := servermodels.MetricResult{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				s := getSlice(l[j])

				r.Name = "Write:" + lll["device"].(string)

				r.Min = services.FormatSizePerSecond(getMin(s))
				r.Max = services.FormatSizePerSecond(getMax(s))
				r.Value = prom.PrometheusResultToValue2(l[j])
				//r.Value = llll[j]
				responseMetric = append(responseMetric, r)
			}
		case "write":
			//min, _ := prom.PrometheusQuery2(false, "", "", "", `min_over_time(node_disk_write_time_seconds_total{instance=~"`+ip+`:9100"`+`}[1h])`)
			//max, _ := prom.PrometheusQuery2(false, "", "", "", `max_over_time(node_disk_write_time_seconds_total{instance=~"`+ip+`:9100"`+`}[1h])`)
			l, _ := prom.PrometheusQuery2(true, start, end, step, `irate(node_disk_write_time_seconds_total{instance=~"`+ip+`:9100"`+`}[5m])`)
			for j := 0; j < len(l); j++ {
				r := servermodels.MetricResult{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				s := getSlice(l[j])

				r.Name = "Write:" + lll["device"].(string)

				r.Min = services.FormatSecond(getMin(s))
				r.Max = services.FormatSecond(getMax(s))
				r.Value = prom.PrometheusResultToValue2(l[j])
				//r.Value = llll[j]
				responseMetric = append(responseMetric, r)
			}
		case "read":
			l, _ := prom.PrometheusQuery2(true, start, end, step, `irate(node_disk_read_time_seconds_total{instance=~"`+ip+`:9100"`+`}[5m])`)
			for j := 0; j < len(l); j++ {
				r := servermodels.MetricResult{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				s := getSlice(l[j])

				r.Name = "Read:" + lll["device"].(string)
				r.Min = services.FormatSecond(getMin(s))
				r.Max = services.FormatSecond(getMax(s))
				r.Value = prom.PrometheusResultToValue2(l[j])
				//r.Value = llll[j]
				responseMetric = append(responseMetric, r)
			}
		case "Receive":
			l, _ := prom.PrometheusQuery2(true, start, end, step, `irate(node_network_receive_bytes_total{instance=~"`+ip+`:9100"`+`,device="`+workName+`"}[5m])`)
			for j := 0; j < len(l); j++ {
				r := servermodels.MetricResult{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				s := getSlice(l[j])

				r.Name = "In:" + lll["device"].(string)

				min, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", getMin(s)), 64)
				max, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", getMax(s)), 64)
				r.Min = min
				r.Max = max
				r.Value = prom.PrometheusResultToValue2(l[j])
				//r.Value = llll[j]
				responseMetric = append(responseMetric, r)
			}
		case "Transmit":
			l, _ := prom.PrometheusQuery2(true, start, end, step, `irate(node_network_transmit_bytes_total{instance=~"`+ip+`:9100"`+`,device="`+workName+`"}[5m])`)
			for j := 0; j < len(l); j++ {
				r := servermodels.MetricResult{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				s := getSlice(l[j])

				r.Name = "Out:" + lll["device"].(string)

				min, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", getMin(s)), 64)
				max, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", getMax(s)), 64)
				r.Min = min
				r.Max = max
				r.Value = prom.PrometheusResultToValue2(l[j])
				responseMetric = append(responseMetric, r)
			}
		case "ErrDropIn": // 误包统计接收
			l, _ := prom.PrometheusQuery2(true, start, end, step, `irate(node_network_receive_errs_total{instance=~"`+ip+`:9100"`+`,device="`+workName+`"}[5m])`)

			for j := 0; j < len(l); j++ {
				r := servermodels.MetricResult{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				s := getSlice(l[j])

				r.Name = "Err/Drop in:" + lll["device"].(string)

				r.Min = services.Strval(getMin(s)) + "p/s"
				r.Max = services.Strval(getMax(s)) + "p/s"
				r.Value = prom.PrometheusResultToValue2(l[j])
				//r.Value = llll[j]
				responseMetric = append(responseMetric, r)
			}
		case "ErrDropOut": //误包统计发送
			l, _ := prom.PrometheusQuery2(true, start, end, step, `irate(node_network_transmit_errs_total{instance=~"`+ip+`:9100"`+`,device="`+workName+`"}[5m])`)

			for j := 0; j < len(l); j++ {
				r := servermodels.MetricResult{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				s := getSlice(l[j])

				r.Name = "Err/Drop out:" + lll["device"].(string)

				r.Min = services.Strval(getMin(s)) + "p/s"
				r.Max = services.Strval(getMax(s)) + "p/s"
				fmt.Println("l[j]", l[j])
				r.Value = prom.PrometheusResultToValue2(l[j])
				//r.Value = llll[j]
				responseMetric = append(responseMetric, r)
			}
		case "LoseDropOut": // 丢包统计发送
			l, _ := prom.PrometheusQuery2(true, start, end, step, `irate(node_network_receive_drop_total{instance=~"`+ip+`:9100"`+`,device="`+workName+`"}[5m])`)
			for j := 0; j < len(l); j++ {
				r := servermodels.MetricResult{}
				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				s := getSlice(l[j])
				r.Name = "Lose/Drop out:" + lll["device"].(string)
				r.Min = services.Strval(getMin(s)) + "p/s"
				r.Max = services.Strval(getMax(s)) + "p/s"
				r.Value = prom.PrometheusResultToValue2(l[j])
				responseMetric = append(responseMetric, r)
			}
		case "LoseDropIn": //丢包统计接收
			l, _ := prom.PrometheusQuery2(true, start, end, step, `irate(node_network_transmit_drop_total{instance=~"`+ip+`:9100"`+`,device="`+workName+`"}[5m])`)
			for j := 0; j < len(l); j++ {
				r := servermodels.MetricResult{}
				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				s := getSlice(l[j])
				r.Name = "Lose/Drop in:" + lll["device"].(string)
				r.Min = services.Strval(getMin(s)) + "p/s"
				r.Max = services.Strval(getMax(s)) + "p/s"
				r.Value = prom.PrometheusResultToValue2(l[j])
				responseMetric = append(responseMetric, r)
			}
		case "Free":
			l, _ := prom.PrometheusQuery2(true, start, end, step, `node_memory_MemFree_bytes{instance=~"`+ip+`:9100"`+`}>0`)
			c, _ := prom.PrometheusQuery2(false, "", "", "", `node_memory_MemFree_bytes{instance=~"`+ip+`:9100"`+`}>0`)
			if len(c) > 0 {
				for j := 0; j < len(l); j++ {
					r := servermodels.MetricResult{}

					//ll := l[i].(map[string]interface{})
					//lll := ll["metric"].(map[string]interface{})

					//cc := prom.PrometheusResultToValueForSize(c)

					r.Name = "free"

					r.Current = prom.PrometheusResultToValueForSize(c[0])
					//llll := prom.PrometheusResultToValueForSize(l)
					r.Value = prom.PrometheusResultToValue2(l[j])
					responseMetric = append(responseMetric, r)
				}
			}

		case "Total":
			l, _ := prom.PrometheusQuery2(true, start, end, step, `node_memory_MemTotal_bytes{instance=~"`+ip+`:9100"`+`}>0`)
			c, _ := prom.PrometheusQuery2(false, "", "", "", `node_memory_MemTotal_bytes{instance=~"`+ip+`:9100"`+`}>0`)
			if len(c) > 0 {
				for j := 0; j < len(l); j++ {
					r := servermodels.MetricResult{}

					//ll := l[i].(map[string]interface{})
					//lll := ll["metric"].(map[string]interface{})

					//cc := prom.PrometheusResultToValueForSize(c)

					r.Name = "total"

					r.Current = prom.PrometheusResultToValueForSize(c[0])
					r.Value = prom.PrometheusResultToValue2(l[j])
					//r.Value = llll[j]
					responseMetric = append(responseMetric, r)
				}
			}

		case "Available":
			l, _ := prom.PrometheusQuery2(true, start, end, step, `node_memory_MemAvailable_bytes{instance=~"`+ip+`:9100"`+`}>0`)
			c, _ := prom.PrometheusQuery2(false, "", "", "", `node_memory_MemAvailable_bytes{instance=~"`+ip+`:9100"`+`}>0`)
			if len(c) > 0 {
				for j := 0; j < len(l); j++ {
					r := servermodels.MetricResult{}

					//ll := l[i].(map[string]interface{})
					//lll := ll["metric"].(map[string]interface{})

					r.Current = prom.PrometheusResultToValueForSize(c[0])

					r.Name = "Available"

					r.Value = prom.PrometheusResultToValue2(l[j])
					responseMetric = append(responseMetric, r)
				}
			}
		case "CPUMode":
			l, _ := prom.PrometheusQuery2(true, start, end, step, `sum(irate(node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`}[5m]))by(mode)`)
			c, _ := prom.PrometheusQuery2(false, "", "", "", `sum(irate(node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`}[5m]))by(mode)`)
			//a, _ := prom.PrometheusQuery2(false, "", "", "", `avg(node_cpu_seconds_total{instance=~"`+ip+`:9100"`+`})by(mode)`)
			for j := 0; j < len(l); j++ {
				r := servermodels.MetricResult{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				for o := 0; o < len(c); o++ {
					oo := c[o].(map[string]interface{})
					ooo := oo["metric"].(map[string]interface{})
					if ooo["mode"] == lll["mode"] {
						r.Current = prom.PrometheusResultToValue2(c[o])
					}
				}
				//r.Current = prom.PrometheusResultToValue2(c[j])

				//aa := prom.PrometheusResultToValue2(a)
				r.Name = lll["mode"]

				//r.Current = cc[j]
				s := getSlice(l[j])
				r.Avg = prom.FormValue(getAvg(s))
				r.Value = prom.PrometheusResultToValue2(l[j])
				//r.Value = llll[j]
				responseMetric = append(responseMetric, r)
			}
		case "CPUAvgMode":
			nodeLoad1, _ := prom.PrometheusQuery2(true, start, end, step, `node_load1{instance="`+ip+`:9100"`+`}`)
			nodeLoad1Current, _ := prom.PrometheusQuery2(false, "", "", "", `node_load1{instance="`+ip+`:9100"`+`}`)

			node_load5, _ := prom.PrometheusQuery2(true, start, end, step, `node_load5{instance="`+ip+`:9100"`+`}`)
			node_load5Current, _ := prom.PrometheusQuery2(false, "", "", "", `node_load5{instance="`+ip+`:9100"`+`}`)

			nodeLoad15, _ := prom.PrometheusQuery2(true, start, end, step, `node_load15{instance="`+ip+`:9100"`+`}`)
			nodeLoad15Current, _ := prom.PrometheusQuery2(false, "", "", "", `node_load15{instance="`+ip+`:9100"`+`}`)

			for j := 0; j < len(nodeLoad1); j++ {
				min1 := servermodels.MetricResult{}
				ll := nodeLoad1[j].(map[string]interface{})
				min1.Name = ll["metric"].(map[string]interface{})["__name__"].(string)
				min1.Current = prom.PrometheusResultToValue2(nodeLoad1Current[0])
				s := getSlice(nodeLoad1[j])
				min1.Avg = prom.FormValue(getAvg(s))
				min1.Value = prom.PrometheusResultToValue2(nodeLoad1[j])
				responseMetric = append(responseMetric, min1)
			}
			for j := 0; j < len(node_load5); j++ {
				min5 := servermodels.MetricResult{}
				ll := node_load5[j].(map[string]interface{})
				min5.Name = ll["metric"].(map[string]interface{})["__name__"].(string)
				min5.Current = prom.PrometheusResultToValue2(node_load5Current[0])
				s := getSlice(node_load5[j])
				min5.Avg = prom.FormValue(getAvg(s))
				min5.Value = prom.PrometheusResultToValue2(node_load5[j])
				responseMetric = append(responseMetric, min5)
			}
			for j := 0; j < len(nodeLoad15); j++ {
				fmt.Println("12121212", nodeLoad15)
				min15 := servermodels.MetricResult{}
				ll := nodeLoad15[j].(map[string]interface{})
				min15.Name = ll["metric"].(map[string]interface{})["__name__"].(string)
				min15.Current = prom.PrometheusResultToValue2(nodeLoad15Current[0])
				s := getSlice(nodeLoad15[j])
				min15.Avg = prom.FormValue(getAvg(s))
				min15.Value = prom.PrometheusResultToValue2(nodeLoad15[j])
				responseMetric = append(responseMetric, min15)
			}
		case "Disk":
			l, _ := prom.PrometheusQuery2(false, "", "", "", `node_filesystem_free_bytes{fstype!~"(tmpfs|rootfs).*",instance=~"`+ip+`:9100"`+`}`)
			for j := 0; j < len(l); j++ {
				r := servermodels.MetricResult{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				r.Value = prom.PrometheusResultToValue2(l[j])

				//aa := prom.PrometheusResultToValue2(a)
				r.Type = lll["fstype"]
				r.MountPoint = lll["mountpoint"]

				//r.Current = cc[j]
				//s := getSlice(l[j])
				//r.Avg = prom.FormValue(getAvg(s))
				//r.Value = prom.PrometheusResultToValue2(l[j])
				//r.Value = llll[j]
				responseMetric = append(responseMetric, r)
			}

		}
	}
	return responseMetric
}

func QueryPhysicalTopK(ips, k string, start, end int64, metrics []string) []servermodels.OverviewTopType {

	allServer, err := cmdb.GetAllPhysicalHostList("", "all", []string{}, []string{})
	if err != nil {
		klog.Error(err)
	}
	allList := allServer.Data.DataList
	t := services.FormatTime(float64(end/1000 - start/1000))
	fmt.Println("cputime", t)
	responseMetric := []servermodels.OverviewTopType{}
	for i := 0; i < len(metrics); i++ {
		switch metrics[i] {
		case "cpuPercent":
			//topk(50,avg(instance:memory_use_percent:avg30m{region="cn-shanghai-2",az="cn-shanghai-2a"})by(instance,region,az,lab))
			r := servermodels.OverviewTopType{Name: metrics[i], Unit: "%"}
			rr := servermodels.EchartType{}
			rr.Info.Name = metrics[i]
			rr.Info.Unit = "%"
			var cpuTop prom.RateTopResult
			switch t {
			case "1d", "1w", "30d":
				cpuTop, _ = prom.GetCpuRateTopKNew(k, ips, t, time.Now())
			default:
				cpuTop, _ = prom.GetCpuRateTopK(k, ips, t, time.Now())
			}
			c := dgraphmanager.String2int(cpuTop.Result, allList)
			for j := 0; j < len(c); j++ {
				v := servermodels.ValueType{Value: services.Form2(c[j].Percent), Name: c[j].Name, Ip: c[j].Ip}
				rr.Values = append(rr.Values, v)
			}
			r.Echarts = append(r.Echarts, rr)
			responseMetric = append(responseMetric, r)
		case "memPercent":
			r := servermodels.OverviewTopType{Name: metrics[i], Unit: "%"}
			rr := servermodels.EchartType{}
			rr.Info.Name = metrics[i]
			rr.Info.Unit = "%"
			memTop, _ := prom.GetMemoryRateTopK(k, ips, t, time.Now())

			c := dgraphmanager.String2int(memTop.Result, allList)
			for j := 0; j < len(c); j++ {
				cc, _ := strconv.ParseFloat(c[j].Percent, 64)
				v := servermodels.ValueType{Value: services.Form2(cc * 100), Name: c[j].Name, Ip: c[j].Ip}
				rr.Values = append(rr.Values, v)
			}
			r.Echarts = append(r.Echarts, rr)
			responseMetric = append(responseMetric, r)
		case "diskPercent":
			r := servermodels.OverviewTopType{Name: metrics[i], Unit: "%"}
			rr := servermodels.EchartType{}
			rr.Info.Name = metrics[i]
			rr.Info.Unit = "%"
			diskTop, _ := prom.GetDiskRateTopK(k, ips, t, time.Now())

			c := dgraphmanager.String2int(diskTop.Result, allList)
			for j := 0; j < len(c); j++ {
				cc, _ := strconv.ParseFloat(c[j].Percent, 64)
				v := servermodels.ValueType{Value: services.Form2(cc * 100), Name: c[j].Name, Ip: c[j].Ip}
				rr.Values = append(rr.Values, v)
			}

			r.Echarts = append(r.Echarts, rr)
			responseMetric = append(responseMetric, r)
		case "netIn":
			r := servermodels.OverviewTopType{Name: metrics[i], Unit: ""}
			rr := servermodels.EchartType{}
			rr.Info.Name = metrics[i]
			rr.Info.UnitType = "storage"
			netInTop, _ := prom.GetNetworkReceiveRateTopK(k, ips, t, time.Now())
			c := dgraphmanager.String2int(netInTop.Result, allList)
			for j := 0; j < len(c); j++ {
				cc, _ := strconv.ParseFloat(c[j].Percent, 64)
				v := servermodels.ValueType{Value: services.Form2(cc), Name: c[j].Name, Ip: c[j].Ip}
				rr.Values = append(rr.Values, v)
			}

			r.Echarts = append(r.Echarts, rr)
			responseMetric = append(responseMetric, r)
		case "netOut":
			r := servermodels.OverviewTopType{Name: metrics[i], Unit: ""}
			rr := servermodels.EchartType{}
			rr.Info.Name = metrics[i]
			rr.Info.UnitType = "storage"
			netOutTop, _ := prom.GetNetworkTransmitRateTopK(k, ips, t, time.Now())
			c := dgraphmanager.String2int(netOutTop.Result, allList)
			for j := 0; j < len(c); j++ {
				cc, _ := strconv.ParseFloat(c[j].Percent, 64)
				v := servermodels.ValueType{Value: services.Form2(cc), Name: c[j].Name, Ip: c[j].Ip}
				rr.Values = append(rr.Values, v)
			}

			r.Echarts = append(r.Echarts, rr)
			responseMetric = append(responseMetric, r)
		}
	}
	return responseMetric
}

//func GetMinMaxValueOfRange(lv interface{}) (min,max string) {
//	min,max := "",""
//	lvv := lv.([]interface{})
//	for i := 0; i < len(lvv); i++ {
//
//	}
//	return min,max
//
//}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/dbmsmanager/dbmsservice.go
```golang
package dbmsmanager

import (
	"encoding/json"
	"fmt"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	dbmsmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/dbmsservice"
	"io"
	"k8s.io/klog/v2"
	"net/http"
	"strings"
)

type DBMSResult struct {
	Code    int        `json:"code"`
	Message string     `json:"message"`
	Data    DBMSBlocks `json:"data"`
}

type DBMSBlocks struct {
	TotalCount int `json:"total"`
}

// 获取mysql列表
func GetDbMysqlList(param dbmsmodel.MysqlRequestParam) (dbmsmodel.MysqlListResult, error) {
	klog.Infof("get GetDbMysqlList param %+v", param)

	if param.PageSize == 0 {
		param.PageSize = int(^uint16(0))
	}

	rst := dbmsmodel.MysqlListResult{}
	c := http.Client{}
	url := "http://" + config.GetDefaultUrl(config.DBMSService) + "/dbms/v1/cloudProducts/mysql/list"

	jsons, _ := json.Marshal(param)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)

	if err != nil {
		klog.Error(err)
		return rst, err
	}
	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rst)

	if err != nil {
		klog.Error("redisjson", err)
		return rst, err
	}
	return rst, nil

}

// 获取redis列表
func GetDbRedisList(param dbmsmodel.RedisRequestParam) (dbmsmodel.RedisListResult, error) {
	klog.Infof("get GetDbMysqlList param %+v", param)
	if param.PageSize == 0 {
		param.PageSize = int(^uint16(0))
	}
	rst := dbmsmodel.RedisListResult{}
	c := http.Client{}
	url := "http://" + config.GetDefaultUrl(config.DBMSService) + "/dbms/v1/cloudProducts/redis/list"
	fmt.Println("redisListUrl", url)
	jsons, _ := json.Marshal(param)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)

	if err != nil {
		klog.Error("GetDbRedisList", err)
		return rst, err
	}
	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rst)

	if err != nil {
		klog.Error("redisjson", err)
		return rst, err
	}
	return rst, nil

}

// 获取数据库资源池列表
func GetDBResourcePoolList(region, azCode string, dbType []string, searchType string, searchValue string, pageNo int, pageSize int) (dbmsmodel.DBResourcePoolListResult, error) {
	rst := dbmsmodel.DBResourcePoolListResult{}
	c := http.Client{}
	url := "http://" + config.GetDefaultUrl(config.DBMSService) + "/dbms/v1/dbResourcePool/list"
	postData := DBResourcePoolListPost{
		Region:      region,
		Az:          azCode,
		DbType:      dbType,
		PageNo:      pageNo,
		PageSize:    pageSize,
		SearchType:  searchType,
		SearchValue: searchValue,
	}
	jsons, _ := json.Marshal(postData)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)

	if err != nil {
		klog.Error(err)
		return rst, err
	}
	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rst)

	if err != nil {
		klog.Error(err)
		return rst, err
	}
	return rst, nil
}

// 获取数据库资源池详情信息
func GetDBResourcePoolDetail(id string) (dbmsmodel.DBResourcePoolResult, error) {
	rst := dbmsmodel.DBResourcePoolResult{}
	c := http.Client{}
	url := "http://" + config.GetDefaultUrl(config.DBMSService) + "/dbms/v1/dbResourcePool/detail?id=" + id
	reqest, _ := http.NewRequest("GET", url, nil)
	reqest.Header.Set("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8")
	reqest.Header.Set("Accept-Charset", "GBK,utf-8;q=0.7,*;q=0.3")
	reqest.Header.Set("Accept-Encoding", "gzip,deflate,sdch")
	reqest.Header.Set("Accept-Language", "zh-CN,zh;q=0.8")
	reqest.Header.Set("Cache-Control", "max-age=0")
	reqest.Header.Set("Connection", "keep-alive")
	reqest.Header.Set("User-Agent", "chrome 100")

	respons, err := c.Do(reqest)
	if err != nil {
		klog.Error(err)
		return rst, err
	}

	b, _ := io.ReadAll(respons.Body)
	err = json.Unmarshal(b, &rst)
	if err != nil {
		klog.Error(err)
		return rst, err
	}
	if rst.Code != 200 {
		klog.Info("get data from dbms error!")
	}
	return rst, nil
}

func GetDBInstanceList(param QueryInstanceList) (dbmsmodel.DBInstanceListResult, error) {
	rst := dbmsmodel.DBInstanceListResult{}
	c := http.Client{}

	url := "http://" + config.GetDefaultUrl(config.DBMSService) + "/dbms/v1/dbResourcePool/instanceList"
	fmt.Println("url", url)
	postData := QueryInstanceList{
		ID:              param.ID,
		InstanceType:    param.InstanceType,
		InstanceVersion: param.InstanceVersion,
		PageNo:          param.PageNo,
		PageSize:        param.PageSize,
		SearchType:      param.SearchType,
		SearchValue:     param.SearchValue,
		Status:          param.Status,
	}

	fmt.Printf("postData %+v", postData)
	jsons, _ := json.Marshal(postData)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)

	if err != nil {
		klog.Error(err)
		return rst, err
	}
	b, _ := io.ReadAll(res.Body)
	e := json.Unmarshal(b, &rst)

	if e != nil {
		return rst, err
	}
	return rst, nil
}

func GetDbmsTotalCount(url string) int {
	klog.Info(url)
	c := http.Client{}
	dbmsResult := DBMSResult{}
	hostUrlPost := cmdbmodel.HostUrlPost{
		PageNo:   1,
		PageSize: 1,
	}
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	resp, err := c.Post(url, "application/json", jsoninfo)
	if err != nil {
		klog.Info(err)
		return 0
	}
	b, er := io.ReadAll(resp.Body)
	if er != nil {
		klog.Info(er)
		return 0
	}

	e := json.Unmarshal(b, &dbmsResult)
	if e != nil {
		return 0
	}

	return dbmsResult.Data.TotalCount
}

// 获取数据库资源池列表
func GetDBcloudProductRedisList(region string, dbType []string, searchType string, searchValue string, pageNo int, pageSize int) (dbmsmodel.DBResourcePoolListResult, error) {
	rst := dbmsmodel.DBResourcePoolListResult{}
	c := http.Client{}
	url := "http://" + config.GetDefaultUrl(config.DBMSService) + "/dbms/v1/cloudProductRedis/list"
	postData := DBResourcePoolListPost{
		Region:      region,
		DbType:      dbType,
		PageNo:      pageNo,
		PageSize:    pageSize,
		SearchType:  searchType,
		SearchValue: searchValue,
	}
	jsons, _ := json.Marshal(postData)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)

	if err != nil {
		klog.Error(err)
		return rst, err
	}
	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rst)

	if err != nil {
		klog.Error(err)
		return rst, err
	}
	return rst, nil
}

// 获取数据库资源池服务器列表
func GetServerList(params ServerListParams) (dbmsmodel.DBServerListResult, error) {
	rst := dbmsmodel.DBServerListResult{}
	c := http.Client{}
	url := "http://" + config.GetDefaultUrl(config.DBMSService) + "/dbms/v1/dbResourcePool/serverList"

	jsons, _ := json.Marshal(params)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)

	if err != nil {
		klog.Error(err)
		return rst, err
	}
	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rst)

	if err != nil {
		klog.Error(err)
		return rst, err
	}
	return rst, nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/dbmsmanager/model.go
```golang
package dbmsmanager

type DBResourcePoolListPost struct {
	PageNo      int      `json:"pageNo"`
	PageSize    int      `json:"pageSize"`
	Region      string   `json:"region"`
	Az          string   `json:"az"`
	SearchType  string   `json:"searchType"`
	SearchValue string   `json:"searchValue"`
	DbType      []string `json:"dbType"`
}

type QueryInstanceList struct {
	ID              string   `json:"id"`
	InstanceType    []int    `json:"instanceType"`
	InstanceVersion []string `json:"instanceVersion"`
	PageNo          int      `json:"pageNo"`
	PageSize        int      `json:"pageSize"`
	SearchType      string   `json:"searchType"`
	SearchValue     string   `json:"searchValue"`
	Status          []int    `json:"status"`
}

type ServerListParams struct {
	PageNo   int    `json:"pageNo"`
	PageSize int    `json:"pageSize"`
	Region   string `json:"region"`
	Id       string `json:"id"`
	//SearchType      string   `json:"searchType"`
	//SearchValue     string   `json:"searchValue"`
	RunState        []string `json:"runState"`
	AllocationState []string `json:"allocationState"`
	Az              []string `json:"az"`
	Lab             []string `json:"lab"` //机房
	Room            []string `json:"room"`
	Cabinet         []int    `json:"cabinetId"`
	Rack            []int    `json:"rackId"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/esmanager/esmanagerservice.go
```golang
package esmanager

import (
	"context"
	"encoding/json"
	"errors"
	"log"
	"os"
	"strconv"
	"time"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"

	elastic "github.com/olivere/elastic/v7"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
)

type AlertsSuccess struct {
	Code    int    `json:"code"`
	Message string `json:"message"`
	Data    Alerts `json:"data"`
}

type Alerts struct {
	result []AlertResult
}

type AlertResult struct {
	TotalCount int         `json:"totalCount"`
	TotalPage  int         `json:"totalPage"`
	Data       []AlertData `json:"data"`
}

// type data struct {
// 	Alert []alert `json:"alert"`
// }

type AlertData struct {
	StartsAt        time.Time `json:"startsAt"`
	AlertName       string    `json:"alertName"`
	AlertInstance   string    `json:"alertInstance"`
	ResourceType    string    `json:"resourceType"`
	ResourceSubType string    `json:"resourceSubType"`
	BelongRegion    string    `json:"belongRegion"`
	AvailableArea   string    `json:"availableArea"`
	AlertLevel      string    `json:"alertLevel"`
}

var esclient *elastic.Client
var host = "http://" + config.GetDefaultUrl(config.ElasticsearchService) + "/"
var ResourceList cmdbmodel.ResourceList

func init() {
	errorlog := log.New(os.Stdout, "APP", log.LstdFlags)
	var err error
	esclient, err = elastic.NewClient(elastic.SetErrorLog(errorlog), elastic.SetURL(host), elastic.SetSniff(false), elastic.SetHealthcheck(false))
	if err != nil {
		panic(err)
	}
	// info, code, err := esclient.Ping(host).Do(context.Background())
	// if err != nil {
	// 	panic(err)
	// }
	//fmt.Printf("Elasticsearch returned with code %d and version %s\n", code, info.Version.Number)

	// esversion, err := esclient.ElasticsearchVersion(host)
	// if err != nil {
	// 	panic(err)
	// }
	//fmt.Printf("Elasticsearch version %s\n", esversion)
	ResourceList, _ = cmdbmanager.GetResourceData()
}

//(*Alerts,error)
func (a *AlertResult) GetAlertsList(_index string, _type string, qString []string, alertRst *AlertResult) error {
	var res *elastic.SearchResult
	var resT *elastic.SearchResult
	var t int64
	var err error
	q := elastic.NewQueryStringQuery("alerts.labels.severity:" + qString[0])
	if len(qString) > 1 {
		res, err = esclient.Search(_index).Type(_type).Do(context.Background())
	} else {
		res, err = esclient.Search(_index).Type(_type).Query(q).Do(context.Background())
	}
	if err != nil {
		println(err.Error())
	}
	t = res.TotalHits()

	sizeString := strconv.FormatInt(t, 10)
	sizeInt, _ := strconv.Atoi(sizeString)
	if len(qString) > 1 {
		resT, err = esclient.Search(_index).Type(_type).Size(sizeInt).Do(context.Background())
	} else {
		resT, err = esclient.Search(_index).Type(_type).Query(q).Size(sizeInt).Do(context.Background())
	}
	//resT, err := esclient.Search(_index).Type(_type).Query(q).Size(sizeInt).Do(context.Background())
	if err != nil {
		println(err.Error())
	}
	for _, hit := range resT.Hits.Hits {
		var hits map[string]interface{}
		err = json.Unmarshal(hit.Source, &hits)
		if vCw, ok := hits["alerts"]; ok {
			alerts := vCw.([]interface{})
			//count = len(alerts) + count
			for _, alert := range alerts {
				alertData := alert.(map[string]interface{})
				//fmt.Println(alert)
				var alertModel AlertData
				if aCw, ok := alertData["labels"]; ok {
					labels := aCw.(map[string]interface{})
					//fmt.Println(aCw)
					if severity, ok := labels["severity"]; ok {
						if IsContain(qString, severity.(string)) {
							alertModel.AlertLevel = severity.(string)
							if alertName, ok := labels["alertname"]; ok {
								alertModel.AlertName = alertName.(string)
								//fmt.Println(alertName.(string))
							}
							if instance, ok := labels["instance"]; ok {
								alertModel.AlertInstance = instance.(string)
								//fmt.Println(instance.(string))
							}
							if region, ok := labels["region"]; ok {
								alertModel.BelongRegion = region.(string)
								//fmt.Println(region.(string))
							}
							if zone, ok := labels["zone"]; ok {
								alertModel.AvailableArea = zone.(string)
								//fmt.Println(zone.(string))
							}

							alertModel.ResourceType = "物理资源"
							if sAt, er := alertData["startsAt"]; er {
								//fmt.Println(sAt)
								tt, _ := time.Parse("2006-01-02T15:04:05Z07:00", sAt.(string))
								alertModel.StartsAt = tt
							}
							alertRst.TotalCount++
							alertRst.Data = append(alertRst.Data, alertModel)
							if alertRst.TotalCount >= 100 {
								return err
							}

						}

					}

				}

			}
		}
	}
	return err
}

func (a *AlertResult) GetEsPage(query alertmanagermodel.ESQuery) (alertmanagermodel.AlertResult, error) {
	alertResult, err := a.GetEsList(query)
	if err != nil {
		return alertResult, err
	}

	//分页
	alertResult.TotalCount = len(alertResult.DataList)
	alertResult.PageNo = query.PageNo
	alertResult.PageSize = query.PageSize
	low := (query.PageNo - 1) * query.PageSize
	if low > alertResult.TotalCount {
		return alertResult, errors.New("PageSize is too large ")
	}
	hight := low + query.PageSize
	if hight > alertResult.TotalCount {
		hight = alertResult.TotalCount
	}
	alertResult.DataList = alertResult.DataList[low:hight]
	return alertResult, err
}

func (a *AlertResult) GetEsList(query alertmanagermodel.ESQuery) (alertmanagermodel.AlertResult, error) {
	//var res *elastic.SearchResult
	var resT *elastic.SearchResult
	//var t int64
	var err error
	var alertResult alertmanagermodel.AlertResult

	alertDataMap := make(map[string]string)
	println("query:", query.AlertLevel)
	//boolQ := elastic.NewTermsQuery("alerts.labels.severity", "p0","p1","p2","p3")
	// matchQ := elastic.NewMatchQuery("severity", query.AlertLevel)
	// matchQ.Operator("or")
	// boolQ.Must(matchQ)
	resT, err = esclient.Search().Index("alertmanager-*").Do(context.Background()) //.From((pageNo - 1) * pageSize).Size(pageSize)

	if err != nil {
		println(err.Error())
	}
	if err != nil {
		println(err.Error())
	}
	for _, hit := range resT.Hits.Hits {
		var hits map[string]interface{}
		err = json.Unmarshal(hit.Source, &hits)
		if vCw, ok := hits["alerts"]; ok {
			alerts := vCw.([]interface{})
			//count = len(alerts) + count
			for _, alert := range alerts {
				alertData := alert.(map[string]interface{})
				//fmt.Println(alert)
				//var alertModel AlertData
				var alertModel alertmanagermodel.AlertData
				if annotations, er := alertData["annotations"]; er {
					//fmt.Println(sAt)
					expression := annotations.(map[string]interface{})
					if lubanExpressionWithChinaese, ok := expression["lubanExpressionWithChinese"]; ok {
						alertModel.ExpressionWithChinaese = lubanExpressionWithChinaese.(string)
					}
				}
				if fingerprint, er := alertData["fingerprint"]; er {
					//fmt.Println(sAt)
					alertModel.Id = fingerprint.(string)
				}
				if sSta, er := alertData["status"]; er {
					alertModel.State = sSta.(string)
				}
				if sAt, er := alertData["startsAt"]; er {
					//fmt.Println(sAt)
					tt, _ := time.Parse("2006-01-02T15:04:05Z07:00", sAt.(string))
					alertModel.StartsAt = tt
				}
				if sEt, er := alertData["endsAt"]; er {
					//fmt.Println(sAt)
					tt, _ := time.Parse("2006-01-02T15:04:05Z07:00", sEt.(string))
					alertModel.EndsAt = tt
				}
				if aCw, ok := alertData["labels"]; ok {
					labels := aCw.(map[string]interface{})
					if severity, ok := labels["severity"]; ok {
						if severity != "p0" && severity != "p1" && severity != "p2" && severity != "p3" {
							continue
						}

						//fmt.Println(instance.(string))
					} else {
						continue
					}
					//fmt.Println(labels)
					// if alertName, ok := labels["alertname"]; ok {
					// 	alertModel.AlertName = alertName.(string)
					// 	//fmt.Println(alertName.(string))
					// }
					//去重数据
					if _, ok := alertDataMap[alertModel.Id]; ok {
						continue
					}
					alertDataMap[alertModel.Id] = alertModel.Id
					// if instance, ok := labels["instance"]; ok {
					// 	alertModel.AlertInstance = instance.(string)
					// 	//fmt.Println(instance.(string))
					// }
					if instance, ok := labels["lubanResourceName"]; ok {
						alertModel.AlertInstance = instance.(string)
						//klog.Infof("alert instance: %s %s", instance, alertModel.AlertInstance)
						//fmt.Println(instance.(string))
					}
					if resourceTypeCode, ok := labels["lubanResourceType"]; ok {
						alertModel.ResourceTypeCode = resourceTypeCode.(string)
						alertModel.ResourceTypeName = GetResourceData(alertModel.ResourceTypeCode, "")
						//fmt.Println(region.(string))
					}
					if resourceSubTypeCode, ok := labels["lubanResourceSubType"]; ok {
						alertModel.ResourceSubTypeCode = resourceSubTypeCode.(string)
						alertModel.ResourceSubTypeName = GetResourceData("", alertModel.ResourceSubTypeCode)
						//fmt.Println(zone.(string))
					}
					if serverType, ok := labels["galaxyServerType"]; ok {
						alertModel.ServerType = serverType.(string)
					}
					if severity, ok := labels["severity"]; ok {
						alertModel.AlertLevel = severity.(string)
						//fmt.Println(zone.(string))
					}
					if handler, ok := labels["lubanNoticeMail"]; ok {
						alertModel.Handler = handler.(string)
						//fmt.Println(zone.(string))
					}
					if lubanAlarmView, ok := labels["lubanAlarmView"]; ok {
						alertModel.AlertName = lubanAlarmView.(string)
						//fmt.Println(zone.(string))
					}
					if lubanPolicyName, ok := labels["lubanPolicyName"]; ok {
						alertModel.PolicyName = lubanPolicyName.(string)
						//fmt.Println(zone.(string))
					}
					if lubanThreshold, ok := labels["lubanThreshold"]; ok {
						alertModel.ThresholdValue = lubanThreshold.(string)
						//fmt.Println(zone.(string))
					}
					if lubanRegion, ok := labels["region"]; ok {
						alertModel.Region = lubanRegion.(string)
					}
					if alertModel.State == "firing" && alertModel.Handler == "" {
						alertModel.Status = "待处理"
						alertModel.State = "todo"
					} else if alertModel.State == "firing" {
						alertModel.Status = "处理中"
					} else if alertModel.State == "resolved" {
						alertModel.Status = "已解决"
					} else if alertModel.State == "blocked" {
						alertModel.Status = "已屏蔽"
					}
					if query.PolicyName == "" || query.PolicyName == alertModel.PolicyName &&
						(len(query.AlertLevel) <= 0 || services.In(query.AlertLevel, alertModel.AlertLevel)) &&
						(len(query.StateList) <= 0 || services.In(query.StateList, alertModel.State)) &&
						(len(query.ResourceTypeCode) <= 0 || services.In(query.ResourceTypeCode, alertModel.ResourceTypeCode)) &&
						(len(query.ResourceSubTypeCode) <= 0 || services.In(query.ResourceSubTypeCode, alertModel.ResourceSubTypeCode)) {
						alertResult.DataList = append(alertResult.DataList, alertModel)
					}

					//alertModel.ResourceType = "物理资源"
					//多选
					// if len(query.AlertLevel) != 0 {
					// 	fmt.Println("query.AlertLevel")
					// 	fmt.Println(query.AlertLevel)
					// 	fmt.Println("alertModel.AlertLevel")
					// 	fmt.Println(alertModel.AlertLevel)
					// 	stateIn := services.In(query.AlertLevel, alertModel.AlertLevel)
					// 	if !stateIn {
					// 		continue
					// 	}
					// }
					// if len(query.StateList) != 0 {
					// 	fmt.Println("query.StateList")
					// 	fmt.Println(query.StateList)
					// 	fmt.Println("alertModel.State")
					// 	fmt.Println(alertModel.State)
					// 	stateIn := services.In(query.StateList, alertModel.State)
					// 	if !stateIn {
					// 		continue
					// 	}
					// }
					// if len(query.ResourceTypeCode) != 0 {
					// 	stateIn := services.In(query.ResourceTypeCode, alertModel.ResourceTypeCode)
					// 	if !stateIn {
					// 		continue
					// 	}
					// }
					// if len(query.ResourceSubTypeCode) != 0 {
					// 	stateIn := services.In(query.ResourceSubTypeCode, alertModel.ResourceSubTypeCode)
					// 	if !stateIn {
					// 		continue
					// 	}
					// }
					//alertResult.TotalCount += 1

				}

			}
		}
	}
	return alertResult, err
}

func IsContain(items []string, item string) bool {
	for _, eachItem := range items {
		if eachItem == item {
			return true
		}
	}
	return false
}
func GetResourceData(resourceKey, resourceSubKey string) string {
	// var ResourceList []cmdbmodel.Resource
	// ResourceList, _ = cmdbmanager.GetResourceData()
	if resourceKey != "" {
		for _, resource := range ResourceList.ResourceType {
			if resource.ResourceKey == resourceKey {
				return resource.ResourceValue
			}
		}
	} else if resourceSubKey != "" {
		for _, resource := range ResourceList.ResourceSubType {
			if resource.ResourceKey == resourceSubKey {
				return resource.ResourceValue
			}
		}
	}

	return ""
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/esmanager/k3sEs.go
```golang
package esmanager

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"github.com/olivere/elastic/v7"
	"github.com/pkg/errors"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"io"
	"io/ioutil"
	"net/http"
	"strconv"
	"strings"
	"time"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	k3smodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/k3sEs"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	"k8s.io/klog/v2"
)

var (
	EsIndexDateFormat = "060102.15:04:05"
	OperationsUp      = []string{"REST.PUT.UPLOADPART", "REST.POST.COMPLETE_MULTIUPLOAD", "REST.POST.OBJECT", "REST.PUT.OBJECT"}
	OperationsDown    = []string{"REST.GET.OBJECT"}
)

var FlowInOutMap = map[string]string{
	"false": "外网",
	"true":  "内网",
}

//var FlowCDNMap = map[string]string{
//	"-":   "不确定流量",
//	"kc":  "金山CDN",
//	"bc":  "头条CDN",
//	"crr": "跨区域复制",
//}

func GetBucketPoolBand() string {
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	//nowDate           = strings.Split(now, ".")
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	//index             = nowDate[0]
	subIndex := oneDayAgoDate[0]

	totalResult, er := GetEsWideDataScroll(subIndex, "")
	if er != nil {
		klog.Info(er)
		return ""
	}
	count := len(totalResult.Hits.Hits)

	var up, down int64
	for i := 0; i < count; i++ {
		j := totalResult.Hits.Hits[i]
		up += j.Source.Traffic_up
		down += j.Source.Traffic_down
	}
	upBand := services.FormatSize(float64(up / 86400))
	downBand := services.FormatSize(float64(down / 86400))
	return upBand + "/" + downBand
}

func GetBucketPoolBandSum(region string) string {
	//OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	//oneDayAgoDate := strings.Split(OneDayAgo, ".")
	//subIndex := oneDayAgoDate[0]
	//upBand := services.FormatSize(float64(GetBucketPoolTrafficUpSum(subIndex, region) / 86400))
	//downBand := services.FormatSize(float64(GetBucketPoolTrafficDownSum(subIndex, region) / 86400))
	trafficUp, _ := GetTrafficSum(region, "", "", "", GetDateIndex(-1), TrafficUp)
	trafficDown, _ := GetTrafficSum(region, "", "", "", GetDateIndex(-1), TrafficDown)
	upBand := services.FormatSize(float64(trafficUp / 86400))
	downBand := services.FormatSize(float64(trafficDown / 86400))
	return upBand + "/" + downBand
}
func GetBucketPoolTrafficUpSum(dayIndex, region string) int64 {
	q := elastic.NewBoolQuery()
	if region != "" && region != "all" && region != "ALL" {
		q.Must(elastic.NewTermQuery("ks3region", strings.ToUpper(region)))
	}
	index := fmt.Sprintf("col.ks3_wide.%s", dayIndex)

	if client.EsClient == nil {
		klog.Error("EsClient is nil....")
		return 0
	}

	do, err := client.EsClient.Search().Index(index).
		Query(q).
		Aggregation("trafficUpSum", elastic.NewSumAggregation().Field("traffic_up")).
		Do(context.Background())
	if err != nil {
		klog.Error("EsClient sum times error...." + err.Error())
		return 0
	}

	var trafficUpSum int64
	if v, ok := do.Aggregations.Sum("trafficUpSum"); ok {
		trafficUpSum, _ = strconv.ParseInt(fmt.Sprintf("%1.0f", *v.Value), 10, 64)
	}
	return trafficUpSum
}

func GetBucketPoolTrafficDownSum(dayIndex, region string) int64 {
	q := elastic.NewBoolQuery()
	if region != "" && region != "all" && region != "ALL" {
		q.Must(elastic.NewTermQuery("ks3region", strings.ToUpper(region)))
	}
	index := fmt.Sprintf("col.ks3_wide.%s", dayIndex)

	if client.EsClient == nil {
		klog.Error("EsClient is nil....")
		return 0
	}

	do, err := client.EsClient.Search().Index(index).
		Query(q).
		Aggregation("trafficDownSum", elastic.NewSumAggregation().Field("traffic_down")).
		Do(context.Background())
	if err != nil {
		klog.Error("EsClient sum times error...." + err.Error())
		return 0
	}

	var trafficDownSum int64
	if v, ok := do.Aggregations.Sum("trafficDownSum"); ok {
		trafficDownSum, _ = strconv.ParseInt(fmt.Sprintf("%1.0f", *v.Value), 10, 64)
	}
	return trafficDownSum
}

func GetBucketPoolCode() map[string]int64 {
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	//nowDate           = strings.Split(now, ".")
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	//index             = nowDate[0]
	subIndex := oneDayAgoDate[0]
	var codeMap = map[string]int64{
		"2xx": 0,
		"3xx": 0,
		"4xx": 0,
		"5xx": 0,
	}
	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, subIndex)
	result, err := GetEsWideData(url)
	if err != nil {
		klog.Info(err)
		return codeMap
	}
	total := result.Hits.Total
	//if total > 10000 {
	//	total = 10000
	//}
	totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s", config.DefaultK3sEsService, subIndex, strconv.Itoa(total))
	totalResult, er := GetEsWideData(totalUrl)
	//totalResult, er := GetMultiEsWideData(subIndex, total)
	if er != nil {
		klog.Info(er)
		return codeMap
	}
	count := len(totalResult.Hits.Hits)

	for o := 0; o < count; o++ {
		j := totalResult.Hits.Hits[o]
		s := strings.Split(j.Source.Code, "")
		if len(s) > 0 {
			switch s[0] {
			case "2":
				codeMap["2xx"]++
			case "3":
				codeMap["3xx"]++
			case "4":
				codeMap["4xx"]++
			case "5":
				codeMap["5xx"]++

			}
		}
	}

	// var up, down int64
	// for i := 0; i < count; i++ {
	// 	j := totalResult.Hits.Hits[i]
	// 	up += j.Source.Traffic_up
	// 	down += j.Source.Traffic_down
	// }
	// upBand := services.FormatSize(float64(up / 86400))
	// downBand := services.FormatSize(float64(down / 86400))
	return codeMap
}

//func GetBucketPoolCodeAggr(region, dayIndex string) map[string]int64 {
//	var codeMap = map[string]int64{
//		"2xx": 0,
//		"3xx": 0,
//		"4xx": 0,
//		"5xx": 0,
//	}
//	//subIndex = "220725"
//	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, dayIndex)
//	if region != "" && region != "all" {
//		url = url + "&q=ks3region:" + strings.ToUpper(region)
//	}
//	c := http.Client{Timeout: time.Second * 3}
//	query := `{
//				"aggs": {
//					"code": {
//						"terms": {
//							"field": "code",
//							"size": 10000
//						}
//					}
//				}
//			}`
//	jsoninfo := strings.NewReader(query)
//	resp, err := c.Post(url, "application/json", jsoninfo)
//	if err != nil {
//		klog.Errorf("Failed to get es bucket pool store aggr data ，err: %s", err)
//		return codeMap
//	}
//	defer resp.Body.Close()
//	body, _ := io.ReadAll(resp.Body)
//	aggr := EsKs3StoreCodeAggr{}
//	json.Unmarshal(body, &aggr)
//
//	for _, bucket := range aggr.Aggregations.Code.Buckets {
//		s := strings.Split(bucket.Key, "")
//		if len(s) > 0 {
//			switch s[0] {
//			case "2":
//				codeMap["2xx"] += bucket.DocCount
//			case "3":
//				codeMap["3xx"] += bucket.DocCount
//			case "4":
//				codeMap["4xx"] += bucket.DocCount
//			case "5":
//				codeMap["5xx"] += bucket.DocCount
//			}
//		}
//	}
//	return codeMap
//}

func GetBucketPoolCodeAggr(region, dayIndex string) map[string]int64 {
	var codeMap = map[string]int64{
		"2xx": 0,
		"3xx": 0,
		"4xx": 0,
		"5xx": 0,
	}
	//dayIndex = "220725"
	q := elastic.NewBoolQuery()
	if region != "" && region != "all" && region != "ALL" {
		q.Must(elastic.NewTermQuery("ks3region", strings.ToUpper(region)))
	}
	index := fmt.Sprintf("col.ks3_wide.%s", dayIndex)

	if client.EsClient == nil {
		klog.Error("EsClient is nil....")
		return codeMap
	}

	do, err := client.EsClient.Search().Index(index).
		Query(q).
		Aggregation("code", elastic.NewTermsAggregation().Field("code").Size(10000).
			SubAggregation("apiNum", elastic.NewSumAggregation().Field("times"))).
		Do(context.Background())

	if err != nil {
		klog.Error("EsClient sum times error...." + err.Error())
		return codeMap
	}
	items, _ := do.Aggregations.Terms("code")

	for _, bucket := range items.Buckets {
		s := strings.Split(bucket.Key.(string), "")
		//if v, ok := bucket.Sum("apiNum"); ok {
		//	times, _ := strconv.ParseInt(fmt.Sprintf("%1.0f", *v.Value), 10, 64)
		//}
		if len(s) > 0 {
			switch s[0] {
			case "2":
				codeMap["2xx"] += bucket.DocCount
			case "3":
				codeMap["3xx"] += bucket.DocCount
			case "4":
				codeMap["4xx"] += bucket.DocCount
			case "5":
				codeMap["5xx"] += bucket.DocCount
			}
		}
	}
	return codeMap
}

// 基于id的前一天流量统计
func GetBucketFlowById(id string) (float64, float64) {
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	//nowDate           = strings.Split(now, ".")
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	//index             = nowDate[0]
	subIndex := oneDayAgoDate[0]
	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, subIndex, id)
	result, err := GetEsWideData(url)
	if err != nil {
		klog.Info(err)
		return 0, 0
	}
	total := result.Hits.Total

	totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, subIndex, strconv.Itoa(total), id)
	totalResult, er := GetEsWideData(totalUrl)
	if er != nil {
		klog.Info(er)
		return 0, 0
	}
	count := len(totalResult.Hits.Hits)

	var up, down int64
	for i := 0; i < count; i++ {
		j := totalResult.Hits.Hits[i]
		up += j.Source.Traffic_up
		down += j.Source.Traffic_down
	}
	return float64(up), float64(down)
}

// 前一天资源池流量细节统计
func GetBucketPoolFlowDetail() map[string]int64 {
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	//nowDate           = strings.Split(now, ".")
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	//index             = nowDate[0]
	subIndex := oneDayAgoDate[0]
	codeMap := map[string]int64{
		"外网上传":    0,
		"外网下载":    0,
		"内网上传":    0,
		"内网下载":    0,
		"CDN上传":   0,
		"CDN下载":   0,
		"跨区域复制上传": 0,
		"跨区域复制下载": 0,
	}
	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, subIndex)
	result, err := GetEsWideData(url)
	if err != nil {
		klog.Info(err)
		return codeMap
	}
	total := result.Hits.Total
	//if total > 10000 {
	//	total = 10000
	//}
	totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s", config.DefaultK3sEsService, subIndex, strconv.Itoa(total))
	totalResult, er := GetEsWideData(totalUrl)
	//totalResult, er := GetMultiEsWideData(subIndex, total)
	if er != nil {
		klog.Info(er)
		return codeMap
	}
	count := len(totalResult.Hits.Hits)

	for o := 0; o < count; o++ {
		j := totalResult.Hits.Hits[o]
		if j.Source.Isinner == "false" {
			codeMap["外网上传"] += j.Source.Traffic_up
			codeMap["外网下载"] += j.Source.Traffic_down
		} else if j.Source.Isinner == "true" {
			codeMap["内网上传"] += j.Source.Traffic_up
			codeMap["内网下载"] += j.Source.Traffic_down
		}

		if j.Source.Usertype == "crr" {
			codeMap["跨区域复制上传"] += j.Source.Traffic_up
			codeMap["跨区域复制下载"] += j.Source.Traffic_down
		} else if j.Source.Usertype != "-" {
			codeMap["CDN上传"] += j.Source.Traffic_up
			codeMap["CDN下载"] += j.Source.Traffic_down
		}

	}

	return codeMap
}

// 基于id的前一天code数量统计
func GetBucketCodeById(id string) map[string]float64 {
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	//nowDate           = strings.Split(now, ".")
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	//index             = nowDate[0]
	subIndex := oneDayAgoDate[0]
	var codeMap = map[string]float64{
		"2xx": 0,
		"3xx": 0,
		"4xx": 0,
		"5xx": 0,
	}
	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, subIndex, id)
	result, err := GetEsWideData(url)
	if err != nil {
		klog.Info(err)
		return codeMap
	}
	total := result.Hits.Total

	totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, subIndex, strconv.Itoa(total), id)
	totalResult, er := GetEsWideData(totalUrl)
	if er != nil {
		klog.Info(er)
		return codeMap
	}
	count := len(totalResult.Hits.Hits)

	for o := 0; o < count; o++ {
		j := totalResult.Hits.Hits[o]
		s := strings.Split(j.Source.Code, "")
		if len(s) > 0 {
			switch s[0] {
			case "2":
				codeMap["2xx"]++
			case "3":
				codeMap["3xx"]++
			case "4":
				codeMap["4xx"]++
			case "5":
				codeMap["5xx"]++

			}
		}
	}

	return codeMap
}

// 基于id的前一天code数量统计
func GetBucketErrCodeById(id string) float64 {
	var rst float64
	codeMap := GetBucketCodeById(id)
	for k, v := range codeMap {
		if k == "4xx" || k == "5xx" {
			rst += v
		}
	}
	return rst
}

func GetBucketPoolStore() map[string]float64 {
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	//nowDate           = strings.Split(now, ".")
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	//index             = nowDate[0]
	subIndex := oneDayAgoDate[0]
	var codeMap = map[string]float64{
		"归档存储":  0,
		"非归档存储": 0,
		//"低频存储": 0,
	}
	url := fmt.Sprintf("http://%s/col.ks3_store_of_day.%s/_search?from=0&size=1", config.DefaultK3sEsService, subIndex)
	result, err := GetEsStoreData(url)
	if err != nil {
		klog.Info(err)
		return codeMap
	}
	total := result.Hits.Total

	totalUrl := fmt.Sprintf("http://%s/col.ks3_store_of_day.%s/_search?from=0&size=%s", config.DefaultK3sEsService, subIndex, strconv.Itoa(total))
	totalResult, er := GetEsStoreData(totalUrl)
	if er != nil {
		klog.Info(er)
		return codeMap
	}

	count := len(totalResult.Hits.Hits)
	for i := 0; i < count; i++ {
		j := totalResult.Hits.Hits[i]
		switch j.Source.StorageClass {
		case "ARCHIVE":
			codeMap["归档存储"] += j.Source.AllSize
		case "STANDARD":
			codeMap["非归档存储"] += j.Source.AllSize
			// case "STANDARD_IA":
			// 	standard_ia += j.Source.AllSize
		}

	}

	return codeMap
}

func GetBucketPoolStoreAggr(region string) map[string]float64 {
	var rst EsKs3StoreAggr
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	subIndex := oneDayAgoDate[0]
	var codeMap = map[string]float64{
		"标准存储": 0,
		"归档存储": 0,
		"低频存储": 0,
	}
	//subIndex = "220725"
	url := fmt.Sprintf("http://%s/col.ks3_store_of_day.%s/_search?from=0&size=1", config.DefaultK3sEsService, subIndex)
	if region != "" && region != "all" {
		url = url + "&q=ks3region:" + strings.ToUpper(region)
	}
	c := http.Client{Timeout: time.Second * 3}

	query := `{"aggs": {
					"storageclass": {
					  "terms": {
						"field": "storageclass",
						"size": 10000
					  },
					  "aggs": {
						"allSize": {
						  "sum": {
							"field": "allSize"
						  }
						}
					  }
					}
				  }
				}`
	jsoninfo := strings.NewReader(query)
	resp, err := c.Post(url, "application/json", jsoninfo)
	if err != nil {
		klog.Errorf("Failed to get es bucket pool store aggr data ，err: %s", err)
		return codeMap
	}
	defer resp.Body.Close()
	body, _ := io.ReadAll(resp.Body)
	json.Unmarshal(body, &rst)

	for _, bucket := range rst.Aggregations.Storageclass.Buckets {
		switch bucket.Key {
		//case "ARCHIVE":
		//	codeMap["归档存储"] += bucket.AllSize.Value
		//case "STANDARD":
		//	codeMap["非归档存储"] += bucket.AllSize.Value
		case "STANDARD":
			codeMap["标准存储"] += bucket.AllSize.Value
		case "ARCHIVE":
			codeMap["归档存储"] += bucket.AllSize.Value
		case "STANDARD_IA":
			codeMap["低频存储"] += bucket.AllSize.Value
		}
	}

	return codeMap
}

func GetStorageTypeCapacityMap(region string) map[string]float64 {
	var rst EsKs3StoreAggr
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	subIndex := oneDayAgoDate[0]
	var codeMap = map[string]float64{
		"ARCHIVE":     0,
		"STANDARD":    0,
		"STANDARD_IA": 0,
	}
	//subIndex = "220725"
	url := fmt.Sprintf("http://%s/col.ks3_store_of_day.%s/_search?from=0&size=1", config.DefaultK3sEsService, subIndex)
	if region != "" && region != "all" {
		url = url + "&q=ks3region:" + strings.ToUpper(region)
	}
	c := http.Client{Timeout: time.Second * 3}

	query := `{"aggs": {
					"storageclass": {
					  "terms": {
						"field": "storageclass",
						"size": 10000
					  },
					  "aggs": {
						"allSize": {
						  "sum": {
							"field": "allSize"
						  }
						}
					  }
					}
				  }
				}`
	jsoninfo := strings.NewReader(query)
	resp, err := c.Post(url, "application/json", jsoninfo)
	if err != nil {
		klog.Errorf("Failed to get es bucket pool store aggr data ，err: %s", err)
		return codeMap
	}
	defer resp.Body.Close()
	body, _ := io.ReadAll(resp.Body)
	json.Unmarshal(body, &rst)

	for _, bucket := range rst.Aggregations.Storageclass.Buckets {
		switch bucket.Key {
		case "ARCHIVE":
			codeMap["ARCHIVE"] += bucket.AllSize.Value
		case "STANDARD":
			codeMap["STANDARD"] += bucket.AllSize.Value
		case "STANDARD_IA":
			codeMap["STANDARD_IA"] += bucket.AllSize.Value
		}
	}

	return codeMap
}

func GetBucketPoolApiNum() string {
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	subIndex := oneDayAgoDate[0]
	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, subIndex)
	result, err := GetEsWideData(url)
	if err != nil {
		klog.Info(err)
		return ""
	}
	total := result.Hits.Total
	//if total > 10000 {
	//	total = 10000
	//}
	totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s", config.DefaultK3sEsService, subIndex, strconv.Itoa(total))
	totalResult, er := GetEsWideData(totalUrl)
	//totalResult, er := GetMultiEsWideData(subIndex, total)
	if er != nil {
		klog.Info(er)
		return ""
	}
	count := len(totalResult.Hits.Hits)

	var times int64
	for i := 0; i < count; i++ {
		j := totalResult.Hits.Hits[i]
		times += j.Source.Times
	}
	return strconv.FormatInt(times, 10)
}

func GetBucketPoolApiNumSum(region string) string {
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	subIndex := oneDayAgoDate[0]

	//subIndex = "220706"

	q := elastic.NewBoolQuery()
	if region != "" && region != "all" && region != "ALL" {
		q.Must(elastic.NewTermQuery("ks3region", strings.ToUpper(region)))
	}
	index := fmt.Sprintf("col.ks3_wide.%s", subIndex)

	if client.EsClient == nil {
		klog.Error("EsClient is nil....")
		return "0"
	}

	do, err := client.EsClient.Search().Index(index).
		Query(q).
		Aggregation("apiNum", elastic.NewSumAggregation().Field("times")).
		Do(context.Background())
	if err != nil {
		klog.Error("EsClient sum times error...." + err.Error())
		return "0"
	}

	var times int64
	if v, ok := do.Aggregations.Sum("apiNum"); ok {
		times, _ = strconv.ParseInt(fmt.Sprintf("%1.0f", *v.Value), 10, 64)
	}
	return strconv.FormatInt(times, 10)
}

func GetBucketApiNumByid(id string) (int64, error) {
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	//nowDate           = strings.Split(now, ".")
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	//index             = nowDate[0]
	subIndex := oneDayAgoDate[0]
	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, subIndex, id)
	result, err := GetEsWideData(url)
	if err != nil {
		klog.Info(err)
		return 0, err
	}
	total := result.Hits.Total

	totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, subIndex, strconv.Itoa(total), id)
	totalResult, er := GetEsWideData(totalUrl)
	if er != nil {
		klog.Info(er)
		return 0, er
	}
	count := len(totalResult.Hits.Hits)

	var times int64
	for i := 0; i < count; i++ {
		j := totalResult.Hits.Hits[i]
		times += j.Source.Times
	}
	return times, nil
}

func Get30Ks3Capacity(region string) ([]resourcepoolmodel.EchartType, error) {
	rst := make([]resourcepoolmodel.EchartType, 0)
	info := resourcepoolmodel.InfoType{Unit: "B", UnitType: "storage", Name: "存储容量库存"}
	r := resourcepoolmodel.EchartType{Info: info}

	for i := 30; i > 0; i-- {

		hourTime := -24 * i

		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		var size int = 0
		ctx, cefl := context.WithTimeout(context.Background(), 1*time.Minute)
		defer cefl()
		key := "objectStoragePool_overviewLine_capacity:" + region
		rs, err := client.HGet(ctx, key, Index)
		if err != nil {
			size = GetEsStoreSumCapacity(Index, region)
			if size > 0 {
				client.HSet(ctx, key, Index, size)
			}
			DeleteExpireFields(ctx, key)
		} else {
			size, _ = strconv.Atoi(rs)
		}

		timeStamp := time.Now().Add(time.Duration(hourTime) * time.Hour).Unix()
		echart := services.ValueType{
			Value:      size,
			Name:       timeStamp,
			TimeSteamp: timeStamp,
		}
		r.Values = append(r.Values, echart)

	}
	rst = append(rst, r)

	return rst, nil
}

// 统计30天返回bucketNum的情况
func Get30BucketNumLine() ([]resourcepoolmodel.EchartType, error) {
	rst := make([]resourcepoolmodel.EchartType, 0)
	info := resourcepoolmodel.InfoType{Unit: "个", UnitType: "number", Name: "bucket总量"}
	r := resourcepoolmodel.EchartType{Info: info}

	//globeMap := make(map[resourcepoolmodel.InfoType][]services.ValueType)
	for i := 30; i > 0; i-- {

		//codeMap := make(map[string]int64)
		hourTime := -24 * i

		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		url := fmt.Sprintf("http://%s/col.ks3_store_of_day.%s/_search?from=0&size=1", config.DefaultK3sEsService, Index)
		result, err := GetEsWideData(url)
		if err != nil {
			klog.Info(err)
			return rst, err
		}
		total := result.Hits.Total

		// totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s", config.DefaultK3sEsService, subIndex, strconv.Itoa(total))
		// totalResult := GetEsWideData(totalUrl)
		// count := len(totalResult.Hits.Hits)

		// var times int64 = 0
		// for i := 0; i < count; i++ {
		// 	j := totalResult.Hits.Hits[i]
		// 	times += j.Source.Times
		// }

		timeStamp := time.Now().Add(time.Duration(hourTime) * time.Hour).Unix()
		echart := services.ValueType{
			Value:      total / 3,
			Name:       timeStamp,
			TimeSteamp: timeStamp,
		}
		r.Values = append(r.Values, echart)

	}
	rst = append(rst, r)

	return rst, nil
}

// 统计30天返回apiNum的情况
func Get30ApiNumLine() ([]resourcepoolmodel.EchartType, error) {
	rst := make([]resourcepoolmodel.EchartType, 0)
	info := resourcepoolmodel.InfoType{Unit: "次", UnitType: "number", Name: "api请求数"}
	r := resourcepoolmodel.EchartType{Info: info}

	for i := 30; i > 0; i-- {

		hourTime := -24 * i
		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		var times int64 = 0
		ctx, cefl := context.WithTimeout(context.Background(), 1*time.Minute)
		defer cefl()
		key := "objectStoragePool_overviewLine_APITimes"
		rs, err := client.HGet(ctx, key, Index)
		if err != nil {
			times = getApiTimesFromEsWide(Index)
			client.HSet(ctx, key, Index, times)
			DeleteExpireFields(ctx, key)
		} else {
			times, _ = strconv.ParseInt(rs, 10, 64)
		}
		timeStamp := time.Now().Add(time.Duration(hourTime) * time.Hour).Unix()
		echart := services.ValueType{
			Value:      times,
			Name:       timeStamp,
			TimeSteamp: timeStamp,
		}
		r.Values = append(r.Values, echart)

	}
	rst = append(rst, r)
	return rst, nil
}

////统计30天返回apiNum的情况
//func Get30ApiNum() int64 {
//	var times int64 = 0
//	for i := 30; i > 0; i-- {
//		hourTime := -24 * i
//
//		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
//		AgoDate := strings.Split(Ago, ".")
//		Index := AgoDate[0]
//
//		url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, Index)
//		result, err := GetEsWideData(url)
//		if err != nil {
//			klog.Info(err)
//			return 0
//		}
//		total := result.Hits.Total
//		//if total > 10000 {
//		//	total = 10000
//		//}
//		totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s", config.DefaultK3sEsService, Index, strconv.Itoa(total))
//		totalResult, er := GetEsWideData(totalUrl)
//		//totalResult, er := GetMultiEsWideData(Index, total)
//		if err != nil {
//			klog.Info(er)
//			return 0
//		}
//		count := len(totalResult.Hits.Hits)
//
//		for i := 0; i < count; i++ {
//			j := totalResult.Hits.Hits[i]
//			times += j.Source.Times
//		}
//
//	}
//
//	return times
//}

// 统计30天返回apiNum的情况
func Get30ApiNum() int64 {
	var timesTotal int64 = 0
	for i := 30; i > 0; i-- {
		hourTime := -24 * i

		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		var times int64 = 0
		ctx, cefl := context.WithTimeout(context.Background(), 1*time.Minute)
		defer cefl()
		key := "objectStoragePool_overviewLine_APITimes"
		rs, err := client.HGet(ctx, key, Index)
		if err != nil {
			times = getApiTimesFromEsWide(Index)
			client.HSet(ctx, key, Index, times)
			DeleteExpireFields(ctx, key)
		} else {
			times, _ = strconv.ParseInt(rs, 10, 64)
		}

		timesTotal += times
	}

	return timesTotal
}

// 基于id统计30天返回apiNum的情况
func Get30ApiNumLineById(id string) ([]resourcepoolmodel.EchartType, error) {
	rst := make([]resourcepoolmodel.EchartType, 0)
	info := resourcepoolmodel.InfoType{Unit: "次", UnitType: "number", Name: "api请求数"}
	r := resourcepoolmodel.EchartType{Info: info}

	//globeMap := make(map[resourcepoolmodel.InfoType][]services.ValueType)
	for i := 30; i > 0; i-- {

		//codeMap := make(map[string]int64)
		hourTime := -24 * i

		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, Index, id)
		result, err := GetEsWideData(url)
		if err != nil {
			klog.Info(err)
			return rst, err
		}
		total := result.Hits.Total

		totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, Index, strconv.Itoa(total), id)
		totalResult, er := GetEsWideData(totalUrl)
		if err != nil {
			klog.Info(er)
			return rst, err
		}
		count := len(totalResult.Hits.Hits)

		var times int64 = 0
		for i := 0; i < count; i++ {
			j := totalResult.Hits.Hits[i]
			times += j.Source.Times
		}

		timeStamp := time.Now().Add(time.Duration(hourTime)*time.Hour).UnixNano() / 1e6
		echart := services.ValueType{
			Value:      times,
			Name:       timeStamp,
			TimeSteamp: timeStamp,
		}
		r.Values = append(r.Values, echart)

	}
	rst = append(rst, r)

	return rst, nil
}

// 基于bucketId统计30天返回store的情况
func Get30StoreLineById(id string) ([]resourcepoolmodel.EchartType, error) {
	rst := make([]resourcepoolmodel.EchartType, 0)

	globeMap := make(map[resourcepoolmodel.InfoType][]services.ValueType)
	for i := 30; i > 0; i-- {

		var codeMap = map[string]float64{
			"总量":  0,
			"增量":  0,
			"删除量": 0,
		}

		hourTime := -24 * i
		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		url := fmt.Sprintf("http://%s/col.ks3_store_of_day.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, Index, id)
		result, err := GetEsStoreData(url)
		if err != nil {
			klog.Info(err)
			return rst, err
		}
		total := result.Hits.Total

		totalUrl := fmt.Sprintf("http://%s/col.ks3_store_of_day.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, Index, strconv.Itoa(total), id)
		totalResult, er := GetEsStoreData(totalUrl)
		if er != nil {
			klog.Info(er)
			return rst, err
		}
		count := len(totalResult.Hits.Hits)

		for o := 0; o < count; o++ {
			j := totalResult.Hits.Hits[o]
			codeMap["总量"] += j.Source.AllSize
			codeMap["增量"] += j.Source.AddSize
			codeMap["删除量"] += j.Source.DelSize
		}

		timeStamp := time.Now().Add(time.Duration(hourTime)*time.Hour).UnixNano() / 1e6
		for k, v := range codeMap {
			info := resourcepoolmodel.InfoType{Unit: "B", UnitType: "storage", Name: k}
			echart := services.ValueType{
				Value:      v,
				Name:       timeStamp,
				TimeSteamp: timeStamp,
			}
			globeMap[info] = append(globeMap[info], echart)
		}

	}
	for k, v := range globeMap {
		r := resourcepoolmodel.EchartType{Info: k, Values: v}
		rst = append(rst, r)
	}

	return rst, nil
}

func GetStoreLineById(id string) (map[string]float64, error) {
	var codeMap = map[string]float64{
		"总量":  0,
		"增量":  0,
		"删除量": 0,
	}

	Index := GetDateIndex(-1)

	url := fmt.Sprintf("http://%s/col.ks3_store_of_day.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, Index, id)
	result, err := GetEsStoreData(url)
	if err != nil {
		klog.Info(err)
		return codeMap, err
	}
	total := result.Hits.Total

	totalUrl := fmt.Sprintf("http://%s/col.ks3_store_of_day.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, Index, strconv.Itoa(total), id)
	totalResult, er := GetEsStoreData(totalUrl)
	if er != nil {
		klog.Info(er)
		return codeMap, err
	}
	count := len(totalResult.Hits.Hits)

	for o := 0; o < count; o++ {
		j := totalResult.Hits.Hits[o]
		codeMap["总量"] += j.Source.AllSize
		codeMap["增量"] += j.Source.AddSize
		codeMap["删除量"] += j.Source.DelSize
	}

	return codeMap, nil
}

func Get30Flow(region string) string {
	var up, down int64

	for i := 1; i < 31; i++ {
		hourTime := -24 * i
		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		flowMap, _ := GetFlowByDayCache(Index, region)
		up += flowMap["up"]
		down += flowMap["down"]
	}

	upFlow := services.FormatSize(float64(up))
	downFlow := services.FormatSize(float64(down))
	return upFlow + "/" + downFlow
}

func GetFlowByDay(dateIndex, region string) (map[string]int64, error) {
	var flowMap = map[string]int64{
		"up":   0,
		"down": 0,
	}
	//flowMap["up"] = GetBucketPoolTrafficUpSum(dayIndex, region)
	//flowMap["down"] = GetBucketPoolTrafficDownSum(dayIndex, region)

	flowMap["up"], _ = GetTrafficSum(region, "", "", "", dateIndex, TrafficUp)
	flowMap["down"], _ = GetTrafficSum(region, "", "", "", dateIndex, TrafficDown)

	return flowMap, nil
}

func GetFlowByDayCache(dayIndex, region string) (map[string]int64, error) {
	var flowMap = map[string]int64{
		"up":   0,
		"down": 0,
	}
	ctx, cefl := context.WithTimeout(context.Background(), 3*time.Minute)
	defer cefl()
	key := "objectStoragePool_overviewLine_traffic:" + region
	rs, err := client.HGet(ctx, key, dayIndex)
	if err != nil {
		flowMap, err = GetFlowByDay(dayIndex, region)
		if err == nil {
			valueJson, _ := json.Marshal(flowMap)
			client.HSet(ctx, key, dayIndex, valueJson)
		}
		DeleteExpireFields(ctx, key)
	} else {
		err = json.Unmarshal([]byte(rs), &flowMap)
	}
	return flowMap, nil
}

// 统计30天返回code的情况
func Get30CodeLine(region string) ([]resourcepoolmodel.EchartType, error) {
	rst := make([]resourcepoolmodel.EchartType, 0)

	globeMap := make(map[resourcepoolmodel.InfoType][]services.ValueType)
	for i := 30; i > 0; i-- {
		hourTime := -24 * i
		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]
		var codeMap = map[string]int64{
			"2xx": 0,
			"3xx": 0,
			"4xx": 0,
			"5xx": 0,
		}

		ctx, cefl := context.WithTimeout(context.Background(), 3*time.Minute)
		defer cefl()
		key := "objectStoragePool_overviewLine_code:" + region
		rs, err := client.HGet(ctx, key, Index)
		if err != nil {
			codeMap = GetBucketPoolCodeAggr(region, Index)
			valueJson, _ := json.Marshal(codeMap)
			client.HSet(ctx, key, Index, valueJson)
			DeleteExpireFields(ctx, key)
		} else {
			err = json.Unmarshal([]byte(rs), &codeMap)
		}
		timeStamp := time.Now().Add(time.Duration(hourTime) * time.Hour).Unix()
		for k, v := range codeMap {
			info := resourcepoolmodel.InfoType{Unit: "次", UnitType: "number", Name: k}
			echart := services.ValueType{
				Value:      v,
				Name:       timeStamp,
				TimeSteamp: timeStamp,
			}
			globeMap[info] = append(globeMap[info], echart)
		}

	}
	for k, v := range globeMap {
		r := resourcepoolmodel.EchartType{Info: k, Values: v}
		rst = append(rst, r)
	}

	return rst, nil
}

func GetDateIndex(offset int) string {
	hourTime := 24 * offset
	Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
	AgoDate := strings.Split(Ago, ".")
	return AgoDate[0]
}

func DeleteExpireFields(ctx context.Context, k string) {
	fields, err := client.HKeys(ctx, k)
	if err != nil {
		return
	}

	indexExpire := GetDateIndex(-40) // 取40天之前的日期作为数据是否过期的判断条件
	fieldsExpire := make([]string, 0)
	for _, field := range fields {
		if field < indexExpire {
			fieldsExpire = append(fieldsExpire, field)
		}
	}

	if len(fieldsExpire) > 0 {
		client.HDelBatch(ctx, k, fieldsExpire)
	}
}

func deleteHMapField(ctx context.Context, k string, offset int) {
	deleteDate := time.Now().Add(time.Duration(-24*offset) * time.Hour).Format(EsIndexDateFormat)
	deleteIndex := strings.Split(deleteDate, ".")[0]
	client.HDel(ctx, k, deleteIndex)
}

func getApiTimesFromEsWide(dayIndex string) int64 {
	totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, dayIndex)
	return int64(GetEsWideSumTimes(totalUrl))
}

func getCodeMapFromEsWide(dayIndex string) map[string]int64 {
	var codeMap = map[string]int64{
		"2xx": 0,
		"3xx": 0,
		"4xx": 0,
		"5xx": 0,
	}
	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, dayIndex)
	result, err := GetEsWideData(url)
	if err != nil {
		klog.Error(err)
		return codeMap
	}
	total := result.Hits.Total

	totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s", config.DefaultK3sEsService, dayIndex, strconv.Itoa(total))
	totalResult, er := GetEsWideData(totalUrl)

	if er != nil {
		klog.Error(err)
		return codeMap
	}
	count := len(totalResult.Hits.Hits)

	for o := 0; o < count; o++ {
		j := totalResult.Hits.Hits[o]
		s := strings.Split(j.Source.Code, "")
		if len(s) > 0 {
			switch s[0] {
			case "2":
				codeMap["2xx"]++
			case "3":
				codeMap["3xx"]++
			case "4":
				codeMap["4xx"]++
			case "5":
				codeMap["5xx"]++

			}
		}
	}

	return codeMap
}

func getMethodMapFromEsWide(dayIndex string) map[string]int64 {
	var methodMap = map[string]int64{
		"GET":     0,
		"PUT":     0,
		"POST":    0,
		"HEAD":    0,
		"DELETE":  0,
		"OPTIONS": 0,
	}
	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, dayIndex)
	result, err := GetEsWideData(url)
	if err != nil {
		klog.Error(err)
		return methodMap
	}
	total := result.Hits.Total

	totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s", config.DefaultK3sEsService, dayIndex, strconv.Itoa(total))
	totalResult, er := GetEsWideData(totalUrl)
	if er != nil {
		klog.Error(err)
		return methodMap
	}
	count := len(totalResult.Hits.Hits)

	for o := 0; o < count; o++ {
		j := totalResult.Hits.Hits[o]
		s := strings.Split(j.Source.Operation, ".")
		if len(s) > 1 {
			switch s[1] {
			case "GET":
				methodMap["GET"] += j.Source.Times
			case "POST":
				methodMap["POST"] += j.Source.Times
			case "PUT":
				methodMap["PUT"] += j.Source.Times
			case "DELETE":
				methodMap["DELETE"] += j.Source.Times
			case "HEAD":
				methodMap["HEAD"] += j.Source.Times
			case "OPTIONS":
				methodMap["OPTIONS"] += j.Source.Times

			}
		}
	}
	return methodMap
}

func getMethodMapFromEsAggr(region, storageClass, dayIndex string) map[string]int64 {
	var methodMap = map[string]int64{
		"GET":     0,
		"PUT":     0,
		"POST":    0,
		"HEAD":    0,
		"DELETE":  0,
		"OPTIONS": 0,
	}
	esSum, err := GetTimesByEsSum(region, storageClass, dayIndex)
	if err != nil {
		return methodMap
	}
	cnt := len(esSum.Aggregations.GroupBy.Bucket)
	for i := 0; i < cnt; i++ {
		j := esSum.Aggregations.GroupBy.Bucket[i]
		methodTimes, _ := strconv.ParseInt(fmt.Sprintf("%1.0f", j.TotalTimes.Value), 10, 64)

		s := strings.Split(j.Key, ".")
		if len(s) > 1 {
			switch s[1] {
			case "GET":
				methodMap["GET"] += methodTimes
			case "POST":
				methodMap["POST"] += methodTimes
			case "PUT":
				methodMap["PUT"] += methodTimes
			case "DELETE":
				methodMap["DELETE"] += methodTimes
			case "HEAD":
				methodMap["HEAD"] += methodTimes
			case "OPTIONS":
				methodMap["OPTIONS"] += methodTimes

			}
		}
	}
	return methodMap
}

func getflowMapFromEsWide(region, dayIndex string) map[string]int64 {
	bandMap := map[string]int64{
		"外网上传":    0,
		"外网下载":    0,
		"内网上传":    0,
		"内网下载":    0,
		"CDN上传":   0,
		"CDN下载":   0,
		"跨区域复制上传": 0,
		"跨区域复制下载": 0,
	}

	aggr, err := GetTrafficAggrFromEs(region, "", dayIndex)
	if err != nil {
		return bandMap
	}

	for _, userTypeBucket := range aggr.Aggregations.Usertype.UsertypeBuckets {
		for _, isInnerBucket := range userTypeBucket.IsInner.IsInnerBuckets {
			up, _ := strconv.ParseInt(fmt.Sprintf("%1.0f", isInnerBucket.Up.Value), 10, 64)
			down, _ := strconv.ParseInt(fmt.Sprintf("%1.0f", isInnerBucket.Down.Value), 10, 64)
			if userTypeBucket.Key == "crr" {
				bandMap["跨区域复制上传"] += up
				bandMap["跨区域复制下载"] += down
			} else if userTypeBucket.Key != "-" {
				bandMap["CDN上传"] += up
				bandMap["CDN下载"] += down
			}
			if isInnerBucket.Key == "false" {
				bandMap["外网上传"] += up
				bandMap["外网下载"] += down
			} else {
				bandMap["内网上传"] += up
				bandMap["内网下载"] += down
			}
		}
	}
	return bandMap
}

type trafficType string

var TrafficUp trafficType = "up"
var TrafficDown trafficType = "down"

func GetTrafficSum(region, storageType, userType, isInner, dayIndex string, traffic trafficType) (int64, error) {
	trafficField := "traffic_up"
	q := elastic.NewBoolQuery()
	queries := make([]elastic.Query, 0)
	if region != "" && region != "all" && region != "ALL" {
		queries = append(queries, elastic.NewTermQuery("ks3region", strings.ToUpper(region)))
	}
	if storageType != "" && storageType != "all" && storageType != "ALL" {
		queries = append(queries, elastic.NewTermQuery("storageclass", storageType))
	}
	if userType != "" && userType != "all" && userType != "ALL" {
		queries = append(queries, elastic.NewTermQuery("usertype", userType))
	}
	if isInner != "" && isInner != "all" && isInner != "ALL" {
		queries = append(queries, elastic.NewTermQuery("isinner", isInner))
	}
	if TrafficUp == traffic {
		ops := []interface{}{"REST.PUT.UPLOADPART", "REST.POST.COMPLETE_MULTIUPLOAD", "REST.POST.OBJECT", "REST.PUT.OBJECT"}
		queries = append(queries, elastic.NewTermsQuery("operation", ops...))
	}
	if TrafficDown == traffic {
		trafficField = "traffic_down"
		ops := []interface{}{"REST.GET.OBJECT"}
		queries = append(queries, elastic.NewTermsQuery("operation", ops...))
	}
	q.Filter(queries...)
	if client.EsClient == nil {
		klog.Error("EsClient is nil....")
		return 0, errors.New("EsClient is nil")
	}

	index := fmt.Sprintf("col.ks3_wide.%s", dayIndex)
	do, err := client.EsClient.Search().Index(index).
		Query(q).
		From(0).Size(1).
		Aggregation("trafficSum", elastic.NewSumAggregation().Field(trafficField)).
		Do(context.Background())
	if err != nil {
		klog.Error("EsClient sum traffic error...." + err.Error())
		return 0, err
	}

	var trafficValue int64
	if v, ok := do.Aggregations.Sum("trafficSum"); ok {
		trafficValue, _ = strconv.ParseInt(fmt.Sprintf("%1.0f", *v.Value), 10, 64)
	}
	return trafficValue, nil
}

// 基于id统计30天返回code的情况
func Get30CodeLineById(id string) ([]resourcepoolmodel.EchartType, error) {
	rst := make([]resourcepoolmodel.EchartType, 0)

	globeMap := make(map[resourcepoolmodel.InfoType][]services.ValueType)
	for i := 30; i > 0; i-- {

		var codeMap = map[string]int64{
			"2xx": 0,
			"3xx": 0,
			"4xx": 0,
			"5xx": 0,
		}

		hourTime := -24 * i
		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, Index, id)
		result, err := GetEsWideData(url)
		if err != nil {
			klog.Info(err)
			return rst, err
		}
		total := result.Hits.Total

		totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, Index, strconv.Itoa(total), id)
		totalResult, er := GetEsWideData(totalUrl)
		if er != nil {
			klog.Info(er)
			return rst, err
		}
		count := len(totalResult.Hits.Hits)

		for o := 0; o < count; o++ {
			j := totalResult.Hits.Hits[o]
			s := strings.Split(j.Source.Code, "")
			if len(s) > 0 {
				switch s[0] {
				case "2":
					codeMap["2xx"]++
				case "3":
					codeMap["3xx"]++
				case "4":
					codeMap["4xx"]++
				case "5":
					codeMap["5xx"]++

				}
			}
		}

		timeStamp := time.Now().Add(time.Duration(hourTime)*time.Hour).UnixNano() / 1e6
		for k, v := range codeMap {
			info := resourcepoolmodel.InfoType{Unit: "次", UnitType: "number", Name: k}
			echart := services.ValueType{
				Value:      v,
				Name:       timeStamp,
				TimeSteamp: timeStamp,
			}
			globeMap[info] = append(globeMap[info], echart)
		}

	}
	for k, v := range globeMap {
		r := resourcepoolmodel.EchartType{Info: k, Values: v}
		rst = append(rst, r)
	}

	return rst, nil
}

// 基于id统计30天读写成功率的情况
func Get30RWOKLineById(id string) ([]resourcepoolmodel.EchartType, error) {
	rst := make([]resourcepoolmodel.EchartType, 0)

	globeMap := make(map[resourcepoolmodel.InfoType][]services.ValueType)
	for i := 30; i > 0; i-- {

		var codeMap = map[string]float64{
			"读成功率": 0,
			"写成功率": 0,
		}

		hourTime := -24 * i
		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, Index, id)
		result, err := GetEsWideData(url)
		if err != nil {
			klog.Info(err)
			return rst, err
		}
		total := result.Hits.Total

		totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, Index, strconv.Itoa(total), id)
		totalResult, er := GetEsWideData(totalUrl)
		if er != nil {
			klog.Info(er)
			return rst, err
		}
		count := len(totalResult.Hits.Hits)

		var rTotal, rOK, wTotal, wOK float64
		for o := 0; o < count; o++ {
			j := totalResult.Hits.Hits[o]
			s := strings.Split(j.Source.Operation, ".")
			c := strings.Split(j.Source.Code, "")
			if len(s) > 1 {
				switch s[1] {
				case "GET":
					rTotal++
					if len(c) > 0 {
						switch c[0] {
						case "2":
							rOK++
						}
					}
				case "POST":
					wTotal++
					if len(c) > 0 {
						switch c[0] {
						case "2":
							wOK++
						}
					}
				case "PUT":
					wTotal++
					if len(c) > 0 {
						switch c[0] {
						case "2":
							wOK++
						}
					}
				case "HEAD":
					rTotal++
					if len(c) > 0 {
						switch c[0] {
						case "2":
							rOK++
						}
					}
				}
			}
		}
		if rTotal > 0 {
			codeMap["读成功率"] = services.FormPercent(rOK / rTotal)
		}

		if wTotal > 0 {
			codeMap["写成功率"] = services.FormPercent(wOK / wTotal)
		}

		timeStamp := time.Now().Add(time.Duration(hourTime)*time.Hour).UnixNano() / 1e6
		for k, v := range codeMap {
			info := resourcepoolmodel.InfoType{Unit: "%", UnitType: "percent", Name: k}
			echart := services.ValueType{
				Value:      v,
				Name:       timeStamp,
				TimeSteamp: timeStamp,
			}
			globeMap[info] = append(globeMap[info], echart)
		}

	}
	for k, v := range globeMap {
		r := resourcepoolmodel.EchartType{Info: k, Values: v}
		rst = append(rst, r)
	}

	return rst, nil
}

// 基于id统计前一天读写成功率的情况
func GetRWOKById(id string) map[string]float64 {

	var codeMap = map[string]float64{
		"读成功率": 0,
		"写成功率": 0,
	}

	Ago := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	AgoDate := strings.Split(Ago, ".")
	Index := AgoDate[0]

	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, Index, id)
	result, err := GetEsWideData(url)
	if err != nil {
		klog.Info(err)
		return codeMap
	}
	total := result.Hits.Total

	totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, Index, strconv.Itoa(total), id)
	totalResult, er := GetEsWideData(totalUrl)
	if er != nil {
		klog.Info(er)
		return codeMap
	}
	count := len(totalResult.Hits.Hits)

	var rTotal, rOK, wTotal, wOK float64
	for o := 0; o < count; o++ {
		j := totalResult.Hits.Hits[o]
		s := strings.Split(j.Source.Operation, ".")
		c := strings.Split(j.Source.Code, "")
		if len(s) > 1 {
			switch s[1] {
			case "GET":
				rTotal++
				if len(c) > 0 {
					switch c[0] {
					case "2":
						rOK++
					}
				}
			case "POST":
				wTotal++
				if len(c) > 0 {
					switch c[0] {
					case "2":
						wOK++
					}
				}
			case "PUT":
				wTotal++
				if len(c) > 0 {
					switch c[0] {
					case "2":
						wOK++
					}
				}
			case "HEAD":
				rTotal++
				if len(c) > 0 {
					switch c[0] {
					case "2":
						rOK++
					}
				}
			}
		}
	}
	if rTotal > 0 {
		codeMap["读成功率"] = services.FormPercent(rOK / rTotal)
	}

	if wTotal > 0 {
		codeMap["写成功率"] = services.FormPercent(wOK / wTotal)
	}

	return codeMap
}

// 统计30天请求的情况
func Get30ApiLine(region string) ([]resourcepoolmodel.EchartType, error) {
	rst := make([]resourcepoolmodel.EchartType, 0)

	globeMap := make(map[resourcepoolmodel.InfoType][]services.ValueType)
	for i := 30; i > 0; i-- {
		var methodMap = map[string]int64{
			"GET":     0,
			"PUT":     0,
			"POST":    0,
			"HEAD":    0,
			"DELETE":  0,
			"OPTIONS": 0,
		}

		hourTime := -24 * i
		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		ctx, cefl := context.WithTimeout(context.Background(), 3*time.Minute)
		defer cefl()
		key := "objectStoragePool_overviewLine_method:" + region
		rs, err := client.HGet(ctx, key, Index)
		if err != nil {
			methodMap = getMethodMapFromEsAggr(region, "", Index)
			valueJson, _ := json.Marshal(methodMap)
			client.HSet(ctx, key, Index, valueJson)
			DeleteExpireFields(ctx, key)
		} else {
			err = json.Unmarshal([]byte(rs), &methodMap)
		}

		timeStamp := time.Now().Add(time.Duration(hourTime) * time.Hour).Unix()
		for k, v := range methodMap {
			info := resourcepoolmodel.InfoType{Unit: "次", UnitType: "number", Name: k}
			echart := services.ValueType{
				Value:      v,
				Name:       timeStamp,
				TimeSteamp: timeStamp,
			}
			globeMap[info] = append(globeMap[info], echart)
		}

	}
	for k, v := range globeMap {
		r := resourcepoolmodel.EchartType{Info: k, Values: v}
		rst = append(rst, r)
	}

	return rst, nil
}

// 统计资源池前一天请求细节情况
func GetBucketPoolApiNumDetail() resourcepoolmodel.EchartType {
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	//nowDate           = strings.Split(now, ".")
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	//index             = nowDate[0]
	subIndex := oneDayAgoDate[0]
	chart := resourcepoolmodel.EchartType{}
	chart.Info.Name = "总体API请求"
	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, subIndex)
	result, err := GetEsWideData(url)
	if err != nil {
		klog.Info(err)
		return chart
	}
	total := result.Hits.Total
	//if total > 10000 {
	//	total = 10000
	//}
	totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s", config.DefaultK3sEsService, subIndex, strconv.Itoa(total))
	totalResult, er := GetEsWideData(totalUrl)
	//totalResult, er := GetMultiEsWideData(subIndex, total)
	if er != nil {
		klog.Info(er)
		return chart
	}
	count := len(totalResult.Hits.Hits)

	var times int64
	var restfulMap = map[string]int64{
		"GET":     0,
		"PUT":     0,
		"POST":    0,
		"HEAD":    0,
		"DELETE":  0,
		"OPTIONS": 0,
	}
	for i := 0; i < count; i++ {
		j := totalResult.Hits.Hits[i]
		times += j.Source.Times
		s := strings.Split(j.Source.Operation, ".")
		if len(s) > 1 {
			switch s[1] {
			case "GET":
				restfulMap["GET"] += j.Source.Times
			case "POST":
				restfulMap["POST"] += j.Source.Times
			case "PUT":
				restfulMap["PUT"] += j.Source.Times
			case "DELETE":
				restfulMap["DELETE"] += j.Source.Times
			case "HEAD":
				restfulMap["HEAD"] += j.Source.Times
			case "OPTIONS":
				restfulMap["OPTIONS"] += j.Source.Times

			}
		}
	}
	chart.Info.Total = times
	for k, v := range restfulMap {
		value := services.ValueType{Name: k, Value: v}
		chart.Values = append(chart.Values, value)
	}
	return chart
}

// 基于id统计bucket前一天请求细节情况
func GetBucketApiNumDetailById(id string) resourcepoolmodel.EchartType {
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	//nowDate           = strings.Split(now, ".")
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	//index             = nowDate[0]
	subIndex := oneDayAgoDate[0]
	chart := resourcepoolmodel.EchartType{}
	chart.Info.Name = "总体API请求"

	url := ""
	if id == "" {
		url = fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, subIndex)
	} else {
		url = fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, subIndex, id)
	}

	//url = fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, subIndex, id)
	result, err := GetEsWideData(url)
	if err != nil {
		klog.Info(err)
		return chart
	}
	total := result.Hits.Total
	//if total > 10000 {
	//	total = 10000
	//}
	totalUrl := ""
	var totalResult EsKs3Wide
	var er error
	if id == "" {
		totalUrl = fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s", config.DefaultK3sEsService, subIndex, strconv.Itoa(total))
		totalResult, er = GetEsWideData(totalUrl)
		if er != nil {
			klog.Info(er)
			return chart
		}
	} else {
		totalUrl = fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, subIndex, strconv.Itoa(total), id)
		totalResult, er = GetEsWideData(totalUrl)
		if er != nil {
			klog.Info(er)
			return chart
		}
	}

	//totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, subIndex, strconv.Itoa(total), id)

	count := len(totalResult.Hits.Hits)

	//klog.Infof("id is %s:", id)
	//klog.Infof("totalUrl is %s:", totalUrl)
	//klog.Infof("总体API请求 hits len is %d:", count)

	var times int64
	var restfulMap = map[string]int64{
		"GET":     0,
		"PUT":     0,
		"POST":    0,
		"HEAD":    0,
		"DELETE":  0,
		"OPTIONS": 0,
	}
	for i := 0; i < count; i++ {
		j := totalResult.Hits.Hits[i]
		times += j.Source.Times
		s := strings.Split(j.Source.Operation, ".")
		if len(s) > 1 {
			switch s[1] {
			case "GET":
				restfulMap["GET"] += j.Source.Times
			case "POST":
				restfulMap["POST"] += j.Source.Times
			case "PUT":
				restfulMap["PUT"] += j.Source.Times
			case "DELETE":
				restfulMap["DELETE"] += j.Source.Times
			case "HEAD":
				restfulMap["HEAD"] += j.Source.Times
			case "OPTIONS":
				restfulMap["OPTIONS"] += j.Source.Times

			}
		}
	}
	chart.Info.Total = times
	for k, v := range restfulMap {
		value := services.ValueType{Name: k, Value: v}
		chart.Values = append(chart.Values, value)
	}
	return chart
}

func GetBucketApiNumDetail(region, storageClass string) resourcepoolmodel.EchartType {
	chart := resourcepoolmodel.EchartType{}
	chart.Info.Name = "总体API请求"

	var times int64
	var restfulMap = map[string]int64{
		"GET":     0,
		"PUT":     0,
		"POST":    0,
		"HEAD":    0,
		"DELETE":  0,
		"OPTIONS": 0,
	}
	Ago := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	AgoDate := strings.Split(Ago, ".")
	Index := AgoDate[0]
	esSum, err := GetTimesByEsSum(region, storageClass, Index)
	if err != nil {
		return chart
	}
	cnt := len(esSum.Aggregations.GroupBy.Bucket)
	for i := 0; i < cnt; i++ {
		j := esSum.Aggregations.GroupBy.Bucket[i]
		methodTimes, _ := strconv.ParseInt(fmt.Sprintf("%1.0f", j.TotalTimes.Value), 10, 64)
		times += methodTimes

		s := strings.Split(j.Key, ".")
		if len(s) > 1 {
			switch s[1] {
			case "GET":
				restfulMap["GET"] += methodTimes
			case "POST":
				restfulMap["POST"] += methodTimes
			case "PUT":
				restfulMap["PUT"] += methodTimes
			case "DELETE":
				restfulMap["DELETE"] += methodTimes
			case "HEAD":
				restfulMap["HEAD"] += methodTimes
			case "OPTIONS":
				restfulMap["OPTIONS"] += methodTimes

			}
		}
	}
	chart.Info.Total = times
	for k, v := range restfulMap {
		value := services.ValueType{Name: k, Value: v}
		chart.Values = append(chart.Values, value)
	}
	return chart
}

// 统计30天带宽的情况
func Get30BandLine(region string) ([]resourcepoolmodel.EchartType, error) {
	rst := make([]resourcepoolmodel.EchartType, 0)

	globeMap := make(map[resourcepoolmodel.InfoType][]services.ValueType)
	for i := 30; i > 0; i-- {

		bandMap := map[string]int64{
			"外网上传": 0,
			"外网下载": 0,
			//"内网上传": 0,
			//"内网下载": 0,
			//"CDN上传":   0,
			//"CDN下载":   0,
			"跨区域复制上传": 0,
			"跨区域复制下载": 0,
		}

		hourTime := -24 * i
		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		ctx, cefl := context.WithTimeout(context.Background(), 3*time.Minute)
		defer cefl()
		key := "objectStoragePool_overviewLine_flow:" + region
		rs, err := client.HGet(ctx, key, Index)
		if err != nil {
			//bandMap = getflowMapFromEsWide(strings.ToUpper(region), Index)
			bandMap["外网上传"], _ = GetTrafficSum(region, "", "", "false", Index, TrafficUp)
			bandMap["外网下载"], _ = GetTrafficSum(region, "", "", "false", Index, TrafficDown)
			//bandMap["内网上传"], _ = GetTrafficSum(region, "", "", "true", Index, TrafficUp)
			//bandMap["内网下载"], _ = GetTrafficSum(region, "", "", "true", Index, TrafficDown)
			bandMap["跨区域复制上传"], _ = GetTrafficSum(region, "", "crr", "", Index, TrafficUp)
			bandMap["跨区域复制下载"], _ = GetTrafficSum(region, "", "crr", "", Index, TrafficDown)
			valueJson, _ := json.Marshal(bandMap)
			client.HSet(ctx, key, Index, valueJson)
			DeleteExpireFields(ctx, key)
		} else {
			err = json.Unmarshal([]byte(rs), &bandMap)
		}

		timeStamp := time.Now().Add(time.Duration(hourTime) * time.Hour).Unix()
		for k, v := range bandMap {
			//过滤掉内网数据
			if k == "内网上传" || k == "内网下载" {
				continue
			}
			if k == "外网上传" {
				k = "内外网上传"
			} else if k == "外网下载" {
				k = "内外网下载"
			}
			info := resourcepoolmodel.InfoType{Unit: "Bps", UnitType: "storage", Name: k}
			echart := services.ValueType{
				Value:      v / 86400,
				Name:       timeStamp,
				TimeSteamp: timeStamp,
			}
			globeMap[info] = append(globeMap[info], echart)
		}

	}
	for k, v := range globeMap {
		r := resourcepoolmodel.EchartType{Info: k, Values: v}
		rst = append(rst, r)
	}

	return rst, nil
}

// 基于id统计30天带宽的情况
func Get30BandLineById(id string) ([]resourcepoolmodel.EchartType, error) {
	rst := make([]resourcepoolmodel.EchartType, 0)

	globeMap := make(map[resourcepoolmodel.InfoType][]services.ValueType)
	for i := 30; i > 0; i-- {

		codeMap := map[string]int64{
			"内外网上传": 0,
			"内外网下载": 0,
			//"内网上传": 0,
			//"内网下载": 0,
			//"CDN上传":   0,
			//"CDN下载":   0,
			"跨区域复制上传": 0,
			"跨区域复制下载": 0,
		}

		hourTime := -24 * i
		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, Index, id)
		result, err := GetEsWideData(url)
		if err != nil {
			klog.Info(err)
			return rst, err
		}
		total := result.Hits.Total

		totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, Index, strconv.Itoa(total), id)
		totalResult, er := GetEsWideData(totalUrl)
		if er != nil {
			klog.Info(er)
			return rst, er
		}
		count := len(totalResult.Hits.Hits)

		for o := 0; o < count; o++ {
			j := totalResult.Hits.Hits[o]
			if j.Source.Isinner == "false" {
				if services.In(OperationsUp, j.Source.Operation) {
					codeMap["内外网上传"] += j.Source.Traffic_up
				} else if services.In(OperationsDown, j.Source.Operation) {
					codeMap["内外网下载"] += j.Source.Traffic_down
				}
			}
			//else if j.Source.Isinner == "true" {
			//	codeMap["内网上传"] += j.Source.Traffic_up
			//	codeMap["内网下载"] += j.Source.Traffic_down
			//}
			if j.Source.Usertype == "crr" {
				if services.In(OperationsUp, j.Source.Operation) {
					codeMap["跨区域复制上传"] += j.Source.Traffic_up
				} else if services.In(OperationsDown, j.Source.Operation) {
					codeMap["跨区域复制下载"] += j.Source.Traffic_down
				}
			}
			//else if j.Source.Usertype != "-" {
			//	codeMap["CDN上传"] += j.Source.Traffic_up
			//	codeMap["CDN下载"] += j.Source.Traffic_down
			//}

		}

		timeStamp := time.Now().Add(time.Duration(hourTime)*time.Hour).UnixNano() / 1e6
		for k, v := range codeMap {
			info := resourcepoolmodel.InfoType{Unit: "Bps", UnitType: "storage", Name: k}
			echart := services.ValueType{
				Value:      v / 86400,
				Name:       timeStamp,
				TimeSteamp: timeStamp,
			}
			globeMap[info] = append(globeMap[info], echart)
		}

	}
	for k, v := range globeMap {
		r := resourcepoolmodel.EchartType{Info: k, Values: v}
		rst = append(rst, r)
	}

	return rst, nil
}

// 统计30天流量的情况
func Get30FlowLine(region string) ([]resourcepoolmodel.EchartType, error) {
	rst := make([]resourcepoolmodel.EchartType, 0)

	globeMap := make(map[resourcepoolmodel.InfoType][]services.ValueType)
	for i := 30; i > 0; i-- {
		codeMap := map[string]int64{
			"外网上传": 0,
			"外网下载": 0,
			//"内网上传":    0,
			//"内网下载":    0,
			"跨区域复制上传": 0,
			"跨区域复制下载": 0,
		}
		hourTime := -24 * i
		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		ctx, cefl := context.WithTimeout(context.Background(), 3*time.Minute)
		defer cefl()
		key := "objectStoragePool_overviewLine_flow:" + region
		rs, err := client.HGet(ctx, key, Index)
		if err != nil {
			//codeMap = getflowMapFromEsWide(strings.ToUpper(region), Index)
			codeMap["外网上传"], _ = GetTrafficSum(region, "", "", "false", Index, TrafficUp)
			codeMap["外网下载"], _ = GetTrafficSum(region, "", "", "false", Index, TrafficDown)
			//codeMap["内网上传"], _ = GetTrafficSum(region, "", "", "true", Index, TrafficUp)
			//codeMap["内网下载"], _ = GetTrafficSum(region, "", "", "true", Index, TrafficDown)
			codeMap["跨区域复制上传"], _ = GetTrafficSum(region, "", "crr", "", Index, TrafficUp)
			codeMap["跨区域复制下载"], _ = GetTrafficSum(region, "", "crr", "", Index, TrafficDown)

			valueJson, _ := json.Marshal(codeMap)
			client.HSet(ctx, key, Index, valueJson)
			DeleteExpireFields(ctx, key)
		} else {
			err = json.Unmarshal([]byte(rs), &codeMap)
		}
		timeStamp := time.Now().Add(time.Duration(hourTime) * time.Hour).Unix()
		for k, v := range codeMap {
			//过滤掉内网数据
			if k == "内网上传" || k == "内网下载" {
				continue
			}
			if k == "外网上传" {
				k = "内外网上传"
			} else if k == "外网下载" {
				k = "内外网下载"
			}
			info := resourcepoolmodel.InfoType{Unit: "B", UnitType: "storage", Name: k}
			echart := services.ValueType{
				Value:      v,
				Name:       timeStamp,
				TimeSteamp: timeStamp,
			}
			globeMap[info] = append(globeMap[info], echart)
		}

	}

	for k, v := range globeMap {
		r := resourcepoolmodel.EchartType{Info: k, Values: v}
		rst = append(rst, r)
	}

	return rst, nil
}

// 基于id统计30天流量的情况
func Get30FlowLineById(id string) ([]resourcepoolmodel.EchartType, error) {
	rst := make([]resourcepoolmodel.EchartType, 0)

	globeMap := make(map[resourcepoolmodel.InfoType][]services.ValueType)
	for i := 30; i > 0; i-- {

		codeMap := map[string]int64{
			"内外网上传": 0, // "外网上传" 改为 "内外网上传"
			"内外网下载": 0,
			//"内网上传": 0,
			//"内网下载": 0,
			//"CDN上传":   0,
			//"CDN下载":   0,
			"跨区域复制上传": 0,
			"跨区域复制下载": 0,
		}
		hourTime := -24 * i

		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, Index, id)
		result, err := GetEsWideData(url)
		if err != nil {
			klog.Info(err)
			return rst, err
		}
		total := result.Hits.Total

		totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, Index, strconv.Itoa(total), id)
		totalResult, er := GetEsWideData(totalUrl)
		if err != nil {
			klog.Info(er)
			return rst, er
		}
		count := len(totalResult.Hits.Hits)

		for o := 0; o < count; o++ {
			j := totalResult.Hits.Hits[o]
			if j.Source.Isinner == "false" {
				if services.In(OperationsUp, j.Source.Operation) {
					codeMap["内外网上传"] += j.Source.Traffic_up
				} else if services.In(OperationsDown, j.Source.Operation) {
					codeMap["内外网下载"] += j.Source.Traffic_down
				}
			}
			//else if j.Source.Isinner == "true" {
			//	codeMap["内网上传"] += j.Source.Traffic_up
			//	codeMap["内网下载"] += j.Source.Traffic_down
			//}
			if j.Source.Usertype == "crr" {
				if services.In(OperationsUp, j.Source.Operation) {
					codeMap["跨区域复制上传"] += j.Source.Traffic_up
				} else if services.In(OperationsDown, j.Source.Operation) {
					codeMap["跨区域复制下载"] += j.Source.Traffic_down
				}
			}
			//else if j.Source.Usertype != "-" {
			//	codeMap["CDN上传"] += j.Source.Traffic_up
			//	codeMap["CDN下载"] += j.Source.Traffic_down
			//}

		}

		timeStamp := time.Now().Add(time.Duration(hourTime)*time.Hour).UnixNano() / 1e6
		for k, v := range codeMap {
			info := resourcepoolmodel.InfoType{Unit: "B", UnitType: "storage", Name: k}
			echart := services.ValueType{
				Value:      v,
				Name:       timeStamp,
				TimeSteamp: timeStamp,
			}
			globeMap[info] = append(globeMap[info], echart)
		}

	}
	for k, v := range globeMap {
		r := resourcepoolmodel.EchartType{Info: k, Values: v}
		rst = append(rst, r)
	}

	return rst, nil
}

// 基于id统计前天流量的情况
func GetFlowById(id string) map[string]int64 {

	codeMap := map[string]int64{
		"外网流入流量":  0,
		"外网流出流量":  0,
		"内网流入流量":  0,
		"内网流出流量":  0,
		"CDN上传":   0,
		"CDN下载":   0,
		"跨区域复制上传": 0,
		"跨区域复制下载": 0,
	}

	Ago := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	AgoDate := strings.Split(Ago, ".")
	Index := AgoDate[0]
	//Index = "220725"
	url := ""
	if id == "" {
		url = fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, Index)
	} else {
		url = fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, Index, id)
	}
	//url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, Index, id)
	result, err := GetEsWideData(url)
	if err != nil {
		klog.Info(err)
		return codeMap
	}
	total := result.Hits.Total

	totalUrl := ""
	if id == "" {
		totalUrl = fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s", config.DefaultK3sEsService, Index, strconv.Itoa(total))
	} else {
		totalUrl = fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, Index, strconv.Itoa(total), id)
	}

	//totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, Index, strconv.Itoa(total), id)
	totalResult, er := GetEsWideData(totalUrl)
	if err != nil {
		klog.Info(er)
		return codeMap
	}
	count := len(totalResult.Hits.Hits)

	for o := 0; o < count; o++ {
		j := totalResult.Hits.Hits[o]
		if j.Source.Isinner == "false" {
			codeMap["外网流入流量"] += j.Source.Traffic_up
			codeMap["外网流出流量"] += j.Source.Traffic_down
		} else if j.Source.Isinner == "true" {
			codeMap["内网流入流量"] += j.Source.Traffic_up
			codeMap["内网流出流量"] += j.Source.Traffic_down
		}
		if j.Source.Usertype == "crr" {
			codeMap["跨区域复制上传"] += j.Source.Traffic_up
			codeMap["跨区域复制下载"] += j.Source.Traffic_down
		} else if j.Source.Usertype != "-" {
			codeMap["CDN上传"] += j.Source.Traffic_up
			codeMap["CDN下载"] += j.Source.Traffic_down
		}

	}

	return codeMap
}

func GetBucketChargeInfoCache(bucketId string) map[string]int64 {
	infoMap := map[string]int64{
		"trafficUp":           0,
		"trafficDown":         0,
		"outNetTrafficUp":     0,
		"outNetTrafficDown":   0,
		"innerNetTrafficUp":   0,
		"innerNetTrafficDown": 0,
		"CDNTrafficUp":        0,
		"CDNTrafficDown":      0,
		"crrTrafficUp":        0,
		"crrTrafficDown":      0,
		"30trafficDown":       0,
		"requestTimes":        0,
		"GET":                 0,
		"PUT":                 0,
		"POST":                0,
		"HEAD":                0,
		"DELETE":              0,
		"OPTIONS":             0,
		"2xx":                 0,
		"3xx":                 0,
		"4xx":                 0,
		"5xx":                 0,
		"codeErr":             0,
		"rTotal":              0,
		"wTotal":              0,
		"rOK":                 0,
		"wOK":                 0,
		"totalCount":          0,
		"deleteCount":         0,
		"putCount":            0,
	}
	operationsUp := []string{"REST.PUT.UPLOADPART", "REST.POST.COMPLETE_MULTIUPLOAD", "REST.POST.OBJECT", "REST.PUT.OBJECT"}
	operationsDown := []string{"REST.GET.OBJECT"}

	lastDay := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	lastDayIndex := strings.Split(lastDay, ".")[0]
	ctx, cefl := context.WithTimeout(context.Background(), 3*time.Minute)
	defer cefl()

	key := "bucket_charge_info:" + lastDayIndex
	rs, err := client.HGet(ctx, key, bucketId)
	if err != nil {
		totalResult, er := GetBucketEsWideDataScroll(lastDayIndex, bucketId)
		if er != nil && er != io.EOF {
			klog.Error("GetBucketEsWideDataScroll error...." + er.Error())
			return infoMap
		}
		count := len(totalResult.Hits.Hits)
		for i := 0; i < count; i++ {
			j := totalResult.Hits.Hits[i]
			if j.Source.Isinner == "false" {
				if services.In(operationsUp, j.Source.Operation) {
					infoMap["outNetTrafficUp"] += j.Source.Traffic_up
				} else if services.In(operationsDown, j.Source.Operation) {
					infoMap["outNetTrafficDown"] += j.Source.Traffic_down
				}
			} else if j.Source.Isinner == "true" {
				if services.In(operationsUp, j.Source.Operation) {
					infoMap["innerNetTrafficUp"] += j.Source.Traffic_up
				} else if services.In(operationsDown, j.Source.Operation) {
					infoMap["innerNetTrafficDown"] += j.Source.Traffic_down
				}
			}
			if j.Source.Usertype == "crr" {
				if services.In(operationsUp, j.Source.Operation) {
					infoMap["crrTrafficUp"] += j.Source.Traffic_up
				} else if services.In(operationsDown, j.Source.Operation) {
					infoMap["crrTrafficDown"] += j.Source.Traffic_down
				}
			}
			//else if j.Source.Usertype != "-" {
			//	infoMap["CDNTrafficUp"] += j.Source.Traffic_up
			//	infoMap["CDNTrafficDown"] += j.Source.Traffic_down
			//}
			if services.In(operationsUp, j.Source.Operation) {
				infoMap["trafficUp"] += j.Source.Traffic_up
			} else if services.In(operationsDown, j.Source.Operation) {
				infoMap["trafficDown"] += j.Source.Traffic_down
			}
			infoMap["requestTimes"] += j.Source.Times

			s := strings.Split(j.Source.Operation, ".")
			c := strings.Split(j.Source.Code, "")
			if len(s) > 1 {
				switch s[1] {
				case "GET":
					infoMap["GET"] += j.Source.Times
					infoMap["rTotal"]++
					if len(c) > 0 && c[0] == "2" {
						infoMap["rOK"]++
					}
				case "POST":
					infoMap["POST"] += j.Source.Times
					infoMap["wTotal"]++
					if len(c) > 0 && c[0] == "2" {
						infoMap["wOK"]++
					}
				case "PUT":
					infoMap["PUT"] += j.Source.Times
					infoMap["wTotal"]++
					if len(c) > 0 && c[0] == "2" {
						infoMap["wOK"]++
					}
				case "DELETE":
					infoMap["DELETE"] += j.Source.Times
				case "HEAD":
					infoMap["HEAD"] += j.Source.Times
					infoMap["rTotal"]++
					if len(c) > 0 && c[0] == "2" {
						infoMap["rOK"]++
					}
				case "OPTIONS":
					infoMap["OPTIONS"] += j.Source.Times

				}
			}
			if len(c) > 0 {
				switch c[0] {
				case "2":
					infoMap["2xx"]++
				case "3":
					infoMap["3xx"]++
				case "4":
					infoMap["4xx"]++
				case "5":
					infoMap["5xx"]++

				}
			}
			infoMap["codeErr"] = infoMap["4xx"] + infoMap["5xx"]
		}
		_, infoMap["30trafficDown"], _ = Get30DownloadById(bucketId)
		putCnt, delCnt, totalCnt := CountObjectByBucketId("", bucketId)
		infoMap["totalCount"] = totalCnt
		infoMap["deleteCount"] = delCnt
		infoMap["putCount"] = putCnt

		valueJson, _ := json.Marshal(infoMap)
		client.HSet(ctx, key, bucketId, valueJson)
		client.Expire(ctx, key, 7*24*3600) //一周后过期
	} else {
		err = json.Unmarshal([]byte(rs), &infoMap)
	}
	return infoMap
}

// 前一天流量统计
func GetBucketFlow() (float64, float64) {
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	//nowDate           = strings.Split(now, ".")
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	//index             = nowDate[0]
	subIndex := oneDayAgoDate[0]
	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, subIndex)
	result, err := GetEsWideData(url)
	if err != nil {
		klog.Info(err)
		return 0, 0
	}
	total := result.Hits.Total
	//if total > 10000 {
	//	total = 10000
	//}
	totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s", config.DefaultK3sEsService, subIndex, strconv.Itoa(total))
	totalResult, er := GetEsWideData(totalUrl)
	//totalResult, er := GetMultiEsWideData(subIndex, total)
	if er != nil {
		klog.Info(er)
		return 0, 0
	}
	count := len(totalResult.Hits.Hits)

	var up, down int64
	for i := 0; i < count; i++ {
		j := totalResult.Hits.Hits[i]
		up += j.Source.Traffic_up
		down += j.Source.Traffic_down
	}
	return float64(up), float64(down)
}

// 获取对象存储总流入/流出
func GetFlowAllByEsSum(region string) map[string]float64 {
	codeMap := map[string]float64{
		"up":   0,
		"down": 0,
	}

	Ago := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	AgoDate := strings.Split(Ago, ".")
	Index := AgoDate[0]

	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, Index)

	c := http.Client{Timeout: time.Second * 30}

	query := `{
			"query": {
				"bool" : {
				 "must":[
					  {
						"term" : { "ks3region" : "` + region + `" }
					  }
				  ]
				}
			  },
			  "aggs": {
				"up_total": {
				  "sum": {
					"field": "traffic_up"
				  }
				},
				"down_total": {
				  "sum": {
					"field": "traffic_down"
				  }
				}
			  }
			}`

	jsoninfo := strings.NewReader(query)
	resp, err := c.Post(url, "application/json", jsoninfo)
	if err != nil {
		klog.Errorf("Failed to get Tsdb data ，err: %s", err)
		return codeMap
	}
	defer resp.Body.Close()

	body, _ := io.ReadAll(resp.Body)
	jsonMap := make(map[string]interface{})
	json.Unmarshal(body, &jsonMap)
	if aggr, ok := jsonMap["aggregations"]; ok {
		aggrMap := aggr.(map[string]interface{})
		if total, ok := aggrMap["up_total"]; ok {
			totalMap := total.(map[string]interface{})
			if value, ok := totalMap["value"]; ok {
				codeMap["up"] = value.(float64)
			}
		}
		if total, ok := aggrMap["down_total"]; ok {
			totalMap := total.(map[string]interface{})
			if value, ok := totalMap["value"]; ok {
				codeMap["down"] = value.(float64)
			}
		}
	}
	return codeMap
}

// 基于内网流量的情况
func GetFlowInnerByEsSum(region, storageType string) map[string]float64 {
	codeMap := map[string]float64{
		"up":   0,
		"down": 0,
	}

	Ago := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	AgoDate := strings.Split(Ago, ".")
	Index := AgoDate[0]

	//Index = "220725"

	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, Index)

	c := http.Client{Timeout: time.Second * 30}

	query := `{
			"query": {
				"bool" : {
				 "must":[
					  {
						"term" : { "isinner" : "true" }
					  },
					  {
						"term" : { "storageclass" : "` + storageType + `" }
					  },
					  {
						"term" : { "ks3region" : "` + region + `" }
					  }
				  ]
				}
			  },
			  "aggs": {
				"up_total": {
				  "sum": {
					"field": "traffic_up"
				  }
				},
				"down_total": {
				  "sum": {
					"field": "traffic_down"
				  }
				}
			  }
			}`
	jsoninfo := strings.NewReader(query)
	resp, err := c.Post(url, "application/json", jsoninfo)
	if err != nil {
		klog.Errorf("Failed to get Tsdb data ，err: %s", err)
		return codeMap
	}
	defer resp.Body.Close()
	body, _ := io.ReadAll(resp.Body)
	jsonMap := make(map[string]interface{})
	json.Unmarshal(body, &jsonMap)
	if aggr, ok := jsonMap["aggregations"]; ok {
		aggrMap := aggr.(map[string]interface{})
		if total, ok := aggrMap["up_total"]; ok {
			totalMap := total.(map[string]interface{})
			if value, ok := totalMap["value"]; ok {
				codeMap["up"] = value.(float64)
			}
		}
		if total, ok := aggrMap["down_total"]; ok {
			totalMap := total.(map[string]interface{})
			if value, ok := totalMap["value"]; ok {
				codeMap["down"] = value.(float64)
			}
		}
	}
	return codeMap
}

// 基于外网流量的情况
func GetFlowOuterByEsSum(region, storageType string) map[string]float64 {
	codeMap := map[string]float64{
		"up":   0,
		"down": 0,
	}

	Ago := time.Now().Add(time.Duration(-24 * time.Hour)).Format(EsIndexDateFormat)
	AgoDate := strings.Split(Ago, ".")
	Index := AgoDate[0]

	//Index = "220725"

	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, Index)
	c := http.Client{Timeout: time.Second * 30}

	query := `{
				"query": {
					"bool" : {
				 		"must":[
					  		{
							"term" : { "isinner" : "false" }
					  		},
					 		 {
							"term" : { "storageclass" : "` + storageType + `" }
					 		 },
					  		{
							"term" : { "ks3region" : "` + region + `" }
					  		}
				  		]
					}
			  },
			  "aggs": {
				"up_total": {
				  "sum": {
					"field": "traffic_up"
				  }
				},
				"down_total": {
				  "sum": {
					"field": "traffic_down"
				  }
				}
			  }
			}`
	jsoninfo := strings.NewReader(query)
	resp, err := c.Post(url, "application/json", jsoninfo)
	if err != nil {
		klog.Errorf("Failed to get Tsdb data ，err: %s", err)
		return codeMap
	}
	defer resp.Body.Close()
	body, _ := io.ReadAll(resp.Body)
	jsonMap := make(map[string]interface{})
	json.Unmarshal(body, &jsonMap)
	if aggr, ok := jsonMap["aggregations"]; ok {
		aggrMap := aggr.(map[string]interface{})
		if total, ok := aggrMap["up_total"]; ok {
			totalMap := total.(map[string]interface{})
			if value, ok := totalMap["value"]; ok {
				codeMap["up"] = value.(float64)
			}
		}
		if total, ok := aggrMap["down_total"]; ok {
			totalMap := total.(map[string]interface{})
			if value, ok := totalMap["value"]; ok {
				codeMap["down"] = value.(float64)
			}
		}
	}
	return codeMap
}

// API次数
func GetTimesByEsSum(region, storageType, dayIndex string) (EsKs3WideAggr, error) {
	var rst EsKs3WideAggr

	//Index = "220725"

	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, dayIndex)
	c := http.Client{Timeout: time.Second * 30}

	var condition []string
	if storageType != "" {
		condition = append(condition, ` {"term" : { "storageclass" : "`+storageType+`" }}`)
	}
	if region != "" && strings.ToUpper(region) != "ALL" {
		condition = append(condition, ` {"term" : { "ks3region" : "`+strings.ToUpper(region)+`" }}`)
	}
	q := ""
	if len(condition) > 0 {
		q = `"query": {
					"bool" : {
				 		"must":[` + strings.Join(condition, ",") + `]
					}
			 	 },`
	}

	query := `{` + q + `
				  "aggs": {
					"group_by_name": {
					  "terms": {
						"field": "operation",
						"size": 10000
					  },
					  "aggs": {
						"total_times": {
						  "sum": {
							"field": "times"
						  }
						}
					  }
					}
				  }
				}`
	jsoninfo := strings.NewReader(query)
	resp, err := c.Post(url, "application/json", jsoninfo)
	if err != nil {
		klog.Errorf("Failed to get Tsdb data ，err: %s", err)
		return rst, err
	}
	defer resp.Body.Close()
	body, _ := io.ReadAll(resp.Body)
	json.Unmarshal(body, &rst)

	return rst, nil
}

// 基于内网流量的情况
func GetTrafficAggrFromEs(region, storageType, dayIdex string) (EsKs3WideTrafficAggr, error) {
	var rst EsKs3WideTrafficAggr

	//dayIdex = "220706"
	url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1", config.DefaultK3sEsService, dayIdex)

	c := http.Client{Timeout: time.Second * 30}

	query := `{
			"query": {
					"bool" : {
				 		"must":[
					 		 {
							"term" : { "storageclass" : "` + storageType + `" }
					 		 },
					  		{
							"term" : { "ks3region" : "` + region + `" }
					  		}
				  		]
					}
			 	 },
				"aggs": {
					"usertype": {
						"terms": {
							"field": "usertype",
							"size": 10000
						},
						"aggs": {
							"isinner": {
								"terms": {
									"field": "isinner",
									"size": 10000
								},
								"aggs": {
									"up": {
										"sum": {
											"field": "traffic_up"
										}
									},
									"down": {
										"sum": {
											"field": "traffic_down"
										}
									}
								}
							}
						}
					}
				}
	}`
	if storageType == "" {
		query = `{
				"query": {
					"term" : { "ks3region" : "` + region + `" }
			 	 },
				"aggs": {
					"usertype": {
						"terms": {
							"field": "usertype",
							"size": 10000
						},
						"aggs": {
							"isinner": {
								"terms": {
									"field": "isinner",
									"size": 10000
								},
								"aggs": {
									"up": {
										"sum": {
											"field": "traffic_up"
										}
									},
									"down": {
										"sum": {
											"field": "traffic_down"
										}
									}
								}
							}
						}
					}
				}
		}`
	}

	if storageType == "" && (region == "" || region == "ALL") {
		query = `{ "aggs": {
					"usertype": {
						"terms": {
							"field": "usertype",
							"size": 10000
						},
						"aggs": {
							"isinner": {
								"terms": {
									"field": "isinner",
									"size": 10000
								},
								"aggs": {
									"up": {
										"sum": {
											"field": "traffic_up"
										}
									},
									"down": {
										"sum": {
											"field": "traffic_down"
										}
									}
								}
							}
						}
					}
				}
		}`
	}

	jsoninfo := strings.NewReader(query)
	resp, err := c.Post(url, "application/json", jsoninfo)
	if err != nil {
		klog.Errorf("Failed to get Tsdb data ，err: %s", err)
		return rst, err
	}
	defer resp.Body.Close()
	body, _ := io.ReadAll(resp.Body)
	json.Unmarshal(body, &rst)

	return rst, nil
}

func Get30DownloadById(id string) (int64, int64, error) {
	var up, down int64
	q := elastic.NewBoolQuery().Must(elastic.NewTermQuery("bucketid", id))
	if client.EsClient == nil {
		klog.Error("EsClient is nil....")
		return 0, 0, errors.New("EsClient is nil")
	}
	for i := 1; i < 31; i++ {
		index := fmt.Sprintf("col.ks3_wide.%s", GetDateIndex(-i))
		do, err := client.EsClient.Search().Index(index).
			Query(q).
			Aggregation("trafficUpSum", elastic.NewSumAggregation().Field("traffic_up")).
			Aggregation("trafficDownSum", elastic.NewSumAggregation().Field("traffic_down")).
			Do(context.Background())
		if err != nil {
			klog.Error("es client bucket traffic sum aggr error...." + err.Error())
			continue
		}

		if v, ok := do.Aggregations.Sum("trafficUpSum"); ok {
			trafficUpSum, _ := strconv.ParseInt(fmt.Sprintf("%1.0f", *v.Value), 10, 64)
			up += trafficUpSum
		}
		if v, ok := do.Aggregations.Sum("trafficDownSum"); ok {
			trafficDownSum, _ := strconv.ParseInt(fmt.Sprintf("%1.0f", *v.Value), 10, 64)
			down += trafficDownSum
		}
		klog.Infof("Get30DownloadById trafficDownSum: %d,bucketid: %s, index: %s", down, id, GetDateIndex(-i))
	}

	return up, down, nil
}

func Get30StoreById(id string) (float64, float64, float64, error) {
	var all, add, del float64
	for i := 1; i < 31; i++ {
		hourTime := -24 * i
		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		url := fmt.Sprintf("http://%s/col.ks3_store_of_day.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, Index, id)
		result, err := GetEsStoreData(url)
		if err != nil {
			klog.Info(err)
			return 0, 0, 0, err
		}
		total := result.Hits.Total

		totalUrl := fmt.Sprintf("http://%s/col.ks3_store_of_day.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, Index, strconv.Itoa(total), id)
		totalResult, er := GetEsStoreData(totalUrl)
		if er != nil {
			klog.Info(er)
			return 0, 0, 0, er
		}
		count := len(totalResult.Hits.Hits)

		for i := 0; i < count; i++ {
			j := totalResult.Hits.Hits[i]
			all += j.Source.AllSize
			add += j.Source.AddSize
			del += j.Source.DelSize
		}

	}

	return all, add, del, nil
}

func Get30ApiNumById(id string) (int64, error) {
	var times int64
	for i := 1; i < 31; i++ {
		hourTime := -24 * i
		Ago := time.Now().Add(time.Duration(hourTime) * time.Hour).Format(EsIndexDateFormat)
		AgoDate := strings.Split(Ago, ".")
		Index := AgoDate[0]

		url := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=1&q=bucketid:%s", config.DefaultK3sEsService, Index, id)
		result, err := GetEsWideData(url)
		if err != nil {
			klog.Info(err)
			return 0, err
		}
		total := result.Hits.Total

		totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=0&size=%s&q=bucketid:%s", config.DefaultK3sEsService, Index, strconv.Itoa(total), id)
		totalResult, er := GetEsWideData(totalUrl)
		if er != nil {
			klog.Info(err)
			return 0, er
		}
		count := len(totalResult.Hits.Hits)

		for i := 0; i < count; i++ {
			j := totalResult.Hits.Hits[i]
			times += j.Source.Times
		}

	}

	return times, nil
}

// 指标结构体
//type ObjectDataMetrics struct {
//	metrics    map[string]*prometheus.Desc
//	RegionCode string `json:"region"`
//	AzCode     string `json:"az"`
//	Type       string `json:"type"`
//	Status     string `json:"status"`
//	Count      int    `json:"count"`
//	mutex      sync.Mutex
//}

func GetBucketStore(index string) []StoreHit {
	tmp := make([]StoreHit, 0)
	totalResult, err := GetEsStoreData("http://10.177.141.114:9200/col.ks3_store_of_day." + index + "/_search")
	if err != nil {
		klog.Errorf("GetEsStoreData error :%v ", err.Error())
		return tmp
	} else {
		return totalResult.Hits.Hits
	}

}

// func GetBucketWide(url, index, from, size string) []WideHit {
// 	//url := fmt.Sprintf("http://10.177.141.114:9200/col.ks3_wide.%s/_search?from=%s&size=%s",index,from,size)
// 	totalResult, err := GetEsWideData(url)

// 	return totalResult.Hits.Hits
// 	//NewCloudDiskDataMetrics(registry, cloudDiskCountMap)

// }

// get es store
func GetEsStoreData(url string) (EsKs3Store, error) {
	result := EsKs3Store{}
	c := http.Client{}
	resp, err := c.Get(url)
	if err != nil {
		fmt.Println(err.Error())
		return result, err
	}
	b, er := io.ReadAll(resp.Body)
	if er != nil {
		fmt.Println(er.Error())
		return EsKs3Store{}, err
	}
	json.Unmarshal(b, &result)
	return result, nil
}

func GetEsWideSumTimes(url string) int {
	c := http.Client{Timeout: time.Second * 30}
	query := `{"aggs": {"total_times": {"sum": {"field": "times"}}}}`
	jsoninfo := strings.NewReader(query)
	resp, err := c.Post(url, "application/json", jsoninfo)
	if err != nil {
		klog.Errorf("Failed to get Tsdb data ，err: %s", err)
		return 0
	}
	defer resp.Body.Close()
	body, _ := io.ReadAll(resp.Body)
	jsonMap := make(map[string]interface{})
	json.Unmarshal(body, &jsonMap)
	if aggr, ok := jsonMap["aggregations"]; ok {
		aggrMap := aggr.(map[string]interface{})
		if total, ok := aggrMap["total_times"]; ok {
			totalMap := total.(map[string]interface{})
			if value, ok := totalMap["value"]; ok {
				totalTimes := value.(float64)
				result, _ := strconv.Atoi(fmt.Sprintf("%1.0f", totalTimes))
				return result
			}
		}
	}
	return 0
}

func GetEsStoreSumCapacity(dayIndex string, region string) int {
	url := fmt.Sprintf("http://%s/col.ks3_store_of_day.%s/_search?from=0&size=1", config.DefaultK3sEsService, dayIndex)
	if region != "" && region != "all" {
		url = url + "&q=ks3region:" + strings.ToUpper(region)
	}
	c := http.Client{Timeout: time.Second * 30}

	query := `{"aggs": {"total_times": {"sum": {"field": "allSize"}}}}`
	jsoninfo := strings.NewReader(query)
	resp, err := c.Post(url, "application/json", jsoninfo)
	if err != nil {
		klog.Errorf("Failed to get Tsdb data ，err: %s", err)
		return 0
	}
	defer resp.Body.Close()
	body, _ := io.ReadAll(resp.Body)
	jsonMap := make(map[string]interface{})
	json.Unmarshal(body, &jsonMap)
	if aggr, ok := jsonMap["aggregations"]; ok {
		aggrMap := aggr.(map[string]interface{})
		if total, ok := aggrMap["total_times"]; ok {
			totalMap := total.(map[string]interface{})
			if value, ok := totalMap["value"]; ok {
				totalTimes := value.(float64)
				result, _ := strconv.Atoi(fmt.Sprintf("%1.0f", totalTimes))
				return result
			}
		}
	}
	return 0
}

// get es wide
func GetEsWideData(url string) (EsKs3Wide, error) {
	result := EsKs3Wide{}
	c := http.Client{}
	resp, err := c.Get(url)
	if err != nil {
		klog.Error("GetEsWideData error...." + err.Error())
		return result, err
	}
	b, er := io.ReadAll(resp.Body)
	if er != nil {
		fmt.Println(er.Error())
	}
	e := json.Unmarshal(b, &result)
	if e != nil {
		fmt.Println(url)
		klog.Error("json unmarshal error...." + e.Error())
	}
	return result, nil
}

func GetEsWideDataScroll(dayIndex, region string) (EsKs3Wide, error) {
	wideResult := EsKs3Wide{}
	q := elastic.NewBoolQuery()
	if region != "" && region != "all" && region != "ALL" {
		q.Must(elastic.NewTermQuery("ks3region", strings.ToUpper(region)))
	}
	index := fmt.Sprintf("col.ks3_wide.%s", dayIndex)
	if client.EsClient == nil {
		klog.Error("EsClient is nil")
		return wideResult, errors.Errorf("EsClient is nil,ks3es api is not available ")
	}
	do, err := client.EsClient.Scroll(). // 游标滚动查询
						Index(index).
						Query(q).
						Scroll("1m"). // 保持游标查询窗口一分钟
						Size(1000).
						Do(context.Background())
	if err != nil {
		klog.Error("EsClient Scroll first step error...." + err.Error())
		return wideResult, err
	}
	scrollId := do.ScrollId
	wideResult, err = Convert(do)
	if err != nil {
		return wideResult, err
	}
	for {
		result, _ := client.EsClient.Scroll(index).Scroll("1m").
			ScrollId(scrollId). //通过游标id查询
			Do(context.Background())
		if len(result.Hits.Hits) <= 0 { // 跳出循环滚动
			break
		}
		rst, err := Convert(result)
		if err != nil {
			klog.Error("EsClient Scroll first step error...." + err.Error())
			return wideResult, err
		}
		wideResult.Hits.Hits = append(wideResult.Hits.Hits, rst.Hits.Hits...)
	}

	return wideResult, nil
}

func GetBucketEsWideDataScroll(dayIndex, bucketId string) (EsKs3Wide, error) {
	wideResult := EsKs3Wide{}
	q := elastic.NewBoolQuery()
	q.Must(elastic.NewTermQuery("bucketid", bucketId))
	index := fmt.Sprintf("col.ks3_wide.%s", dayIndex)
	if client.EsClient == nil {
		klog.Error("EsClient is nil")
		return wideResult, errors.Errorf("EsClient is nil,ks3es api is not available ")
	}
	do, err := client.EsClient.Scroll(). // 游标滚动查询
						Index(index).
						Query(q).
						Scroll("1m"). // 保持游标查询窗口一分钟
						Size(1000).
						Do(context.Background())
	if err != nil {
		klog.Error("EsClient Scroll first step error...."+err.Error(), "bucketId is: "+bucketId)
		return wideResult, err
	}
	scrollId := do.ScrollId
	wideResult, err = Convert(do)
	if err != nil {
		return wideResult, err
	}
	for {
		result, _ := client.EsClient.Scroll(index).Scroll("1m").
			ScrollId(scrollId). //通过游标id查询
			Do(context.Background())
		if len(result.Hits.Hits) <= 0 { // 跳出循环滚动
			break
		}
		rst, err := Convert(result)
		if err != nil {
			klog.Error("EsClient Scroll first step error...." + err.Error())
			return wideResult, err
		}
		wideResult.Hits.Hits = append(wideResult.Hits.Hits, rst.Hits.Hits...)
	}

	return wideResult, nil
}

func Convert(sr *elastic.SearchResult) (EsKs3Wide, error) {
	result := EsKs3Wide{}
	b, err := json.Marshal(sr)
	if err != nil {
		klog.Error("Marshal 1 error...." + err.Error())
		return result, err
	}
	json.Unmarshal(b, &result)
	if err != nil {
		klog.Error("Unmarshal  error...." + err.Error())
	}
	return result, err
}

func GetMultiEsWideData(Index string, total int) (EsKs3Wide, error) {
	result := EsKs3Wide{}
	c := http.Client{}
	for n := 0; n < total; n += 10000 {
		totalUrl := fmt.Sprintf("http://%s/col.ks3_wide.%s/_search?from=%s&size=10000", config.DefaultK3sEsService, Index, strconv.Itoa(n))
		resp, err := c.Get(totalUrl)
		if err != nil {
			klog.Error("GetEsWideData error...." + err.Error())
			return result, err
		}
		b, er := io.ReadAll(resp.Body)
		if er != nil {
			fmt.Println(er.Error())
		}
		klog.Infof("GetMultiEsWideData response data is: %s", string(b))
		e := json.Unmarshal(b, &result)
		if e != nil {
			klog.Error("json unmarshal error...." + e.Error())
			return result, err
		}
		result.Hits.Hits = append(result.Hits.Hits, result.Hits.Hits...)
	}
	result.Hits.Total = total
	return result, nil
}

func GetEsData(url string) []byte {
	c := http.Client{}
	resp, err := c.Get(url)
	if err != nil {
		fmt.Println(err.Error())
	}
	b, er := io.ReadAll(resp.Body)
	if er != nil {
		fmt.Println(er.Error())
	}
	return b
}

type EsKs3Store struct {
	Hits struct {
		Total int        `json:"total"`
		Hits  []StoreHit `json:"hits"`
	} `json:"hits"`
}

type StoreHit struct {
	Index  string      `json:"_index"`
	Type   string      `json:"_type"`
	Source StoreSource `json:"_source"`
}
type StoreSource struct {
	D            string  `json:"d"`
	UserId       string  `json:"userid"`
	BucketName   string  `json:"bucketname"`
	BucketId     string  `json:"bucketid"`
	Ks3Region    string  `json:"ks3region"`
	Time         int64   `json:"time"`
	StorageClass string  `json:"storageclass"`
	AddTime      int64   `json:"addtime"`
	AllSize      float64 `json:"allSize"`
	DelSize      float64 `json:"delSize"`
	AddSize      float64 `json:"addSize"`
}

type EsKs3Wide struct {
	Hits struct {
		Total int       `json:"total"`
		Hits  []WideHit `json:"hits"`
	} `json:"hits"`
}

type WideHit struct {
	Index  string     `json:"_index"`
	Type   string     `json:"_type"`
	Source WideSource `json:"_source"`
}

type WideSource struct {
	D                 string  `json:"d"`
	UserId            string  `json:"userid"`
	BucketName        string  `json:"bucketname"`
	BucketId          string  `json:"bucketid"`
	Ks3Region         string  `json:"ks3region"`
	Time              int64   `json:"time"`
	StorageClass      string  `json:"storageclass"`
	AddTime           int64   `json:"addtime"`
	Times             int64   `json:"times"`
	Code              string  `json:"code"`
	Remoteipprovince  string  `json:"remoteipprovince"`
	Remoteipisp       string  `json:"remoteipisp"`
	Operation         string  `json:"operation"`
	Isinner           string  `json:"isinner"`
	Usertype          string  `json:"usertype"`
	Traffic_down      int64   `json:"traffic_down"`
	Traffic_up        int64   `json:"traffic_up"`
	Object_size       int64   `json:"object_size"`
	ReadSuccessTimes  float64 `json:"read_success_times"`
	WriteSuccessTimes float64 `json:"write_success_times"`
	ReadErrorTimes    float64 `json:"read_error_times"`
	WriteErrorTimes   float64 `json:"write_error_times"`
}

type EsKs3WideAggr struct {
	Aggregations struct {
		GroupBy struct {
			Bucket []GroupByBucket `json:"buckets"`
		} `json:"group_by_name"`
	} `json:"aggregations"`
}

type GroupByBucket struct {
	Key        string `json:"key"`
	TotalTimes struct {
		Value float64 `json:"value"`
	} `json:"total_times"`
}

type IsInnerGroupByBucket struct {
	Key string `json:"key"`
	Up  struct {
		Value float64 `json:"value"`
	} `json:"up"`
	Down struct {
		Value float64 `json:"value"`
	} `json:"down"`
}
type UserTypeGroupByBucket struct {
	Key     string `json:"key"`
	IsInner struct {
		IsInnerBuckets []IsInnerGroupByBucket `json:"buckets"`
	} `json:"isinner"`
}

type EsKs3WideTrafficAggr struct {
	Aggregations struct {
		Usertype struct {
			UsertypeBuckets []UserTypeGroupByBucket `json:"buckets"`
		} `json:"usertype"`
	} `json:"aggregations"`
}

type EsKs3StoreAggr struct {
	Aggregations struct {
		Storageclass struct {
			Buckets []StorageclassBucket `json:"buckets"`
		} `json:"storageclass"`
	} `json:"aggregations"`
}

type StorageclassBucket struct {
	Key     string `json:"key"`
	AllSize struct {
		Value float64 `json:"value"`
	} `json:"allSize"`
}

type EsKs3StoreCodeAggr struct {
	Aggregations struct {
		Code struct {
			Buckets []CodeBucket `json:"buckets"`
		} `json:"code"`
	} `json:"aggregations"`
}

type CodeBucket struct {
	Key      string `json:"key"`
	DocCount int64  `json:"doc_count"`
}

func debugLog(tag interface{}) {
	klog.Info(tag)
}

// getBucketChargeInfoList 获取bucket 列表从charge接口
func GetBucketChargeInfoList(region, date string) ([]k3smodel.BucketAggregationChargeInfo, error) {
	bucketAggregationChargeInfoResp := k3smodel.BucketAggregationChargeInfo{}
	var bucketList []k3smodel.BucketAggregationChargeInfo
	c := http.Client{}
	// nowDate := time.Now().Format("20060102")
	// region := strings.ToUpper(os.Getenv("DEFAULT_BUCKET_REGION"))
	if region == "" {
		region = "CN-SHANGHAI-2"
	}
	debugLog("getBucketChargeInfoList debug start")
	url := fmt.Sprintf("http://10.177.9.26:18080/chargeInfo/store?date=%s&region=%s", date, region)
	debugLog("url: " + url)
	res, err := c.Get(url)
	if err != nil {
		return nil, err
	}
	if res.StatusCode != 200 {
		debugLog(fmt.Sprintf("res.StatusCode: %d", res.StatusCode))
		return nil, fmt.Errorf("res.StatusCode: %d", res.StatusCode)
	}
	bucketBytes, err := ioutil.ReadAll(res.Body)
	if err != nil {
		return nil, err
	}
	debugLog("getBucketChargeInfoList get bucketBytes ok")
	bucketArr := bytes.Fields(bucketBytes)
	for _, bucket := range bucketArr {
		err = json.NewDecoder(bytes.NewReader(bucket)).Decode(&bucketAggregationChargeInfoResp)
		if err != nil {
			klog.Errorf("bucket entry decode err: %s", err.Error())
			continue
		}
		bucketList = append(bucketList, bucketAggregationChargeInfoResp)
	}
	debugLog("getBucketChargeInfoList bytes.Fields(bucketBytes) ok")
	debugLog(fmt.Sprintf("len(bucketList): %d", len(bucketList)))
	debugLog("getBucketChargeInfoList 	debug end")
	return bucketList, err
}

// getBucketChargeInfoList 获取bucket 列表从charge接口
func GetBucketChargeInfoListById(region, date, bucketId string) ([]k3smodel.BucketAggregationChargeInfo, error) {
	bucketAggregationChargeInfoResp := k3smodel.BucketAggregationChargeInfo{}
	var bucketList []k3smodel.BucketAggregationChargeInfo
	c := http.Client{}
	// nowDate := time.Now().Format("20060102")
	// region := strings.ToUpper(os.Getenv("DEFAULT_BUCKET_REGION"))
	if region == "" {
		region = "CN-SHANGHAI-2"
	}
	debugLog("getBucketChargeInfoList debug start")
	url := fmt.Sprintf("http://10.177.9.26:18080/chargeInfo/store?date=%s&region=%s&bucketId=%s", date, region, bucketId)
	debugLog("url: " + url)
	res, err := c.Get(url)
	if err != nil {
		klog.Error(err)
	}
	if res.StatusCode != 200 {
		debugLog(fmt.Sprintf("res.StatusCode: %d", res.StatusCode))
		return nil, fmt.Errorf("res.StatusCode: %d", res.StatusCode)
	}
	bucketBytes, err := ioutil.ReadAll(res.Body)
	if err != nil {
		return nil, err
	}
	debugLog("getBucketChargeInfoList get bucketBytes ok")
	bucketArr := bytes.Fields(bucketBytes)
	for _, bucket := range bucketArr {
		err = json.NewDecoder(bytes.NewReader(bucket)).Decode(&bucketAggregationChargeInfoResp)
		if err != nil {
			klog.Errorf("bucket entry decode err: %s", err.Error())
			continue
		}
		bucketList = append(bucketList, bucketAggregationChargeInfoResp)
	}
	debugLog("getBucketChargeInfoList bytes.Fields(bucketBytes) ok")
	debugLog(fmt.Sprintf("len(bucketList): %d", len(bucketList)))
	debugLog("getBucketChargeInfoList 	debug end")
	return bucketList, err
}

// getBucketChargeInfoList 获取bucket 列表从charge接口
func GetBucketObjectCountById(region, date, bucketId string) ([]k3smodel.BucketObjectCountInfo, error) {
	bucketAggregationChargeInfoResp := k3smodel.BucketObjectCountInfo{}
	var bucketList []k3smodel.BucketObjectCountInfo
	c := http.Client{}
	if date == "" {
		date = time.Now().Add(time.Duration(-24 * time.Hour)).Format("20060102")
	}
	// region := strings.ToUpper(os.Getenv("DEFAULT_BUCKET_REGION"))
	if region == "" {
		region = "CN-SHANGHAI-2"
	}
	debugLog("getBucketChargeInfoList debug start")
	url := fmt.Sprintf("http://%s/chargeInfo/count?date=%s&region=%s&bucketId=%s", config.DefaultChargeInfoService, date, region, bucketId)
	debugLog("url: " + url)
	res, err := c.Get(url)
	if err != nil {
		return nil, err
	}
	if res.StatusCode != 200 {
		debugLog(fmt.Sprintf("res.StatusCode: %d", res.StatusCode))
		return nil, fmt.Errorf("res.StatusCode: %d", res.StatusCode)
	}
	bucketBytes, err := ioutil.ReadAll(res.Body)
	if err != nil {
		klog.Error(err)
	}
	debugLog("getBucketChargeInfoList get bucketBytes ok")
	bucketArr := bytes.Fields(bucketBytes)
	for _, bucket := range bucketArr {
		err = json.NewDecoder(bytes.NewReader(bucket)).Decode(&bucketAggregationChargeInfoResp)
		if err != nil {
			klog.Errorf("bucket entry decode err: %s", err.Error())
			continue
		}
		bucketList = append(bucketList, bucketAggregationChargeInfoResp)
	}
	debugLog("getBucketChargeInfoList bytes.Fields(bucketBytes) ok")
	debugLog(fmt.Sprintf("len(bucketList): %d", len(bucketList)))
	debugLog("getBucketChargeInfoList 	debug end")
	return bucketList, err
}

func CountObjectByBucketId(region, bucketId string) (putCount, deleteCount, totalCount int64) {
	countList, err := GetBucketObjectCountById(region, "", bucketId)
	if err != nil {
		klog.Error(err)
		return
	}
	for _, cnt := range countList {
		putCount += cnt.PutCount
		deleteCount += cnt.DeleteCount
		totalCount += cnt.TotalCount
	}
	return
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/alertmanager/alertmanagerservice.go
```golang
package alertmanager

import (
	"encoding/json"
	"errors"
	"fmt"
	"io/ioutil"
	"net/http"
	"sort"
	"strings"
	"time"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/configs"

	"github.com/prometheus/alertmanager/api/v2/models"

	"github.com/prometheus/alertmanager/api/v2/client/alert"

	"k8s.io/klog/v2"

	client2 "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
)

var client = &http.Client{}

// var host = "http://" + config.GetDefaultUrl(config.AlertmanagerService) + "/api/v2/alerts/groups?silenced=false&inhibited=false&active=true"
var ResourceList cmdbmodel.ResourceList

func init() {
	ResourceList, _ = cmdbmanager.GetResourceData()
}

// 获取告警等级的count 通过level P0,P1,P2,P3
func GetAlertsByLevel(level string) ([]alertmanagermodel.AlertData, error) {
	var all []alertmanagermodel.AlertData
	var err error
	if level == "" {
		err = errors.New("please insert level")
	} else {
		// parem := "&filter=severity%3D%22" + strings.ToLower(level) + "%22"
		alertQuery := alertmanagermodel.AlertQuery{AlertLevel: []string{level}}
		alertResult, err := GetAlertsDataList(alertQuery)
		if err != nil {
			klog.Errorf("DEBUG - PlatformDataAlerts -1 - 1 err: %v", err)
			return all, err
		}
		return alertResult.DataList, err
		// request, _ := http.NewRequest("GET", "http://"+config.GetDefaultUrl(config.AlertmanagerService)+"/api/v2/alerts/groups?silenced=false&inhibited=false&active=true"+parem, nil)

		// request.Header.Set("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8")
		// request.Header.Set("Accept-Charset", "GBK,utf-8;q=0.7,*;q=0.3")
		// request.Header.Set("Accept-Encoding", "gzip,deflate,sdch")
		// request.Header.Set("Accept-Language", "zh-CN,zh;q=0.8")
		// request.Header.Set("Cache-Control", "max-age=0")
		// request.Header.Set("Connection", "keep-alive")
		// request.Header.Set("User-Agent", "chrome 100")

		// //defer request.Body.Close()
		// respons, err1 := client.Do(request)
		// //defer client.CloseIdleConnections()
		// err = err1
		// if respons.StatusCode == 200 {
		// 	bodyR, _ := ioutil.ReadAll(respons.Body)
		// 	var js []interface{}
		// 	err = json.Unmarshal(bodyR, &js)
		// 	//fmt.Println(js)
		// 	if err == nil {
		// 		for _, data := range js {

		// 			//fmt.Println(severity.LevelCount)
		// 			wsMap := data.(map[string]interface{})
		// 			if vCw, ok := wsMap["alerts"]; ok {
		// 				alerts := vCw.([]interface{})
		// 				for _, alert := range alerts {
		// 					all = append(all, alert)
		// 				}
		// 			}
		// 		}
		// 	}
		// }

	}
	return all, err
}

func GetAlertsDataListPage(alertQuery alertmanagermodel.AlertQuery) (alertmanagermodel.AlertResult, error) {
	alertResult, err := GetAlertsDataList(alertQuery)
	if err != nil {
		return alertResult, err
	}

	results := Bucket{}
	for i := 0; i < len(alertResult.DataList); i++ {
		results.Slice = append(results.Slice, alertResult.DataList[i])
	}
	//results.Slice = alertResult.DataList
	time_by := func(a, b interface{}) bool {
		return true
	}
	if alertQuery.OrderCode == "" {
		alertQuery.OrderCode = "startsAt"
		alertQuery.OrderType = "desc"
	}
	if alertQuery.OrderCode != "" {
		switch alertQuery.OrderCode {
		case "startsAt":
			if alertQuery.OrderType != "" {
				switch alertQuery.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(alertmanagermodel.AlertData).StartsAt.Unix() < b.(alertmanagermodel.AlertData).StartsAt.Unix()
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(alertmanagermodel.AlertData).StartsAt.Unix() > b.(alertmanagermodel.AlertData).StartsAt.Unix()
					}
				}
			}
		case "endsAt":
			if alertQuery.OrderType != "" {
				switch alertQuery.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(alertmanagermodel.AlertData).EndsAt.Unix() < b.(alertmanagermodel.AlertData).EndsAt.Unix()
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(alertmanagermodel.AlertData).EndsAt.Unix() > b.(alertmanagermodel.AlertData).EndsAt.Unix()
					}
				}
			}
		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(results.Slice); i++ {
		alertResult.DataList[i] = results.Slice[i].(alertmanagermodel.AlertData)
	}
	//alertResult.DataList = results.Slice
	alertResult.TotalCount = len(alertResult.DataList)
	alertResult.PageNo = alertQuery.PageNo
	alertResult.PageSize = alertQuery.PageSize
	low := (alertQuery.PageNo - 1) * alertQuery.PageSize
	if low > alertResult.TotalCount {
		return alertResult, errors.New("PageSize is too large ")
	}
	hight := low + alertQuery.PageSize
	if hight > alertResult.TotalCount {
		hight = alertResult.TotalCount
	}
	alertResult.DataList = alertResult.DataList[low:hight]
	return alertResult, err
}

// 列表告警数据公共方法
func GetResourcePoolAlertNum(region, az, resourceTypeCode, resourceSubType, poolName string) int {
	queryParam := alertmanagermodel.AlertQuery{
		Filter: "",
	}
	if region != "" && region != "all" {
		queryParam.Region = region
		//queryParam.Filter = queryParam.Filter + "&filter=region=%22" + region + "%22"
	}
	if az != "" && az != "all" {
		queryParam.Az = []string{az}
		//queryParam.Filter = queryParam.Filter + "&filter=az=%22" + az + "%22"
	}
	queryParam.ResourceTypeCode = []string{resourceTypeCode}
	queryParam.ResourceSubTypeCode = []string{resourceSubType}
	if resourceSubType != "physicalServer" {
		queryParam.InstanceId = poolName
	} else {
		queryParam.AlertInstance = poolName
	}
	queryParam.PageNo = 1
	queryParam.PageSize = 1000
	res, err := GetAlertsDataListPage(queryParam)
	if err != nil {
		return 0
	}
	return len(res.DataList)
}

func GetAlertsDataList(alertQuery alertmanagermodel.AlertQuery) (alertmanagermodel.AlertResult, error) {

	var alertResult alertmanagermodel.AlertResult

	var silenced bool = false
	var inhibited bool = false
	var active bool = true

	params := &alert.GetAlertsParams{
		Silenced:  &silenced,
		Active:    &active,
		Inhibited: &inhibited,
		Filter:    []string{}, //"lubanAlarmView=端口状态", "ifIndex=52,54"
	}
	klog.Infof("DEBUG - PlatformDataAlerts -1 - 1 - 1 params: %+v", params)
	res, err := client2.GetAlerts(params)
	if err != nil {
		klog.Errorf("DEBUG - PlatformDataAlerts -1 - 1 - 2 err: %v", err)
		klog.Error(err)
	}
	regionList, _ := cmdbmanager.GetAllRegions()
	azList, _ := cmdbmanager.GetAllAzs(regionList)
	klog.Errorf("DEBUG - PlatformDataAlerts -1 - 1 - 3 res: %+v", res)
	for _, alert := range res {
		var alertModel alertmanagermodel.AlertData
		if (*alert).Labels["level"] != "p0" && (*alert).Labels["level"] != "p1" && (*alert).Labels["level"] != "p2" && (*alert).Labels["level"] != "p3" {
			klog.Error("DEBUG - PlatformDataAlerts -1 - 1 - 4 continue 1")
			continue
		} else if (*alert).Labels["level"] == "" {
			klog.Error("DEBUG - PlatformDataAlerts -1 - 1 - 5 continue 2")
			continue
		}
		alertModel.AlertLevel = (*alert).Labels["level"]
		alertModel.StartsAt = time.Time(*alert.StartsAt)
		alertModel.EndsAt = time.Time(*alert.EndsAt)
		alertModel.UpdatedAt = time.Time(*alert.UpdatedAt)
		alertModel.ExpressionWithChinaese = (*alert).Annotations["lubanExpressionWithChinese"]
		alertModel.Id = *alert.Fingerprint
		alertModel.State = *alert.Status.State
		alertModel.ResourceTypeCode = (*alert).Labels["lubanResourceType"]
		alertModel.ResourceTypeName = GetResourceData(alertModel.ResourceTypeCode, "")
		alertModel.ResourceSubTypeCode = (*alert).Labels["lubanResourceSubType"]
		alertModel.ResourceSubTypeName = GetResourceData("", alertModel.ResourceSubTypeCode)
		//alertModel.Handler = (*alert).Labels["lubanNoticeMail"]
		alertModel.AlertName = (*alert).Labels["lubanAlarmView"]
		alertModel.ThresholdValue = (*alert).Labels["lubanThreshold"]
		alertModel.PolicyName = (*alert).Labels["lubanPolicyName"]
		alertModel.Region = (*alert).Labels["region"]
		alertModel.Az = (*alert).Labels["az"]

		// 从数据库中获取处理人
		alertHandler := new(alertmanagermodel.AlertHandler)
		configs.DB.Where("alert_id = ?", *alert.Fingerprint).Last(alertHandler)
		alertModel.Handler = alertHandler.Handler
		if alertModel.State == "active" && alertModel.Handler == "" {
			alertModel.Status = "待处理"
			alertModel.State = "todo"
		} else if alertModel.State == "active" {
			alertModel.Status = "处理中"
		} else if alertModel.State == "resolved" {
			alertModel.Status = "已解决"
		} else if alertModel.State == "blocked" {
			alertModel.Status = "已屏蔽"
		}

		if alertModel.ResourceSubTypeCode == "physicalSwitch" {
			// alertModel.AlertInstance = fmt.Sprintf("%v-%v", (*alert).Labels["instance"], (*alert).Labels["ifName"])
			// 只展示IP即可，且同一IP不同端口的告警不重复添加
			physicalSwitchMap := make(map[string]alertmanagermodel.AlertData)
			for _, alertData := range alertResult.DataList {
				if alertData.ResourceSubTypeCode == "physicalSwitch" {
					if _, ok := physicalSwitchMap[alertData.AlertInstance]; ok {
						klog.Error("DEBUG - PlatformDataAlerts -1 - 1 - 6 continue 3")
						continue
					} else {
						physicalSwitchMap[alertData.AlertInstance] = alertData
					}
				}
			}

			alertModel.InstanceId = alert.Labels["identifier"] // 用于跳转时的资源匹配

			if _, ok := physicalSwitchMap[(*alert).Labels["instance"]]; ok {
				klog.Error("DEBUG - PlatformDataAlerts -1 - 1 - 7 continue 4")
				continue
			} else {
				// alertModel.AlertInstance = (*alert).Labels["instance"]
				alertModel.AlertInstance = alert.Labels["identifier"]
			}

			//2021年11月3日添加告警IP针对交换机
			alertModel.InstanceIp = (*alert).Labels["instance"]
		} else if alertModel.ResourceTypeCode == "resourcePool" {
			alertModel.AlertInstance = alert.Labels["resourcePool"]
			if alert.Labels["instanceId"] != "" {
				alertModel.InstanceId = alert.Labels["instanceId"]
				if alertModel.AlertInstance == "" {
					alertModel.AlertInstance = alert.Labels["instanceId"]
				}
			} else if alert.Labels["lubanResourceName"] != "" {
				alertModel.InstanceId = alert.Labels["lubanResourceName"]
				if alertModel.AlertInstance == "" {
					alertModel.AlertInstance = alert.Labels["lubanResourceName"]
				}
			} else if alert.Labels["hostname"] != "" {
				alertModel.InstanceId = alert.Labels["hostname"]
				if alertModel.AlertInstance == "" {
					alertModel.AlertInstance = alert.Labels["hostname"]
				}
			}
		} else {
			alertModel.AlertInstance = (*alert).Labels["instance"]
			if alert.Labels["serviceId"] != "" {
				alertModel.InstanceId = alert.Labels["serviceId"]
				if alertModel.AlertInstance == "" {
					alertModel.AlertInstance = alert.Labels["serviceId"]
				}
			}
		}
		alertModel.SvcId = (*alert).Labels["serviceId"]
		alertModel.SvcInstanceId = (*alert).Labels["serviceInstanceId"]

		if alertModel.EndsAt.Sub(alertModel.StartsAt) <= time.Minute*10 {
			alertModel.AlertTimeLength = "lessThanTenMin"
		} else if time.Minute*10 < alertModel.EndsAt.Sub(alertModel.StartsAt) && alertModel.EndsAt.Sub(alertModel.StartsAt) <= time.Hour*1 {
			alertModel.AlertTimeLength = "tenMinToOneHour"
		} else if time.Hour*1 < alertModel.EndsAt.Sub(alertModel.StartsAt) && alertModel.EndsAt.Sub(alertModel.StartsAt) <= time.Hour*24 {
			alertModel.AlertTimeLength = "oneHourToOneDay"
		} else {
			alertModel.AlertTimeLength = "moreThanOneDay"
		}
		alertModel.AlertDuration = services.DataTimeDiff(alertModel.StartsAt, alertModel.EndsAt)

		// 获取触发告警的server实例
		//if alertQuery.SearchKey == "instanceId" {
		//	if alert.Labels["instanceId"] != "" {
		//		alertModel.InstanceId = alert.Labels["instanceId"]
		//		if alertModel.AlertInstance == "" {
		//			alertModel.AlertInstance = alert.Labels["instanceId"]
		//		}
		//	} else if alert.Labels["serviceId"] != "" {
		//		alertModel.InstanceId = alert.Labels["serviceId"]
		//		if alertModel.AlertInstance == "" {
		//			alertModel.AlertInstance = alert.Labels["serviceId"]
		//		}
		//	} else if alert.Labels["lubanResourceName"] != "" {
		//		alertModel.InstanceId = alert.Labels["lubanResourceName"]
		//		if alertModel.AlertInstance == "" {
		//			alertModel.AlertInstance = alert.Labels["lubanResourceName"]
		//		}
		//	} else if alert.Labels["hostname"] != "" {
		//		alertModel.InstanceId = alert.Labels["hostname"]
		//		if alertModel.AlertInstance == "" {
		//			alertModel.AlertInstance = alert.Labels["hostname"]
		//		}
		//	} else if alert.Labels["identifier"] != "" {
		//		alertModel.InstanceId = alert.Labels["identifier"]
		//		if alertModel.AlertInstance == "" {
		//			alertModel.AlertInstance = alert.Labels["identifier"]
		//		}
		//	}
		//}

		if alert.Labels["lubanResourceType"] == "resourcePool" && alertModel.InstanceId == "" {
			alertModel.InstanceId = alert.Labels["resourcePool"]
		}

		if (alertQuery.AlertInstance == "" || strings.Contains(alertModel.AlertInstance, alertQuery.AlertInstance)) &&
			(alertQuery.Id == "" || alertQuery.Id == alertModel.Id) &&
			(alertQuery.AlertName == "" || alertQuery.AlertName == alertModel.AlertName) &&
			(alertQuery.InstanceIp == "" || alertQuery.InstanceIp == alertModel.InstanceIp) &&
			(alertQuery.SvcId == "" || alertQuery.SvcId == alertModel.SvcId) &&
			//(alertQuery.InstanceId == "" || alertQuery.InstanceId == alertModel.Id) &&
			(alertQuery.InstanceId == "" || alertQuery.InstanceId == alertModel.InstanceId) &&
			(alertQuery.Handler == "" || alertQuery.Handler == alertModel.Handler) &&
			(alertQuery.Region == "" || alertQuery.Region == alertModel.Region) &&
			(alertQuery.ExpressionWithChinaese == "" || alertQuery.ExpressionWithChinaese == alertModel.ExpressionWithChinaese) &&
			(len(alertQuery.AlertTimeLength) <= 0 || services.In(alertQuery.AlertTimeLength, alertModel.AlertTimeLength)) &&
			(len(alertQuery.Az) <= 0 || services.In(alertQuery.Az, alertModel.Az)) &&
			(len(alertQuery.AlertLevel) <= 0 || services.In(alertQuery.AlertLevel, alertModel.AlertLevel)) &&
			(len(alertQuery.StateList) <= 0 || services.In(alertQuery.StateList, alertModel.State)) &&
			(len(alertQuery.ResourceTypeCode) <= 0 || services.In(alertQuery.ResourceTypeCode, alertModel.ResourceTypeCode)) &&
			(len(alertQuery.ResourceSubTypeCode) <= 0 || services.In(alertQuery.ResourceSubTypeCode, alertModel.ResourceSubTypeCode)) {
			alertModel.RegionName = cmdbmanager.GetRegion(alertModel.Region, regionList).RegionName
			alertModel.AzName = cmdbmanager.GetAz(alertModel.Az, azList).AzName

			alertResult.DataList = append(alertResult.DataList, alertModel)

			////此处判断是为了过滤异常值，否则会与总览页的聚合数据对应不上
			//if !(alertModel.AlertName == "" && alertModel.PolicyName == "" && alertModel.ExpressionWithChinaese == "") {
			//	alertResult.DataList = append(alertResult.DataList, alertModel)
			//} else {
			//	klog.Error("DEBUG - PlatformDataAlerts -1 - 1 - 8 not append")
			//}
		} else {
			klog.Error("DEBUG - PlatformDataAlerts -1 - 1 - 9 not append")
		}

	}

	return alertResult, err
}

func GetResourceData(resourceKey, resourceSubKey string) string {
	// var ResourceList []cmdbmodel.Resource
	// ResourceList, _ = cmdbmanager.GetResourceData()

	if resourceKey != "" {
		for _, resource := range ResourceList.ResourceType {
			if resource.ResourceKey == resourceKey {
				return resource.ResourceValue
			}
		}
	} else if resourceSubKey != "" {
		for _, resource := range ResourceList.ResourceSubType {
			if resource.ResourceKey == resourceSubKey {
				return resource.ResourceValue
			}
		}
	}

	return ""
}

// 定义一个通用的结构体
type Bucket struct {
	Slice []interface{}               //承载以任意结构体为元素构成的Slice
	By    func(a, b interface{}) bool //排序规则函数,当需要对新的结构体slice进行排序时，只需定义这个函数即可
}

/*
定义三个必须方法的准则：接收者不能为指针
*/
func (this Bucket) Len() int { return len(this.Slice) }

func (this Bucket) Swap(i, j int) { this.Slice[i], this.Slice[j] = this.Slice[j], this.Slice[i] }

func (this Bucket) Less(i, j int) bool { return this.By(this.Slice[i], this.Slice[j]) }

func GetAlertsByFilter(queryFilter string) ([]interface{}, error) {
	var all = make([]interface{}, 0, 50)
	var err error
	if queryFilter == "" {
		err = errors.New("Please insert queryFilter.")
	} else {
		reqest, _ := http.NewRequest("GET", "http://"+config.GetDefaultUrl(config.AlertmanagerService)+"/api/v2/alerts/groups?silenced=false&inhibited=false&active=true&filter="+queryFilter, nil)

		reqest.Header.Set("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8")
		reqest.Header.Set("Accept-Charset", "GBK,utf-8;q=0.7,*;q=0.3")
		reqest.Header.Set("Accept-Encoding", "gzip,deflate,sdch")
		reqest.Header.Set("Accept-Language", "zh-CN,zh;q=0.8")
		reqest.Header.Set("Cache-Control", "max-age=0")
		reqest.Header.Set("Connection", "keep-alive")
		reqest.Header.Set("User-Agent", "chrome 100")

		//defer reqest.Body.Close()
		client := &http.Client{}
		respons, err1 := client.Do(reqest)
		//defer client.CloseIdleConnections()
		err = err1
		if respons.StatusCode == 200 {
			bodyR, _ := ioutil.ReadAll(respons.Body)
			var js []interface{}
			err = json.Unmarshal(bodyR, &js)
			//fmt.Println(js)
			if err == nil {
				for _, data := range js {

					//fmt.Println(severity.LevelCount)
					wsMap := data.(map[string]interface{})
					if vCw, ok := wsMap["alerts"]; ok {
						alerts := vCw.([]interface{})
						for _, alert := range alerts {
							all = append(all, alert)
						}
					}
				}
			}
		}

	}
	return all, err
}

//func GetAlertsByFilter2(queryFilter string) ([]interface{}, error) {
//	var all []interface{}
//	var err error
//	if queryFilter == "" {
//		err = errors.New("Please insert queryFilter.")
//	} else {
//		reqest, _ := http.NewRequest("GET", "http://"+config.GetDefaultUrl(config.AlertmanagerService)+"/api/v2/alerts/groups?silenced=false&inhibited=false&active=true&filter="+queryFilter, nil)
//
//		reqest.Header.Set("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8")
//		reqest.Header.Set("Accept-Charset", "GBK,utf-8;q=0.7,*;q=0.3")
//		reqest.Header.Set("Accept-Encoding", "gzip,deflate,sdch")
//		reqest.Header.Set("Accept-Language", "zh-CN,zh;q=0.8")
//		reqest.Header.Set("Cache-Control", "max-age=0")
//		reqest.Header.Set("Connection", "keep-alive")
//		reqest.Header.Set("User-Agent", "chrome 100")
//
//		//defer reqest.Body.Close()
//		client := &http.Client{}
//		respons, err1 := client.Do(reqest)
//		//defer client.CloseIdleConnections()
//		err = err1
//		if respons.StatusCode == 200 {
//			bodyR, _ := ioutil.ReadAll(respons.Body)
//			var js []interface{}
//			err = json.Unmarshal(bodyR, &js)
//			//fmt.Println(js)
//			if err == nil {
//				for _, data := range js {
//
//					//fmt.Println(severity.LevelCount)
//					wsMap := data.(map[string]interface{})
//					if vCw, ok := wsMap["alerts"]; ok {
//						alerts := vCw.([]interface{})
//						for _, alert := range alerts {
//							all = append(all, alert)
//						}
//					}
//				}
//			}
//		}
//
//	}
//	return all, err
//}

func CountAlerts(filter []string) (int, error) {
	var silenced bool = false
	var inhibited bool = false
	var active bool = true

	params := &alert.GetAlertsParams{
		Silenced:  &silenced,
		Active:    &active,
		Inhibited: &inhibited,
		Filter:    filter,
	}
	res, err := client2.GetAlerts(params)
	if err != nil {
		klog.Error(err)
		return 0, err
	}
	klog.Errorf("GetAlerts Result List Size: %d", len(res))
	i := 0
	for _, alert := range res {
		if (*alert).Labels["severity"] != "p0" && (*alert).Labels["severity"] != "p1" && (*alert).Labels["severity"] != "p2" && (*alert).Labels["severity"] != "p3" {
			continue
		} else if (*alert).Labels["severity"] == "" {
			continue
		}
		//此处判断是为了过滤异常值，否则会与总览页的聚合数据对应不上
		if !((*alert).Labels["lubanAlarmView"] == "" && (*alert).Labels["lubanPolicyName"] == "" && (*alert).Annotations["lubanExpressionWithChinese"] == "") {
			i++
		}
	}
	return i, err
}

func GetAlerts(filter []string) (models.GettableAlerts, error) {
	var silenced bool = false
	var inhibited bool = false
	var active bool = true

	params := &alert.GetAlertsParams{
		Silenced:  &silenced,
		Active:    &active,
		Inhibited: &inhibited,
		Filter:    filter,
	}
	res, err := client2.GetAlerts(params)
	if err != nil {
		klog.Error(err)
		return make(models.GettableAlerts, 0), err
	}
	return res, nil
}

func CountAlertsNum(alerts models.GettableAlerts, poolTye, severity string) int {
	if alerts == nil || len(alerts) == 0 {
		return 0
	}
	cntAlerts := make(models.GettableAlerts, 0)

	for _, alt := range alerts {
		level := (*alt).Labels["severity"]
		if level != "p0" && level != "p1" && level != "p2" && level != "p3" {
			continue
		}
		if (*alt).Labels["lubanAlarmView"] == "" && (*alt).Labels["lubanPolicyName"] == "" && (*alt).Annotations["lubanExpressionWithChinese"] == "" {
			continue
		}
		if poolTye != "" && (*alt).Labels["lubanResourceSubType"] != poolTye {
			continue
		}
		if severity != "" && level != severity {
			continue
		}
		cntAlerts = append(cntAlerts, alt)
	}
	return len(cntAlerts)
}

// 概览页告警数据公共方法
func GetCommonAlertOverviewNum(alertsParam alertmanagermodel.AlertQuery) (result []alertmanagermodel.OverviewAlert, err error) {

	p0 := alertmanagermodel.OverviewAlert{Name: "紧急告警", Level: "p0", Kind: "error", Number: 0, Unit: "个"}
	p1 := alertmanagermodel.OverviewAlert{Name: "重要告警", Level: "p1", Kind: "warn", Number: 0, Unit: "个"}
	p2 := alertmanagermodel.OverviewAlert{Name: "次要告警", Level: "p2", Kind: "minor", Number: 0, Unit: "个"}
	p3 := alertmanagermodel.OverviewAlert{Name: "提醒告警", Level: "p3", Kind: "info", Number: 0, Unit: "个"}

	alertsParam.PageNo = 1
	alertsParam.PageSize = 10000

	switch alertsParam.Module {
	case "server": // 服务器
		alertsParam.ResourceTypeCode = []string{"physicalResource"}
		alertsParam.ResourceSubTypeCode = []string{"physicalServer"}
	case "switch": // 交换机
		alertsParam.ResourceTypeCode = []string{"physicalResource"}
		alertsParam.ResourceSubTypeCode = []string{"physicalSwitch"}
	case "computer": // 计算资源池
		alertsParam.ResourceTypeCode = []string{"resourcePool"}
		alertsParam.ResourceSubTypeCode = []string{"kec"}
	case "block": // 块存储资源池
		alertsParam.ResourceTypeCode = []string{"resourcePool"}
	case "database": // 数据库资源池
		alertsParam.ResourceTypeCode = []string{"resourcePool"}
		alertsParam.ResourceSubTypeCode = []string{"kcs", "rds"}
	case "object": // 对象资源池
		alertsParam.ResourceTypeCode = []string{"resourcePool"}
		alertsParam.ResourceSubTypeCode = []string{"ks3"}
	case "service": // 服务
		alertsParam.ResourceTypeCode = []string{"service"}
	//case "network": // 网络资源池
	//	alertsParam.ResourceTypeCode = []string{"resourcePool"}
	default:
		fmt.Println("监控大屏幕")
	}

	fmt.Printf("OverviewAlertsParam %+v", alertsParam)
	// 获取告警列表
	res, err := GetAlertsDataList(alertsParam)
	if err != nil {
		return result, err
	}
	for _, item := range res.DataList {
		switch item.AlertLevel {
		case "p0":
			p0.Number++
		case "p1":
			p1.Number++
		case "p2":
			p2.Number++
		case "p3":
			p3.Number++
		}
	}
	result = append(result, p0, p1, p2, p3)
	return result, nil

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/nat/nat.go
```golang
package nat

import (
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"math"
	"sort"
	"strconv"
	"strings"
	"time"

	"github.com/go-redis/redis/v8"
	"github.com/jinzhu/copier"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	vmmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cloudproduct"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	natmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/nat"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	kts "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/ktsmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"k8s.io/klog/v2"
	// "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	// "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
)

type Interface interface {
	Overview(*natmodel.OverviewQuery) (natmodel.OverView, error)
	OverviewTop(*natmodel.TopQuery) ([]natmodel.OverViewLine, error)
	GetNatList(*natmodel.ListQuery) (*natmodel.NatListRsp, error)
	GetMetricLine(*natmodel.MetricQuery) ([]natmodel.MetricLine, error)

	GetNatTop(*vmmodel.TopQuery) ([]vmmodel.OverViewLineNew, error)
}

func New() *Service {
	return &Service{}
}

type Service struct {
}

var NatOverviewTopMapK = map[string]func(list []natmodel.NatTopVm, name, start, end string, k int) ([]natmodel.OverViewLine, error){
	"natBps":       GetNatBps,
	"natPps":       GetNatPps,
	"natBpsPublic": GetNatBpsPublic,
	"natPpsPublic": GetNatPpsPublic,
}

func (s *Service) GetNatTop(param *vmmodel.TopQuery) ([]vmmodel.OverViewLineNew, error) {
	ctx, cefl := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cefl()

	//获取时间间隔
	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	topK, _ := strconv.ParseInt(param.TopK, 10, 64)

	//获取redis集合Key
	param1 := cloudproduct.GetResourceRedisKeyParam{
		ResourceType: config.CloudNatResource,
		Region:       param.Region,
		Az:           param.Az,
		IntervalStr:  intervalStr,
	}
	redisKeyList, err := cloudproduct.GetResourceRedisKeyList(&param1)
	if err != nil {
		return []vmmodel.OverViewLineNew{}, err
	}
	klog.Infof("redisKeyList %+v", redisKeyList)
	//组装数据
	rst := make([]vmmodel.OverViewLineNew, 0, 8)
	name := param.Name
	for i := 0; i < len(name); i++ {
		switch name[i] {
		case "natBps":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "bps"}
			//入口流量
			rIn := vmmodel.EchartTypeNew{}
			rIn.Info.Name = "入网带宽"
			rIn.Info.Unit = "bps"
			rIn.Info.UnitType = "bps"
			var vmNatInLit []vmmodel.VmValueType
			vmNatInKeys := redisKeyList["NatBpsIn"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmNatInKeys {
				//获取集合数据
				vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				vmNatInLit = append(vmNatInLit, vmlist...)
			}
			vmNatInCont := len(vmNatInLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(vmNatInCont) > topK {
				//排序
				vmNatInLit = cloudproduct.VmValueOrder(vmNatInLit, "desc")
				if int64(len(vmNatInLit)) >= topK {
					vmNatInLit = vmNatInLit[:topK]
				}
			}
			for _, v := range vmNatInLit {
				v.Id = v.InstanceId
				v.SubName = v.VpcName
			}
			rIn.Values = vmNatInLit
			r.Echarts = append(r.Echarts, rIn)

			// 出口流量
			rOut := vmmodel.EchartTypeNew{}
			rOut.Info.Name = "出网带宽"
			rOut.Info.Unit = "bps"
			rOut.Info.UnitType = "bps"
			var vmNatOutLit []vmmodel.VmValueType
			vmNatOutKeys := redisKeyList["NatBpsOut"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmNatOutKeys {
				//获取集合数据
				vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				vmNatOutLit = append(vmNatOutLit, vmlist...)
			}
			vmNatOutCont := len(vmNatOutLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(vmNatOutCont) > topK {
				//排序
				vmNatOutLit = cloudproduct.VmValueOrder(vmNatOutLit, "desc")
				if int64(len(vmNatOutLit)) >= topK {
					vmNatOutLit = vmNatOutLit[:topK]
				}
			}
			rOut.Values = vmNatOutLit
			r.Echarts = append(r.Echarts, rOut)

			rst = append(rst, r)
		case "natPps":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "pps"}
			//入口流量
			rIn := vmmodel.EchartTypeNew{}
			rIn.Info.Name = "每秒流入包数"
			rIn.Info.Unit = "pps"
			rIn.Info.UnitType = "pps"
			var vmNatInLit []vmmodel.VmValueType
			vmNatInKeys := redisKeyList["NatPpsIn"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmNatInKeys {
				//获取集合数据
				vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				vmNatInLit = append(vmNatInLit, vmlist...)
			}
			vmNatInCont := len(vmNatInLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(vmNatInCont) > topK {
				//排序
				vmNatInLit = cloudproduct.VmValueOrder(vmNatInLit, "desc")
				if int64(len(vmNatInLit)) >= topK {
					vmNatInLit = vmNatInLit[:topK]
				}
			}
			rIn.Values = vmNatInLit
			r.Echarts = append(r.Echarts, rIn)
			// 出口流量
			rOut := vmmodel.EchartTypeNew{}
			rOut.Info.Name = "每秒流出包数"
			rOut.Info.Unit = "pps"
			rOut.Info.UnitType = "pps"
			var vmNatOutLit []vmmodel.VmValueType
			vmNatOutKeys := redisKeyList["NatPpsOut"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmNatOutKeys {
				//获取集合数据
				vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				vmNatOutLit = append(vmNatOutLit, vmlist...)
			}
			vmNatOutCont := len(vmNatOutLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(vmNatOutCont) > topK {
				//排序
				vmNatOutLit = cloudproduct.VmValueOrder(vmNatOutLit, "desc")
				if int64(len(vmNatOutLit)) >= topK {
					vmNatOutLit = vmNatOutLit[:topK]
				}
			}
			rOut.Values = vmNatOutLit
			r.Echarts = append(r.Echarts, rOut)

			rst = append(rst, r)
		case "natBpsPublic":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "bps"}
			//入口流量
			rIn := vmmodel.EchartTypeNew{}
			rIn.Info.Name = "入网带宽(公网)"
			rIn.Info.Unit = "bps"
			rIn.Info.UnitType = "bps"
			var vmNatInLit []vmmodel.VmValueType
			vmNatInKeys := redisKeyList["NatBpsInPublic"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmNatInKeys {
				//获取集合数据
				vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				vmNatInLit = append(vmNatInLit, vmlist...)
			}
			vmNatInCont := len(vmNatInLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(vmNatInCont) > topK {
				//排序
				vmNatInLit = cloudproduct.VmValueOrder(vmNatInLit, "desc")
				if int64(len(vmNatInLit)) >= topK {
					vmNatInLit = vmNatInLit[:topK]
				}
			}
			rIn.Values = vmNatInLit
			r.Echarts = append(r.Echarts, rIn)
			// 出口流量
			rOut := vmmodel.EchartTypeNew{}
			rOut.Info.Name = "出网带宽(公网)"
			rOut.Info.Unit = "bps"
			rOut.Info.UnitType = "bps"
			var vmNatOutLit []vmmodel.VmValueType
			vmNatOutKeys := redisKeyList["NatBpsOutPublic"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmNatOutKeys {
				//获取集合数据
				vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				vmNatOutLit = append(vmNatOutLit, vmlist...)
			}
			vmNatOutCont := len(vmNatOutLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(vmNatOutCont) > topK {
				//排序
				vmNatOutLit = cloudproduct.VmValueOrder(vmNatOutLit, "desc")
				if int64(len(vmNatOutLit)) >= topK {
					vmNatOutLit = vmNatOutLit[:topK]
				}
			}
			rOut.Values = vmNatOutLit
			r.Echarts = append(r.Echarts, rOut)

			rst = append(rst, r)
		case "natPpsPublic":
			r := vmmodel.OverViewLineNew{Name: name[i], Unit: "pps"}
			//入口流量
			rIn := vmmodel.EchartTypeNew{}
			rIn.Info.Name = "每秒流入包数(公网)"
			rIn.Info.Unit = "pps"
			rIn.Info.UnitType = "pps"
			var vmNatInLit []vmmodel.VmValueType
			vmNatInKeys := redisKeyList["NatPpsInPublic"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmNatInKeys {
				//获取集合数据
				vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				vmNatInLit = append(vmNatInLit, vmlist...)
			}
			vmNatInCont := len(vmNatInLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(vmNatInCont) > topK {
				//排序
				vmNatInLit = cloudproduct.VmValueOrder(vmNatInLit, "desc")
				if int64(len(vmNatInLit)) >= topK {
					vmNatInLit = vmNatInLit[:topK]
				}
			}
			rIn.Values = vmNatInLit
			r.Echarts = append(r.Echarts, rIn)
			// 出口流量
			rOut := vmmodel.EchartTypeNew{}
			rOut.Info.Name = "每秒流出包数(公网)"
			rOut.Info.Unit = "pps"
			rOut.Info.UnitType = "pps"
			var vmNatOutLit []vmmodel.VmValueType
			vmNatOutKeys := redisKeyList["NatPpsOutPublic"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmNatOutKeys {
				//获取集合数据
				vmListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]vmmodel.VmValueType, len(vmListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(vmListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				vmNatOutLit = append(vmNatOutLit, vmlist...)
			}
			vmNatOutCont := len(vmNatOutLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(vmNatOutCont) > topK {
				//排序
				vmNatOutLit = cloudproduct.VmValueOrder(vmNatOutLit, "desc")
				if int64(len(vmNatOutLit)) >= topK {
					vmNatOutLit = vmNatOutLit[:topK]
				}
			}
			rOut.Values = vmNatOutLit
			r.Echarts = append(r.Echarts, rOut)

			rst = append(rst, r)
		}
	}
	return rst, nil
}

//概览页告警
func (n Service) Overview(param *natmodel.OverviewQuery) (natmodel.OverView, error) {

	klog.Infof("get load overview ,region: %s, azs: %q", param.Region, param.Az)

	alerts := make([]models.AlertType, 0, 4)
	p0 := models.AlertType{Name: "紧急告警", Level: "p0", Kind: "error", Number: 0, Unit: "个"}
	p1 := models.AlertType{Name: "重要告警", Level: "p1", Kind: "warn", Number: 0, Unit: "个"}
	p2 := models.AlertType{Name: "次要告警", Level: "p2", Kind: "minor", Number: 0, Unit: "个"}
	p3 := models.AlertType{Name: "提醒告警", Level: "p3", Kind: "info", Number: 0, Unit: "个"}
	alerts = append(alerts, p0, p1, p2, p3)

	cmdbParam := cmdbmodel.GetNatListParam{}
	cmdbParam.PageNo = 1
	cmdbParam.PageSize = math.MaxInt64
	cmdbParam.Region = param.Region
	cmdbRsp, err := cmdbmanager.GetNatList(cmdbParam)

	if err != nil {
		klog.Errorf("get GetNatList err: %v", err)
		return natmodel.OverView{}, nil
	}

	cs := cmdbRsp.Data.DataList
	count := len(cs)
	var (
		public  = 0 //公网
		private = 0 // 内网
	)
	for i := 0; i < count; i++ {
		switch cs[i].NatType {
		case "public":
			public++
		default:
			private++
		}
	}

	chart := natmodel.Chart{Info: natmodel.OverInfo{Name: "NAT统计", Number: count, UnitType: "number"}}
	v1 := natmodel.ValueType{Name: "公网", Value: public}
	chart.Values = append(chart.Values, v1)
	v2 := natmodel.ValueType{Name: "金山云内网", Value: private}
	chart.Values = append(chart.Values, v2)
	state := make([]natmodel.Chart, 0, 1)
	state = append(state, chart)
	rst := natmodel.OverView{param.Region, param.Az, alerts, state}

	return rst, nil
}

// 概览页top
func (n Service) OverviewTop(param *natmodel.TopQuery) (res []natmodel.OverViewLine, err error) {

	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	var nameStr string
	for _, v := range param.Name {
		nameStr += v + "_"
	}

	key := "nat_overviewTop"
	fieldKey := "name_" + nameStr + "topk_" + param.TopK + "_interval_" + intervalStr + "_region" + param.Region + "_Az" + param.Az
	klog.Infof("nat OverviewTop fieldKey", fieldKey)

	redisCon := config.RedisConfig
	var rdb *redis.Client
	rdb = redis.NewClient(&redis.Options{
		Addr:       redisCon["Host"].(string),
		Password:   redisCon["Password"].(string),
		DB:         redisCon["Db"].(int),
		MaxRetries: redisCon["MaxRetries"].(int),
	})

	cache, err := utils.NewRedisCache(rdb, key)
	if err != nil {
		klog.Error("get utils.NewRedisCache failed", err)
		return
	}
	result, err := rdb.Ping(context.Background()).Result()
	if err != nil {
		klog.Error("Ping redis failed", err)
		return
	}

	klog.Infof("result %s", result)
	after := time.After(time.Second * 60)

	for {
		select {
		case <-time.After(time.Second):
			data, err := cache.GetData(context.Background(), fieldKey, GetNatTop(param), time.Minute*10)
			if err != nil {
				klog.Error("nat GetData err ", err)
			}
			if data == "" {
				continue
			}
			var list []natmodel.OverViewLine
			ee := json.Unmarshal([]byte(data), &list)
			if ee != nil {
				klog.Error("Parsing JSON failed", ee)
			}

			klog.Infof("data:%s", list)
			return list, nil
		case <-after:
			return
		}
	}

	return res, nil

}

func GetNatTop(param *natmodel.TopQuery) func() (data string, err error) {

	return func() (data string, err error) {
		var rst []natmodel.OverViewLine
		start := strconv.FormatFloat(param.Start/1000, 'f', 3, 64)
		end := strconv.FormatFloat(param.End/1000, 'f', 3, 64)
		topk, _ := strconv.Atoi(param.TopK)

		// 获取nat列表
		cmdbParam := cmdbmodel.GetNatListParam{}
		cmdbParam.PageNo = 1
		cmdbParam.PageSize = math.MaxInt64
		cmdbParam.Region = param.Region
		cmdbRsp, err := cmdbmanager.GetNatList(cmdbParam)

		if err != nil {
			klog.Errorf("get GetNatList err: %v", err)
			return "", nil
		}

		var natList []natmodel.NatTopVm
		for _, v := range cmdbRsp.Data.DataList {
			natInfo := natmodel.NatTopVm{}
			natInfo.ID = "kscnat--" + v.InstanceId
			natInfo.Name = v.InstanceName
			natList = append(natList, natInfo)
		}

		for _, name := range param.Name {
			if op, ok := NatOverviewTopMapK[name]; ok {
				result, errOp := op(natList, name, start, end, topk)
				if errOp != nil {
					klog.Error(errOp)
					continue
				}
				rst = append(rst, result...)
			}
		}
		res, _ := json.Marshal(rst)
		return string(res), nil

	}
}

// 获取概览页面top nat带宽
func GetNatBps(list []natmodel.NatTopVm, name, start, end string, topk int) ([]natmodel.OverViewLine, error) {
	klog.Info("natBps", "nat带宽")

	rst := make([]natmodel.OverViewLine, 0, 4)
	result := natmodel.OverViewLine{Name: name, Unit: "bps"}

	// in
	inEcharts := natmodel.TopEchartType{}
	inEcharts.Info.Name = "入网带宽"
	inEcharts.Info.Unit = "bps"
	inEcharts.Info.UnitType = "bps"
	for j := 0; j < len(list); j++ {
		metric := []string{"NatBpsIn"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	in := NatValueOrder(list, "desc")
	if len(in) >= topk {
		in = in[:topk]
	}
	for o := 0; o < len(in); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(in[o].Value), 64)
		v := natmodel.ValueType{Value: valueFloat, SubName: in[o].Name, Name: services.GenerateTopK(o + 1), VmId: in[o].ID}
		inEcharts.Values = append(inEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, inEcharts)

	// out
	outEcharts := natmodel.TopEchartType{}
	outEcharts.Info.Name = "出网带宽"
	outEcharts.Info.Unit = "bps"
	outEcharts.Info.UnitType = "bps"
	for j := 0; j < len(list); j++ {
		metric := []string{"NatBpsOut"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := NatValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := natmodel.ValueType{Value: valueFloat, SubName: out[o].Name, Name: services.GenerateTopK(o + 1), VmId: out[o].ID}
		outEcharts.Values = append(outEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, outEcharts)

	rst = append(rst, result)

	return rst, nil
}

// 获取概览页面top nat每秒收发包次数
func GetNatPps(list []natmodel.NatTopVm, name, start, end string, topk int) ([]natmodel.OverViewLine, error) {
	klog.Info("natPps", "nat每秒收发包次数")
	rst := make([]natmodel.OverViewLine, 0, 4)
	result := natmodel.OverViewLine{Name: name, Unit: "pps"}

	// in
	inEcharts := natmodel.TopEchartType{}
	inEcharts.Info.Name = "每秒流入包数"
	inEcharts.Info.Unit = "pps"
	inEcharts.Info.UnitType = "pps"
	for j := 0; j < len(list); j++ {
		metric := []string{"NatPpsIn"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	in := NatValueOrder(list, "desc")
	if len(in) >= topk {
		in = in[:topk]
	}
	for o := 0; o < len(in); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(in[o].Value), 64)
		v := natmodel.ValueType{Value: valueFloat, SubName: in[o].Name, Name: services.GenerateTopK(o + 1), VmId: in[o].ID}
		inEcharts.Values = append(inEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, inEcharts)

	// out
	outEcharts := natmodel.TopEchartType{}
	outEcharts.Info.Name = "每秒流出包数"
	outEcharts.Info.Unit = "pps"
	outEcharts.Info.UnitType = "pps"
	for j := 0; j < len(list); j++ {
		metric := []string{"NatPpsOut"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := NatValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := natmodel.ValueType{Value: valueFloat, SubName: out[o].Name, Name: services.GenerateTopK(o + 1), VmId: out[o].ID}
		outEcharts.Values = append(outEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, outEcharts)

	rst = append(rst, result)

	return rst, nil
}

// 获取概览页面top nat带宽(公网)
func GetNatBpsPublic(list []natmodel.NatTopVm, name, start, end string, topk int) ([]natmodel.OverViewLine, error) {
	klog.Info("natBps", "nat带宽(公网)")

	rst := make([]natmodel.OverViewLine, 0, 4)
	result := natmodel.OverViewLine{Name: name, Unit: "bps"}

	// in
	inEcharts := natmodel.TopEchartType{}
	inEcharts.Info.Name = "入网带宽(公网)"
	inEcharts.Info.Unit = "bps"
	inEcharts.Info.UnitType = "bps"
	for j := 0; j < len(list); j++ {
		metric := []string{"NatBpsInPublic"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	in := NatValueOrder(list, "desc")
	if len(in) >= topk {
		in = in[:topk]
	}
	for o := 0; o < len(in); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(in[o].Value), 64)
		v := natmodel.ValueType{Value: valueFloat, SubName: in[o].Name, Name: services.GenerateTopK(o + 1), VmId: in[o].ID}
		inEcharts.Values = append(inEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, inEcharts)

	// out
	outEcharts := natmodel.TopEchartType{}
	outEcharts.Info.Name = "出网带宽(公网)"
	outEcharts.Info.Unit = "bps"
	outEcharts.Info.UnitType = "bps"
	for j := 0; j < len(list); j++ {
		metric := []string{"NatBpsOutPublic"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := NatValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := natmodel.ValueType{Value: valueFloat, SubName: out[o].Name, Name: services.GenerateTopK(o + 1), VmId: out[o].ID}
		outEcharts.Values = append(outEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, outEcharts)

	rst = append(rst, result)

	return rst, nil
}

// 获取概览页面top nat每秒收发包次数(公网)
func GetNatPpsPublic(list []natmodel.NatTopVm, name, start, end string, topk int) ([]natmodel.OverViewLine, error) {
	klog.Info("natPps", "nat每秒收发包次数(公网)")
	rst := make([]natmodel.OverViewLine, 0, 4)
	result := natmodel.OverViewLine{Name: name, Unit: "pps"}

	// in
	inEcharts := natmodel.TopEchartType{}
	inEcharts.Info.Name = "每秒流入包数(公网)"
	inEcharts.Info.Unit = "pps"
	inEcharts.Info.UnitType = "pps"
	for j := 0; j < len(list); j++ {
		metric := []string{"NatPpsInPublic"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	in := NatValueOrder(list, "desc")
	if len(in) >= topk {
		in = in[:topk]
	}
	for o := 0; o < len(in); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(in[o].Value), 64)
		v := natmodel.ValueType{Value: valueFloat, SubName: in[o].Name, Name: services.GenerateTopK(o + 1), VmId: in[o].ID}
		inEcharts.Values = append(inEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, inEcharts)

	// out
	outEcharts := natmodel.TopEchartType{}
	outEcharts.Info.Name = "每秒流出包数(公网)"
	outEcharts.Info.Unit = "pps"
	outEcharts.Info.UnitType = "pps"
	for j := 0; j < len(list); j++ {
		metric := []string{"NatPpsOutPublic"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := NatValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := natmodel.ValueType{Value: valueFloat, SubName: out[o].Name, Name: services.GenerateTopK(o + 1), VmId: out[o].ID}
		outEcharts.Values = append(outEcharts.Values, v)
	}
	result.Echarts = append(result.Echarts, outEcharts)

	rst = append(rst, result)

	return rst, nil
}

func NatValueOrder(in []natmodel.NatTopVm, code string) []natmodel.NatTopVm {
	results := alert.Bucket{}
	for i := 0; i < len(in); i++ {
		results.Slice = append(results.Slice, in[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	switch code {
	case "asc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(natmodel.NatTopVm).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(natmodel.NatTopVm).Value), 64)
			return aa < bb
		}
	case "desc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(natmodel.NatTopVm).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(natmodel.NatTopVm).Value), 64)
			return aa > bb
		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(in); i++ {
		in[i] = results.Slice[i].(natmodel.NatTopVm)
	}
	return in
}

func (n Service) GetNatList(query *natmodel.ListQuery) (rsp *natmodel.NatListRsp, err error) {
	cmdbParam := cmdbmodel.GetNatListParam{}
	err = copier.Copy(&cmdbParam, query)
	if err != nil {
		klog.Errorf("parameter conversion error: %v", err)
		return
	}

	cmdbParam.PageNo = 1
	cmdbParam.PageSize = math.MaxInt64
	cmdbRsp, err := cmdbmanager.GetNatList(cmdbParam)
	if err != nil {
		klog.Errorf("data fetch error: %v", err)
		return
	}

	klog.Infof("%+v", cmdbRsp)

	cmdbRspData := cmdbRsp.Data
	rsp = &natmodel.NatListRsp{}
	klog.Infof("%+v", cmdbRspData)
	klog.Infof("%+v", rsp)

	err = copier.Copy(rsp, &cmdbRspData)
	if err != nil {
		klog.Errorf("parameter conversion error: %v", err)
		return
	}

	dataList := rsp.DataList
	//sort
	lessFunc := parseOrder(query, dataList)
	if lessFunc != nil {
		sort.Slice(dataList, lessFunc)
	}

	//page
	total := len(dataList)
	offset := (query.PageNo - 1) * query.PageSize
	limit := offset + query.PageSize
	if offset > total {
		err = errors.New("pageNo. is too large")
		return
	}
	if limit > total {
		limit = total
	}
	dataList = dataList[offset:limit]

	for _, n := range dataList {
		host := fmt.Sprintf("kscnat--%s", n.InstanceId)
		//host = "ksnat--aa1411ef-571e-41cc-a46f-b68d9c2da638"
		tag := map[string]string{
			"host": host,
		}
		bpsInQuery := kts.LastQuery{
			Metric: "vpc.nat.bps.in" + "." + host,
			Tags:   tag,
		}
		bpsOutQuery := kts.LastQuery{
			Metric: "vpc.nat.bps.out" + "." + host,
			Tags:   tag,
		}
		ppsInQuery := kts.LastQuery{
			Metric: "vpc.nat.pps.in" + "." + host,
			Tags:   tag,
		}
		ppsOutQuery := kts.LastQuery{
			Metric: "vpc.nat.bps.out" + "." + host,
			Tags:   tag,
		}
		//cpsQuery := kts.LastQuery{
		//	Metric: "vpc.nat.cps" + "." + host,
		//	Tags:   tag,
		//}
		//concurrentConnQuery := kts.LastQuery{
		//	Metric: "vpc.nat.concurrentconn" + "." + host,
		//	Tags:   tag,
		//}

		var queries = []kts.LastQuery{bpsInQuery, bpsOutQuery, ppsInQuery, ppsOutQuery}
		metricsMap, err := kts.TSDBLastQueryBatch(queries...)
		if err != nil {
			klog.Errorf("nat tsdb metrics 查询错误，instanceId: %s", n.InstanceId)
			continue
		}
		fmt.Println("metricsMap", metricsMap)
		//bpsIn, _ := strconv.ParseFloat(metricsMap[bpsInQuery.Metric].Value, 64)
		//inst.BPSIn = bpsIn / 1e6 // bps 转Mbps
		n.BPSIn, _ = strconv.ParseInt(metricsMap[bpsInQuery.Metric].Value, 10, 64)
		n.BPSOut, _ = strconv.ParseInt(metricsMap[bpsOutQuery.Metric].Value, 10, 64)
		n.PPSIn, _ = strconv.ParseInt(metricsMap[ppsInQuery.Metric].Value, 10, 64)
		n.PPSOut, _ = strconv.ParseInt(metricsMap[ppsOutQuery.Metric].Value, 10, 64)
	}

	rsp.PageSize = query.PageSize
	rsp.PageNo = query.PageNo
	rsp.TotalCount = total
	rsp.DataList = dataList
	return rsp, nil
}

func parseOrder(params *natmodel.ListQuery, natlist []natmodel.NatInfo) func(i int, j int) bool {
	klog.Infof("orderCode %s , orderType %s", params.OrderCode, params.OrderType)
	var lessFunc func(i, j int) bool
	if params.OrderCode == "bpsIn" {
		if params.OrderType == "ascending" { //正序
			lessFunc = func(i, j int) bool {
				return natlist[i].BPSIn < natlist[j].BPSIn
			}
		}
		if params.OrderType == "descending" { //逆序
			lessFunc = func(i, j int) bool {
				return natlist[i].BPSIn > natlist[j].BPSIn
			}
		}
	}

	if params.OrderCode == "bpsOut" {
		if params.OrderType == "ascending" {
			lessFunc = func(i, j int) bool {
				return natlist[i].BPSOut < natlist[j].BPSOut
			}
		}
		if params.OrderType == "descending" {
			lessFunc = func(i, j int) bool {
				return natlist[i].BPSOut > natlist[j].BPSOut
			}
		}
	}

	if params.OrderCode == "ppsIn" {
		if params.OrderType == "ascending" {
			lessFunc = func(i, j int) bool {
				return natlist[i].PPSIn < natlist[j].PPSIn
			}
		}
		if params.OrderType == "descending" {
			lessFunc = func(i, j int) bool {
				return natlist[i].PPSIn > natlist[j].PPSIn
			}
		}
	}

	if params.OrderCode == "ppsOut" {
		if params.OrderType == "ascending" {
			lessFunc = func(i, j int) bool {
				return natlist[i].PPSOut < natlist[j].PPSOut
			}
		}
		if params.OrderType == "descending" {
			lessFunc = func(i, j int) bool {
				return natlist[i].PPSOut > natlist[j].PPSOut
			}
		}
	}

	return lessFunc
}

func (n Service) GetMetricLine(query *natmodel.MetricQuery) ([]natmodel.MetricLine, error) {
	result := make([]natmodel.MetricLine, 0)
	start := strconv.FormatFloat(query.Start, 'f', 3, 64)
	end := strconv.FormatFloat(query.End, 'f', 3, 64)
	for j := 0; j < len(query.Name); j++ {
		switch query.Name[j] {
		case "bps":
			result = append(result, getNatBps(query.Id, start, end))
		case "pps":
			result = append(result, getNatPps(query.Id, start, end))
		case "bpsPublic":
			result = append(result, getNatBpsPublic(query.Id, start, end))
		case "ppsPublic":
			result = append(result, getNatPpsPublic(query.Id, start, end))
		case "utilization":
			result = append(result, getUtilization(query.Id, start, end))
		case "ipconflict":
			result = append(result, getIpConflict(query.Id, start, end))
		}
	}
	return result, nil
}

func getNatBps(id string, start, end string) natmodel.MetricLine {
	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBK(end1 - start1) //降采样
	rst := natmodel.MetricLine{Label: "NAT流量", Name: "bps", Unit: "bps", UnitType: "number"}
	//query
	host := "kscnat--" + id
	//host := "ksclb---7f32ca8d-290b-4fad-a652-2c3dfe75228a"
	tags := map[string]string{
		"host": host,
	}
	echartIn := natmodel.EchartType{}
	echartIn.Info = natmodel.InfoType{
		Name:     "入网带宽",
		Unit:     "bps",
		UnitType: "number",
	}

	rangeRst, _ := kts.TSDBRangeQuery(start, end, kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "vpc.nat.bps.in" + "." + host,
		Tags:       tags,
		Downsample: step,
	})
	//rangeRst, _ := kts.TSDBRangeQuerySOCKS5(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echartIn.Values = kts.KtsResultToValues(rangeRst[0].Dps)

	}
	rst.Echarts = append(rst.Echarts, echartIn)

	echartOut := natmodel.EchartType{}
	echartOut.Info = natmodel.InfoType{
		Name:     "出网带宽",
		Unit:     "bps",
		UnitType: "number",
	}

	rangeRst, _ = kts.TSDBRangeQuery(start, end, kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "vpc.nat.bps.out" + "." + host,
		Tags:       tags,
		Downsample: step,
	})
	if len(rangeRst) > 0 {
		echartOut.Values = kts.KtsResultToValues(rangeRst[0].Dps)

	}
	rst.Echarts = append(rst.Echarts, echartOut)
	return rst
}

func getNatPps(id, start, end string) natmodel.MetricLine {
	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBK(end1 - start1) //降采样
	rst := natmodel.MetricLine{Label: "NAT每秒收发包数", Name: "pps", Unit: "个", UnitType: "number"}
	//query
	host := "kscnat--" + id
	//host := "ksclb---7f32ca8d-290b-4fad-a652-2c3dfe75228a"
	tags := map[string]string{
		"host": host,
	}
	echartIn := natmodel.EchartType{}
	echartIn.Info = natmodel.InfoType{
		Name:     "每秒流入包数",
		Unit:     "pps",
		UnitType: "number",
	}

	rangeRst, _ := kts.TSDBRangeQuery(start, end, kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "vpc.nat.pps.in" + "." + host,
		Tags:       tags,
		Downsample: step,
	})
	//rangeRst, _ := kts.TSDBRangeQuerySOCKS5(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echartIn.Values = kts.KtsResultToValues(rangeRst[0].Dps)

	}
	rst.Echarts = append(rst.Echarts, echartIn)

	echartOut := natmodel.EchartType{}
	echartOut.Info = natmodel.InfoType{
		Name:     "每秒流出包数",
		Unit:     "个",
		UnitType: "number",
	}

	rangeRst, _ = kts.TSDBRangeQuery(start, end, kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "vpc.nat.pps.out" + "." + host,
		Tags:       tags,
		Downsample: step,
	})
	if len(rangeRst) > 0 {
		echartOut.Values = kts.KtsResultToValues(rangeRst[0].Dps)

	}
	rst.Echarts = append(rst.Echarts, echartOut)
	return rst
}

func getNatBpsPublic(id, start, end string) natmodel.MetricLine {
	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBK(end1 - start1) //降采样
	rst := natmodel.MetricLine{Label: "NAT出入流量（公网）", Name: "bpsPublic", Unit: "bps", UnitType: "number"}
	//query
	host := "kscnat--" + id
	//host := "ksclb---7f32ca8d-290b-4fad-a652-2c3dfe75228a"
	tags := map[string]string{
		"host": host,
	}
	echartIn := natmodel.EchartType{}
	echartIn.Info = natmodel.InfoType{
		Name:     "入网带宽",
		Unit:     "bps",
		UnitType: "number",
	}

	rangeRst, _ := kts.TSDBRangeQuery(start, end, kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "vpc.nat.public.bps.in" + "." + host,
		Tags:       tags,
		Downsample: step,
	})
	//rangeRst, _ := kts.TSDBRangeQuerySOCKS5(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echartIn.Values = kts.KtsResultToValues(rangeRst[0].Dps)

	}
	rst.Echarts = append(rst.Echarts, echartIn)

	echartOut := natmodel.EchartType{}
	echartOut.Info = natmodel.InfoType{
		Name:     "出网带宽",
		Unit:     "bps",
		UnitType: "number",
	}

	rangeRst, _ = kts.TSDBRangeQuery(start, end, kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "vpc.nat.public.bps.out" + "." + host,
		Tags:       tags,
		Downsample: step,
	})
	if len(rangeRst) > 0 {
		echartOut.Values = kts.KtsResultToValues(rangeRst[0].Dps)

	}
	rst.Echarts = append(rst.Echarts, echartOut)
	return rst
}

func getNatPpsPublic(id, start, end string) natmodel.MetricLine {
	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBK(end1 - start1) //降采样
	rst := natmodel.MetricLine{Label: "NAT出入流量（公网）", Name: "ppsPublic", Unit: "个", UnitType: "number"}
	//query
	host := "kscnat--" + id
	//host := "ksclb---7f32ca8d-290b-4fad-a652-2c3dfe75228a"
	tags := map[string]string{
		"host": host,
	}
	echartIn := natmodel.EchartType{}
	echartIn.Info = natmodel.InfoType{
		Name:     "每秒流入包数（公网）",
		Unit:     "个",
		UnitType: "number",
	}

	rangeRst, _ := kts.TSDBRangeQuery(start, end, kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "vpc.nat.public.pps.in" + "." + host,
		Tags:       tags,
		Downsample: step,
	})
	//rangeRst, _ := kts.TSDBRangeQuerySOCKS5(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echartIn.Values = kts.KtsResultToValues(rangeRst[0].Dps)

	}
	rst.Echarts = append(rst.Echarts, echartIn)

	echartOut := natmodel.EchartType{}
	echartOut.Info = natmodel.InfoType{
		Name:     "每秒流出包数（公网）",
		Unit:     "个",
		UnitType: "number",
	}

	rangeRst, _ = kts.TSDBRangeQuery(start, end, kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "vpc.nat.public.pps.out" + "." + host,
		Tags:       tags,
		Downsample: step,
	})
	if len(rangeRst) > 0 {
		echartOut.Values = kts.KtsResultToValues(rangeRst[0].Dps)

	}
	rst.Echarts = append(rst.Echarts, echartOut)
	return rst
}

func getUtilization(id, start, end string) natmodel.MetricLine {
	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBK(end1 - start1) //降采样
	rst := natmodel.MetricLine{Label: "NAT出入带宽使用率（公网）", Name: "utilization", Unit: "%", UnitType: "percent"}
	//query
	host := "kscnat--" + id
	//host := "ksclb---7f32ca8d-290b-4fad-a652-2c3dfe75228a"
	tags := map[string]string{
		"host": host,
	}
	echartIn := natmodel.EchartType{}
	echartIn.Info = natmodel.InfoType{
		Name:     "NAT入网带宽使用率",
		Unit:     "%",
		UnitType: "percent",
	}

	rangeRst, _ := kts.TSDBRangeQuery(start, end, kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "vpc.nat.public.utilization.in" + "." + host,
		Tags:       tags,
		Downsample: step,
	})
	//rangeRst, _ := kts.TSDBRangeQuerySOCKS5(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echartIn.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echartIn)

	echartOut := natmodel.EchartType{}
	echartOut.Info = natmodel.InfoType{
		Name:     "NAT出网带宽使用率",
		Unit:     "%",
		UnitType: "percent",
	}

	rangeRst, _ = kts.TSDBRangeQuery(start, end, kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "vpc.nat.public.utilization.out" + "." + host,
		Tags:       tags,
		Downsample: step,
	})
	if len(rangeRst) > 0 {
		echartOut.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echartOut)
	return rst
}

func getIpConflict(id, start, end string) natmodel.MetricLine {
	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBK(end1 - start1) //降采样
	rst := natmodel.MetricLine{Label: "NAT端口使用冲突计数", Name: "ipconflict", Unit: "次", UnitType: "number"}
	//query
	host := "kscnat--" + id
	//host := "ksclb---7f32ca8d-290b-4fad-a652-2c3dfe75228a"
	tags := map[string]string{
		"host": host,
	}
	echart := natmodel.EchartType{}
	echart.Info = natmodel.InfoType{
		Name:     "NAT端口使用冲突计数",
		Unit:     "次",
		UnitType: "number",
	}

	rangeRst, _ := kts.TSDBRangeQuery(start, end, kts.RangeQuery{
		Aggregator: "sum",
		Metric:     "vpc.nat.ipconflict" + "." + host,
		Tags:       tags,
		Downsample: step,
	})
	//rangeRst, _ := kts.TSDBRangeQuerySOCKS5(start, end, rangeQ)
	if len(rangeRst) > 0 {
		echart.Values = kts.KtsResultToValues(rangeRst[0].Dps)
	}
	rst.Echarts = append(rst.Echarts, echart)
	return rst
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/nat/util.go
```golang
package nat

import (

//"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/nat/nat_test.go
```golang
package nat

import (
	natmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/nat"
	"math"
	"strconv"
	"testing"
	"time"
)

func Test_1(t *testing.T) {
	s := New()
	query := &natmodel.ListQuery{
		PageNo:   1,
		PageSize: math.MaxInt64,
	}
	rsp, err := s.GetNatList(query)
	if err != nil {
		t.Logf("%+v", err)
		return
	}
	t.Logf("%+v", rsp)

}

func Test_Metric(t *testing.T) {
	id := "b0931853-2b7a-4c69-adf1-bb35567a1c77"
	start := strconv.FormatInt(time.Now().Add(-time.Hour*5).Unix(), 10)
	end := strconv.FormatInt(time.Now().Unix(), 10)

	bps := getNatBpsPublic(id, start, end)
	t.Logf("%+v", bps)
	pps := getNatPpsPublic(id, start, end)
	t.Logf("%+v", pps)

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/resourcepool/aggragateservice.go
```golang
package resourcepoolservice

import (
	"fmt"
	servertemp "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/physicalServer"
	"math"
	"regexp"
	"sort"
	"strconv"
	"strings"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	temp "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/resourcePool"

	alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	"k8s.io/klog/v2"

	"time"

	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"

	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	services "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	prom "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
)

type IComputerPoolService interface {
	GetComputerPoolMetric(*resourcepoolmodel.MonitorTargetListQuery) ([]resourcepoolmodel.LineDataResult, error)
	//GetServerHardwareMetric(string) (servermodels.HardWare, error)
	//GetSwitchMetricLine(*switchmodels.SwitchMetricLineQuery) (map[string][]switchmodels.EchartType, error)
	GetComputerPoolOverview(*resourcepoolmodel.ListQuery) (resourcepoolmodel.OverView1, error)
	GetComputerPoolOverviewLine(*resourcepoolmodel.OverviewLineQuery) ([]resourcepoolmodel.OverViewLine, error)
	GetComputerPoolList(*resourcepoolmodel.ComputerPoolListQuery) (resourcepoolmodel.AggregateMonitorsResult, error)
}

type ComputerPoolService struct {
	PromClient *client.PromClient
}

func NewComputerPoolService() *ComputerPoolService {
	return &ComputerPoolService{
		PromClient: client.NewPromClient(),
	}
}
func (c *ComputerPoolService) GetComputerPoolList(l *resourcepoolmodel.ComputerPoolListQuery) (resourcepoolmodel.AggregateMonitorsResult, error) {
	//从CMDB中获取资源池信息
	if l.SearchKey != "" && l.SearchValue != "" {
		switch l.SearchKey {
		case "name":
			l.Name = l.SearchValue
		}
	}
	var aggragateMonitorsResult resourcepoolmodel.AggregateMonitorsResult
	var aggregates []cmdbmodel.ComputerPool
	var aggregatesResult cmdbmodel.ComputerPoolResult
	// aggregateRegion := config.RegionMap[aggragateListQuery.Region]
	// aggregateAz := config.RegionMap[aggragateListQuery.Az]
	aggregatesResult, err := cmdbmanager.GetAggragateResourcePoolList(l.Region, l.Az, "", strconv.Itoa(l.PageNo), strconv.Itoa(l.PageSize))

	//aggregatesForCount, err := cmdbmanager.GetResourcePoolList(aggragateListQuery.Region, aggragateListQuery.Az, aggragateListQuery.Name, strconv.Itoa(aggragateListQuery.PageNo), "10000")
	if err != nil {
		return aggragateMonitorsResult, err
	}
	aggregates = aggregatesResult.Data.DataList
	currentTime := time.Now()
	if len(aggregates) > 0 {

		for _, aggregate := range aggregates {
			var aggragateMonitor resourcepoolmodel.AggragateMonitor
			nb, _ := regexp.MatchString(l.Name, aggregate.Name)
			if nb || l.Name == "" {

				aggragateMonitor.Id = aggregate.Id
				aggragateMonitor.Name = aggregate.Name
				aggragateMonitor.Region = aggregate.Region
				aggragateMonitor.Az = aggregate.Az
				aggragateMonitor.HostCount = aggregate.HostCount
				aggragateMonitor.VmCount = aggregate.VMCount
				aggragateMonitor.CreateTime = aggregate.CreateTime
				aggragateMonitor.AlertCount = alert.GetResourcePoolAlertNum(aggregate.Region, "", "resourcePool", "kec", aggregate.Name)

				//var hostList []cmdbmodel.HostsResult
				//从cmdb中获取服务器列表
				hostsResult, er := cmdbmanager.GetHostListByResourcePool(strconv.Itoa(aggregate.Id))
				hostList := hostsResult.Data.DataList
				if er != nil {
					return aggragateMonitorsResult, err
				}
				if len(hostList) > 0 {
					ips := ""
					for _, host := range hostList {
						//从CMDB中获取服务器ip
						ip, err := cmdbmanager.GetHostDetailByHostname(host.Name)
						if err == nil && ip != "" {
							if ips == "" {
								ips = ip + ":9100"
							} else {
								ips = ips + "|" + ip + ":9100"
							}
						}
					}
					if ips != "" {
						cpuTotal, _ := prometheusmanager.GetCpuTotal(ips, currentTime)
						cpuRate, err := prometheusmanager.GetCpuRate(ips, currentTime)
						if err != nil {
							return aggragateMonitorsResult, err
						}
						if len(cpuTotal.Result) > 0 && len(cpuRate.Result) > 0 {
							vcpuTotal, _ := strconv.Atoi(cpuTotal.Result[0].Value)
							aggragateMonitor.VcpuTotal = float64(vcpuTotal)
							vcpuRate, _ := strconv.ParseFloat(cpuRate.Result[0].Value, 64)
							aggragateMonitor.VcpuUtilizationRate = vcpuRate
							used := float64(vcpuTotal) * vcpuRate / 100
							aggragateMonitor.VcpuUsedTotal = services.Form2(used).(float64)
							aggragateMonitor.VcpuAvaiLable = services.Form2((aggragateMonitor.VcpuTotal) - aggragateMonitor.VcpuUsedTotal).(float64)
						}
						memoryTotal, _ := prometheusmanager.GetMemoryTotal(ips, currentTime)
						memoryRate, err := prometheusmanager.GetMemoryRate(ips, currentTime)
						if err != nil {
							return aggragateMonitorsResult, err
						}
						if len(memoryTotal.Result) > 0 && len(memoryRate.Result) > 0 {
							vmemoryTotal, _ := strconv.Atoi(memoryTotal.Result[0].Value)
							aggragateMonitor.MemTotal = float64(vmemoryTotal)
							vmemoryRate, _ := strconv.ParseFloat(memoryRate.Result[0].Value, 64)
							aggragateMonitor.MemUtilizationRate = vmemoryRate
							used := float64(vmemoryTotal) * vmemoryRate / 100
							aggragateMonitor.MemUsedTotal = services.Form2(used).(float64)
							aggragateMonitor.MemAvaiLable = aggragateMonitor.MemTotal - aggragateMonitor.MemUsedTotal
						}
						diskRate, err := prometheusmanager.GetDiskRate(ips, currentTime)
						if len(diskRate.Result) > 0 {
							vmdiskRate, _ := strconv.ParseFloat(diskRate.Result[0].Value, 64)
							aggragateMonitor.DiskUtilizationRate = vmdiskRate
						}
					}
				}
				aggragateMonitorsResult.DataList = append(aggragateMonitorsResult.DataList, aggragateMonitor)
			}

		}
	}

	//排序
	if l.OrderCode != "" && l.OrderType != "" {
		results := alert.Bucket{}
		for i := 0; i < len(aggragateMonitorsResult.DataList); i++ {
			results.Slice = append(results.Slice, aggragateMonitorsResult.DataList[i])
		}
		time_by := func(a, b interface{}) bool {
			return true
		}

		switch l.OrderCode {
		case "vcpuUtilizationRate":
			if l.OrderType != "" {
				switch l.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.AggragateMonitor).VcpuUtilizationRate < b.(resourcepoolmodel.AggragateMonitor).VcpuUtilizationRate
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.AggragateMonitor).VcpuUtilizationRate > b.(resourcepoolmodel.AggragateMonitor).VcpuUtilizationRate
					}
				}
			}
		case "memUtilizationRate":
			if l.OrderType != "" {
				switch l.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.AggragateMonitor).MemUtilizationRate < b.(resourcepoolmodel.AggragateMonitor).MemUtilizationRate
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.AggragateMonitor).MemUtilizationRate > b.(resourcepoolmodel.AggragateMonitor).MemUtilizationRate
					}
				}
			}
		case "diskUtilizationRate":
			if l.OrderType != "" {
				switch l.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.AggragateMonitor).DiskUtilizationRate < b.(resourcepoolmodel.AggragateMonitor).DiskUtilizationRate
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.AggragateMonitor).DiskUtilizationRate > b.(resourcepoolmodel.AggragateMonitor).DiskUtilizationRate
					}
				}
			}
		}

		results.By = time_by

		sort.Sort(results)
		for i := 0; i < len(aggragateMonitorsResult.DataList); i++ {
			aggragateMonitorsResult.DataList[i] = results.Slice[i].(resourcepoolmodel.AggragateMonitor)
		}
	}

	//分页
	low := (l.PageNo - 1) * l.PageSize
	if low > len(aggragateMonitorsResult.DataList) {
		klog.Error("page info error")
	}

	hight := low + l.PageSize
	if hight > len(aggragateMonitorsResult.DataList) {
		hight = len(aggragateMonitorsResult.DataList)
	}

	aggragateMonitorsResult.PageNo = l.PageNo
	aggragateMonitorsResult.PageSize = l.PageSize
	aggragateMonitorsResult.TotalCount = len(aggragateMonitorsResult.DataList)
	aggragateMonitorsResult.DataList = aggragateMonitorsResult.DataList[low:hight]

	return aggragateMonitorsResult, err
}

func (c *ComputerPoolService) GetComputerPoolOverview(l *resourcepoolmodel.ListQuery) (res resourcepoolmodel.OverView1, err error) {
	klog.Info("computer pool overview")
	var aggregates []cmdbmodel.ComputerPool

	//服务器监控状态
	severStatu := make([]resourcepoolmodel.StateType, 0, 2)
	UP := resourcepoolmodel.StateType{Prefix: "监控中", Unit: "个"}
	DOWN := resourcepoolmodel.StateType{Prefix: "监控异常", Unit: "个"}
	//告警数据
	alerts := make([]alertmanagermodel.OverviewAlert, 0, 4)

	if l.Region == "" {
		l.Region = "all"
	}
	az := []string{}
	if l.Az == "" || l.Az == "all" {
		az = []string{}
	} else {
		az = append(az, l.Az)
	}

	//获取计算资源池列表
	cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/computePool", "post")
	klog.Infof("aggregates_cmdbCount", cmdbCount)
	aggregatesResult, err := cmdbmanager.GetAggragateResourcePoolList(l.Region, az, "", "1", strconv.Itoa(cmdbCount))
	if err != nil {
		klog.Error(err)
	}
	aggregates = aggregatesResult.Data.DataList
	klog.Infof("aggregates_aggregatesResult_count", len(aggregates))

	for _, aggregate := range aggregates {
		var aggragateMonitor resourcepoolmodel.AggragateMonitor
		aggragateMonitor.Id = aggregate.Id
		aggragateMonitor.Name = aggregate.Name
		if l.Pool != "" && l.Pool != aggregate.Name {
			continue
		}
		//aggragateMonitor.Region = aggregate.Region
		//aggragateMonitor.Az = aggregate.Az
		//var hostList []cmdbmodel.HostsResult

		//从cmdb中获取服务器列表
		klog.Infof("aggregates_aggregate.Id", strconv.Itoa(aggregate.Id))
		hostsResult, er := cmdbmanager.GetHostListByResourcePool(strconv.Itoa(aggregate.Id))
		klog.Infof("aggregates_aggregatesResult_hostsResult", len(hostsResult.Data.DataList))
		hostList := hostsResult.Data.DataList
		if er != nil {
			klog.Error(er)
		}
		if len(hostList) > 0 {
			for _, host := range hostList {
				upQuery := servertemp.NewServerMetics(host.IP+":9100", "", 0).ToString("server_up")
				up, err := client.VectorQuery(upQuery)
				klog.Infof("aggregate.Id", strconv.Itoa(aggregate.Id), "host.name", host.Name, "host.IP", host.IP, "upup", up)
				if err != nil {
					klog.Info(err)
				}
				if len(up) > 0 {
					if math.IsNaN(float64(up[0].Value)) {
						up[0].Value = 0
					}
					if float64(up[0].Value) == 1 {
						UP.Number++
					} else {
						DOWN.Number++
					}
				}
			}
		}
	}
	// 获取计算资源池告警数据
	alertPpram := alertmanagermodel.AlertQuery{
		Module: "computer",
		Az:     az,
	}
	if l.Pool != "" {
		alertPpram.AlertInstance = l.Pool
	}
	//queryParam := alertmanagermodel.AlertQuery{
	//	Filter: "",
	//}
	alertList, err := alert.GetCommonAlertOverviewNum(alertPpram)
	if err != nil {
		return res, err
	}
	alerts = append(alerts, alertList...)
	severStatu = append(severStatu, DOWN, UP)
	res = resourcepoolmodel.OverView1{l.Region, l.Az, l.Pool, "", alerts, severStatu}

	return res, err
}

func buildCommonCondition(parameter *resourcepoolmodel.OverviewLineQuery, extConditions ...string) string {
	var conditions []string
	if len(extConditions) > 0 {
		conditions = append(conditions, extConditions...)
	}
	if parameter.Az != "" && parameter.Az != "all" {
		conditions = append(conditions, "az=\""+parameter.Az+"\"")
	}
	if parameter.Region != "" && parameter.Region != "all" {
		conditions = append(conditions, "region=\""+parameter.Region+"\"")
	}
	var conditionStr string
	if len(conditions) > 0 {
		conditionStr = strings.Join(conditions, ",")
	}
	return conditionStr
}

func (c *ComputerPoolService) GetComputerPoolOverviewLine(t *resourcepoolmodel.OverviewLineQuery) ([]resourcepoolmodel.OverViewLine, error) {
	start1 := strconv.FormatFloat(t.Start/1000, 'f', 3, 64)
	end1 := strconv.FormatFloat(t.End/1000, 'f', 3, 64)
	//end2 := strconv.FormatFloat(end1/1000.0, 'f', 3, 64)
	//t := services.FormatTime(end1 - start1)
	subString := buildCommonCondition(t)
	klog.Infof("subQuery :%s", subString)

	t.Step = services.TimeToStep(t.End/1000 - t.Start/1000)

	responseMetric := []resourcepoolmodel.OverViewLine{}
	for i := 0; i < len(t.Name); i++ {
		switch t.Name[i] {
		case "cpuPercent_old":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Unit: "%"}
			//query := fmt.Sprintf("aggregate_vcpu_used_rate{%s}", subString)
			query := temp.NewPoolMetics(subString, "", "").ToString("computer_pool_cpu_usage_rate")
			l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, query)

			for j := 0; j < len(l); j++ {
				rr := resourcepoolmodel.EchartType{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				rr.Info.Name = lll["lubanResourceName"].(string)
				rr.Info.UnitType = "percent"
				rr.Info.Unit = "%"

				vv := prom.PrometheusResultToValue2(l[j])
				rr.Values = services.RangeValueForForePercent(vv)

				r.Echarts = append(r.Echarts, rr)
			}
			responseMetric = append(responseMetric, r)

		case "cpuPercent":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Unit: "%"}
			az := []string{}
			if t.Az != "all" && t.Az != "" {
				az = append(az, t.Az)
			}
			aggregatesResult, _ := cmdbmanager.GetAggragateResourcePoolList(t.Region, az, "", "1", "1000")
			aggregates := aggregatesResult.Data.DataList
			if len(aggregates) > 0 {
				for _, aggregate := range aggregates {
					klog.Infof("aggregate.Name", aggregate.Name)
					ext := fmt.Sprintf("resourcePool= %s", "\""+aggregate.Name+"\"")
					label := buildCommonCondition(t, ext)
					query := temp.NewPoolMetics(label, "", "").ToString("computer_pool_cpu_rate")
					l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, query)
					if len(l) > 0 {
						rr := resourcepoolmodel.EchartType{}
						rr.Info.Name = aggregate.Name
						rr.Info.UnitType = "percent"
						rr.Info.Unit = "%"
						vv := prom.PrometheusResultToValue2(l[0])
						rr.Values = services.RangeValueForForePercent(vv)
						r.Echarts = append(r.Echarts, rr)
						//todo 旧代码
						////从cmdb中获取服务器列表
						//hostsResult, er := cmdbmanager.GetHostListByResourcePool(strconv.Itoa(aggregate.Id))
						//hostList := hostsResult.Data.DataList
						//if er != nil {
						//	continue
						//}
						//if len(hostList) > 0 {
						//	ips := ""
						//	for _, host := range hostList {
						//		//从CMDB中获取服务器ip
						//		ip, err := cmdbmanager.GetHostDetailByHostname(host.Name)
						//		if err == nil && ip != "" {
						//			if ips == "" {
						//				ips = ip + ":9100"
						//			} else {
						//				ips = ips + "|" + ip + ":9100"
						//			}
						//		}
						//	}
						//	//ips = "10.178.225.231:9100|10.178.224.211:9200"
						//	if ips != "" {
						//		ext := fmt.Sprintf("instance=~\"(%s)\"", ips)
						//		label := buildCommonCondition(t, ext)
						//		query := temp.NewPoolMetics(label, "", "").ToString("computer_pool_cpu_rate")
						//		l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, query)
						//		if len(l) > 0 {
						//			rr := resourcepoolmodel.EchartType{}
						//			rr.Info.Name = aggregate.Name
						//			rr.Info.UnitType = "percent"
						//			rr.Info.Unit = "%"
						//
						//			vv := prom.PrometheusResultToValue2(l[0])
						//			rr.Values = services.RangeValueForForePercent(vv)
						//
						//			r.Echarts = append(r.Echarts, rr)
						//		}
						//	}
						//}
					}
				}
			}
			responseMetric = append(responseMetric, r)
		case "memPercent":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Unit: "%"}
			az := []string{}
			if t.Az != "all" && t.Az != "" {
				az = append(az, t.Az)
			}
			aggregatesResult, _ := cmdbmanager.GetAggragateResourcePoolList(t.Region, az, "", "1", "1000")
			aggregates := aggregatesResult.Data.DataList
			if len(aggregates) > 0 {
				for _, aggregate := range aggregates {
					ext := fmt.Sprintf("resourcePool= %s", "\""+aggregate.Name+"\"")
					label := buildCommonCondition(t, ext)
					query := temp.NewPoolMetics(label, "", "").ToString("computer_pool_mem_rate")
					fmt.Println("computer_pool_mem_rate_query", query)
					l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, query)
					if len(l) > 0 {
						rr := resourcepoolmodel.EchartType{}
						rr.Info.Name = aggregate.Name
						rr.Info.UnitType = "percent"
						rr.Info.Unit = "%"
						vv := prom.PrometheusResultToValue2(l[0])
						rr.Values = services.RangeValueForForePercent(vv)
						r.Echarts = append(r.Echarts, rr)
					}
				}
			}
			responseMetric = append(responseMetric, r)
			//r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Unit: "%"}
			////query := fmt.Sprintf("aggregate_memory_used_rate{%s}", subString)
			//query := temp.NewPoolMetics(subString, "", "").ToString("computer_pool_memory_usage_rate")
			//l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, query)
			//
			//for j := 0; j < len(l); j++ {
			//	rr := resourcepoolmodel.EchartType{}
			//
			//	ll := l[j].(map[string]interface{})
			//	lll := ll["metric"].(map[string]interface{})
			//
			//	rr.Info.Name = lll["lubanResourceName"].(string)
			//	rr.Info.UnitType = "percent"
			//	rr.Info.Unit = "%"
			//
			//	vv := prom.PrometheusResultToValue2(l[j])
			//	rr.Values = services.RangeValueForForePercent(vv)
			//
			//	r.Echarts = append(r.Echarts, rr)
			//}
			//responseMetric = append(responseMetric, r)
		case "diskPercent":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Unit: "%"}
			az := []string{}
			if t.Az != "all" && t.Az != "" {
				az = append(az, t.Az)
			}
			aggregatesResult, _ := cmdbmanager.GetAggragateResourcePoolList(t.Region, az, "", "1", "1000")
			aggregates := aggregatesResult.Data.DataList
			if len(aggregates) > 0 {
				for _, aggregate := range aggregates {
					ext := fmt.Sprintf("resourcePool= %s", "\""+aggregate.Name+"\"")
					label := buildCommonCondition(t, ext)
					query := temp.NewPoolMetics(label, "", "").ToString("computer_pool_disk_rate")
					fmt.Println("queryqueryquery", query)
					l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, query)
					if len(l) > 0 {
						rr := resourcepoolmodel.EchartType{}
						rr.Info.Name = aggregate.Name
						rr.Info.UnitType = "percent"
						rr.Info.Unit = "%"
						vv := prom.PrometheusResultToValue2(l[0])
						rr.Values = services.RangeValueForForePercent(vv)
						r.Echarts = append(r.Echarts, rr)
					}
				}
			}
			responseMetric = append(responseMetric, r)
		case "cpuStock":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Unit: "核"}
			//query := fmt.Sprintf("aggregate_vcpu_remain_count{%s}", subString)
			query := temp.NewPoolMetics(subString, "", "").ToString("computer_pool_vcpu_stock")
			l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, query)

			for j := 0; j < len(l); j++ {
				rr := resourcepoolmodel.EchartType{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				rr.Info.Name = lll["lubanResourceName"].(string)
				rr.Info.UnitType = "number"
				rr.Info.Unit = "核"

				vv := prom.PrometheusResultToValue2(l[j])
				rr.Values = services.PromeForRangeValue2(vv)

				r.Echarts = append(r.Echarts, rr)
			}
			responseMetric = append(responseMetric, r)
		case "memStock":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i]}
			//query := fmt.Sprintf("aggregate_memory_remain_count{%s}", subString)
			query := temp.NewPoolMetics(subString, "", "").ToString("computer_pool_memory_stock")
			l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, query)

			for j := 0; j < len(l); j++ {
				rr := resourcepoolmodel.EchartType{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				rr.Info.Name = lll["lubanResourceName"].(string)
				//rr.Info.Name = "内存库存"
				//rr.Info.UnitType = "storage"
				rr.Info.Unit = "GB"

				vv := prom.PrometheusResultToValue2(l[j])
				rr.Values = services.PromeForRangeValue2(vv)

				r.Echarts = append(r.Echarts, rr)
			}
			responseMetric = append(responseMetric, r)
		}
	}
	return responseMetric, nil
}
func GetCMDBOverView(aggragateListQuery resourcepoolmodel.CMDBOverViewQuery) (resourcepoolmodel.CMDBAggregateOverview, error) {
	//从CMDB中获取资源池信息
	var aggregateOverview resourcepoolmodel.CMDBAggregateOverview
	var aggregates []cmdbmodel.ComputerPool
	var aggregatesResult cmdbmodel.ComputerPoolResult
	// aggregateRegion := config.RegionMap[aggragateListQuery.Region]
	// aggregateAz := config.RegionMap[aggragateListQuery.Az]
	azList := []string{}
	if aggragateListQuery.Az != "" && aggragateListQuery.Az != "all" {
		azList = append(azList, aggragateListQuery.Az)
	}
	aggregatesResult, err := cmdbmanager.GetAggragateResourcePoolList(aggragateListQuery.Region, azList, "", "1", "10000")

	//aggregatesForCount, err := cmdbmanager.GetResourcePoolList(aggragateListQuery.Region, aggragateListQuery.Az, aggragateListQuery.Name, strconv.Itoa(aggragateListQuery.PageNo), "10000")
	if err != nil {
		return aggregateOverview, err
	}
	aggregates = aggregatesResult.Data.DataList
	currentTime := time.Now()
	if len(aggregates) > 0 {
		for _, aggregate := range aggregates {
			cpuRate := "0.00"
			memRate := "0.00"
			diskRate := "0.00"
			vmCount := aggregate.VMCount

			var aggragateMonitor resourcepoolmodel.AggragateMonitor
			aggragateMonitor.Id = aggregate.Id
			aggragateMonitor.Name = aggregate.Name
			aggragateMonitor.Region = aggregate.Region
			aggragateMonitor.Az = aggregate.Az
			aggragateMonitor.HostCount = aggregate.HostCount
			aggragateMonitor.VmCount = aggregate.VMCount
			//var hostList []cmdbmodel.Host
			//从cmdb中获取服务器列表
			//hostList, err = cmdbmanager.GetHostListByResourcePool(strconv.Itoa(aggregate.Id))
			hostsResult, err := cmdbmanager.GetHostListByResourcePool(strconv.Itoa(aggregate.Id))
			hostList := hostsResult.Data.DataList
			if err != nil {
				klog.Error(err)
			}
			if len(hostList) > 0 {
				ips := ""
				for _, host := range hostList {
					//从CMDB中获取服务器ip
					ip, err := cmdbmanager.GetHostDetailByHostname(host.Name)
					if err == nil && ip != "" {
						if ips == "" {
							ips = ip + ":9100"
						} else {
							ips = ips + "|" + ip + ":9100"
						}
					}
				}
				if ips != "" {
					cpuRateR, err := prometheusmanager.GetCpuRate(ips, currentTime)
					if err != nil {
						return aggregateOverview, err
					}
					if len(cpuRateR.Result) > 0 {
						cpuRateResult, _ := strconv.ParseFloat(cpuRateR.Result[0].Value, 64)
						cpuRate = services.Strval(cpuRateResult)
					}
					memoryRateR, err := prometheusmanager.GetMemoryRate(ips, currentTime)
					if err != nil {
						return aggregateOverview, err
					}
					if len(memoryRateR.Result) > 0 {
						memoryRateResult, _ := strconv.ParseFloat(memoryRateR.Result[0].Value, 64)
						memRate = services.Strval(memoryRateResult)
					}
					diskRateR, err := prometheusmanager.GetDiskRate(ips, currentTime)
					if err != nil {
						return aggregateOverview, err
					}
					if len(diskRateR.Result) > 0 {
						diskRateResult, _ := strconv.ParseFloat(diskRateR.Result[0].Value, 64)
						diskRate = services.Strval(diskRateResult)
					}
				}
			}
			aggregateOverview.CpuRate = append(aggregateOverview.CpuRate, resourcepoolmodel.DistributedOverView{
				Name: aggregate.Name,
				Id:   aggregate.Id,
				Distributed: []resourcepoolmodel.OverView{
					{
						Name:  "",
						Code:  "",
						Value: cpuRate,
					},
				},
			})
			aggregateOverview.MemaryRate = append(aggregateOverview.MemaryRate, resourcepoolmodel.DistributedOverView{
				Name: aggregate.Name,
				Id:   aggregate.Id,
				Distributed: []resourcepoolmodel.OverView{
					{
						Name:  "",
						Code:  "",
						Value: memRate,
					},
				},
			})
			aggregateOverview.DiskRate = append(aggregateOverview.DiskRate, resourcepoolmodel.DistributedOverView{
				Name: aggregate.Name,
				Id:   aggregate.Id,
				Distributed: []resourcepoolmodel.OverView{
					{
						Name:  "",
						Code:  "",
						Value: diskRate,
					},
				},
			})
			aggregateOverview.InstanceOverview = append(aggregateOverview.InstanceOverview, resourcepoolmodel.OverView{
				Name:  aggregate.Name,
				Value: vmCount,
			})
		}

	}
	return aggregateOverview, err
}

func (c *ComputerPoolService) GetComputerPoolMetric(monitorTargetListQuery *resourcepoolmodel.MonitorTargetListQuery) ([]resourcepoolmodel.LineDataResult, error) {
	klog.Info("computer_pool_metric")
	//var hostList []cmdbmodel.Host
	//responseMetric := []prometheusModel.ResponseMetric{}
	lineDataResultList := []resourcepoolmodel.LineDataResult{}
	//从cmdb中获取服务器列表
	//hostList, err := cmdbmanager.GetHostListByResourcePool(strconv.Itoa(monitorTargetListQuery.Id))
	hostsResult, er := cmdbmanager.GetHostListByResourcePool(strconv.Itoa(monitorTargetListQuery.Id))
	hostList := hostsResult.Data.DataList
	if er != nil {
		klog.Error(er)
	}
	if len(hostList) > 0 {
		//ips := ""
		for _, host := range hostList {
			lineDataResult := resourcepoolmodel.LineDataResult{}
			lineDataResult.HostName = host.Name
			//从CMDB中获取服务器ip
			ip, err := cmdbmanager.GetHostDetailByHostname(host.Name)
			if err == nil && ip != "" {
				start, err := strconv.ParseFloat(monitorTargetListQuery.Start, 64)
				if err != nil {
					klog.Error(err)
				}
				end, err := strconv.ParseFloat(monitorTargetListQuery.End, 64)
				if err != nil {
					klog.Error(err)
				}
				step := services.TimeToStep(end - start)
				memoryTotal := prometheusmanager.QueryPhsicalMetric(ip, monitorTargetListQuery.Start, monitorTargetListQuery.End, step, monitorTargetListQuery.Qs)

				lineDataResult.Values = PrometheusResultToValue(memoryTotal[0].Value)

				lineDataResultList = append(lineDataResultList, lineDataResult)

			}
		}

	}
	return lineDataResultList, er

}

func PrometheusResultToValue(r interface{}) interface{} {
	var s interface{}
	if valu, ok := r.(map[string]interface{}); ok {

		if resultData, ok := valu["result"]; ok {
			result := resultData.([]interface{})
			if len(result) > 0 {
				resultForValue := result[0].(map[string]interface{})
				if valueData, ok := resultForValue["values"]; ok {
					return valueData
				}
				if valueData, ok := resultForValue["value"]; ok {
					return valueData
				}
			}
		}
	}

	return s
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/resourcepool/networkservice.go
```golang
package resourcepoolservice

import (
	"errors"
	"fmt"
	"math"
	"strconv"
	"strings"
	"time"

	v1 "github.com/prometheus/client_golang/api/prometheus/v1"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	cmdb "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	cmdbmanager "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/network"
	servertemp "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/physicalServer"
	"k8s.io/klog/v2"
)

var clusterTypeNames = map[string]string{
	"XGW":     "XGW集群",
	"Tengine": "Tengine集群",
	"SGW":     "SGW集群",
	"NAT":     "NAT集群",
	"KGW":     "KGW集群",
	"PGW":     "PGW集群",
	"TGW":     "TGW集群",
}
var clusterTypes = [7]string{"XGW", "Tengine", "SGW", "NAT", "KGW", "PGW", "TGW"}

type INetworkPoolService interface {
	Overview(query *resourcepoolmodel.NetworkOverviewQuery) (resourcepoolmodel.OverViewData, error)
	OverviewLine(query *resourcepoolmodel.NetworkOverviewLineQuery) (resourcepoolmodel.NetLineData, error)
	NetworkList(query *resourcepoolmodel.NetworkListQuery) (resourcepoolmodel.NetworkListPage, error)
	NetworkUsage(query *resourcepoolmodel.NetWorkUsageQuery) (resourcepoolmodel.NetworkUsagePage, error)
	NetworkMetricDetail(query *resourcepoolmodel.NetworkDetailQuery) ([]resourcepoolmodel.PoolDetailData, error)
	NetworkMetricDetailSort(query *resourcepoolmodel.NetworkDetailQuery) ([]resourcepoolmodel.PoolDetailData, error)
	NetworkMetricTopLine(query *resourcepoolmodel.NetworkDetailQuery) ([]resourcepoolmodel.PoolDetailData, error)
}

type NetworkPoolService struct {
}

func NewNetworkPoolService() *NetworkPoolService {
	return &NetworkPoolService{}
}

// 获取网络资源池监控概览
func (c *NetworkPoolService) Overview(query *resourcepoolmodel.NetworkOverviewQuery) (resourcepoolmodel.OverViewData, error) {
	res := resourcepoolmodel.OverViewData{}

	alerts, _ := getNetAlerts(query)
	echarts, _ := getNetworkEcharts(query)
	res.Alerts = alerts
	res.Echarts = echarts
	return res, nil

}

func (c *NetworkPoolService) OverviewLine(query *resourcepoolmodel.NetworkOverviewLineQuery) (resourcepoolmodel.NetLineData, error) {
	res := resourcepoolmodel.NetLineData{}
	poolList := getNetworkPoolAll(query.Region, query.PoolType)
	klog.Infof("network OverviewLine DEBUG 1: %+v", poolList)
	for _, name := range query.Name {
		switch name {
		case "cpuRate": // cpu
			res, err := GetNetworkRate(query, poolList, "cpuRate", "node_cpu_seconds_total")
			if err != nil {
				klog.Infof("network OverviewLine DEBUG 3: %+v", poolList)
				klog.Infof("资源池获取cpuRate失败")
			}
			return res, nil
		case "memRate": // 内存
			res, err := GetNetworkRate(query, poolList, "memRate", "node_memory_emAvailable_bytes")
			if err != nil {
				klog.Infof("资源池获取memRate失败")
			}
			return res, nil
		case "diskRate": // 磁盘
			res, err := GetNetworkRate(query, poolList, "diskRate", "node_filesystem_free_bytes")
			if err != nil {
				klog.Infof("资源池获取diskRate失败")
			}
			return res, nil
		}
	}
	return res, nil

}

// 获取网络资源池监控列表
func (c *NetworkPoolService) NetworkList(query *resourcepoolmodel.NetworkListQuery) (res resourcepoolmodel.NetworkListPage, err error) {

	//默认为LB(负载均衡)；LB：负载均衡，EIP：弹性IP，NAT：NAT，BM：裸金属，SL：专线
	if query.IndexType == "" {
		return res, errors.New("Indextype is required")
	}
	pageSize := int(^uint16(0))
	cmdbParam := &cmdbmanager.NetworkPoolListPost{
		RegionCode: query.Region,
		PageNo:     1,
		PageSize:   pageSize,
		Type:       query.IndexType,
		PoolType:   query.PoolType,
		PoolName:   query.PoolName,
		OrderType:  query.OrderType,
		//OrderCode: query.OrderCode,
	}
	poolResult, err := cmdb.GetNetworkPoolList(cmdbParam) // 获取网络资源池列表
	if err != nil {
		klog.Infof("get cmdb.GetNetworkPoolList fail err: %s", err)
		return
	}
	if len(poolResult.Data) == 0 {
		klog.Info("get cmdb.GetNetworkPoolList is empty")
		return
	}
	dataList := make([]resourcepoolmodel.NetworkList, 0)

	const limit = int(^uint16(0))

	for _, v := range poolResult.Data {
		info := resourcepoolmodel.NetworkList{}
		info.PoolName = v.PoolName
		info.PoolType = v.PoolType
		info.RegionCode = v.RegionCode
		info.RegionName = v.RegionName
		info.ServerCount = v.ServerCount
		info.LbCount = v.LBCount     //负载均衡数量
		info.EipCount = v.EipCount   // 弹性ip数量
		info.NatCount = v.NatCount   // NAT 数量
		info.CreatedAt = v.CreatedAt //  创建时间
		info.BMCount = v.BmCount     //裸金属 数量
		info.SLCount = v.SLCount     // 专线 数据
		info.P2pCount = v.P2pCount   // 对等连接数
		info.VPNCount = v.VPNCount   // Vpn 连接数

		phsicalServerReq := &cmdbmanager.NetworkPoolListPost{
			RegionCode: query.Region,
			PoolName:   v.PoolName,
			PageNo:     1,
			PageSize:   limit,
		}

		serverResult, err := cmdbmanager.GetNetworkPhsicalServers(phsicalServerReq) // 获取网络资源池下服务器信息

		ipList := make([]string, 0)
		if err != nil {
			continue
		}
		for _, server := range serverResult.Data.DataList {
			ipList = append(ipList, server.Ip)
		}

		if len(ipList) > 0 {
			cpuRate := NetworkLitsRate(query.Region, v.PoolType, "node_cpu_seconds_total", ipList)
			memorRate := NetworkLitsRate(query.Region, v.PoolType, "node_memory_emAvailable_bytes", ipList)
			diskRate := NetworkLitsRate(query.Region, v.PoolType, "node_filesystem_free_bytes", ipList)

			info.CPUUsedPercent = cpuRate
			info.MemoryUsedPercent = memorRate
			info.DiskUsedPercent = diskRate
		}

		dataList = append(dataList, info)
	}

	res.TotalCount = len(dataList)
	res.PageNo = 1
	res.PageSize = len(dataList)
	res.DataList = dataList

	return res, nil

}

// 获取网络资源池库存列表
func (c *NetworkPoolService) NetworkUsage(query *resourcepoolmodel.NetWorkUsageQuery) (res resourcepoolmodel.NetworkUsagePage, err error) {
	cmdbQuery := cmdbmodel.NetWorkUsageQuery{
		RegionCode: query.RegionCode,
		PageNo:     query.PageNo,
		PageSize:   query.PageSize,
	}
	usageResult, err := cmdb.GetNetworkPoolUsage(cmdbQuery)
	if err != nil {
		klog.Infof("get cmdb.GetNetworkPoolList fail err: %s", err)
		return
	}
	res.PageSize = query.PageSize
	res.PageNo = query.PageNo
	res.TotalCount = usageResult.Data.Total

	poolTypeServerMap := getPoolTypeServerMap(query.RegionCode)
	dataList := make([]resourcepoolmodel.NetWorkInventory, 0)
	for _, v := range usageResult.Data.Result {
		data := resourcepoolmodel.NetWorkInventory{}
		data.RegionCode = v.RegionCode
		data.RegionName = v.RegionName
		data.PoolType = v.PoolType
		data.WayType = v.WayType
		data.Cidr = v.Cidr
		data.IpCount = v.IpCount
		data.IpUsedCount = v.IpUsedCount
		data.IpValidCount = v.IpValidCount
		data.IpRemindCount = v.IpRemindCount
		data.IpUsedRatio = v.IpUsedRatio
		data.IpAvailableRatio = v.IpAvailableRatio
		data.CpuTotal = v.CpuTotal
		data.CpuUsedRatio = NetworkLitsRate(v.RegionCode, v.PoolType, "node_cpu_seconds_total", getServerIp(poolTypeServerMap, v.RegionCode, v.PoolType)) / 100
		data.MemTotal = v.MemTotal
		data.MemUsedRatio = NetworkLitsRate(v.RegionCode, v.PoolType, "node_memory_emAvailable_bytes", getServerIp(poolTypeServerMap, v.RegionCode, v.PoolType)) / 100
		dataList = append(dataList, data)
	}
	res.DataList = dataList
	return
}

func getPoolTypeServerMap(regionCode string) map[string][]cmdbmodel.PhysicalHostData {
	resultMap := make(map[string][]cmdbmodel.PhysicalHostData)
	for _, v := range clusterTypes {
		resultMap[v] = make([]cmdbmodel.PhysicalHostData, 0)
	}

	const limit = int(^uint16(0))
	cmdbParam := &cmdbmanager.NetworkPoolListPost{
		PageNo:   1,
		PageSize: limit,
	}

	poolList := getNetworkPoolAll(regionCode, "")
	if len(poolList) > 0 {
		for _, pool := range poolList {
			cmdbParam.PoolName = pool.PoolName
			cmdbParam.RegionCode = pool.RegionCode
			hostsResult, err := cmdbmanager.GetNetworkPhsicalServers(cmdbParam)
			if err != nil {
				continue
			}
			for _, server := range hostsResult.Data.DataList {
				if !isExist(resultMap[pool.PoolType], server) {
					resultMap[pool.PoolType] = append(resultMap[pool.PoolType], server)
				}
			}
		}
	}
	return resultMap
}

func isExist(servers []cmdbmodel.PhysicalHostData, server cmdbmodel.PhysicalHostData) bool {
	for _, eachServer := range servers {
		if eachServer == server {
			return true
		}
	}
	return false
}

func getServerIp(serverMap map[string][]cmdbmodel.PhysicalHostData, regionCode, poolType string) []string {
	ipList := make([]string, 0)
	serverList := serverMap[poolType]
	for _, server := range serverList {
		if regionCode == server.HostRegionCode {
			ipList = append(ipList, server.Ip)
		}
	}
	return ipList
}

// 获取网络资源池监控指标详情
func (c *NetworkPoolService) NetworkMetricDetail(query *resourcepoolmodel.NetworkDetailQuery) (res []resourcepoolmodel.PoolDetailData, err error) {

	if query.PoolName == "" || query.PoolType == "" || query.Region == "" || query.MetricName == "" || query.Start <= 0 || query.End <= 0 {
		klog.Errorf("Required parameter is missing! Query: %+v", query)
		return nil, errors.New("Invalid request! Required parameter is missing or wrong.")
	}
	metricName := query.MetricName

	_, err = getMetricPromQL(metricName)
	if err != nil {
		klog.Errorf("get metric %s fail! err: %s", metricName, err)
		return
	}

	switch metricName {
	case cluster_netstat_Tcp_CurrEstab: //lab eip  总活动连接数
		clusterConnInfo, err := getMetricInfo(metricName)
		if err != nil {
			klog.Errorf("get %s info fail! err: %s", metricName, err)
			return nil, err
		}

		res, err = getClusterDetailMetricValue(query, &clusterConnInfo, metricName, metricPromQLMap[metricName])
		if err != nil {
			klog.Errorf("get %s value fail! err: %s", metricName, err)
			return nil, err
		}
	case
		node_netstat_Tcp_CurrEstab, //lab eip 节点实例连接数
		node_network_pps,           // pps
		node_network_bps,           //bps
		node_cpu_used_rate,         // cpu使用率
		node_memory_used_bytes,     //内存使用量
		node_memory_used_rate,      // 内存使用率
		node_filesystem_used_bytes, //磁盘使用量
		node_filesystem_used_rate:  //磁盘使用率
		nodeMetricInfo, err := getMetricInfo(metricName)
		if err != nil {
			klog.Errorf("get %s info fail! err: %s", metricName, err)
			return nil, err
		}
		res, err = getDetailMetricValue(query, &nodeMetricInfo, metricName, metricPromQLMap[metricName])
		if err != nil {
			klog.Errorf("get %s value fail! err: %s", metricName, err)
			return nil, err
		}

	default:
		err = errors.New("metricName key not in NetworkMetricDetail metricMap")
		klog.Errorf("get metricName[%v] fail by NetworkMetricDetail! err: %v", metricName, err)
		return nil, err
	}
	return
}

func (c *NetworkPoolService) NetworkMetricDetailSort(query *resourcepoolmodel.NetworkDetailQuery) (res []resourcepoolmodel.PoolDetailData, err error) {
	if query.PoolName == "" || query.PoolType == "" || query.Region == "" || query.Hostname == "" || query.TopK <= 0 || query.MetricName == "" || query.Start <= 0 || query.End <= 0 {
		klog.Errorf("Required parameter is missing! Query: %+v", query)
		return nil, errors.New("Invalid request! Required parameter is missing or wrong.")
	}
	metricName := query.MetricName

	_, err = getMetricPromQL(metricName)
	if err != nil {
		klog.Errorf("get metric %s fail! err: %s", metricName, err)
		return nil, err
	}

	switch metricName {
	case
		node_xgw_slb_traffic_topK,             //节点负载均衡流量排序
		node_xgw_eip_traffic_topK,             //节点弹性IP流量排序
		node_nat_traffic_topK,                 //节点NAT流量排序
		node_tengine_slb_traffic_topK,         //节点负载均衡流量排序
		node_sgw_public_traffic_topK,          //节点公网弹性IP流量排序
		node_xgw_slb_conns_topK,               //节点SLB实例连接数排序
		node_tengine_slb_conns_topK,           //节点SLB实例连接数排
		node_sgw_public_drop_packet_rate_topK: //节点公网弹性IP丢包率排序
		nodeMetricSortInfo, err := getMetricInfo(metricName)
		if err != nil {
			klog.Errorf("get %s info fail! err: %s", metricName, err)
			return nil, err
		}
		res, err = getDetailMetricSortValue(query, &nodeMetricSortInfo, metricName, metricPromQLMap[metricName])
		if err != nil {
			klog.Errorf("get %s value fail! err: %s", metricName, err)
			return nil, err
		}
	default:
		err = errors.New("metricName key not in NetworkMetricDetailSort metricMap")
		klog.Errorf("get metricName[%v] fail by NetworkMetricDetailSort! err: %v", metricName, err)
		return nil, err
	}
	return
}

// 获取网络资源池监控top折线图
func (c *NetworkPoolService) NetworkMetricTopLine(query *resourcepoolmodel.NetworkDetailQuery) (res []resourcepoolmodel.PoolDetailData, err error) {

	metricName := query.MetricName
	_, err = getmetricTopLinePromQLMap(metricName)
	if err != nil {
		klog.Errorf("get getmetricTopLinePromQLMap %s fail! err: %s", metricName, err)
		return
	}

	pSql := metricTopLinePromQLMap[metricName]
	start := query.Start / 1e3
	end := query.End / 1e3
	duration := end - start
	step := services.TimeToStepForInt(end - start)

	if start >= end {
		return nil, errors.New("Start time greater than end time!")
	}
	// 构造 top label
	topLabel := NetworkDetailSortBuildCommonCondition(&resourcepoolmodel.PoolDetailLabel{
		HostName: query.Hostname,
	})
	klog.Infof("topLabel: %s\n", topLabel)

	//获取top数据
	fmt.Println("pSql", pSql[0])
	topRes, err := client.VectorQuery(network.NewNetworkMeticsSort(topLabel, query.TopK, duration).ToString(pSql[0]))

	if res != nil {
		klog.Infof("get node_tgw_lpeer_bytes_in_topk  err : %s\n", err)
	}

	for _, v := range topRes {
		var lineLabel string
		poolDetailData := resourcepoolmodel.PoolDetailData{}
		poolDetailData.Info.Unit = metricInfoMap[metricName].Unit
		poolDetailData.Info.UnitType = metricInfoMap[metricName].UnitType

		switch metricName {
		case "slbConns", "slbTrafficIn", "slbTrafficOut", "tengineSlbConns", "tengineSlbTrafficIn", "tengineSlbTrafficOut": //slbConns/tengineSlbConns 节点SLB实例连接数 slbTraffic节点负载均衡流量
			poolDetailData.Info.Name = string(v.Metric["ip"]) + "_" + string(v.Metric["port"])
			lineLabel = NetworkDetailBuildCommonCondition(&resourcepoolmodel.PoolDetailLabel{
				HostName: query.Hostname,
				IP:       string(v.Metric["ip"]),
				Port:     string(v.Metric["port"]),
			})
		case "eipTrafficIn", "eipTrafficOut": //节点弹性IP流量
			poolDetailData.Info.Name = string(v.Metric["eip"])
			lineLabel = NetworkDetailBuildCommonCondition(&resourcepoolmodel.PoolDetailLabel{
				HostName: query.Hostname,
				Eip:      string(v.Metric["eip"]),
			})
		case "natTrafficIn", "natTrafficOut": //节点NAT流量
			poolDetailData.Info.Name = string(v.Metric["vni"])
			lineLabel = NetworkDetailBuildCommonCondition(&resourcepoolmodel.PoolDetailLabel{
				HostName: query.Hostname,
				Vni:      string(v.Metric["vni"]),
			})
		case "tgwLpeerBytesIn", "tgwLpeerBytesOut", "tgwDcytesIn", "tgwDcBytesOut", "tgwVpnBytesIn", "tgwVpnBytesOut":
			poolDetailData.Info.Name = string(v.Metric["domain"]) + "_" + string(v.Metric["vni"]) // 悬浮出来是domain_vni
			lineLabel = NetworkDetailBuildCommonCondition(&resourcepoolmodel.PoolDetailLabel{
				HostName: query.Hostname,
				Vni:      string(v.Metric["vni"]),
				Domain:   string(v.Metric["domain"]),
				Tgwtype:  string(v.Metric["tgwtype"]),
			})
		case "sgwPublicDropPacketRateIn", "sgwPublicDropPacketRateOut", "sgwPublicEipTrafficIn", "sgwPublicEipTrafficOut": //sgw节点公网弹性IP流量 丢包率
			poolDetailData.Info.Name = string(v.Metric["ip"])
			lineLabel = NetworkDetailBuildCommonCondition(&resourcepoolmodel.PoolDetailLabel{
				HostName: query.Hostname,
				IP:       string(v.Metric["ip"]),
			})
		}
		klog.Infof(" lineLabel: %s\n", lineLabel)
		// 根据label获取数据
		values, err := client.MatrixQuery(network.NewNetworkMetics(lineLabel).ToString(pSql[1]), v1.Range{
			Start: time.Unix(start, 0),
			End:   time.Unix(end, 0),
			Step:  time.Duration(step) * time.Second,
		})
		if err != nil {
			klog.Infof("get values err ", err)
		}
		// 实际数据
		detailValues := []services.ValueType{}
		for _, i := range values {
			for _, j := range i.Values {
				timeStr := time.Unix(j.Timestamp.Unix(), 0).Format("2006-01-02 15:04:05")
				value := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: services.FormPercent(j.Value.String()), IsForecast: false, Day: timeStr}
				detailValues = append(detailValues, value)
			}
		}
		poolDetailData.Values = detailValues
		res = append(res, poolDetailData)
	}

	return
}

func getDetailMetricSortValue(query *resourcepoolmodel.NetworkDetailQuery, metricInfo *resourcepoolmodel.MetricInfo, metricName, promQl string) (res []resourcepoolmodel.PoolDetailData, err error) {

	start := query.Start / 1e3
	end := query.End / 1e3
	if start >= end {
		return nil, errors.New("Start time greater than end time!")
	}
	duration := end - start

	// 构造 label
	poolDetailLabel := resourcepoolmodel.PoolDetailLabel{
		HostName: query.Hostname,
	}
	label := NetworkDetailSortBuildCommonCondition(&poolDetailLabel)
	klog.Infof("Detail label: %s\n", label)

	// 根据label获取数据
	values, err := client.VectorQuery(network.NewNetworkMeticsSort(label, query.TopK, duration).ToString(promQl))

	if err != nil {
		klog.Errorf("Failed to get %s value of %s, err: %s\n", metricName, query.Hostname, err.Error())
		return
	}
	klog.Infof("VectorQuery result of node[%v]: %v\n", query.Hostname, values)

	metricInfo.Name = query.Hostname
	poolDetailData := resourcepoolmodel.PoolDetailData{}
	poolDetailData.Info = *metricInfo

	// 实际数据
	detailValues := []services.ValueType{}
	for _, i := range values {
		var instanceName string
		var ipStr string

		if eipIns, ok := i.Metric["eip"]; ok { // 有eip取eip
			ipStr = string(eipIns)
		} else if ipIns, ok := i.Metric["ip"]; ok { // 有ip取ip
			ipStr = string(ipIns)
		} else if vni, ok := i.Metric["vni"]; ok { // 有vni取vni
			ipStr = string(vni)
		} else {
			klog.Errorf("get eipInstanceName fail from %v! eip or ip tag that in got metric value is missing.", i)
		}

		// 获取eip信息
		eipInfo, err := cmdb.GetEipDetail(ipStr)
		if err != nil {
			klog.Errorf("get eipInfo of %q fail! err: %s", ipStr, err)
		}

		if eipInfo.Data.Name == "" {
			instanceName = ipStr
		} else {
			instanceName = eipInfo.Data.Name
		}

		timeStr := time.Unix(i.Timestamp.Unix(), 0).Format("2006-01-02 15:04:05")
		value := services.ValueType{Name: instanceName, TimeSteamp: i.Timestamp.String(), Value: services.FormPercent(i.Value.String()), IsForecast: false, Day: timeStr}
		detailValues = append(detailValues, value)
	}
	poolDetailData.Values = detailValues
	res = append(res, poolDetailData)
	return
}

func getDetailMetricValue(query *resourcepoolmodel.NetworkDetailQuery, metricInfo *resourcepoolmodel.MetricInfo, metricName, promQl string) (res []resourcepoolmodel.PoolDetailData, err error) {

	start := query.Start / 1e3
	end := query.End / 1e3
	if start >= end {
		return nil, errors.New("Start time greater than end time!")
	}
	step := services.TimeToStepForInt(end - start)
	klog.Infof("start: %v; end: %v; step: %v \n", query.Start/1e3, query.End/1e3, step)

	pageSize := int(^uint16(0))

	//获取网络资源池下的服务器列表
	cmdbParam := &cmdbmanager.NetworkPoolListPost{
		RegionCode: query.Region,
		PageNo:     1,
		PageSize:   pageSize,
		PoolName:   query.PoolName,
	}

	physicalListResult, err := cmdb.GetNetworkPhsicalServers(cmdbParam)

	if err != nil {
		klog.Infof("get hosts from cmdb.GetNetworkPhsicalServers fail! err: %s \n", err)
		return
	}

	if len(physicalListResult.Data.DataList) == 0 {
		klog.Info("hosts got from cmdb.GetNetworkPhsicalServers is empty!")
		return
	}

	for _, hostdata := range physicalListResult.Data.DataList {
		metricInfo.Name = hostdata.Name
		poolDetailData := resourcepoolmodel.PoolDetailData{}
		poolDetailData.Info = *metricInfo
		// 构造 label
		poolDetailLabel := resourcepoolmodel.PoolDetailLabel{
			Region:           query.Region,
			ResourcePoolType: strings.ToLower(query.PoolType),
			ResourcePool:     strings.ToLower(query.PoolName),
			AZ:               hostdata.HostAzCode,
			HostName:         hostdata.Name,
			Instance:         hostdata.Ip,
		}
		fmt.Printf("poolDetailLabel %+v", poolDetailLabel)
		label := NetworkDetailBuildCommonCondition(&poolDetailLabel)
		klog.Infof("Detail label: %s\n", label)

		// 根据label获取数据
		values, err := client.MatrixQuery(network.NewNetworkMetics(label).ToString(promQl), v1.Range{
			Start: time.Unix(start, 0),
			End:   time.Unix(end, 0),
			Step:  time.Duration(step) * time.Second,
		})
		if err != nil {
			klog.Errorf("Failed to get %s value of %s, err: %s\n", metricName, hostdata.Name, err.Error())
			continue
		}
		klog.Infof("MatrixQuery result of node[%v]: %v\n", hostdata.Name, values)

		// 实际数据
		detailValues := []services.ValueType{}
		for _, i := range values {
			for _, j := range i.Values {
				timeStr := time.Unix(j.Timestamp.Unix(), 0).Format("2006-01-02 15:04:05")
				value := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: services.FormPercent(j.Value.String()), IsForecast: false, Day: timeStr}
				detailValues = append(detailValues, value)
			}
		}

		poolDetailData.Values = detailValues
		res = append(res, poolDetailData)
	}

	return
}

func getClusterDetailMetricValue(query *resourcepoolmodel.NetworkDetailQuery, metricInfo *resourcepoolmodel.MetricInfo, metricName, promQl string) (res []resourcepoolmodel.PoolDetailData, err error) {
	start := query.Start / 1e3
	end := query.End / 1e3
	if start >= end {
		return nil, errors.New("Start time greater than end time!")
	}
	step := services.TimeToStepForInt(end - start)
	klog.Infof("start: %v; end: %v; step: %v \n", query.Start/1e3, query.End/1e3, step)

	metricInfo.Name = query.PoolName
	poolDetailData := resourcepoolmodel.PoolDetailData{}
	poolDetailData.Info = *metricInfo

	// 构造 label
	poolDetailLabel := resourcepoolmodel.PoolDetailLabel{
		Region:           query.Region,
		ResourcePoolType: strings.ToLower(query.PoolType),
		ResourcePool:     strings.ToLower(query.PoolName),
	}
	label := NetworkDetailBuildCommonCondition(&poolDetailLabel)
	klog.Infof("Detail label: %s\n", label)

	// 根据label获取数据
	values, err := client.MatrixQuery(network.NewNetworkMetics(label).ToString(promQl), v1.Range{
		Start: time.Unix(start, 0),
		End:   time.Unix(end, 0),
		Step:  time.Duration(step) * time.Second,
	})
	if err != nil {
		klog.Errorf("Failed to get %s value of %s, err: %s\n", metricName, query.PoolName, err.Error())
		return
	}
	klog.Infof("MatrixQuery result of cluster[%v]: %v\n", query.PoolName, values)

	// 实际数据
	detailValues := []services.ValueType{}
	for _, i := range values {
		for _, j := range i.Values {
			timeStr := time.Unix(j.Timestamp.Unix(), 0).Format("2006-01-02 15:04:05")
			value := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: services.FormPercent(j.Value.String()), IsForecast: false, Day: timeStr}
			detailValues = append(detailValues, value)
		}
	}

	poolDetailData.Values = detailValues
	res = append(res, poolDetailData)

	return
}

// 构造节点监控数据详情label
func NetworkDetailBuildCommonCondition(parameter *resourcepoolmodel.PoolDetailLabel, extConditions ...string) string {
	var conditions []string
	if len(extConditions) > 0 {
		conditions = append(conditions, extConditions...)
	}
	if parameter.Region != "" {
		conditions = append(conditions, "region=\""+parameter.Region+"\"")
	}

	if parameter.ResourcePoolType != "" {
		conditions = append(conditions, "resourcePoolType=~\".*"+parameter.ResourcePoolType+".*\"")
	}

	if parameter.ResourcePool != "" {
		conditions = append(conditions, "resourcePool=~\".*"+parameter.ResourcePool+".*\"")
	}
	if parameter.AZ != "" {
		conditions = append(conditions, "az=\""+parameter.AZ+"\"")
	}

	if parameter.Instance != "" {
		conditions = append(conditions, "instance=\""+parameter.Instance+":9100\"")
	}

	if parameter.IP != "" {
		conditions = append(conditions, "ip=\""+parameter.IP+"\"")
	}

	if parameter.Eip != "" {
		conditions = append(conditions, "eip=\""+parameter.Eip+"\"")
	}

	if parameter.Port != "" {
		conditions = append(conditions, "port=\""+parameter.Port+"\"")
	}

	if parameter.HostName != "" {
		conditions = append(conditions, "hostname=\""+parameter.HostName+"\"")
	}

	if parameter.Vni != "" {
		conditions = append(conditions, "vni=\""+parameter.Vni+"\"")
	}
	if parameter.Domain != "" {
		conditions = append(conditions, "domain=\""+parameter.Domain+"\"")
	}

	var conditionStr string
	if len(conditions) > 0 {
		conditionStr = strings.Join(conditions, ",")
	}
	return conditionStr
}

func NetworkDetailSortBuildCommonCondition(parameter *resourcepoolmodel.PoolDetailLabel, extConditions ...string) string {
	var conditions []string
	if len(extConditions) > 0 {
		conditions = append(conditions, extConditions...)
	}
	if parameter.HostName != "" {
		conditions = append(conditions, "hostname=\""+parameter.HostName+"\"")
	}

	if parameter.IP != "" {
		conditions = append(conditions, "instance=\""+parameter.IP+":9200\"")
	}

	var conditionStr string
	if len(conditions) > 0 {
		conditionStr = strings.Join(conditions, ",")
	}
	return conditionStr
}

func GetNetworkRate(query *resourcepoolmodel.NetworkOverviewLineQuery, list []cmdbmodel.NetworkPool, name, promQl string) (res resourcepoolmodel.NetLineData, err error) {
	start := query.Start / 1e3
	end := query.End / 1e3
	step := services.TimeToStepForInt(end - start)
	klog.Errorf("start: %v; end: %v; step: %v", query.Start/1e3, query.End/1e3, step)

	res.Info = resourcepoolmodel.LineInfo{
		Name:     name,
		Unit:     "%",
		UnitType: "percent",
	}

	res.Pools = []resourcepoolmodel.PoolData{}
	const limit = int(^uint16(0))
	for _, pool := range list {
		poolInfo := resourcepoolmodel.PoolInfo{
			Name: pool.PoolName,
			//Prognosis: prognosis,  预测数据标识
		}
		poolpool := resourcepoolmodel.PoolData{
			Info: poolInfo,
		}

		phsicalServerReq := &cmdbmanager.NetworkPoolListPost{
			RegionCode: query.Region,
			PoolName:   pool.PoolName,
			PageNo:     1,
			PageSize:   limit,
		}

		serverResult, err := cmdbmanager.GetNetworkPhsicalServers(phsicalServerReq)
		klog.Infof("network OverviewLine DEBUG 2 - 1: %+v", serverResult)

		ipList := make([]string, 0)

		if err != nil {
			klog.Infof("network OverviewLine DEBUG 2 - 2: %+v", err)

			continue
		}
		for _, server := range serverResult.Data.DataList {
			ipList = append(ipList, server.Ip)
		}

		paramLabel := &resourcepoolmodel.NetworkPoolLable{
			Region: query.Region,
			//ResourcePoolType: strings.ToLower(pool.PoolType),
			//ResourcePool:     strings.ToLower(pool.PoolName),
			//HostList: pool.Hosts,
			IPList: ipList,
		}
		label := NetworkbuildCommonCondition(paramLabel)
		klog.Infof("label :%s", label)
		q := network.NewNetworkMetics(label).ToString(promQl)
		klog.Infof("network OverviewLine DEBUG 2 - 3: %+v", q)

		values, err := client.MatrixQuery(q, v1.Range{
			Start: time.Unix(start, 0),
			End:   time.Unix(end, 0),
			Step:  time.Duration(step) * time.Second,
		})
		if err != nil {
			klog.Infof("network OverviewLine DEBUG 2 - 4: %+v", err)
			klog.Errorf("Failed to get %s usage: %s", name, err.Error())
			continue
		}
		klog.Infof("label :%v", values)

		// 实际数据
		poolValues := []services.ValueType{}
		for _, i := range values {
			for _, j := range i.Values {
				timeStr := time.Unix(j.Timestamp.Unix(), 0).Format("2006-01-02 15:04:05")
				rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: services.FormPercent(j.Value.String()), IsForecast: false, Day: timeStr}
				poolValues = append(poolValues, rr)
			}
		}

		if len(poolValues) == 0 {
			klog.Infof("network OverviewLine DEBUG 2 - 5: %+v", poolValues)

			klog.Infof("%s Data parsing length is 0 ", name)
			res.Pools = append(res.Pools, poolpool)
			continue
		}

		// 补充开头
		repairFirstList := []services.ValueType{}
		first := poolValues[0].TimeSteamp.(string) // 实际第一条时间
		repairFirstTime, _ := strconv.ParseInt(first, 10, 64)
		firstStep := int64(step)

		for n := start; n < repairFirstTime; n += firstStep {
			repairFirst := services.ValueType{
				Name:       strconv.FormatInt(n, 10),
				TimeSteamp: strconv.FormatInt(n, 10),
				IsForecast: false,
				Day:        time.Unix(n, 0).Format("2006-01-02 15:04:05"),
			}
			//fmt.Println("repairFirstrepairFirst",repairFirst)
			repairFirstList = append(repairFirstList, repairFirst)
		}

		//补充中间
		var repairMiddleList = []services.ValueType{}
		var poolValuesLen = len(poolValues)

		for i := 0; i < poolValuesLen; i++ {
			repairMiddleList = append(repairMiddleList, poolValues[i])
			// 最后一个取样点
			if i >= poolValuesLen-1 {
				break
			}
			// 当前取样点时间
			currentTimeStr := poolValues[i].TimeSteamp.(string)
			currentTimeInt, _ := strconv.Atoi(currentTimeStr)
			// 下一取样点时间
			nextTimeStr := poolValues[i+1].TimeSteamp.(string)
			nexTimeInt, _ := strconv.Atoi(nextTimeStr)

			// 如果下一取样点时间与当前取样点时间 <= step，即没有断点
			if nexTimeInt-currentTimeInt <= step {
				continue
			}
			// 处理断点
			for t := currentTimeInt + step; t < nexTimeInt; t += step {
				strT := strconv.Itoa(t)
				middleInfo := services.ValueType{
					TimeSteamp: strT,
					IsForecast: false,
				}
				repairMiddleList = append(repairMiddleList, middleInfo)
			}
		}

		// 补充结尾
		repairLastList := []services.ValueType{}
		last := poolValues[len(poolValues)-1].TimeSteamp.(string) // 实际最后一条时间
		repairLastTime, _ := strconv.ParseInt(last, 10, 64)

		for m := repairLastTime + firstStep; m <= end; m += firstStep {
			repairLast := services.ValueType{
				Name:       strconv.FormatInt(m, 10),
				TimeSteamp: strconv.FormatInt(m, 10),
				IsForecast: false,
				Day:        time.Unix(m, 0).Format("2006-01-02 15:04:05"),
			}
			repairLastList = append(repairLastList, repairLast)
		}

		repairFirstList = append(repairFirstList, repairMiddleList...)
		repairFirstList = append(repairFirstList, repairLastList...)

		//// todo 计算预测时间key
		//var prognosis int
		//
		////选择日期范围 大于7天的 取监控数据最新7天的数据
		//var forecastList []services.ValueType
		//if end-start > 7*86400 && len(repairFirstList) >= 7 { // 时间间隔大于7天的
		//	lens := len(repairFirstList)
		//	forecastList = repairFirstList[lens-8:]
		//	prognosis = len(repairFirstList)
		//} else {
		//	forecastList = repairFirstList
		//	prognosis = len(forecastList) - 1
		//}
		//
		////获取实际数据的时间间隔
		//latestTimeStr := forecastList[len(forecastList)-1].TimeSteamp.(string)
		//latesTime, _ := strconv.ParseInt(latestTimeStr, 10, 64)
		//firstTimeStr := forecastList[0].TimeSteamp.(string)
		//firstTime, _ := strconv.ParseInt(firstTimeStr, 10, 64)
		//duration := latesTime - firstTime
		//
		////todo 获取预测波形图
		//prediction := GetPredictionWaveform(forecastList, duration, step)
		//repairFirstList = append(repairFirstList, prediction...)

		poolpool.Values = repairFirstList
		res.Pools = append(res.Pools, poolpool)

	}

	klog.Infof("network OverviewLine DEBUG 2 - 6: %+v", res)

	return res, nil
}

func getNetAlerts(query *resourcepoolmodel.NetworkOverviewQuery) ([]resourcepoolmodel.NetAlert, error) {
	alertsOverview := make([]resourcepoolmodel.NetAlert, 0)

	numP0 := make(map[string]int, 0)
	numP1 := make(map[string]int, 0)
	numP2 := make(map[string]int, 0)
	numP3 := make(map[string]int, 0)

	for _, v := range clusterTypes {
		numP0[v] = 0
		numP1[v] = 0
		numP2[v] = 0
		numP3[v] = 0
	}

	filter := []string{}
	if query.Region != "" {
		filter = append(filter, fmt.Sprintf("region=%s", query.Region))
	}
	filter = append(filter, fmt.Sprintf("lubanResourceType=%s", "resourcePool"))
	alerts, err := alert.GetAlerts(filter)
	if err == nil && len(alerts) > 0 {
		for _, v := range clusterTypes {
			numP0[v] = alert.CountAlertsNum(alerts, strings.ToLower(v), "p0")
			numP1[v] = alert.CountAlertsNum(alerts, strings.ToLower(v), "p1")
			numP2[v] = alert.CountAlertsNum(alerts, strings.ToLower(v), "p2")
			numP3[v] = alert.CountAlertsNum(alerts, strings.ToLower(v), "p3")
		}
	}

	subListP0 := make([]resourcepoolmodel.SubNetAlert, 0)
	subListP1 := make([]resourcepoolmodel.SubNetAlert, 0)
	subListP2 := make([]resourcepoolmodel.SubNetAlert, 0)
	subListP3 := make([]resourcepoolmodel.SubNetAlert, 0)
	for _, v := range clusterTypes {
		subAlertP0 := resourcepoolmodel.SubNetAlert{clusterTypeNames[v], v, numP0[v], "个", "error"}
		subListP0 = append(subListP0, subAlertP0)
		subAlertP1 := resourcepoolmodel.SubNetAlert{clusterTypeNames[v], v, numP1[v], "个", "warn"}
		subListP1 = append(subListP1, subAlertP1)
		subAlertP2 := resourcepoolmodel.SubNetAlert{clusterTypeNames[v], v, numP2[v], "个", "minor"}
		subListP2 = append(subListP2, subAlertP2)
		subAlertP3 := resourcepoolmodel.SubNetAlert{clusterTypeNames[v], v, numP3[v], "个", "info"}
		subListP3 = append(subListP3, subAlertP3)
	}

	p0 := resourcepoolmodel.NetAlert{Name: "紧急告警", Level: "p0", Kind: "error", Number: totalNum(subListP0), Unit: "个", List: subListP0}
	p1 := resourcepoolmodel.NetAlert{Name: "重要告警", Level: "p1", Kind: "warn", Number: totalNum(subListP1), Unit: "个", List: subListP1}
	p2 := resourcepoolmodel.NetAlert{Name: "次要告警", Level: "p2", Kind: "minor", Number: totalNum(subListP2), Unit: "个", List: subListP2}
	p3 := resourcepoolmodel.NetAlert{Name: "提醒告警", Level: "p3", Kind: "info", Number: totalNum(subListP3), Unit: "个", List: subListP3}

	alertsOverview = append(alertsOverview, p0, p1, p2, p3)

	return alertsOverview, nil
}

func totalNum(subAlerts []resourcepoolmodel.SubNetAlert) int {
	cnt := 0
	for _, v := range subAlerts {
		cnt += v.Number
	}
	return cnt
}

func runStateNum(echartValue map[string]services.ValueType) (int, []services.ValueType) {
	cnt := 0
	for _, v := range echartValue {
		cnt += v.Value.(int)
	}
	values := make([]services.ValueType, 0)
	for _, v := range clusterTypes {
		values = append(values, echartValue[v])
	}

	return cnt, values
}

func getNetworkEcharts(query *resourcepoolmodel.NetworkOverviewQuery) ([]resourcepoolmodel.EchartType, error) {
	echarts := make([]resourcepoolmodel.EchartType, 0)

	upMap := make(map[string]services.ValueType)
	downMap := make(map[string]services.ValueType)

	for _, v := range clusterTypes {
		upMap[v] = services.ValueType{
			Id:         v,
			Value:      0,
			Name:       clusterTypeNames[v],
			IsForecast: false,
		}
		downMap[v] = services.ValueType{
			Id:         v,
			Value:      0,
			Name:       clusterTypeNames[v],
			IsForecast: false,
		}
	}

	typeServerMap := getPoolTypeServerMap(query.Region)

	for poolType, servers := range typeServerMap {
		for _, server := range servers {
			upQuery := servertemp.NewServerMetics(server.Ip+":9100", "", 0).ToString("server_up")
			up, err := client.VectorQuery(upQuery)
			if err != nil {
				klog.Info(err)
				continue
			}
			if len(up) > 0 {
				if math.IsNaN(float64(up[0].Value)) {
					up[0].Value = 0
				}
				if float64(up[0].Value) == 1 {
					if chartValue, ok := upMap[poolType]; ok {
						chartValue.Value = chartValue.Value.(int) + 1
						upMap[poolType] = chartValue
					} else {
						klog.Infof("resource pool type not find in upMap: %s", poolType)
					}

				} else {
					if chartValue, ok := downMap[poolType]; ok {
						chartValue.Value = chartValue.Value.(int) + 1
						downMap[poolType] = chartValue
					} else {
						klog.Infof("resource pool type not find in downMap: %s", poolType)
					}
				}
			} else {
				if chartValue, ok := downMap[poolType]; ok {
					chartValue.Value = chartValue.Value.(int) + 1
					downMap[poolType] = chartValue
				} else {
					klog.Infof("resource pool type not find in downMap: %s", poolType)
				}
			}

		}
	}

	//const limit = int(^uint16(0))
	//cmdbParam := &cmdbmanager.NetworkPoolListPost{
	//	RegionCode: query.Region,
	//	PageNo:     1,
	//	PageSize:   limit,
	//}
	//
	//poolList := getNetworkPoolAll(query.Region, "")
	//if len(poolList) > 0 {
	//	hostMap := make(map[int]cmdbmodel.PhysicalHostData)
	//	for _, pool := range poolList {
	//		cmdbParam.PoolName = pool.PoolName
	//		hostsResult, err := cmdbmanager.GetNetworkPhsicalServers(cmdbParam)
	//		if err != nil {
	//			continue
	//		}
	//		for _, server := range hostsResult.Data.DataList {
	//			hostMap[server.Uid] = server
	//		}
	//	}
	//
	//	for _, v := range hostMap {
	//		upQuery := servertemp.NewServerMetics(v.Ip+":9100", "", 0).ToString("server_up")
	//		up, err := client.VectorQuery(upQuery)
	//		if err != nil {
	//			klog.Info(err)
	//			continue
	//		}
	//		if len(up) > 0 {
	//			if math.IsNaN(float64(up[0].Value)) {
	//				up[0].Value = 0
	//			}
	//			if float64(up[0].Value) == 1 {
	//				if chartValue, ok := upMap[v.ResourcePoolType]; ok {
	//					chartValue.Value = chartValue.Value.(int) + 1
	//					upMap[v.ResourcePoolType] = chartValue
	//				} else {
	//					klog.Infof("resource pool type not find in upMap: %s", v.ResourcePoolType)
	//				}
	//
	//			} else {
	//				if chartValue, ok := downMap[v.ResourcePoolType]; ok {
	//					chartValue.Value = chartValue.Value.(int) + 1
	//					downMap[v.ResourcePoolType] = chartValue
	//				} else {
	//					klog.Infof("resource pool type not find in downMap: %s", v.ResourcePoolType)
	//				}
	//			}
	//		}
	//	}
	//
	//}

	downNum, downValues := runStateNum(downMap)
	echartDown := resourcepoolmodel.EchartType{
		Info: resourcepoolmodel.InfoType{
			Name:     "监控异常",
			Total:    downNum,
			Unit:     "个",
			UnitType: "number",
		},
		Values: downValues,
	}
	echarts = append(echarts, echartDown)

	upNum, upValues := runStateNum(upMap)
	echartUp := resourcepoolmodel.EchartType{
		Info: resourcepoolmodel.InfoType{
			Name:     "监控中",
			Total:    upNum,
			Unit:     "个",
			UnitType: "number",
		},
		Values: upValues,
	}
	echarts = append(echarts, echartUp)

	return echarts, nil
}

// 获取列表使用率
func NetworkLitsRate(region, poolType, promQl string, ipList []string) (rate float64) {
	paramLabel := &resourcepoolmodel.NetworkPoolLable{
		Region: region,
		//ResourcePoolType: strings.ToLower(poolType),
		IPList: ipList,
	}
	label := NetworkbuildCommonCondition(paramLabel)

	klog.Infof("NetworkLitsRate label[%s] of %s is: %s", promQl, poolType, label)

	// 取一段时间内（10m）最后一个时间点的数据，避免查不到数据的问题

	start := time.Now().Add(time.Minute * (-10))
	end := time.Now()

	step := 1 * time.Minute
	queryRes, err := client.MatrixQuery(network.NewNetworkMetics(label).ToString(promQl), v1.Range{
		Start: start,
		End:   end,
		Step:  step,
	})
	if err != nil {
		klog.Errorf("Failed to get  poolType[%s] value of %s, err: %s\n", poolType, region, err.Error())
		return
	}

	if len(queryRes) == 0 {
		klog.Infof("MatrixQuery result of pool[%v] is empty.\n", poolType)
		return
	}
	// 取最后一个元素
	resSamplePair := queryRes[len(queryRes)-1]
	if len(resSamplePair.Values) == 0 {
		klog.Infof("MatrixQuery SamplePair result of pool[%v] is empty.\n", poolType)
		return
	}

	klog.Infof("MatrixQuery result of pool[%v]: %v\n", poolType, queryRes)

	resSampleValue := resSamplePair.Values[0].Value
	if math.IsNaN(float64(resSampleValue)) {
		rate = 0
	} else {
		rate = services.FormPercent(float64(resSampleValue))
	}

	return
}

func NetworkbuildCommonCondition(parameter *resourcepoolmodel.NetworkPoolLable, extConditions ...string) string {
	var conditions []string
	if len(extConditions) > 0 {
		conditions = append(conditions, extConditions...)
	}
	if parameter.Region != "" {
		conditions = append(conditions, "region=\""+parameter.Region+"\"")
	}

	if parameter.ResourcePoolType != "" {
		conditions = append(conditions, "resourcePoolType=\""+parameter.ResourcePoolType+"\"")
	}

	if parameter.ResourcePool != "" {
		conditions = append(conditions, "resourcePool=~\".*"+parameter.ResourcePool+"-o.*\"")
	}
	if parameter.HostList != nil && len(parameter.HostList) > 0 {
		hosts := ""
		for _, hostname := range parameter.HostList {
			hosts = hosts + "|" + hostname
		}
		conditions = append(conditions, "hostname=~\".*"+hosts+"-o.*\"")
	}
	if parameter.IPList != nil && len(parameter.IPList) > 0 {
		instances := ""
		for _, ip := range parameter.IPList {
			if instances == "" {
				instances = ip + ":9100"
			} else {
				instances = instances + "|" + ip + ":9100"
			}
		}
		if len(parameter.IPList) == 1 {
			conditions = append(conditions, "instance=\""+instances+"\"")
		} else {
			conditions = append(conditions, "instance=~\"( "+instances+")\"")
		}

	}

	var conditionStr string
	if len(conditions) > 0 {
		conditionStr = strings.Join(conditions, ",")
	}
	return conditionStr
}

func getNetworkPoolAll(region, poolType string) []cmdbmodel.NetworkPool {
	const limit = int(^uint16(0))
	cmdbParam := &cmdbmanager.NetworkPoolListPost{
		RegionCode: region,
		PoolType:   []string{poolType},
		PageNo:     1,
		PageSize:   limit,
	}
	listAll := make([]cmdbmodel.NetworkPool, 0)
	netType := []string{"LB", "EIP", "NAT", "BM", "SL"}

	for _, v := range netType {
		cmdbParam.Type = v
		poolResult, err := cmdb.GetNetworkPoolList(cmdbParam)
		if err == nil && len(poolResult.Data) > 0 {
			listAll = append(listAll, poolResult.Data...)
		}
	}
	return listAll
}

func getMetricInfo(key string) (resourcepoolmodel.MetricInfo, error) {
	if v, ok := metricInfoMap[key]; ok {
		return v, nil
	} else {
		return resourcepoolmodel.MetricInfo{}, errors.New("metric key is not exist!")
	}
}

func getMetricPromQL(key string) (string, error) {
	if v, ok := metricPromQLMap[key]; ok {
		return v, nil
	} else {
		return "", errors.New("metric key is not exist!")
	}
}
func getmetricTopLinePromQLMap(key string) (int, error) {
	if v, ok := metricTopLinePromQLMap[key]; ok {
		return len(v), nil
	} else {
		return 0, errors.New("metric key is not exist!")
	}
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/resourcepool/map.go
```golang
package resourcepoolservice

import resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"

var (
	numberMetricInfo = resourcepoolmodel.MetricInfo{
		Unit:     "个",
		UnitType: "number",
	}
	storageMetricInfo = resourcepoolmodel.MetricInfo{
		Unit:     "byte",
		UnitType: "storage",
	}
	percentMetricInfo = resourcepoolmodel.MetricInfo{
		Unit:     "%",
		UnitType: "percent",
	}
	bpsMetricInfo = resourcepoolmodel.MetricInfo{
		Unit:     "bps",
		UnitType: "storage",
	}
)

var (
	node_cpu_used_rate                       = "cpuRate"
	node_memory_used_rate                    = "memoryRate"
	node_memory_used_bytes                   = "memoryUsage"
	node_filesystem_used_rate                = "diskRate"
	node_filesystem_used_bytes               = "diskUsage"
	node_network_pps                         = "pps"
	node_network_bps                         = "bps"
	node_netstat_Tcp_CurrEstab               = "conn"
	cluster_netstat_Tcp_CurrEstab            = "clusterConn"
	node_xgw_slb_conns_topK                  = "slbConnsTopK"          //old
	node_xgw_slb_traffic_topK                = "slbTrafficTopK"        // old
	node_xgw_eip_traffic_topK                = "eipTrafficTopK"        // old
	node_nat_traffic_topK                    = "natTrafficTopK"        // old
	node_tengine_slb_conns_topK              = "tengineSlbConnsTopK"   //old tengine节点SLB实例连接数(来源未知)
	node_tengine_slb_traffic_topK            = "tengineSlbTrafficTopK" //old tengine节点负载均衡流量(来源未知)
	node_sgw_public_traffic_topK             = "sgwTrafficTopK"        //todo 弹性ip-sgw-eip节点公网弹性IP流量(来源未知)
	node_sgw_public_drop_packet_rate_topK    = "sgwDropPacketRateTopK" //todo 弹性ip-sgw-eip节点公网弹性IP丢包率(来源未知)
	node_tgw_lpeer_bytes_in                  = "tgwLpeerBytesIn"
	node_tgw_lpeer_bytes_out                 = "tgwLpeerBytesOut"
	node_tgw_dc_bytes_in                     = "tgwDcytesIn"
	node_tgw_dc_bytes_out                    = "tgwDcBytesOut"
	node_tgw_vpn_bytes_in                    = "tgwVpnBytesIn"
	node_tgw_vpn_bytes_out                   = "tgwVpnBytesOut"
	node_xgw_slb_conns                       = "slbConns"                   // xgw节点SLB实例连接数
	node_xgw_slb_traffic_in                  = "slbTrafficIn"               // 节点负载均衡流量入
	node_xgw_slb_traffic_out                 = "slbTrafficOut"              // 节点负载均衡流量出
	node_xgw_eip_traffic_in                  = "eipTrafficIn"               // 节点弹性IP流量入
	node_xgw_eip_traffic_out                 = "eipTrafficOut"              // 节点弹性IP流量出
	node_tengine_slb_conns                   = "tengineSlbConns"            //tengine节点SLB实例连接数
	node_tengine_slb_traffic_in              = "tengineSlbTrafficIn"        //tengine节点负载均衡流量入
	node_tengine_slb_traffic_out             = "tengineSlbTrafficOut"       //tengine节点负载均衡流量出
	node_sgw_public_eip_traffic_in           = "sgwPublicEipTrafficIn"      // sgw节点公网弹性IP流量入
	node_sgw_public_eip_traffic_out          = "sgwPublicEipTrafficOut"     // sgw节点公网弹性IP流量入
	node_sgw_public_eip_drop_packet_rate_in  = "sgwPublicDropPacketRateIn"  //sgw节点公网弹性IP入丢包率
	node_sgw_public_eip_drop_packet_rate_out = "sgwPublicDropPacketRateOut" //sgw节点公网弹性IP出丢包率
	node_nat_traffic_in                      = "natTrafficIn"               // 节点nat流量入
	node_nat_traffic_out                     = "natTrafficOut"              // 节点nat流量出
)

// 返回数据单位
var metricInfoMap = map[string]resourcepoolmodel.MetricInfo{
	cluster_netstat_Tcp_CurrEstab:         numberMetricInfo,
	node_netstat_Tcp_CurrEstab:            numberMetricInfo,
	node_network_pps:                      numberMetricInfo,
	node_network_bps:                      bpsMetricInfo,
	node_cpu_used_rate:                    percentMetricInfo,
	node_memory_used_bytes:                storageMetricInfo,
	node_memory_used_rate:                 percentMetricInfo,
	node_filesystem_used_bytes:            storageMetricInfo,
	node_filesystem_used_rate:             percentMetricInfo,
	node_xgw_slb_conns_topK:               numberMetricInfo,
	node_xgw_slb_traffic_topK:             storageMetricInfo,
	node_xgw_eip_traffic_topK:             storageMetricInfo,
	node_nat_traffic_topK:                 storageMetricInfo,
	node_tengine_slb_conns_topK:           numberMetricInfo,
	node_tengine_slb_traffic_topK:         storageMetricInfo,
	node_sgw_public_traffic_topK:          storageMetricInfo,
	node_sgw_public_drop_packet_rate_topK: percentMetricInfo,
	node_tgw_lpeer_bytes_in:               storageMetricInfo,
	node_tgw_lpeer_bytes_out:              storageMetricInfo,
	node_tgw_dc_bytes_in:                  storageMetricInfo,
	node_tgw_dc_bytes_out:                 storageMetricInfo,
	node_tgw_vpn_bytes_in:                 storageMetricInfo,
	node_tgw_vpn_bytes_out:                storageMetricInfo,
	node_xgw_slb_conns:                    numberMetricInfo,
	node_xgw_slb_traffic_in:               storageMetricInfo,
	node_xgw_slb_traffic_out:              storageMetricInfo,
	node_xgw_eip_traffic_in:               storageMetricInfo,
	node_xgw_eip_traffic_out:              storageMetricInfo,
	node_tengine_slb_conns:                numberMetricInfo,
	node_tengine_slb_traffic_in:           storageMetricInfo,
	node_tengine_slb_traffic_out:          storageMetricInfo,
	node_nat_traffic_in:                   storageMetricInfo,
	node_nat_traffic_out:                  storageMetricInfo,
	node_sgw_public_eip_traffic_in:        storageMetricInfo,
	node_sgw_public_eip_traffic_out:       storageMetricInfo,
	node_sgw_public_eip_drop_packet_rate_in:  percentMetricInfo,
	node_sgw_public_eip_drop_packet_rate_out:  percentMetricInfo,
}

// psql
var metricPromQLMap = map[string]string{
	cluster_netstat_Tcp_CurrEstab:         "cluster_netstat_Tcp_CurrEstab",
	node_netstat_Tcp_CurrEstab:            "node_netstat_Tcp_CurrEstab",
	node_network_pps:                      "node_network_pps",
	node_network_bps:                      "node_network_bps",
	node_cpu_used_rate:                    "node_cpu_used_rate",
	node_memory_used_bytes:                "node_memory_used_bytes",
	node_memory_used_rate:                 "node_memory_used_rate",
	node_filesystem_used_bytes:            "node_filesystem_used_bytes",
	node_filesystem_used_rate:             "node_filesystem_used_rate",
	node_xgw_slb_conns_topK:               "node_xgw_slb_conns_topK",
	node_xgw_slb_traffic_topK:             "node_xgw_slb_traffic_topK",
	node_xgw_eip_traffic_topK:             "node_xgw_eip_traffic_topK",
	node_nat_traffic_topK:                 "node_nat_traffic_topK",
	node_tengine_slb_conns_topK:           "node_tengine_slb_conns_topK",
	node_tengine_slb_traffic_topK:         "node_tengine_slb_traffic_topK",
	node_sgw_public_traffic_topK:          "node_sgw_public_traffic_topK",
	node_sgw_public_drop_packet_rate_topK: "node_sgw_public_drop_packet_rate_topK",
}

var metricTopLinePromQLMap = map[string][]string{
	node_tgw_lpeer_bytes_in:              {"node_tgw_lpeer_bytes_in_topK", "node_tgw_lpeer_bytes_in"},
	node_tgw_lpeer_bytes_out:             {"node_tgw_lpeer_bytes_out_topK", "node_tgw_lpeer_bytes_out"},
	node_tgw_dc_bytes_in:                 {"node_tgw_dc_bytes_out_topK", "node_tgw_dc_bytes_in"},
	node_tgw_dc_bytes_out:                {"node_tgw_dc_bytes_out_topK", "node_tgw_dc_bytes_out"},
	node_tgw_vpn_bytes_in:                {"node_tgw_vpn_bytes_out_topK", "node_tgw_vpn_bytes_in"},
	node_tgw_vpn_bytes_out:               {"node_tgw_vpn_bytes_out_topK", "node_tgw_vpn_bytes_out"},
	node_tgw_vpn_bytes_out:               {"node_tgw_vpn_bytes_out_topK", "node_tgw_vpn_bytes_out"},
	node_xgw_slb_conns:                   {"node_xgw_slb_conns_topK", "node_xgw_slb_conns"},
	node_xgw_slb_traffic_in:              {"node_xgw_slb_traffic_in_topK", "node_xgw_slb_traffic_in"},
	node_xgw_slb_traffic_out:             {"node_xgw_slb_traffic_out_topK", "node_xgw_slb_traffic_out"},
	node_xgw_eip_traffic_in:              {"node_xgw_eip_traffic_in_topK", "node_xgw_eip_traffic_in"},
	node_xgw_eip_traffic_out:             {"node_xgw_eip_traffic_out_topK", "node_xgw_eip_traffic_out"},
	node_tengine_slb_conns:               {"node_tengine_slb_conns_topK", "node_tengine_slb_conns"},
	node_nat_traffic_in:                  {"node_nat_traffic_in_topK", "node_nat_traffic_in"},
	node_nat_traffic_out:                 {"node_nat_traffic_out_topK", "node_nat_traffic_out"},
	node_tengine_slb_traffic_in:          {"node_tengine_slb_traffic_in_topK", "node_tengine_slb_traffic_in"},
	node_tengine_slb_traffic_out:         {"node_tengine_slb_traffic_out_topK", "node_tengine_slb_traffic_out"},
	node_sgw_public_eip_traffic_in:       {"node_sgw_public_eip_traffic_in_topK", "node_sgw_public_eip_traffic_in"},
	node_sgw_public_eip_traffic_out:      {"node_sgw_public_eip_traffic_out_topK", "node_sgw_public_eip_traffic_out"},
	node_sgw_public_eip_drop_packet_rate_in: {"node_sgw_public_eip_drop_packet_rate_in_topK", "node_sgw_public_eip_drop_packet_rate_in"},
	node_sgw_public_eip_drop_packet_rate_out: {"node_sgw_public_eip_drop_packet_rate_out_topK", "node_sgw_public_eip_drop_packet_rate_out"},
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/resourcepool/databaseservice.go
```golang
package resourcepoolservice

import (
	"encoding/json"
	"errors"
	"fmt"
	alertmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	kts "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/ktsmanager"
	prom "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	temp "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/physicalServer"
	"io"
	"math"
	"net/http"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"time"

	v1 "github.com/prometheus/client_golang/api/prometheus/v1"
	promModel "github.com/prometheus/common/model"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	dbmsmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/dbmsservice"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/prometheus/labels"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/dbmsmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/databaseResourcePool"
	"k8s.io/klog/v2"
)

type DatabaseServer interface {
	Overview(query *resourcepoolmodel.DatabaseOverviewQuery) (resourcepoolmodel.OverviewDataData, error)
	OverviewLine(query *resourcepoolmodel.DatabaseOverviewLineQuery) (resourcepoolmodel.LineData, error)
	DatabaseList(query *resourcepoolmodel.DatabaseListQuery) (resourcepoolmodel.Data, error)
	DbTypeList() ([]string, error)
	Monitor(*resourcepoolmodel.DatabaseMonitorQuery) (resourcepoolmodel.DatabaseMonitorLine, error)
	ServerList(query *resourcepoolmodel.ServerListQuery) (resourcepoolmodel.ServerListPageData, error)
	InstanceList(query *resourcepoolmodel.InstanceListQuery) (resourcepoolmodel.InstanceListPageData, error)
}

type DatabaseServerService struct {
	PromClient *client.PromClient
}

func NewDatabaseServerService() *DatabaseServerService {
	return &DatabaseServerService{
		PromClient: client.NewPromClient(),
	}
}

var DBInstanceStatusMapping = map[int]string{
	1: "ACTIVE",        // 运行中
	2: "EXPIRING_SOON", // 即将过期
	3: "INVALID",       // 已过期
	5: "CREATING",      // 创建中
	6: "RUNNING_TASK",  // 任务中
}

var redisMetricMap = map[string]string{
	"host":              "ksckcs",
	"cpuUsedPercent":    "rds.cpu_used_percent",
	"memoryUsedPercent": "rds.memory_used_percent",
	"riops":             "rds.riops",
	"wiops":             "rds.wiops",
	"netInput":          "rds.bytes_received",
	"netOutput":         "rds.bytes_sent",
	"connect":           "rds.threads_connected",
	"qps":               "rds.qps",
	"tps":               "rds.tps",
}
var mysqlMetricMap = map[string]string{
	"host":              "kscrds",
	"cpuUsedPercent":    "rds.cpu_used_percent",
	"memoryUsedPercent": "rds.memory_used_percent",
	"riops":             "rds.riops",
	"wiops":             "rds.wiops",
	"netInput":          "rds.bytes_received",
	"netOutput":         "rds.bytes_sent",
	"connect":           "rds.threads_connected",
	"qps":               "rds.qps",
	"tps":               "rds.tps",
}

// 获取数据库监控概览
func (c *DatabaseServerService) Overview(param *resourcepoolmodel.DatabaseOverviewQuery) (resourcepoolmodel.OverviewDataData, error) {
	res := resourcepoolmodel.OverviewDataData{}

	//获取告警数据
	alertParam := alertmodel.AlertQuery{
		Module: "database",
		Region: param.Region,
	}
	if param.Az != "" && param.Az != "all" {
		alertParam.Az = []string{param.Az}
	}

	alertList, err := alert.GetCommonAlertOverviewNum(alertParam)
	res.Alerts = append(res.Alerts, alertList...)

	//获取数据库列表
	total, _ := dbmsmanager.GetDBResourcePoolList(param.Region, param.Az, []string{}, "name", "", 1, 1)
	totalCnt := int(total.Data.Total)
	klog.Infof("totalCnt %d", totalCnt)

	klog.Infof("db az debug: region is %s, az is %s, totalCnt %d", param.Region, param.Az, totalCnt)

	if totalCnt == 0 {
		return res, nil
	}
	dbmsResult, err := dbmsmanager.GetDBResourcePoolList(param.Region, param.Az, []string{}, "name", "", 1, totalCnt)
	if err != nil {
		return res, err
	}

	blockViewList := resourcepoolmodel.DatabaseViewType{}

	serverExceptionValues := []services.ValueType{}
	instanceExceptionValues := []services.ValueType{}
	var totalDownNum int        // 资源池异常服务总数
	var totalExampleDownNum int // 资源池异常实例总数
	for i := 0; i < totalCnt; i++ {
		resourcePool := dbmsResult.Data.Data[i]
		servers := make([]interface{}, len(resourcePool.Servers))
		for s, v := range resourcePool.Servers {
			servers[s] = v
		}
		serversNbnormalNum := getAbnormalCnt(servers)
		totalDownNum += serversNbnormalNum
		serverExceptionValues = append(serverExceptionValues, services.ValueType{
			Name:  resourcePool.Name,
			Value: serversNbnormalNum,
		})

		// todo 数据库异常实例统计
		instanceParam := dbmsmanager.QueryInstanceList{
			ID:       resourcePool.ID,
			PageNo:   1,
			PageSize: 100,
		}
		instanceList, instanceErr := dbmsmanager.GetDBInstanceList(instanceParam)
		klog.Infof("instanceListCnt %d", instanceList.Data.Total)

		if instanceErr != nil {
			return res, errors.New("Failed to get resource pool instance")
		}
		if len(instanceList.Data.Data) == 0 {
			continue
		}

		var exampleNum int // 资源池异常数
		for _, instanceValue := range instanceList.Data.Data {
			// 实例子异常
			if DBInstanceStatusMapping[instanceValue.Status] == "EXPIRING_SOON" || DBInstanceStatusMapping[instanceValue.Status] == "INVALID" {
				exampleNum += 1
			}
		}
		instanceExceptionValues = append(instanceExceptionValues, services.ValueType{
			Name:  resourcePool.Name,
			Value: exampleNum,
		})

		totalExampleDownNum += exampleNum
	}

	// 异常服务器统计
	serverException := resourcepoolmodel.EchartType{}
	serverException.Info.Name = "服务器异常统计"
	serverException.Info.Total = totalDownNum
	serverException.Info.Unit = "个"
	serverException.Info.UnitType = "individual"
	serverException.Values = serverExceptionValues
	blockViewList.List = append(blockViewList.List, []resourcepoolmodel.EchartType{serverException})

	//数据库异常实例统计
	instanceException := resourcepoolmodel.EchartType{}
	instanceException.Info.Name = "数据库异常实例统计"
	instanceException.Info.Total = totalExampleDownNum
	instanceException.Info.Unit = "个"
	instanceException.Info.UnitType = "individual"
	instanceException.Values = instanceExceptionValues
	blockViewList.List = append(blockViewList.List, []resourcepoolmodel.EchartType{instanceException})

	res.BlockView = blockViewList
	return res, nil

}

func MysqlbuildCommonCondition(parameter *resourcepoolmodel.MysqlLable, extConditions ...string) string {
	var conditions []string
	if len(extConditions) > 0 {
		conditions = append(conditions, extConditions...)
	}
	if parameter.Region != "" {
		conditions = append(conditions, "region=\""+parameter.Region+"\"")
	}

	if parameter.ResourcePoolType != "" {
		conditions = append(conditions, "resourcePoolType=\""+parameter.ResourcePoolType+"\"")
	}

	if parameter.ResourcePool != "" {
		conditions = append(conditions, "resourcePool=\""+parameter.ResourcePool+"\"")
	}

	if parameter.IPList != nil && len(parameter.IPList) > 0 {
		instances := ""
		for _, ip := range parameter.IPList {
			if instances == "" {
				instances = ip + ":9100"
			} else {
				instances = instances + "|" + ip + ":9100"
			}
		}
		if len(parameter.IPList) == 1 {
			conditions = append(conditions, "instance=\""+instances+"\"")
		} else {
			conditions = append(conditions, "instance=~\"( "+instances+")\"")
		}

	}

	var conditionStr string
	if len(conditions) > 0 {
		conditionStr = strings.Join(conditions, ",")
	}
	return conditionStr
}

// 获取数据库监控概览line
func (c *DatabaseServerService) OverviewLine(param *resourcepoolmodel.DatabaseOverviewLineQuery) (rrr resourcepoolmodel.LineData, err error) {

	//获取数据库资源池总数
	total, _ := dbmsmanager.GetDBResourcePoolList(param.Region, param.Az, []string{}, "", "", 1, 1)
	totalCnt := int(total.Data.Total)
	klog.Infof("totalCnt %d", totalCnt)

	if totalCnt == 0 {
		return rrr, nil
	}
	dbmsResult, err := dbmsmanager.GetDBResourcePoolList(param.Region, param.Az, []string{}, "", "", 1, totalCnt)
	poolList := dbmsResult.Data.Data

	for _, name := range param.Name {
		switch name {
		case "cpuRate": // cpu
			res, err := GerDatabaseRate(param, poolList, "cpuRate", "node_cpu_seconds_total")
			if err != nil {
				klog.Infof("资源池获取cpuRate失败")
			}
			return res, nil
		case "memRate": // 内存
			res, err := GerDatabaseRate(param, poolList, "memRate", "node_memory_emAvailable_bytes")
			if err != nil {
				klog.Infof("资源池获取memRate失败")
			}
			return res, nil
		case "diskRate": // 磁盘
			res, err := GerDatabaseRate(param, poolList, "diskRate", "node_filesystem_free_bytes")
			if err != nil {
				klog.Infof("资源池获取diskRate失败")
			}
			return res, nil
		}
	}
	return rrr, nil

}

// 获取数据库全部类型
func (c *DatabaseServerService) DbTypeList() ([]string, error) {
	url := "http://" + config.GetDefaultUrl(config.DBMSService) + "/dbms/v1/dbResourcePool/list"
	cli := http.Client{}
	dbmsResult := dbmsmodel.DBResourcePoolListResult{}
	jsons, _ := json.Marshal(cmdbmodel.HostUrlPost{PageNo: 1, PageSize: 1000})
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	typeList := make([]string, 0)

	resp, err := cli.Post(url, "application/json", jsoninfo)
	if err != nil {
		klog.Info(err)
		return typeList, nil
	}
	b, er := io.ReadAll(resp.Body)
	if er != nil {
		klog.Info(er)
		return typeList, nil
	}
	json.Unmarshal(b, &dbmsResult)
	dbPools := dbmsResult.Data.Data
	tempMap := make(map[string]bool, len(dbPools))
	for _, dbPool := range dbPools {
		if tempMap[dbPool.DBType] == false {
			tempMap[dbPool.DBType] = true
			typeList = append(typeList, dbPool.DBType)
		}
	}
	return typeList, nil
}

// 获取数据库监控列表
func (c *DatabaseServerService) DatabaseList(q *resourcepoolmodel.DatabaseListQuery) (resourcepoolmodel.Data, error) {
	rst := resourcepoolmodel.Data{}
	//获取数据库资源池总数
	//totalCnt := dbmsmanager.GetDbmsTotalCount("http://" + config.GetDefaultUrl(config.DBMSService) + "/dbms/v1/dbResourcePool/list")
	//klog.Infof("cmdbCount: %d", totalCnt)

	if q.SearchKey != "" && q.SearchValue != "" {
		switch q.SearchKey {
		case "name":
			q.Name = q.SearchValue
		case "region":
			q.Region = q.SearchValue
		}
	}

	searchType := ""
	if q.Name != "" {
		searchType = "name"
	}
	const limit = int(^uint16(0))
	dbmsResult, err := dbmsmanager.GetDBResourcePoolList(q.Region, q.Az, q.DbType, searchType, q.Name, 1, limit)
	if err != nil {
		klog.Error(err)
		return rst, err
	}
	if dbmsResult.Code != 200 {
		klog.Info("get data from dbms error!")
		return rst, errors.New("get data from cmdb error")
	}
	rstData := dbmsResult.Data
	klog.Info("rstData")
	klog.Info(rstData)
	count := len(dbmsResult.Data.Data)

	for i := 0; i < count; i++ {
		j := rstData.Data[i]
		//多选 已经交给dbms负责搜索，当前方法暂时注释
		//if len(q.DbType) > 0 {
		//	klog.Infof("q.DbType: %v,j.DbType: %v", q.DbType, j.DBType)
		//	dbTypeIn := services.In(q.DbType, j.DBType)
		//	if !dbTypeIn {
		//		continue
		//	}
		//}

		data := resourcepoolmodel.DataList{}
		performance := j.Performance
		data.ID = j.ID
		data.Name = j.Name
		data.Region = j.Region
		data.DBType = j.DBType
		//data.CPUUsedPercent = services.FormPercent(performance.CPUUsedPercent / 1e2)
		data.CPUUsedPercent = services.FormPercent(DBPollLitsRate(j.RegionCode, j.Name, "node_cpu_seconds_total", []string{}) / 1e2)
		//data.MemoryUsedPercent = services.FormPercent(performance.MemoryUsedPercent / 1e2)
		data.MemoryUsedPercent = services.FormPercent(DBPollLitsRate(j.RegionCode, j.Name, "node_memory_emAvailable_bytes", []string{}) / 1e2)
		//data.DiskUsedPercent = services.FormPercent(performance.DiskUsedPercent / 1e2)
		data.DiskUsedPercent = services.FormPercent(DBPollLitsRate(j.RegionCode, j.Name, "node_filesystem_free_bytes", []string{}) / 1e2)
		data.ServerCount = int(j.ServerCount)

		s := make([]interface{}, len(j.Servers))
		for i, v := range j.Servers {
			s[i] = v
		}
		data.AbnormalServerCount = getAbnormalCnt(s)
		data.InstanceTotal = performance.InstanceTotal
		data.InstanceUsed = performance.InstanceUsed
		data.InstanceUnused = performance.InstanceUnused

		//计算异常数据库实例数量
		instanceParam := dbmsmanager.QueryInstanceList{
			ID:       j.ID,
			PageNo:   1,
			PageSize: limit,
		}
		instanceList, instanceErr := dbmsmanager.GetDBInstanceList(instanceParam)
		if instanceErr != nil {
			return rst, errors.New("failed to get resource pool instance")
		}
		klog.Infof("instanceList value: %v", instanceList)
		if len(instanceList.Data.Data) > 0 {
			for _, instance := range instanceList.Data.Data {
				if DBInstanceStatusMapping[instance.Status] == "EXPIRING_SOON" || DBInstanceStatusMapping[instance.Status] == "INVALID" {
					data.AbnormalInstance += 1
				}
			}
		} else {
			data.AbnormalInstance = 0
		}
		data.CreateTime = j.CreateTime
		data.WarningNum = alert.GetResourcePoolAlertNum(q.Region, "", "resourcePool", j.ResourcePoolType, j.Name)
		rst.DataList = append(rst.DataList, data)
	}

	//order
	if q.OrderCode != "" && q.OrderType != "" {
		results := alert.Bucket{}
		for i := 0; i < len(rst.DataList); i++ {
			results.Slice = append(results.Slice, rst.DataList[i])
		}
		time_by := func(a, b interface{}) bool {
			return a.(resourcepoolmodel.DataList).CreateTime > b.(resourcepoolmodel.DataList).CreateTime
		}

		switch q.OrderCode {
		case "cpuUsedPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DataList).CPUUsedPercent < b.(resourcepoolmodel.DataList).CPUUsedPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DataList).CPUUsedPercent > b.(resourcepoolmodel.DataList).CPUUsedPercent
				}
			}

		case "memoryUsedPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DataList).MemoryUsedPercent < b.(resourcepoolmodel.DataList).MemoryUsedPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DataList).MemoryUsedPercent > b.(resourcepoolmodel.DataList).MemoryUsedPercent
				}
			}
		case "diskUsedPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DataList).DiskUsedPercent < b.(resourcepoolmodel.DataList).DiskUsedPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DataList).DiskUsedPercent > b.(resourcepoolmodel.DataList).DiskUsedPercent
				}
			}

		case "createTime":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DataList).CreateTime < b.(resourcepoolmodel.DataList).CreateTime
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DataList).CreateTime > b.(resourcepoolmodel.DataList).CreateTime
				}
			}

		}
		results.By = time_by
		sort.Sort(results)
		for i := 0; i < len(results.Slice); i++ {
			rst.DataList[i] = results.Slice[i].(resourcepoolmodel.DataList)
		}
	}

	low := (q.PageNo - 1) * q.PageSize
	if low > len(rst.DataList) {
		return rst, nil
	}
	hight := low + q.PageSize
	if hight > len(rst.DataList) {
		hight = len(rst.DataList)
	}
	rst.PageNo = q.PageNo
	rst.PageSize = q.PageSize
	rst.TotalCount = len(rst.DataList)
	rst.DataList = rst.DataList[low:hight]

	return rst, nil
}

func (c *DatabaseServerService) Monitor(q *resourcepoolmodel.DatabaseMonitorQuery) (resourcepoolmodel.DatabaseMonitorLine, error) {
	monitorLine := resourcepoolmodel.DatabaseMonitorLine{}

	dbResourcePool, err := dbmsmanager.GetDBResourcePoolDetail(q.Id)
	if err != nil {
		return monitorLine, err
	}
	klog.V(1).Infof("get database resource pool detail: %+v\n", dbResourcePool)

	querySql, ok := databaseResourcePool.MonitorMetric[databaseResourcePool.Metric(q.Metric)]
	if !ok {
		klog.Warningf("%s metric not found", q.Metric)
		return monitorLine, fmt.Errorf("%s metric not found", q.Metric)
	}

	querySql.Labels = labels.MatcherPairs{}
	var resultKey string
	if q.Metric == string(databaseResourcePool.CpuCountAmount) {
		resultKey = "instance_ip"
		if err := querySql.Labels.AddMatcher(labels.MatchEqual, "resource_pool_name", dbResourcePool.Data.ID); err != nil {
			klog.Warningf("Add labels error: %s", err.Error())
		}
	} else {
		resultKey = "instance"
		if err := querySql.Labels.AddMatcher(labels.MatchEqual, "resourcePool", dbResourcePool.Data.Name); err != nil {
			klog.Warningf("Add labels error: %s", err.Error())
		}
		querySql.By = []promModel.LabelName{"instance"}
	}

	promSql, err := querySql.Render()
	if err != nil {
		klog.Error(err)
		return monitorLine, err
	}

	matrixResult, err := c.PromClient.MatrixQuery(
		promSql,
		v1.Range{
			Start: time.Unix(q.Start, 0),
			End:   time.Unix(q.End, 0),
			Step:  time.Duration(q.Step) * time.Second,
		},
	)
	if err != nil {
		// klog.Errorf()
		return monitorLine, err
	}
	klog.V(1).Infof("prometheus query result: %#v", matrixResult)
	data := []resourcepoolmodel.DatabaseMonitorDetail{}
	for _, v := range matrixResult {
		detail := resourcepoolmodel.DatabaseMonitorDetail{
			Hostname: strings.Split(string(v.Metric[promModel.LabelName(resultKey)]), ":")[0],
			Values:   v.Values,
		}
		data = append(data, detail)
	}
	monitorLine.Data = data
	monitorLine.Message = "success"
	monitorLine.Code = 200
	return monitorLine, nil
}

// 获取数据库服务器列表
func (c *DatabaseServerService) ServerList(q *resourcepoolmodel.ServerListQuery) (resourcepoolmodel.ServerListPageData, error) {
	rst := resourcepoolmodel.ServerListPageData{}
	const limit = int(^uint16(0))
	serverListReq := dbmsmanager.ServerListParams{
		PageNo:   1,
		PageSize: limit,
		Id:       q.Id,
		Region:   q.Region,
		RunState: q.RunState,
		Az:       q.Az,
		Lab:      q.Lab,
	}

	serverListRst, err := dbmsmanager.GetServerList(serverListReq)
	if err != nil {
		klog.Error(err)
		return rst, err
	}
	if serverListRst.Code != 200 {
		klog.Info("get server list data from dbms error!")
		return rst, errors.New("get data from cmdb error")
	}
	for _, server := range serverListRst.Data.Data {
		if q.SearchKey != "" { //模糊搜索
			if q.SearchKey == "name" && q.SearchValue != "" {
				if match, _ := regexp.MatchString(q.SearchValue, server.Name); !match {
					continue
				}
			} else if q.SearchKey == "ip" && q.SearchValue != "" {
				if match, _ := regexp.MatchString(q.SearchValue, server.Ip); !match {
					continue
				}
			} else if q.SearchKey == "sn" && q.SearchValue != "" {
				if match, _ := regexp.MatchString(q.SearchValue, server.Sn); !match {
					continue
				}
			}
		}

		dbServer := resourcepoolmodel.DBServer{}
		dbServer.Name = server.Name
		//dbServer.State = server.RunState
		upQuery := temp.NewServerMetics(server.Ip+":9100", "", 0).ToString("server_up")
		up, err := client.VectorQuery(upQuery)
		if err != nil {
			klog.Info(err)
		}
		dbServer.State = "down"
		for _, v := range up {
			if math.IsNaN(float64(v.Value)) {
				v.Value = 0
			}
			if float64(v.Value) == 1 {
				dbServer.State = "up"
			} else {
				dbServer.State = "down"
			}
		}

		dbServer.Region = server.Region
		dbServer.Az = server.Az
		dbServer.Lab = server.LabName
		dbServer.IP = server.Ip
		dbServer.Sn = server.Sn
		//dbServer.CPUTotal = server.Performance.CPUTotal

		host, _ := cmdbmanager.GetHostDetailByIP(server.Ip)
		dbServer.CPUTotal = host.CpuTotal

		dbServer.CPUUnused = server.Performance.CPUUnused
		//dbServer.CPUUsedPercent = server.Performance.CPUUsedPercent

		//cpu load
		cpuQuery := temp.NewServerMetics(server.Ip+":9100", "", 0).ToString("server_cpu_usage_rate")
		cpu, err := client.VectorQuery(cpuQuery)
		if err != nil {
			klog.Info(err)
		}
		for _, v := range cpu {
			if math.IsNaN(float64(v.Value)) {
				v.Value = 0
			}
			dbServer.CPUUsedPercent = services.FormPercent(float64(v.Value))
		}
		//dbServer.MemoryTotal = server.Performance.MemoryTotal / 1024
		mt, _ := prom.PrometheusQuery2(false, "", "", "", `node_memory_MemTotal_bytes{instance=~"`+server.Ip+`:9100"}`)
		if len(mt) > 0 {
			oo := mt[0].(map[string]interface{})
			if valueData, ok := oo["value"]; ok {
				value := valueData.([]interface{})
				vv, _ := strconv.ParseFloat(value[1].(string), 64)
				i, _ := strconv.Atoi(fmt.Sprintf("%1.0f", vv))
				dbServer.MemoryTotal = i / 1024 / 1024 / 1024
			}
		}

		//dbServer.MemoryUnused = server.Performance.MemoryUnused / 1024
		m, _ := prom.PrometheusQuery2(false, "", "", "", `node_memory_MemAvailable_bytes{instance=~"`+server.Ip+`:9100"}`)
		if len(m) > 0 {
			oo := m[0].(map[string]interface{})
			if valueData, ok := oo["value"]; ok {
				value := valueData.([]interface{})
				vv, _ := strconv.ParseFloat(value[1].(string), 64)
				i, _ := strconv.Atoi(fmt.Sprintf("%1.0f", vv))
				dbServer.MemoryUnused = i / 1024 / 1024 / 1024
			}
		}

		//dbServer.MemoryUsedPercent = server.Performance.MemoryUsedPercent
		memQuery := temp.NewServerMetics(server.Ip+":9100", "", 0).ToString("server_memory_usage_rate")
		mem, err := client.VectorQuery(memQuery)
		if err != nil {
			klog.Info(err)
		}
		for _, v := range mem {
			if math.IsNaN(float64(v.Value)) {
				v.Value = 0
			}
			dbServer.MemoryUsedPercent = services.FormPercent(float64(v.Value))
		}

		dbServer.DiskTotal = server.Performance.DiskTotal
		//dbServer.DiskUnused = server.Performance.DiskUnused
		c, _ := prom.PrometheusQuery2(false, "", "", "", `node_filesystem_avail_bytes{instance=~"`+server.Ip+`:9100"`+`,fstype!~"(tmpfs|rootfs)"}`)
		if len(c) > 0 {
			oo := c[0].(map[string]interface{})
			if valueData, ok := oo["value"]; ok {
				value := valueData.([]interface{})
				vv, _ := strconv.ParseFloat(value[1].(string), 64)
				i, _ := strconv.Atoi(fmt.Sprintf("%1.0f", vv))
				dbServer.DiskUnused = i / 1024 / 1024 / 1024
			}
		}

		//dbServer.DiskUsedPercent = server.Performance.DiskUsedPercent
		diskQuery := temp.NewServerMetics(server.Ip+":9100", "", 0).ToString("server_disk_usage_rate")
		klog.Infof("diskQuerydiskQuery ", diskQuery)
		disk, err := client.VectorQuery(diskQuery)
		klog.Infof("diskVectorQuery ", disk)

		if err != nil {
			klog.Info(err)
		}
		for _, v := range disk {
			if math.IsNaN(float64(v.Value)) {
				v.Value = 0
			}
			klog.Infof("dbServer.DiskUsedPercent", float64(v.Value))
			dbServer.DiskUsedPercent = services.FormPercent(float64(v.Value))
		}
		dbServer.CreateTime = server.CreateTime

		resourceTypeCode := []string{"physicalResource"}
		resourceSubTypeCode := []string{"physicalServer"}
		t := alertmodel.AlertQuery{PageNo: 1, PageSize: 10000, ResourceTypeCode: resourceTypeCode, ResourceSubTypeCode: resourceSubTypeCode, Az: q.Az, AlertInstance: server.Ip + `:9100`}
		res, err := alert.GetAlertsDataListPage(t)
		if err != nil {
			klog.Error(err)
			dbServer.AlertNumber = 0
		} else {
			dbServer.AlertNumber = len(res.DataList)
		}

		rst.DataList = append(rst.DataList, dbServer)
	}

	//order
	if q.OrderCode != "" && q.OrderType != "" {
		results := alert.Bucket{}
		for i := 0; i < len(rst.DataList); i++ {
			results.Slice = append(results.Slice, rst.DataList[i])
		}
		time_by := func(a, b interface{}) bool {
			return a.(resourcepoolmodel.DBServer).CreateTime > b.(resourcepoolmodel.DBServer).CreateTime
		}

		switch q.OrderCode {

		case "cpuTotal":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).CPUTotal < b.(resourcepoolmodel.DBServer).CPUTotal
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).CPUTotal > b.(resourcepoolmodel.DBServer).CPUTotal
				}
			}
		case "cpuUnused":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).CPUUnused < b.(resourcepoolmodel.DBServer).CPUUnused
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).CPUUnused > b.(resourcepoolmodel.DBServer).CPUUnused
				}
			}
		case "cpuUsedPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).CPUUsedPercent < b.(resourcepoolmodel.DBServer).CPUUsedPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).CPUUsedPercent > b.(resourcepoolmodel.DBServer).CPUUsedPercent
				}
			}

		case "memoryTotal":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).MemoryTotal < b.(resourcepoolmodel.DBServer).MemoryTotal
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).MemoryTotal > b.(resourcepoolmodel.DBServer).MemoryTotal
				}
			}
		case "memoryUnused":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).MemoryUnused < b.(resourcepoolmodel.DBServer).MemoryUnused
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).MemoryUnused > b.(resourcepoolmodel.DBServer).MemoryUnused
				}
			}

		case "memoryUsedPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).MemoryUsedPercent < b.(resourcepoolmodel.DBServer).MemoryUsedPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).MemoryUsedPercent > b.(resourcepoolmodel.DBServer).MemoryUsedPercent
				}
			}

		case "diskTotal":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).DiskTotal < b.(resourcepoolmodel.DBServer).DiskTotal
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).DiskTotal > b.(resourcepoolmodel.DBServer).DiskTotal
				}
			}
		case "diskUnused":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).DiskUnused < b.(resourcepoolmodel.DBServer).DiskUnused
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).DiskUnused > b.(resourcepoolmodel.DBServer).DiskUnused
				}
			}

		case "diskUsedPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).DiskUsedPercent < b.(resourcepoolmodel.DBServer).DiskUsedPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).DiskUsedPercent > b.(resourcepoolmodel.DBServer).DiskUsedPercent
				}
			}

		case "createTime":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).CreateTime < b.(resourcepoolmodel.DBServer).CreateTime
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.DBServer).CreateTime > b.(resourcepoolmodel.DBServer).CreateTime
				}
			}

		}
		results.By = time_by
		sort.Sort(results)
		for i := 0; i < len(results.Slice); i++ {
			rst.DataList[i] = results.Slice[i].(resourcepoolmodel.DBServer)
		}
	}

	low := (q.PageNo - 1) * q.PageSize
	if low > len(rst.DataList) {
		return rst, nil
	}
	hight := low + q.PageSize
	if hight > len(rst.DataList) {
		hight = len(rst.DataList)
	}
	rst.PageNo = q.PageNo
	rst.PageSize = q.PageSize
	rst.TotalCount = len(rst.DataList)
	rst.DataList = rst.DataList[low:hight]
	return rst, nil
}

// 获取数据库服务器列表
func (c *DatabaseServerService) InstanceList(q *resourcepoolmodel.InstanceListQuery) (resourcepoolmodel.InstanceListPageData, error) {
	rst := resourcepoolmodel.InstanceListPageData{}
	const limit = int(^uint16(0))
	instanceParam := dbmsmanager.QueryInstanceList{
		ID:       q.Id,
		PageNo:   1,
		PageSize: limit,
	}
	instanceList, err := dbmsmanager.GetDBInstanceList(instanceParam)
	klog.Infof("instanceList count %d", instanceList.Data.Total)
	if err != nil {
		return rst, errors.New("Failed to get resource pool instance")
	}

	for _, instance := range instanceList.Data.Data {
		if len(q.RunState) > 0 && !services.In(q.RunState, DBInstanceStatusMapping[instance.Status]) {
			continue
		}
		if len(q.TenantIdList) > 0 && !services.In(q.TenantIdList, instance.TenantID) {
			continue
		}
		if len(q.TenantNameList) > 0 && !services.In(q.TenantNameList, instance.TenantName) {
			continue
		}
		if len(q.Az) > 0 && !services.In(q.Az, instance.AzCode) {
			continue
		}

		if q.SearchKey != "" { //模糊搜索
			if q.SearchKey == "id" && q.SearchValue != "" {
				if match, _ := regexp.MatchString(q.SearchValue, instance.ID); !match {
					continue
				}
			} else if q.SearchKey == "name" && q.SearchValue != "" {
				if match, _ := regexp.MatchString(q.SearchValue, instance.Name); !match {
					continue
				}
			} else if q.SearchKey == "ip" && q.SearchValue != "" {
				if match, _ := regexp.MatchString(q.SearchValue, instance.IP); !match {
					continue
				}
			} else if q.SearchKey == "tenantId" && q.SearchValue != "" {
				if match, _ := regexp.MatchString(q.SearchValue, instance.TenantID); !match {
					continue
				}
			} else if q.SearchKey == "tenantName" && q.SearchValue != "" {
				if match, _ := regexp.MatchString(q.SearchValue, instance.TenantName); !match {
					continue
				}
			}
		}

		monitorInstance := resourcepoolmodel.InstanceMonitor{}
		monitorInstance.ID = instance.ID
		monitorInstance.Name = instance.Name
		monitorInstance.DbType = instance.DbType
		monitorInstance.Status = DBInstanceStatusMapping[instance.Status]
		monitorInstance.TenantId = instance.TenantID
		monitorInstance.TenantName = instance.TenantName
		monitorInstance.Ip = instance.IP
		monitorInstance.Region = instance.RegionName
		monitorInstance.Az = instance.AzName
		monitorInstance.AzCode = instance.AzCode
		monitorInstance.CreateTime = instance.ServiceBeginTime
		rst.DataList = append(rst.DataList, monitorInstance)
	}

	setOrderMetricsInfo(&rst.DataList, q.OrderCode)
	//order
	if q.OrderCode != "" && q.OrderType != "" {
		orderList := alert.Bucket{}
		for i := 0; i < len(rst.DataList); i++ {
			orderList.Slice = append(orderList.Slice, rst.DataList[i])
		}
		time_by := func(a, b interface{}) bool {
			return a.(resourcepoolmodel.InstanceMonitor).CreateTime > b.(resourcepoolmodel.InstanceMonitor).CreateTime
		}

		switch q.OrderCode {
		case "cpuUsedPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).CPUUsedPercent < b.(resourcepoolmodel.InstanceMonitor).CPUUsedPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).CPUUsedPercent > b.(resourcepoolmodel.InstanceMonitor).CPUUsedPercent
				}
			}

		case "memoryUsedPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).MemoryUsedPercent < b.(resourcepoolmodel.InstanceMonitor).MemoryUsedPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).MemoryUsedPercent > b.(resourcepoolmodel.InstanceMonitor).MemoryUsedPercent
				}
			}

		case "iops":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).IOPS < b.(resourcepoolmodel.InstanceMonitor).IOPS
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).IOPS > b.(resourcepoolmodel.InstanceMonitor).IOPS
				}
			}

		case "netInput":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).NetInput < b.(resourcepoolmodel.InstanceMonitor).NetInput
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).NetInput > b.(resourcepoolmodel.InstanceMonitor).NetInput
				}
			}

		case "netOutput":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).NetOutput < b.(resourcepoolmodel.InstanceMonitor).NetOutput
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).NetOutput > b.(resourcepoolmodel.InstanceMonitor).NetOutput
				}
			}

		case "connect":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).Connect < b.(resourcepoolmodel.InstanceMonitor).Connect
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).Connect > b.(resourcepoolmodel.InstanceMonitor).Connect
				}
			}

		case "qps":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).QPS < b.(resourcepoolmodel.InstanceMonitor).QPS
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).QPS > b.(resourcepoolmodel.InstanceMonitor).QPS
				}
			}

		case "tps":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).TPS < b.(resourcepoolmodel.InstanceMonitor).TPS
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).TPS > b.(resourcepoolmodel.InstanceMonitor).TPS
				}
			}

		case "createTime":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).CreateTime < b.(resourcepoolmodel.InstanceMonitor).CreateTime
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(resourcepoolmodel.InstanceMonitor).CreateTime > b.(resourcepoolmodel.InstanceMonitor).CreateTime
				}
			}

		}

		orderList.By = time_by
		sort.Sort(orderList)

		for i := 0; i < len(orderList.Slice); i++ {
			rst.DataList[i] = orderList.Slice[i].(resourcepoolmodel.InstanceMonitor)
		}

	}

	low := (q.PageNo - 1) * q.PageSize
	if low > len(rst.DataList) {
		return rst, nil
	}
	hight := low + q.PageSize
	if hight > len(rst.DataList) {
		hight = len(rst.DataList)
	}
	rst.PageNo = q.PageNo
	rst.PageSize = q.PageSize
	rst.TotalCount = len(rst.DataList)
	rst.DataList = rst.DataList[low:hight]
	setMetricsInfo(&rst.DataList)
	return rst, nil
}

func getAbnormalCnt(s []interface{}) int {
	cnt := 0
	for _, s := range s {
		if v, ok := s.(dbmsmodel.Server); ok {
			if v.RunState == "down" {
				cnt++
			}
		} else if v, ok := s.(dbmsmodel.DBInstance); ok {
			if v.Status == "down" {
				cnt++
			}
		}

	}
	return cnt
}

// 获取数据库使用率

func GerDatabaseRate(param *resourcepoolmodel.DatabaseOverviewLineQuery, list []dbmsmodel.DBResourcePool, name, promQl string) (res resourcepoolmodel.LineData, err error) {

	start := param.Start / 1e3
	end := param.End / 1e3
	step := services.TimeToStepForInt(end - start)
	klog.Errorf("start: %v; end: %v; step: %v", param.Start/1e3, param.End/1e3, step)

	res.Info = resourcepoolmodel.MetricLineInfo{
		Name:     name,
		Unit:     "%",
		UnitType: "percent",
	}
	res.Poll = []resourcepoolmodel.Poll{}
	for _, vv := range list {
		paramLabel := &resourcepoolmodel.MysqlLable{
			Region:           param.Region,
			ResourcePoolType: vv.ResourcePoolType,
			ResourcePool:     vv.Name,
		}
		label := MysqlbuildCommonCondition(paramLabel)
		klog.Infof("label :%s", label)

		values, err := client.MatrixQuery(databaseResourcePool.NewDatabaseMetics(label).ToString(promQl), v1.Range{
			Start: time.Unix(start, 0),
			End:   time.Unix(end, 0),
			Step:  time.Duration(step) * time.Second,
		})
		if err != nil {
			klog.Errorf("Failed to get %s usage: %s", name, err.Error())
			continue
		}

		// 实际数据
		poolValues := []services.ValueType{}
		for _, i := range values {
			for _, j := range i.Values {
				timeStr := time.Unix(j.Timestamp.Unix(), 0).Format("2006-01-02 15:04:05")
				rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: services.FormPercent(j.Value.String()), IsForecast: false, Day: timeStr}
				poolValues = append(poolValues, rr)
			}
		}

		if len(poolValues) == 0 {
			klog.Errorf("%s Data parsing failed ", name)
			continue
		}
		// 补充开头
		repairFirstList := []services.ValueType{}
		first := poolValues[0].TimeSteamp.(string) // 实际第一条时间
		repairFirstTime, _ := strconv.ParseInt(first, 10, 64)
		firstStep := int64(step)

		for n := start; n < repairFirstTime; n += firstStep {
			repairFirst := services.ValueType{
				Name:       strconv.FormatInt(n, 10),
				TimeSteamp: strconv.FormatInt(n, 10),
				IsForecast: false,
				Day:        time.Unix(n, 0).Format("2006-01-02 15:04:05"),
			}
			//fmt.Println("repairFirstrepairFirst",repairFirst)
			repairFirstList = append(repairFirstList, repairFirst)
		}

		//补充中间
		var repairMiddleList = []services.ValueType{}
		var poolValuesLen = len(poolValues)

		for i := 0; i < poolValuesLen; i++ {
			repairMiddleList = append(repairMiddleList, poolValues[i])
			// 最后一个取样点
			if i >= poolValuesLen-1 {
				break
			}
			// 当前取样点时间
			currentTimeStr := poolValues[i].TimeSteamp.(string)
			currentTimeInt, _ := strconv.Atoi(currentTimeStr)
			// 下一取样点时间
			nextTimeStr := poolValues[i+1].TimeSteamp.(string)
			nexTimeInt, _ := strconv.Atoi(nextTimeStr)

			// 如果下一取样点时间与当前取样点时间 <= step，即没有断点
			if nexTimeInt-currentTimeInt <= step {
				continue
			}
			// 处理断点
			for t := currentTimeInt + step; t < nexTimeInt; t += step {
				strT := strconv.Itoa(t)
				middleInfo := services.ValueType{
					TimeSteamp: strT,
					IsForecast: false,
				}
				repairMiddleList = append(repairMiddleList, middleInfo)
			}
		}

		// 补充结尾
		repairLastList := []services.ValueType{}
		last := poolValues[len(poolValues)-1].TimeSteamp.(string) // 实际最后一条时间
		repairLastTime, _ := strconv.ParseInt(last, 10, 64)

		for m := repairLastTime + firstStep; m <= end; m += firstStep {
			repairLast := services.ValueType{
				Name:       strconv.FormatInt(m, 10),
				TimeSteamp: strconv.FormatInt(m, 10),
				IsForecast: false,
				Day:        time.Unix(m, 0).Format("2006-01-02 15:04:05"),
			}
			repairLastList = append(repairLastList, repairLast)
		}

		repairFirstList = append(repairFirstList, repairMiddleList...)
		repairFirstList = append(repairFirstList, repairLastList...)

		// todo 计算预测时间key
		var prognosis int

		//选择日期范围 大于7天的 取监控数据最新7天的数据
		var forecastList []services.ValueType
		if end-start > 7*86400 && len(repairFirstList) >= 7 { // 时间间隔大于7天的
			lens := len(repairFirstList)
			forecastList = repairFirstList[lens-8:]
			prognosis = len(repairFirstList)
		} else {
			forecastList = repairFirstList
			prognosis = len(forecastList) - 1
		}

		//获取实际数据的时间间隔
		latestTimeStr := forecastList[len(forecastList)-1].TimeSteamp.(string)
		latesTime, _ := strconv.ParseInt(latestTimeStr, 10, 64)
		firstTimeStr := forecastList[0].TimeSteamp.(string)
		firstTime, _ := strconv.ParseInt(firstTimeStr, 10, 64)
		duration := latesTime - firstTime

		//todo 获取预测波形图
		prediction := GetPredictionWaveform(forecastList, duration, step)
		repairFirstList = append(repairFirstList, prediction...)

		poolInfo := resourcepoolmodel.PollOverviewInfo{
			Name:      vv.Name,
			Prognosis: prognosis, // 预测数据标识
		}

		poolpool := resourcepoolmodel.Poll{
			Info:   poolInfo,
			Values: repairFirstList,
		}
		res.Poll = append(res.Poll, poolpool)
	}

	return res, nil
}

//// 获取内存使用率
//func MemRate(list []resourcepoolmodel.ResourcePoolInfo, name, lable string, start, end int64, step int) (res resourcepoolmodel.LineData, err error) {
//
//	res.Poll = []resourcepoolmodel.Poll{}
//
//	for _, vv := range list {
//
//		values, err := client.MatrixQuery(databaseResourcePool.NewDatabaseMetics(lable, vv.ServersIps).ToString("node_cpu_seconds_total"), v1.Range{
//			Start: time.Unix(start, 0),
//			End:   time.Unix(end, 0),
//			Step:  time.Duration(step) * time.Second,
//		})
//		if err != nil {
//			klog.Errorf("获取内存使用率数据失败", err)
//			return res, err
//		}
//		poolValues := []services.ValueType{}
//
//		for _, i := range values {
//			for _, j := range i.Values {
//				rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: services.FormPercent(j.Value.String())}
//				poolValues = append(poolValues, rr)
//			}
//		}
//
//		poolInfo := resourcepoolmodel.PollOverviewInfo{
//			Name: vv.ResourcePoolName,
//		}
//
//		poolpool := resourcepoolmodel.Poll{
//			Info:   poolInfo,
//			Values: poolValues,
//		}
//		res.Poll = append(res.Poll, poolpool)
//
//	}
//
//	return res, nil
//}
//
//// 获取磁盘使用率
//func DiskRate(list []resourcepoolmodel.ResourcePoolInfo, name, lable string, start, end int64, step int) (res resourcepoolmodel.LineData, err error) {
//
//	res.Info = resourcepoolmodel.MetricLineInfo{
//		Name:     name,
//		Unit:     "%",
//		UnitType: "percent",
//	}
//
//	res.Poll = []resourcepoolmodel.Poll{}
//
//	fmt.Println("1212121wesl;dsl;d;sld;sd;ll")
//	for _, vv := range list {
//
//		values, err := client.MatrixQuery(databaseResourcePool.NewDatabaseMetics(lable, vv.ServersIps).ToString("node_filesystem_free_bytes"), v1.Range{
//			Start: time.Unix(start, 0),
//			End:   time.Unix(end, 0),
//			Step:  time.Duration(step) * time.Second,
//		})
//		if err != nil {
//			klog.Errorf("获取磁盘使用率数据失败", err)
//			return res, err
//		}
//		poolValues := []services.ValueType{}
//
//		for _, i := range values {
//			for _, j := range i.Values {
//				rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: services.FormPercent(j.Value.String())}
//				poolValues = append(poolValues, rr)
//			}
//		}
//
//		poolInfo := resourcepoolmodel.PollOverviewInfo{
//			Name: vv.ResourcePoolName,
//		}
//
//		poolpool := resourcepoolmodel.Poll{
//			Info:   poolInfo,
//			Values: poolValues,
//		}
//		res.Poll = append(res.Poll, poolpool)
//	}
//
//	return res, nil
//}

// 获取列表使用率
func DBPollLitsRate(region, poolName, promQl string, ipList []string) (rate float64) {

	paramLabel := &resourcepoolmodel.MysqlLable{
		Region:       region,
		ResourcePool: poolName,
		IPList:       ipList,
	}
	label := MysqlbuildCommonCondition(paramLabel)

	klog.Infof("DBPollLitsRate label[%s] of %s is: %s", promQl, poolName, label)

	// 取一段时间内（10m）最后一个时间点的数据，避免查不到数据的问题

	start := time.Now().Add(time.Minute * (-10))
	end := time.Now()

	step := 1 * time.Minute
	queryRes, err := client.MatrixQuery(databaseResourcePool.NewDatabaseMetics(label).ToString(promQl), v1.Range{
		Start: start,
		End:   end,
		Step:  step,
	})
	if err != nil {
		klog.Errorf("Failed to get  poolName[%s] value of %s, err: %s\n", poolName, region, err.Error())
		return
	}

	if len(queryRes) == 0 {
		klog.Infof("MatrixQuery result of pool[%v] is empty.\n", poolName)
		return
	}
	// 取最后一个元素
	resSamplePair := queryRes[len(queryRes)-1]
	if len(resSamplePair.Values) == 0 {
		klog.Infof("MatrixQuery SamplePair result of pool[%v] is empty.\n", poolName)
		return
	}

	klog.Infof("MatrixQuery result of pool[%v]: %v\n", poolName, queryRes)

	resSampleValue := resSamplePair.Values[0].Value
	if math.IsNaN(float64(resSampleValue)) {
		rate = 0
	} else {
		rate = services.FormPercent(float64(resSampleValue))
	}

	return
}

func GetPredictionWaveform(poolValues []services.ValueType, duration int64, step int) (res []services.ValueType) {

	// 实际数据中最后一个采样点Yn
	var latestPointRate float64
	if poolValues[len(poolValues)-1].Value != nil {
		latestPointRate = poolValues[len(poolValues)-1].Value.(float64)
	}

	for i := 0; i < len(poolValues)-1; i++ {
		// 实际数据中第一采样点Ym
		var startPoint = poolValues[i]
		var t, _ = strconv.Atoi(startPoint.TimeSteamp.(string))

		// 预测采样点时间
		var timestamp = t + int(duration) + step
		timestampStr := strconv.Itoa(timestamp)

		timeStr := time.Unix(int64(timestamp), 0).Format("2006-01-02 15:04:05")
		forecast := services.ValueType{Name: timestampStr, TimeSteamp: timestampStr, IsForecast: true, Day: timeStr}
		if startPoint.Value == nil {
			res = append(res, forecast)
			continue
		}

		var startPointRate = startPoint.Value.(float64)
		if startPointRate == 0 {
			latestPointRate = 0
		} else if startPointRate > latestPointRate {
			latestPointRate = startPointRate
		} else {
			// 获取采样点总数量
			pointNum, _ := strconv.ParseFloat(strconv.Itoa(len(poolValues)), 64)
			latestPointRate += (latestPointRate - startPointRate) / pointNum
		}

		forecast.Value = services.FormPercent(latestPointRate)
		res = append(res, forecast)
	}

	return res

}

func setMetricsInfo(instances *[]resourcepoolmodel.InstanceMonitor) error {
	for i, inst := range *instances {
		host := fmt.Sprintf("kscrds--%s", inst.ID)
		//host = "kscrds--aa1411ef-571e-41cc-a46f-b68d9c2da638"
		tag := map[string]string{
			"host": host,
		}
		cpuQuery := kts.LastQuery{
			Metric: "rds.cpu_used_percent" + "." + host,
			Tags:   tag,
		}
		memQuery := kts.LastQuery{
			Metric: "rds.memory_used_percent" + "." + host,
			Tags:   tag,
		}
		riopsQuery := kts.LastQuery{
			Metric: "rds.riops" + "." + host,
			Tags:   tag,
		}
		wiopsQuery := kts.LastQuery{
			Metric: "rds.wiops" + "." + host,
			Tags:   tag,
		}
		recQuery := kts.LastQuery{
			Metric: "rds.bytes_received" + "." + host,
			Tags:   tag,
		}
		sentQuery := kts.LastQuery{
			Metric: "rds.bytes_sent" + "." + host,
			Tags:   tag,
		}
		connQuery := kts.LastQuery{
			Metric: "rds.threads_connected" + "." + host,
			Tags:   tag,
		}
		qpsQuery := kts.LastQuery{
			Metric: "rds.qps" + "." + host,
			Tags:   tag,
		}
		tpsQuery := kts.LastQuery{
			Metric: "rds.tps" + "." + host,
			Tags:   tag,
		}
		var queries = []kts.LastQuery{cpuQuery, memQuery, riopsQuery, wiopsQuery, recQuery, sentQuery, connQuery, qpsQuery, tpsQuery}
		metricsMap, err := kts.TSDBLastQueryBatch(queries...)
		if err != nil {
			klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			//return err
			continue
		}

		cpu := metricsMap[cpuQuery.Metric].Value
		mem := metricsMap[memQuery.Metric].Value
		riops := metricsMap[riopsQuery.Metric].Value
		wiops := metricsMap[wiopsQuery.Metric].Value

		rec := metricsMap[recQuery.Metric].Value
		sent := metricsMap[sentQuery.Metric].Value
		conn := metricsMap[connQuery.Metric].Value
		qps := metricsMap[qpsQuery.Metric].Value
		tps := metricsMap[tpsQuery.Metric].Value

		vcpu, _ := strconv.ParseFloat(cpu, 64)
		(*instances)[i].CPUUsedPercent = services.FormPercent(vcpu / 1e2)
		vmem, _ := strconv.ParseFloat(mem, 64)
		(*instances)[i].MemoryUsedPercent = services.FormPercent(vmem / 1e2)

		vriops, _ := strconv.Atoi(riops)
		vwiops, _ := strconv.Atoi(wiops)
		(*instances)[i].IOPS = int64(vriops + vwiops)

		(*instances)[i].NetInput, _ = strconv.ParseFloat(rec, 64)
		(*instances)[i].NetOutput, _ = strconv.ParseFloat(sent, 64)
		(*instances)[i].Connect, _ = strconv.ParseInt(conn, 10, 64)
		(*instances)[i].QPS, _ = strconv.ParseInt(qps, 10, 64)
		(*instances)[i].TPS, _ = strconv.ParseInt(tps, 10, 64)

	}
	return nil
}

func setOrderMetricsInfo(instances *[]resourcepoolmodel.InstanceMonitor, orderField string) error {
	if orderField == "createTime" || orderField == "" {
		return nil
	}

	for i, inst := range *instances {
		metricMap := mysqlMetricMap
		if inst.DbType == "redis" {
			metricMap = redisMetricMap
		}
		host := fmt.Sprintf("%s--%s", metricMap["host"], inst.ID)
		//host = "kscrds--aa1411ef-571e-41cc-a46f-b68d9c2da638"
		tag := map[string]string{
			"host": host,
		}

		switch orderField {
		case "cpuUsedPercent":
			cpuQuery := kts.LastQuery{
				Metric: "rds.cpu_used_percent" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{cpuQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				cpu := metricsMap[cpuQuery.Metric].Value
				vcpu, _ := strconv.ParseFloat(cpu, 64)
				(*instances)[i].CPUUsedPercent = services.FormPercent(vcpu / 1e2)
			}
		case "memoryUsedPercent":
			memQuery := kts.LastQuery{
				Metric: "rds.memory_used_percent" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{memQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				mem := metricsMap[memQuery.Metric].Value
				vmem, _ := strconv.ParseFloat(mem, 64)
				(*instances)[i].MemoryUsedPercent = services.FormPercent(vmem / 1e2)
			}
		case "iops":
			riopsQuery := kts.LastQuery{
				Metric: "rds.riops" + "." + host,
				Tags:   tag,
			}
			wiopsQuery := kts.LastQuery{
				Metric: "rds.wiops" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{riopsQuery, wiopsQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				riops := metricsMap[riopsQuery.Metric].Value
				wiops := metricsMap[wiopsQuery.Metric].Value
				vriops, _ := strconv.Atoi(riops)
				vwiops, _ := strconv.Atoi(wiops)
				(*instances)[i].IOPS = int64(vriops + vwiops)
			}
		case "netInput":
			recQuery := kts.LastQuery{
				Metric: "rds.bytes_received" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{recQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				rec := metricsMap[recQuery.Metric].Value
				(*instances)[i].NetInput, _ = strconv.ParseFloat(rec, 64)
			}

		case "netOutput":
			sentQuery := kts.LastQuery{
				Metric: "rds.bytes_sent" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{sentQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				sent := metricsMap[sentQuery.Metric].Value
				(*instances)[i].NetOutput, _ = strconv.ParseFloat(sent, 64)
			}
		case "connect":
			connQuery := kts.LastQuery{
				Metric: "rds.threads_connected" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{connQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				conn := metricsMap[connQuery.Metric].Value
				(*instances)[i].Connect, _ = strconv.ParseInt(conn, 10, 64)
			}
		case "qps":
			qpsQuery := kts.LastQuery{
				Metric: "rds.qps" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{qpsQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				qps := metricsMap[qpsQuery.Metric].Value
				(*instances)[i].QPS, _ = strconv.ParseInt(qps, 10, 64)
			}
		case "tps":
			tpsQuery := kts.LastQuery{
				Metric: "rds.tps" + "." + host,
				Tags:   tag,
			}
			metricsMap, err := kts.TSDBLastQueryBatch([]kts.LastQuery{tpsQuery}...)
			if err != nil {
				klog.Errorf("mysql tsdb metrics 查询错误，instanceId: %s", inst.ID)
			} else {
				tps := metricsMap[tpsQuery.Metric].Value
				(*instances)[i].TPS, _ = strconv.ParseInt(tps, 10, 64)
			}
		}

	}
	return nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/resourcepool/objectstorageservice.go
```golang
package resourcepoolservice

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"math"
	"net/http"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"time"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	objectmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/object"

	alertmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	"k8s.io/klog/v2"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"

	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/esmanager"
	prom "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	temp "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/resourcePool"
)

type IObjectPoolService interface {
	GetObjectPoolMetric(string) []resourcepoolmodel.MetricT
	//GetServerHardwareMetric(string) (servermodels.HardWare, error)
	//GetSwitchMetricLine(*switchmodels.SwitchMetricLineQuery) (map[string][]switchmodels.EchartType, error)
	GetObjectPoolOverview(*resourcepoolmodel.ObjectOverviewLineQuery) (resourcepoolmodel.ObjectOverView, error)
	GetObjectPoolOverviewLine(*resourcepoolmodel.OverviewLineQuery) ([]resourcepoolmodel.OverViewLine, error)
	GetObjectPoolList(*resourcepoolmodel.ListQuery) (resourcepoolmodel.ObjectStoragePoolListDataResult, error)
	GetObjectPoolUsageList(*resourcepoolmodel.ObjectStorageUsageQuery) (resourcepoolmodel.ObjectStoragePoolUsageResult, error)
	Test() interface{}
}

type ObjectPoolService struct {
}

func NewObjectPoolService() *ObjectPoolService {
	return &ObjectPoolService{}
}

func (b *ObjectPoolService) GetObjectPoolOverview(t *resourcepoolmodel.ObjectOverviewLineQuery) (resourcepoolmodel.ObjectOverView, error) {
	result := resourcepoolmodel.ObjectOverView{Region: t.Region}

	//获取告警数据
	alerts := make([]alertmodel.OverviewAlert, 0, 4)
	queryParam := alertmodel.AlertQuery{
		Filter: "",
		Module: "object",
	}
	if t.Region != "" && t.Region != "all" {
		queryParam.Filter = queryParam.Filter + "&filter=region=%22" + t.Region + "%22"
	}
	alertList, err := alert.GetCommonAlertOverviewNum(queryParam)
	if err != nil {
		return result, err
	}
	alerts = append(alerts, alertList...)

	//资源总揽
	overall := resourcepoolmodel.ObjectView{}
	storage := resourcepoolmodel.ChartInfo{}
	storage.Info.Name = "存储容量"
	storage.Info.Unit = "B"
	storage.Info.UnitType = "storage"

	percent := resourcepoolmodel.ChartInfo{}
	percent.Info.Name = "Bucket容量占比"
	percent.Info.Unit = "%"
	percent.Info.UnitType = "percent"

	number := resourcepoolmodel.ChartInfo{}
	number.Info.Name = "服务质量占比"
	number.Info.UnitType = "number"

	//资源池容量
	//storeMap := esmanager.GetBucketPoolStore()
	storeMap := esmanager.GetBucketPoolStoreAggr(t.Region)
	storageTypes := []string{"标准存储", "归档存储", "低频存储"}
	codes := []string{"2xx", "3xx", "4xx", "5xx"}

	if len(storeMap) > 0 {

		var tt float64
		for _, lable := range storageTypes {
			if v, ok := storeMap[lable]; ok {
				tt += v
				rrr := services.ValueType{Name: lable, Value: v}
				storage.Values = append(storage.Values, rrr)
			}
		}
		storage.Info.Total = services.Strval(tt)
		overall.Capacity = append(overall.Capacity, storage)

		for _, lable := range storageTypes {
			if v, ok := storeMap[lable]; ok {
				var per float64
				if tt > 0 {
					per = v / tt
				}
				rrr := services.ValueType{Name: lable, Value: prom.FormPercent(per)}
				percent.Values = append(percent.Values, rrr)
			}
		}
		overall.Bucket = append(overall.Bucket, percent)
	}
	//qs
	//codeMap := esmanager.GetBucketPoolCode()
	OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(esmanager.EsIndexDateFormat)
	oneDayAgoDate := strings.Split(OneDayAgo, ".")
	subIndex := oneDayAgoDate[0]
	codeMap := esmanager.GetBucketPoolCodeAggr(t.Region, subIndex)
	if len(codeMap) > 0 {
		var codeTotalCount int64
		for _, v := range codeMap {
			codeTotalCount += v

		}
		for _, code := range codes {
			if v, ok := codeMap[code]; ok {
				var percent float64
				if codeTotalCount > 0 {
					percent = float64(v / codeTotalCount)
				}
				rrr := services.ValueType{Name: code, Value: v, Percent: prom.FormPercent(percent)}
				number.Values = append(number.Values, rrr)
			}
		}
		number.Info.Total = codeTotalCount
		overall.Qs = append(overall.Qs, number)
	}

	result = resourcepoolmodel.ObjectOverView{t.Region, alerts, overall}
	return result, nil
}

var FlowInOutMap = map[string]string{
	"false": "内网",
	"true":  "内网",
}

var FlowCDNMap = map[string]string{
	"-":   "不确定流量",
	"kc":  "金山CDN",
	"bc":  "头条CDN",
	"crr": "跨区域复制",
}

func (b *ObjectPoolService) GetObjectPoolOverviewLine(t *resourcepoolmodel.OverviewLineQuery) ([]resourcepoolmodel.OverViewLine, error) {
	start := services.Strval(int(t.Start) / 1000)
	end := services.Strval(int(t.End) / 1000)
	step := services.TimeToStep(t.End/1000 - t.Start/1000)
	//start2 := time.Now().Add(time.Duration(-24*30) * time.Hour).Unix()
	//start := strconv.FormatInt(start2, 10)
	//end2 := time.Now().Add(time.Duration(-24*1) * time.Hour).Unix()
	//end := strconv.FormatInt(end2, 10)
	////duration := services.GetPromDuration(config.PromeTimeDurtion)
	lable := services.BuildCommonCondition(t.Region, t.Az, "resourcePoolType=\"ks3\"")

	responseMetric := []resourcepoolmodel.OverViewLine{}
	for i := 0; i < len(t.Name); i++ {
		switch t.Name[i] {
		case "stockCapacity":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i]}
			query := temp.NewPoolMetics(lable, "", "").ToString("object_pool_storage_stock")
			//l, err := prom.PrometheusQuery2(true, start, end, "86400", query)
			l, err := prom.PrometheusQuery2(true, start, end, step, query)
			if err != nil {
				klog.Error(err)
				return responseMetric, nil
			}
			for j := 0; j < len(l); j++ {
				rr := resourcepoolmodel.EchartType{}
				rr.Info.Name = "存储容量库存"
				rr.Info.Unit = "GB"
				rr.Info.UnitType = "storage"

				vv := prom.PrometheusResultToValue2(l[j])
				rr.Values = services.PromeForRangeValue2(vv)

				r.Echarts = append(r.Echarts, rr)
			}
			responseMetric = append(responseMetric, r)
		//case "stockCapacity":
		//	r := resourcepoolmodel.OverViewLine{Name: t.Name[i]}
		//	rr, err := esmanager.Get30Ks3Capacity(t.Region)
		//	if err != nil {
		//		klog.Info(err)
		//		return responseMetric, nil
		//	}
		//	r.Echarts = append(r.Echarts, rr...)
		//	responseMetric = append(responseMetric, r)
		case "bucket":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i]}
			echart := Get30BucketNumLineProm(t.Region)
			r.Echarts = append(r.Echarts, echart)
			responseMetric = append(responseMetric, r)
		case "bucket_old":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i]}
			rr, err := esmanager.Get30BucketNumLine()
			if err != nil {
				klog.Info(err)
				return responseMetric, nil
			}
			r.Echarts = append(r.Echarts, rr...)
			responseMetric = append(responseMetric, r)
		case "qs":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Unit: "个", UnitType: "number"}
			rr, err := esmanager.Get30CodeLine(t.Region)
			if err != nil {
				klog.Info(err)
				return responseMetric, nil
			}
			r.Echarts = append(r.Echarts, rr...)
			responseMetric = append(responseMetric, r)
		case "api":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Label: "api请求数", Unit: "个", UnitType: "number"}
			rr, err := esmanager.Get30ApiNumLine()
			if err != nil {
				klog.Info(err)
				return responseMetric, nil
			}
			r.Echarts = append(r.Echarts, rr...)
			responseMetric = append(responseMetric, r)
		case "requestNum":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Unit: "个", UnitType: "number"}
			rr, err := esmanager.Get30ApiLine(t.Region) //报错
			if err != nil {
				klog.Info(err)
				return responseMetric, nil
			}
			r.Echarts = append(r.Echarts, rr...)
			responseMetric = append(responseMetric, r)
		case "connectNum":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Unit: "个"}
			// l, _ := prom.PrometheusQuery2(true, start2, end2, t.Step, ``)

			// for j := 0; j < len(l); j++ {
			// 	rr := resourcepoolmodel.EchartType{}

			// 	//ll := l[j].(map[string]interface{})
			// 	//lll := ll["metric"].(map[string]interface{})

			// 	rr.Info.Name = "资源池连接数"

			// 	vv := prom.PrometheusResultToValue2(l[j])
			// 	rr.Values = services.PromeForRangeValue2(vv)

			// 	r.Echarts = append(r.Echarts, rr)
			// }
			responseMetric = append(responseMetric, r)
		case "band":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Label: "带宽", Unit: "Bps", UnitType: "stroage"}
			rr, err := esmanager.Get30BandLine(t.Region)
			if err != nil {
				klog.Info(err)
				return responseMetric, nil
			}
			r.Echarts = append(r.Echarts, rr...)
			responseMetric = append(responseMetric, r)
		case "flow":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Label: "流量", Unit: "B", UnitType: "storage"}
			rr, err := esmanager.Get30FlowLine(t.Region)
			if err != nil {
				klog.Info(err)
				return responseMetric, nil
			}
			r.Echarts = append(r.Echarts, rr...)
			responseMetric = append(responseMetric, r)
		case "capacityTrend":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Label: "资源池容量趋势", Unit: "GB", UnitType: "storage"}
			rr, err := GetCapacityTrendLine(start, end, step, t.Region)
			if err != nil {
				klog.Info(err)
				return responseMetric, nil
			}
			r.Echarts = append(r.Echarts, rr...)
			responseMetric = append(responseMetric, r)
		}
	}
	return responseMetric, nil
}

func GetCapacityTrendLine(start, end, step, region string) ([]resourcepoolmodel.EchartType, error) {
	echarts := make([]resourcepoolmodel.EchartType, 0)
	rangIf := true
	query := fmt.Sprintf(`sum(floor(storage_resource_pool_total{resourcePoolType="%v"}))`, "ks3")
	if region != "" && region != "all" {
		query = fmt.Sprintf(`sum(floor(storage_resource_pool_total{resourcePoolType="%v",region="%v"}))`, "ks3", region)
	}
	l, err := prom.PrometheusQuery2(rangIf, start, end, step, query)
	if err != nil {
		klog.Error(err)
		return echarts, nil
	}
	if len(l) > 0 {
		rr := resourcepoolmodel.EchartType{}
		rr.Info.Name = "总量"
		rr.Info.Label = "capTotal"
		rr.Info.Unit = "GB"
		rr.Info.UnitType = "storage"

		vv := prom.PrometheusResultToValue2(l[0])
		rr.Values = services.PromeForRangeValue2(vv)

		echarts = append(echarts, rr)
	}
	query = fmt.Sprintf(`sum(storage_resource_pool_usage{resourcePoolType="%v"})/(sum(storage_resource_pool_total{resourcePoolType="%v"})>0)`, "ks3", "ks3")
	if region != "" && region != "all" {
		query = fmt.Sprintf(`sum(storage_resource_pool_usage{resourcePoolType="%v",region="%v"})/(sum(storage_resource_pool_total{resourcePoolType="%v",region="%v"})>0)`, "ks3", region, "ks3", region)
	}
	l, err = prom.PrometheusQuery2(rangIf, start, end, step, query)
	if err != nil {
		klog.Error(err)
		return echarts, nil
	}
	if len(l) > 0 {
		rr := resourcepoolmodel.EchartType{}
		rr.Info.Name = "使用率"
		rr.Info.Label = "capUseRate"
		rr.Info.Unit = "%"
		rr.Info.UnitType = "percent"

		vv := prom.PrometheusResultToValue2(l[0])
		rr.Values = services.PromeForRangeValue2(vv)

		echarts = append(echarts, rr)

	}

	query = fmt.Sprintf(`sum(floor(storage_resource_pool_usage{resourcePoolType="%v"}))`, "ks3")
	if region != "" && region != "all" {
		query = fmt.Sprintf(`sum(floor(storage_resource_pool_usage{resourcePoolType="%v",region="%v"}))`, "ks3", region)
	}
	l, err = prom.PrometheusQuery2(rangIf, start, end, step, query)
	if err != nil {
		klog.Error(err)
		return echarts, nil
	}
	if len(l) > 0 {
		rr := resourcepoolmodel.EchartType{}
		rr.Info.Name = "使用量"
		rr.Info.Label = "capUsage"
		rr.Info.Unit = "GB"
		rr.Info.UnitType = "storage"

		vv := prom.PrometheusResultToValue2(l[0])
		rr.Values = services.PromeForRangeValue2(vv)

		echarts = append(echarts, rr)
	}
	return echarts, nil
}

//func GetCapacityTrendLine(start, end, step string) ([]resourcepoolmodel.EchartType, error) {
//	echarts := make([]resourcepoolmodel.EchartType, 0)
//	rangIf := true
//	echartsMap := make(map[string]resourcepoolmodel.EchartType, 0)
//
//	capTotal := resourcepoolmodel.EchartType{
//		Info: resourcepoolmodel.InfoType{
//			Name:     "总量",
//			Label:    "capTotal",
//			Unit:     "GB",
//			UnitType: "storage",
//		},
//	}
//	capUseRate := resourcepoolmodel.EchartType{
//		Info: resourcepoolmodel.InfoType{
//			Name:     "使用率",
//			Label:    "capTotal",
//			Unit:     "%",
//			UnitType: "percent",
//		},
//	}
//	capUsage := resourcepoolmodel.EchartType{
//		Info: resourcepoolmodel.InfoType{
//			Name:     "使用量",
//			Label:    "capUsage",
//			Unit:     "GB",
//			UnitType: "storage",
//		},
//	}
//	echartsMap["capTotal"] = capTotal
//	echartsMap["capUseRate"] = capUseRate
//	echartsMap["capUsage"] = capUsage
//
//	var wg sync.WaitGroup
//	wg.Add(3)
//	for key, _ := range echartsMap {
//		go func(name string) {
//			defer wg.Done()
//			var query string
//			switch name {
//			case "capTotal":
//				query = fmt.Sprintf(`floor(storage_resource_pool_total{resourcePoolName="%v"}/3)`, "ks3")
//			case "capUseRate":
//				query = fmt.Sprintf(`storage_resource_pool_usage{resourcePoolName="%v"}/storage_resource_pool_total{resourcePoolName="%v"}`, "ks3", "ks3")
//			case "capUsage":
//				query = fmt.Sprintf(`floor(storage_resource_pool_usage{resourcePoolName="%v"}/3)`, "ks3")
//			}
//			l, err := prom.PrometheusQuery2(rangIf, start, end, step, query)
//			if err != nil {
//				klog.Error(err)
//			}
//			vv := prom.PrometheusResultToValue2(l[0])
//			echart := echartsMap[name]
//			echart.Values = services.PromeForRangeValue2(vv)
//			echartsMap[name] = echart
//		}(key)
//	}
//	wg.Wait()
//	echarts = append(echarts, echartsMap["capTotal"], echartsMap["capUseRate"], echartsMap["capUsage"])
//	return echarts, nil
//}

func Get30BucketNumLineProm(region string) resourcepoolmodel.EchartType {
	lable := services.BuildCommonCondition(region, "")
	echart := resourcepoolmodel.EchartType{Info: resourcepoolmodel.InfoType{Unit: "个", UnitType: "number", Name: "bucket总量"}}
	query := temp.NewPoolMetics(lable, "", "").ToString("object_pool_bucket_count")
	for i := 30; i > 0; i-- {
		hourTime := -24 * i
		gtime := time.Now().Add(time.Duration(hourTime) * time.Hour)
		//gtime = time.Now()
		v := services.ValueType{
			Value:      0,
			Name:       gtime.Unix(),
			TimeSteamp: gtime.Unix(),
		}
		//从redis取数
		Index := strings.Split(gtime.Format(esmanager.EsIndexDateFormat), ".")[0]
		ctx, cefl := context.WithTimeout(context.Background(), 3*time.Minute)
		defer cefl()
		key := "objectStoragePool_bucket_num:" + region
		rs, err := client.HGet(ctx, key, Index)
		if err != nil {
			data, err := prom.GetRateData(query, gtime)
			if err != nil {
				klog.Error(err)
				echart.Values = append(echart.Values, v)
				continue
			}
			if len(data.Result) > 0 && data.Result[0].Value != "0" {
				v.Value = data.Result[0].Value
				client.HSet(ctx, key, Index, v.Value)
			}
			echart.Values = append(echart.Values, v)
			esmanager.DeleteExpireFields(ctx, key)
		} else {
			v.Value = rs
			echart.Values = append(echart.Values, v)
		}
	}
	return echart
}

// 获取对象存储资源池列表
func (b *ObjectPoolService) GetObjectPoolList(t *resourcepoolmodel.ListQuery) (resourcepoolmodel.ObjectStoragePoolListDataResult, error) {
	//从CMDB中获取资源池信息
	var objectStoragesResult resourcepoolmodel.ObjectStoragePoolListDataResult
	var objectRes []cmdbmodel.ObjectRe
	var objectStoragePoolResult cmdbmodel.ObjectStoragePoolResult
	objectStoragePoolResult, err := cmdbmanager.GetObjectStorageResourcePoolList(t.Region, t.Az, t.Name, strconv.Itoa(t.PageNo), strconv.Itoa(t.PageSize))
	if err != nil {
		klog.Error(err)
		return objectStoragesResult, nil
	}

	objectRes = objectStoragePoolResult.Data.DataList
	currentTime := time.Now()
	if len(objectRes) > 0 {
		objectStoragesResult.TotalCount = objectStoragePoolResult.Data.TotalCount
		for _, objectRe := range objectRes {
			var objectStorageMonitor resourcepoolmodel.ObjectStorageMonitor
			objectStorageMonitor.Id = objectRe.Id
			objectStorageMonitor.Name = objectRe.Name
			objectStorageMonitor.Region = objectRe.RegionName
			objectStorageMonitor.RegionCode = objectRe.RegionCode
			objectStorageMonitor.AzCode = objectRe.AzCode
			objectStorageMonitor.ResourcePool = objectRe.ResourcePool
			objectStorageMonitor.HostNumber = objectRe.HostNumber
			objectStorageMonitor.BucketNumber = objectRe.BucketNumber
			objectStorageMonitor.ObjectAmount = objectRe.ObjectNumber
			objectStorageMonitor.BucketAmount = objectRe.BucketNumber
			//objectStorageMonitor.Bandwidth = esmanager.GetBucketPoolBand()
			objectStorageMonitor.Bandwidth = esmanager.GetBucketPoolBandSum(objectRe.RegionCode)
			objectStorageMonitor.APIRequestAmount = esmanager.GetBucketPoolApiNumSum(objectRe.RegionCode)
			objectStorageMonitor.HttpRequestAmount = objectStorageMonitor.APIRequestAmount
			objectStorageMonitor.Flow = esmanager.Get30Flow(objectRe.RegionCode)
			objectStorageMonitor.AlertAmount = strconv.Itoa(alert.GetResourcePoolAlertNum(t.Region, "", "resourcePool", "ks3", objectRe.ResourcePool))
			objectStorageMonitor.CreateTime = objectRe.CreateTime
			objectStorageMonitor.Status = objectRe.Status
			objectStorageMonitor.ServerStatus = []resourcepoolmodel.ObjectStorageServerStatus{}
			for _, host := range objectRe.Servers {
				status := resourcepoolmodel.ObjectStorageServerStatus{}
				status.Address = host.Ip
				status.Role = host.Role
				status.Status = host.StatusMsg
				objectStorageMonitor.ServerStatus = append(objectStorageMonitor.ServerStatus, status)
			}

			OneDayAgo := time.Now().Add(time.Duration(-24 * time.Hour)).Format(esmanager.EsIndexDateFormat)
			oneDayAgoDate := strings.Split(OneDayAgo, ".")
			lastDayIndex := oneDayAgoDate[0]

			codeMap := esmanager.GetBucketPoolCodeAggr(objectRe.RegionCode, lastDayIndex)
			for k, v := range codeMap {
				if k == "4xx" || k == "5xx" {
					objectStorageMonitor.ErrorReturnAmount += v
				}
			}

			//模糊搜索
			nb, _ := regexp.MatchString(t.Name, objectRe.Name)
			if !nb {
				continue
			}

			CapacityTotal, err := prom.GetCapTotalMultiAz(objectRe.RegionCode, objectRe.AzCode, objectRe.Name, currentTime)
			if err != nil {
				klog.Error(err)
				return objectStoragesResult, nil
			}
			CapacityUsedTotal, err := prom.GetCapUsedMultiAz(objectRe.RegionCode, objectRe.AzCode, objectRe.Name, currentTime)
			if err != nil {
				klog.Error(err)
				return objectStoragesResult, nil
			}
			if len(CapacityTotal.Result) > 0 && len(CapacityTotal.Result[0].Values) > 0 {
				value := CapacityTotal.Result[0].Values[len(CapacityTotal.Result[0].Values)-1].([]interface{})
				v1, _ := strconv.ParseFloat(value[1].(string), 64)
				//objectStorageMonitor.CapacityTotal = v1
				objectStorageMonitor.CapacityTotal, _ = strconv.ParseFloat(fmt.Sprintf("%.0f", v1), 64)
			}
			if len(CapacityUsedTotal.Result) > 0 && len(CapacityUsedTotal.Result[0].Values) > 0 {
				value := CapacityUsedTotal.Result[0].Values[len(CapacityUsedTotal.Result[0].Values)-1].([]interface{})
				v2, _ := strconv.ParseFloat(value[1].(string), 64)
				objectStorageMonitor.CapacityUsedTotal, _ = strconv.ParseFloat(fmt.Sprintf("%.0f", v2), 64)
			}
			if objectStorageMonitor.CapacityTotal > 0 && objectStorageMonitor.CapacityUsedTotal < objectStorageMonitor.CapacityTotal {
				v3 := services.FormPercent(objectStorageMonitor.CapacityUsedTotal / objectStorageMonitor.CapacityTotal)
				objectStorageMonitor.CapacityUsedRate = v3 * 1e2
				objectStorageMonitor.CapacityAvailable = objectStorageMonitor.CapacityTotal - objectStorageMonitor.CapacityUsedTotal
			}

			objectStorageMonitor.MonitorStatus = "monitoring"
			if objectStorageMonitor.CapacityTotal <= 0 {
				objectStorageMonitor.MonitorStatus = "aAbnormal"
			}
			//多选
			if len(t.StorageType) != 0 {
				stateIn := services.In(t.StorageType, objectStorageMonitor.ResourcePool)
				if !stateIn {
					continue
				}
			}
			if len(t.MonitorStatus) != 0 {
				stateIn := services.In(t.MonitorStatus, objectStorageMonitor.MonitorStatus)
				if !stateIn {
					continue
				}
			}
			objectStoragesResult.DataList = append(objectStoragesResult.DataList, objectStorageMonitor)
		}
	}

	//分页
	low := (t.PageNo - 1) * t.PageSize
	if low > len(objectStoragesResult.DataList) {
		return objectStoragesResult, nil
	}

	hight := low + t.PageSize
	if hight > len(objectStoragesResult.DataList) {
		hight = len(objectStoragesResult.DataList)
	}

	objectStoragesResult.PageNo = t.PageNo
	objectStoragesResult.PageSize = t.PageSize
	objectStoragesResult.TotalCount = len(objectStoragesResult.DataList)
	objectStoragesResult.DataList = objectStoragesResult.DataList[low:hight]

	return objectStoragesResult, err
}

func (b *ObjectPoolService) GetObjectPoolBaseList(t *resourcepoolmodel.ListQuery) (resourcepoolmodel.ObjectStoragePoolListDataResult, error) {
	//从CMDB中获取资源池信息
	var objectStoragesResult resourcepoolmodel.ObjectStoragePoolListDataResult
	var objectRes []cmdbmodel.ObjectRe
	var objectStoragePoolResult cmdbmodel.ObjectStoragePoolResult
	objectStoragePoolResult, err := cmdbmanager.GetObjectStorageResourcePoolList(t.Region, t.Az, t.Name, strconv.Itoa(t.PageNo), strconv.Itoa(t.PageSize))
	if err != nil {
		klog.Error(err)
		return objectStoragesResult, nil
	}

	objectRes = objectStoragePoolResult.Data.DataList
	currentTime := time.Now()
	if len(objectRes) > 0 {
		objectStoragesResult.TotalCount = objectStoragePoolResult.Data.TotalCount
		for _, objectRe := range objectRes {
			var objectStorageMonitor resourcepoolmodel.ObjectStorageMonitor
			objectStorageMonitor.Id = objectRe.Id
			objectStorageMonitor.Name = objectRe.Name
			objectStorageMonitor.Region = objectRe.RegionName
			objectStorageMonitor.RegionCode = objectRe.RegionCode
			objectStorageMonitor.ResourcePool = objectRe.ResourcePool
			objectStorageMonitor.HostNumber = objectRe.HostNumber
			objectStorageMonitor.BucketNumber = objectRe.BucketNumber
			objectStorageMonitor.ObjectAmount = objectRe.ObjectNumber
			objectStorageMonitor.BucketAmount = objectRe.BucketNumber

			objectStorageMonitor.CreateTime = objectRe.CreateTime
			objectStorageMonitor.Status = objectRe.Status

			//模糊搜索
			nb, _ := regexp.MatchString(t.Name, objectRe.Name)
			if !nb {
				continue
			}

			CapacityTotal, err := prom.GetCapTotalMultiAz(objectRe.RegionCode, objectRe.AzCode, objectRe.Name, currentTime)
			if err != nil {
				klog.Error(err)
				return objectStoragesResult, nil
			}
			CapacityUsedTotal, err := prom.GetCapUsedMultiAz(objectRe.RegionCode, objectRe.AzCode, objectRe.Name, currentTime)
			if err != nil {
				klog.Error(err)
				return objectStoragesResult, nil
			}
			if len(CapacityTotal.Result) > 0 && len(CapacityTotal.Result[0].Values) > 0 {
				value := CapacityTotal.Result[0].Values[len(CapacityTotal.Result[0].Values)-1].([]interface{})
				v1, _ := strconv.ParseFloat(value[1].(string), 64)
				objectStorageMonitor.CapacityTotal = v1
			}
			if len(CapacityUsedTotal.Result) > 0 && len(CapacityUsedTotal.Result[0].Values) > 0 {
				value := CapacityUsedTotal.Result[0].Values[len(CapacityUsedTotal.Result[0].Values)-1].([]interface{})
				v2, _ := strconv.ParseFloat(value[1].(string), 64)
				objectStorageMonitor.CapacityUsedTotal = v2
			}
			if objectStorageMonitor.CapacityTotal > 0 && objectStorageMonitor.CapacityUsedTotal < objectStorageMonitor.CapacityTotal {
				v3 := services.FormPercent(objectStorageMonitor.CapacityUsedTotal / objectStorageMonitor.CapacityTotal)
				objectStorageMonitor.CapacityUsedRate = v3 * 1e2
				objectStorageMonitor.CapacityAvailable = objectStorageMonitor.CapacityTotal - objectStorageMonitor.CapacityUsedTotal
			}

			objectStorageMonitor.MonitorStatus = "monitoring"
			if objectStorageMonitor.CapacityTotal <= 0 {
				objectStorageMonitor.MonitorStatus = "aAbnormal"
			}
			//多选
			if len(t.StorageType) != 0 {
				stateIn := services.In(t.StorageType, objectStorageMonitor.ResourcePool)
				if !stateIn {
					continue
				}
			}
			if len(t.MonitorStatus) != 0 {
				stateIn := services.In(t.MonitorStatus, objectStorageMonitor.MonitorStatus)
				if !stateIn {
					continue
				}
			}
			objectStoragesResult.DataList = append(objectStoragesResult.DataList, objectStorageMonitor)
		}
	}

	//分页
	low := (t.PageNo - 1) * t.PageSize
	if low > len(objectStoragesResult.DataList) {
		return objectStoragesResult, nil
	}

	hight := low + t.PageSize
	if hight > len(objectStoragesResult.DataList) {
		hight = len(objectStoragesResult.DataList)
	}

	objectStoragesResult.PageNo = t.PageNo
	objectStoragesResult.PageSize = t.PageSize
	objectStoragesResult.TotalCount = len(objectStoragesResult.DataList)
	objectStoragesResult.DataList = objectStoragesResult.DataList[low:hight]

	return objectStoragesResult, err
}

func (b *ObjectPoolService) GetObjectPoolMetric(id string) (rst []resourcepoolmodel.MetricT) {
	q := resourcepoolmodel.ListQuery{PageNo: 1, PageSize: 1000, Region: "all"}
	idd, _ := strconv.Atoi(id)

	//获取对象存储列表
	list, err := b.GetObjectPoolBaseList(&q)
	if err != nil {
		klog.Error(err)
		return
	}
	poolCapTotal := resourcepoolmodel.MetricT{
		ID:       id,
		Name:     "当前存储容量",
		Unit:     "GB",
		UnitType: "strage",
		Kind:     "info",
	}

	poolBucketNum := resourcepoolmodel.MetricT{
		ID:       id,
		Name:     "存储空间bucket数量",
		Unit:     "个",
		UnitType: "number",
		Kind:     "info",
	}

	for i := 0; i < len(list.DataList); i++ {
		j := list.DataList[i]
		if j.Id == idd {
			poolCapTotal.Value, _ = strconv.ParseFloat(fmt.Sprintf("%.0f", j.CapacityTotal), 64) // 当前存储容量
			poolBucketNum.Value = j.BucketAmount                                                 // 存储空间bucket数量
		}
	}
	poolObjectNum := resourcepoolmodel.MetricT{
		ID:       id,
		Name:     "object总量",
		Unit:     "个",
		UnitType: "number",
		Value:    getBucketCount(id),
		Kind:     "info",
	}

	pool30ApiNum := resourcepoolmodel.MetricT{
		ID:       id,
		Name:     "近30天api请求数",
		Unit:     "个",
		UnitType: "number",
		Value:    esmanager.Get30ApiNum(),
		Kind:     "info",
	}

	Ago := time.Now().Add(time.Duration(-24 * time.Hour)).Format(esmanager.EsIndexDateFormat)
	AgoDate := strings.Split(Ago, ".")
	lastDayIndex := AgoDate[0]

	//flowAll := esmanager.GetFlowAllByEsSum(strings.ToUpper("cn-shanghai-2"))
	flowAll, _ := esmanager.GetFlowByDayCache(lastDayIndex, "cn-shanghai-2")
	up := flowAll["up"]
	down := flowAll["down"]
	poolFlowIn := resourcepoolmodel.MetricT{
		ID:       id,
		Name:     "总流入量",
		Unit:     "Byte",
		UnitType: "storage",
		Value:    up,
		Kind:     "info",
	}
	poolFlowOut := resourcepoolmodel.MetricT{
		ID:       id,
		Name:     "总流出量",
		Unit:     "Byte",
		UnitType: "storage",
		Value:    down,
		Kind:     "info",
	}

	rst = append(rst, poolCapTotal, poolBucketNum, poolObjectNum, pool30ApiNum, poolFlowIn, poolFlowOut)

	return
}

//func getBucketCount(bucketPoolId string) int64 {
//	fmt.Println("getBucketCount begin", time.Now())
//	const limit = int(^uint16(0))
//	hostUrlPost := objectmodel.HostUrlPost{
//		PageNo:   1,
//		PageSize: limit,
//		Region:   "all",
//	}
//	jsons, _ := json.Marshal(hostUrlPost)
//	result := string(jsons)
//	jsoninfo := strings.NewReader(result)
//	c := http.Client{}
//	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/bucket", "application/json", jsoninfo)
//
//	if err != nil {
//		klog.Error(err)
//		return 0
//	}
//
//	b, _ := io.ReadAll(resp.Body)
//	cmdb := objectmodel.CMDBResult{Data: objectmodel.CmdbBucks{DataList: make([]objectmodel.CmdbBucket, 0, limit)}}
//	err = json.Unmarshal(b, &cmdb)
//	if err != nil {
//		klog.Error(err)
//		return 0
//	}
//	if cmdb.Code != 200 {
//		klog.Info("get data from nova cmdb error!")
//		return 0
//	}
//
//	poolBucketList := make([]objectmodel.CmdbBucket, 0)
//	for _, bucket := range cmdb.Data.DataList {
//		if bucketPoolId != "" && strconv.Itoa(bucket.PoolId) == bucketPoolId {
//			poolBucketList = append(poolBucketList, bucket)
//		}
//	}
//
//	cnt := make(chan int64)
//	defer close(cnt)
//	for _, bucket := range poolBucketList {
//		go func(c chan int64, bucketId string) {
//			var bucketCountTotal int64 = 0
//			countList, err := esmanager.GetBucketObjectCountById(strings.ToUpper(bucket.RegionCode), time.Now().Format("20060102"), bucketId)
//			if err == nil {
//				for _, cnt := range countList {
//					bucketCountTotal += cnt.TotalCount
//				}
//			}
//			cnt <- bucketCountTotal
//		}(cnt, bucket.ID)
//	}
//	var objectCount int64 = 0
//	count := len(poolBucketList)
//	for j := 0; j < count; j++ {
//		objectCount += <-cnt
//	}
//	fmt.Println("getBucketCount end", time.Now())
//	return objectCount
//}

func getBucketCount(bucketPoolId string) int64 {
	const limit = int(^uint16(0))
	hostUrlPost := objectmodel.HostUrlPost{
		PageNo:   1,
		PageSize: limit,
		Region:   "all",
	}
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	c := http.Client{}
	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/bucket", "application/json", jsoninfo)

	if err != nil {
		klog.Error(err)
		return 0
	}

	b, _ := io.ReadAll(resp.Body)
	cmdb := objectmodel.CMDBResult{Data: objectmodel.CmdbBucks{DataList: make([]objectmodel.CmdbBucket, 0, limit)}}
	err = json.Unmarshal(b, &cmdb)
	if err != nil {
		klog.Error(err)
		return 0
	}
	if cmdb.Code != 200 {
		klog.Info("get data from nova cmdb error!")
		return 0
	}

	poolBucketList := make([]objectmodel.CmdbBucket, 0)
	for _, bucket := range cmdb.Data.DataList {
		if bucketPoolId != "" && strconv.Itoa(bucket.PoolId) == bucketPoolId {
			poolBucketList = append(poolBucketList, bucket)
		}
	}

	var objectCount int64 = 0
	for _, bucket := range poolBucketList {
		objectCount += bucket.ObjectCount
	}

	return objectCount
}

// 获取对象存储资源池-库存list
func (b *ObjectPoolService) GetObjectPoolUsageList(t *resourcepoolmodel.ObjectStorageUsageQuery) (resourcepoolmodel.ObjectStoragePoolUsageResult, error) {
	//从CMDB中获取资源池信息
	var objectStoragesResult resourcepoolmodel.ObjectStoragePoolUsageResult
	var objectRes []cmdbmodel.ObjectRe
	var objectStoragePoolResult cmdbmodel.ObjectStoragePoolResult
	objectStoragePoolResult, err := cmdbmanager.GetObjectStorageResourcePoolList(t.Region, "all", t.Name, strconv.Itoa(t.PageNo), strconv.Itoa(t.PageSize))

	if err != nil {
		//return objectStoragesResult, err
	}
	objectRes = objectStoragePoolResult.Data.DataList
	currentTime := time.Now()
	lastDayTime := currentTime.Add(-time.Hour * 24)
	lastWeekTime := currentTime.Add(-time.Hour * 24 * 7)
	lastMonthTime := currentTime.Add(-time.Hour * 24 * 30)

	if len(objectRes) > 0 {
		objectStoragesResult.TotalCount = objectStoragePoolResult.Data.TotalCount
		for _, objectRe := range objectRes {
			if t.Name != "" && t.Name != objectRe.Name {
				continue
			}
			var objectStorageUsage resourcepoolmodel.ObjectStorageUsage
			objectStorageUsage.Id = objectRe.Id
			objectStorageUsage.Name = objectRe.Name
			objectStorageUsage.Region = objectRe.RegionName
			objectStorageUsage.RegionCode = objectRe.RegionCode
			objectStorageUsage.ResourcePool = objectRe.ResourcePool
			objectStorageUsage.CreateTime = objectRe.CreateTime

			CapacityTotal, err := prom.GetCapTotalMultiAz(objectRe.RegionCode, objectRe.AzCode, objectRe.Name, currentTime)
			if err != nil {
				return objectStoragesResult, err
			}
			CapacityTotalLastWeek, err := prom.GetCapTotalMultiAz(objectRe.RegionCode, objectRe.AzCode, objectRe.Name, lastWeekTime)
			if err != nil {
				return objectStoragesResult, err
			}
			CapacityUsedTotal, err := prom.GetCapUsedMultiAz(objectRe.RegionCode, objectRe.AzCode, objectRe.Name, currentTime)
			if err != nil {
				return objectStoragesResult, err
			}
			CapacityUsedTotalLastDay, err := prom.GetCapUsedMultiAz(objectRe.RegionCode, objectRe.AzCode, objectRe.Name, lastDayTime)
			if err != nil {
				return objectStoragesResult, err
			}
			CapacityUsedTotalLastWeek, err := prom.GetCapUsedMultiAz(objectRe.RegionCode, objectRe.AzCode, objectRe.Name, lastWeekTime)
			if err != nil {
				return objectStoragesResult, err
			}
			CapacityUsedTotalLastMonth, err := prom.GetCapUsedMultiAz(objectRe.RegionCode, objectRe.AzCode, objectRe.Name, lastMonthTime)
			if err != nil {
				return objectStoragesResult, err
			}
			// CapacityUsedRate, err := prom.GetCapRate(objectRe.RegionCode, objectRe.Name, currentTime)
			// if err != nil {
			// 	return objectStoragesResult, err
			// }
			if len(CapacityTotal.Result) > 0 && len(CapacityTotal.Result[0].Values) > 0 {
				value := CapacityTotal.Result[0].Values[len(CapacityTotal.Result[0].Values)-1].([]interface{})
				v1, _ := strconv.ParseFloat(value[1].(string), 64)
				//v1, _ := strconv.ParseFloat(CapacityTotal.Result[0].Value, 64)
				//objectStorageUsage.CapacityTotal = v1
				objectStorageUsage.CapacityTotal, _ = strconv.ParseFloat(fmt.Sprintf("%.0f", v1), 64)
			}
			if len(CapacityTotalLastWeek.Result) > 0 && len(CapacityTotalLastWeek.Result[0].Values) > 0 {
				value := CapacityTotalLastWeek.Result[0].Values[len(CapacityTotalLastWeek.Result[0].Values)-1].([]interface{})
				v1, _ := strconv.ParseFloat(value[1].(string), 64)
				objectStorageUsage.CapacityTotalLastWeek, _ = strconv.ParseFloat(fmt.Sprintf("%.0f", v1), 64)
			}
			if len(CapacityUsedTotal.Result) > 0 && len(CapacityUsedTotal.Result[0].Values) > 0 {
				value := CapacityUsedTotal.Result[0].Values[len(CapacityUsedTotal.Result[0].Values)-1].([]interface{})
				v2, _ := strconv.ParseFloat(value[1].(string), 64)
				//v2, _ := strconv.ParseFloat(CapacityUsed.Result[0].Value, 64)
				//objectStorageUsage.CapacityUsedTotal = v2
				objectStorageUsage.CapacityUsedTotal, _ = strconv.ParseFloat(fmt.Sprintf("%.0f", v2), 64)
			}
			if objectStorageUsage.CapacityTotal > 0 && objectStorageUsage.CapacityUsedTotal <= objectStorageUsage.CapacityTotal {
				v3, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", (objectStorageUsage.CapacityUsedTotal/objectStorageUsage.CapacityTotal)*100), 64)
				objectStorageUsage.CapacityUsedRate = v3
				objectStorageUsage.CapacityAvailable = objectStorageUsage.CapacityTotal - objectStorageUsage.CapacityUsedTotal
			}
			// if len(CapacityUsedRate.Result) > 0 && CapacityUsedRate.Result[0].Value != "NaN" {
			// 	v3, _ := strconv.ParseFloat(CapacityUsedRate.Result[0].Value, 64)
			// 	v33, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", v3), 64)
			// 	objectStorageUsage.CapacityUsedRate = v33
			// }
			// if objectStorageUsage.CapacityTotal > 0 && objectStorageUsage.CapacityUsedTotal >= 0 {
			// 	objectStorageUsage.CapacityAvailable = objectStorageUsage.CapacityTotal - objectStorageUsage.CapacityUsedTotal
			// }

			klog.Infof("CapacityUsedTotalLastDay result is %+v", CapacityUsedTotalLastDay)
			if len(CapacityUsedTotalLastDay.Result) > 0 && len(CapacityUsedTotalLastDay.Result[0].Values) > 0 {
				value := CapacityUsedTotalLastDay.Result[0].Values[len(CapacityUsedTotalLastDay.Result[0].Values)-1].([]interface{})
				v2, _ := strconv.ParseFloat(value[1].(string), 64)
				//v2, _ := strconv.ParseFloat(CapacityUsedTotalLastDay.Result[0].Value, 64)
				v2, _ = strconv.ParseFloat(fmt.Sprintf("%.0f", v2), 64)
				objectStorageUsage.CapacityUsedIncrementDay = objectStorageUsage.CapacityUsedTotal - v2
			}
			if len(CapacityUsedTotalLastWeek.Result) > 0 && len(CapacityUsedTotalLastWeek.Result[0].Values) > 0 {
				value := CapacityUsedTotalLastWeek.Result[0].Values[len(CapacityUsedTotalLastWeek.Result[0].Values)-1].([]interface{})
				v2, _ := strconv.ParseFloat(value[1].(string), 64)
				//v2, _ := strconv.ParseFloat(CapacityUsedTotalLastWeek.Result[0].Value, 64)
				v2, _ = strconv.ParseFloat(fmt.Sprintf("%.0f", v2), 64)
				objectStorageUsage.CapacityUsedIncrementWeek = objectStorageUsage.CapacityUsedTotal - v2
			}
			if len(CapacityUsedTotalLastMonth.Result) > 0 && len(CapacityUsedTotalLastMonth.Result[0].Values) > 0 {
				value := CapacityUsedTotalLastMonth.Result[0].Values[len(CapacityUsedTotalLastMonth.Result[0].Values)-1].([]interface{})
				v2, _ := strconv.ParseFloat(value[1].(string), 64)
				//v2, _ := strconv.ParseFloat(CapacityUsedTotalLastMonth.Result[0].Value, 64)
				v2, _ = strconv.ParseFloat(fmt.Sprintf("%.0f", v2), 64)
				objectStorageUsage.CapacityUsedIncrementMonth = objectStorageUsage.CapacityUsedTotal - v2
			}
			if objectStorageUsage.CapacityUsedIncrementDay == 0 {
				capLastDay := GetKS3DiskCapacity(objectRe.RegionCode, strconv.Itoa(objectRe.Id), -1)
				klog.Infof("capLastDay is %+v", capLastDay)
				if capLastDay.Total_used_space > 0 {
					objectStorageUsage.CapacityUsedIncrementDay = objectStorageUsage.CapacityUsedTotal - float64(capLastDay.Total_used_space)
				}
			}
			if objectStorageUsage.CapacityUsedIncrementWeek == 0 {
				capLastWeek := GetKS3DiskCapacity(objectRe.RegionCode, strconv.Itoa(objectRe.Id), -7)
				klog.Infof("capLastWeek is %+v", capLastWeek)
				if capLastWeek.Total_used_space > 0 {
					objectStorageUsage.CapacityUsedIncrementWeek = objectStorageUsage.CapacityUsedTotal - float64(capLastWeek.Total_used_space)
				}
			}
			if objectStorageUsage.CapacityUsedIncrementMonth == 0 {
				capLastMonth := GetKS3DiskCapacity(objectRe.RegionCode, strconv.Itoa(objectRe.Id), -30)
				klog.Infof("capLastMonth is %+v", capLastMonth)
				if capLastMonth.Total_used_space > 0 {
					objectStorageUsage.CapacityUsedIncrementMonth = objectStorageUsage.CapacityUsedTotal - float64(capLastMonth.Total_used_space)
				}
			}

			//else {
			//	objectStorageUsage.CapacityUsedIncrementMonth = objectStorageUsage.CapacityUsedTotal
			//}
			days := 0.00
			if objectStorageUsage.CapacityUsedIncrementMonth > 0 {
				days, _ = strconv.ParseFloat(Strval(objectStorageUsage.CapacityAvailable/(objectStorageUsage.CapacityUsedIncrementMonth/30)), 64)
			} else {
				days = 9999.99
			}
			objectStorageUsage.RemainingDays = days
			objectStoragesResult.DataList = append(objectStoragesResult.DataList, objectStorageUsage)
		}
	}
	//排序
	results := alert.Bucket{}
	for i := 0; i < len(objectStoragesResult.DataList); i++ {
		results.Slice = append(results.Slice, objectStoragesResult.DataList[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}
	if t.OrderCode == "" {
		t.OrderCode = "createTime"
		t.OrderType = "desc"
	}
	if t.OrderCode != "" {
		switch t.OrderCode {
		case "capacityTotal":
			if t.OrderType != "" {
				switch t.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.ObjectStorageUsage).CapacityTotal < b.(resourcepoolmodel.ObjectStorageUsage).CapacityTotal
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.ObjectStorageUsage).CapacityTotal > b.(resourcepoolmodel.ObjectStorageUsage).CapacityTotal
					}
				}
			}
		case "capacityAvailable":
			if t.OrderType != "" {
				switch t.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.ObjectStorageUsage).CapacityAvailable < b.(resourcepoolmodel.ObjectStorageUsage).CapacityAvailable
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.ObjectStorageUsage).CapacityAvailable > b.(resourcepoolmodel.ObjectStorageUsage).CapacityAvailable
					}
				}
			}
		case "capacityUsedRate":
			if t.OrderType != "" {
				switch t.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.ObjectStorageUsage).CapacityUsedRate < b.(resourcepoolmodel.ObjectStorageUsage).CapacityUsedRate
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.ObjectStorageUsage).CapacityUsedRate > b.(resourcepoolmodel.ObjectStorageUsage).CapacityUsedRate
					}
				}
			}
		case "createTime":
			if t.OrderType != "" {
				switch t.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.ObjectStorageUsage).CreateTime < b.(resourcepoolmodel.ObjectStorageUsage).CreateTime
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.ObjectStorageUsage).CreateTime > b.(resourcepoolmodel.ObjectStorageUsage).CreateTime
					}
				}
			}
		}

	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(objectStoragesResult.DataList); i++ {
		objectStoragesResult.DataList[i] = results.Slice[i].(resourcepoolmodel.ObjectStorageUsage)
	}
	//分页
	low := (t.PageNo - 1) * t.PageSize
	if low > len(objectStoragesResult.DataList) {
		return objectStoragesResult, nil
	}

	hight := low + t.PageSize
	if hight > len(objectStoragesResult.DataList) {
		hight = len(objectStoragesResult.DataList)
	}

	objectStoragesResult.PageNo = t.PageNo
	objectStoragesResult.PageSize = t.PageSize
	objectStoragesResult.TotalCount = len(objectStoragesResult.DataList)
	objectStoragesResult.DataList = objectStoragesResult.DataList[low:hight]

	return objectStoragesResult, err
}

type MailboxResponse struct {
	Code    int     `json:"code"`
	Data    Mailbox `json:"data"`
	Message string  `json:"message"`
}

type Mailbox struct {
	SMTPServer string `json:"SMTPServer"` // 邮箱服务器地址
	Port       int    `json:"port"`       // 邮箱服务器端口
	//From string `json:"from"`
	//To string `json:"to"`
	Username string `json:"username"` // 邮箱用户名
	Password string `json:"password"` // 邮箱密码
}

func (b *ObjectPoolService) Test() interface{} {

	s := "string(body)"
	return s
}

func GetKS3DiskCapacity(region, id string, dayOffSet int) (capData resourcepoolmodel.Cap) {
	dateIndex := esmanager.GetDateIndex(dayOffSet)
	ctx, _ := context.WithTimeout(context.Background(), 1*time.Minute)
	key := "objectStoragePool_disk_capacity:" + region + ":" + id
	rs, err := client.HGet(ctx, key, dateIndex)
	if err != nil {
		fields, err := client.HKeys(ctx, key)
		if err != nil || len(fields) == 0 {
			return
		}
		if float64(len(fields)) <= math.Abs(float64(dayOffSet)) {
			lastDateIndex := GetMinDateIndex(fields)
			rs, err = client.HGet(ctx, key, lastDateIndex)
			if err != nil {
				return
			}
		}
	}
	err = json.Unmarshal([]byte(rs), &capData)
	return
}

func GetMinDateIndex(fields []string) string {
	min := fields[0]
	for _, field := range fields {
		if field < min {
			min = field
		}
	}
	return min
}

// 获取资源管理-对象存储资源池-概览页面数据
func GetCMDBObjectStorageOverView(bucket cmdbmodel.BucketRequest) (resourcepoolmodel.CMDBObjectStorageOverview, error) {

	var hostOverview resourcepoolmodel.CMDBObjectStorageOverview
	currentTime := time.Now()

	var (
		STANDARDCount   = 0 //标准存储数量
		STANDARDIACount = 0 //低频存储数量
		ARCHIVECount    = 0 //归档存储数量

		STANDARDUsedCap   = 0.00 //标准存储使用量
		STANDARDIAUsedCap = 0.00 //低频存储使用量
		ARCHIVEUsedCap    = 0.00 //归档存储使用量
	)
	//获取对象存储bucket列表
	bucketResult, err := cmdbmanager.GetBucketList(bucket)
	if err != nil {
		return hostOverview, err
	}
	for _, bucket := range bucketResult.DataList {
		switch {
		case bucket.StorageType == "STANDARD":
			STANDARDCount++
			STANDARDUsedCap += float64(bucket.Size)
		case bucket.StorageType == "STANDARD_IA":
			STANDARDIACount++
			STANDARDIAUsedCap += float64(bucket.Size)
		case bucket.StorageType == "ARCHIVE":
			ARCHIVECount++
			ARCHIVEUsedCap += float64(bucket.Size)
		}
	}

	//Bucket统计
	bucketCountOverview := []resourcepoolmodel.OverView{
		resourcepoolmodel.OverView{
			Name:  "标准存储",
			Code:  "STANDARD",
			Value: STANDARDCount,
			Unit:  "个",
		},
		resourcepoolmodel.OverView{
			Name:  "归档存储",
			Code:  "ARCHIVE",
			Value: ARCHIVECount,
			Unit:  "个",
		},
		resourcepoolmodel.OverView{
			Name:  "低频存储",
			Code:  "STANDARD_IA",
			Value: STANDARDIACount,
			Unit:  "个",
		},
	}
	hostOverview.BucketCountOverview = append(hostOverview.BucketCountOverview, bucketCountOverview...)

	//Bucket总数
	hostOverview.BucketSumOverview = resourcepoolmodel.ChartBaseOverview{
		Name:  "总数",
		Code:  "sum",
		Value: bucketResult.TotalCount,
		Unit:  "个",
	}

	//存储使用量
	storageUsedOverview := []resourcepoolmodel.OverView{
		resourcepoolmodel.OverView{
			Name:     "标准存储",
			Code:     "STANDARD",
			Value:    STANDARDUsedCap,
			Unit:     "B",
			UnitType: "storage",
		},
		resourcepoolmodel.OverView{
			Name:     "归档存储",
			Code:     "ARCHIVE",
			Value:    ARCHIVEUsedCap,
			Unit:     "B",
			UnitType: "storage",
		},
		resourcepoolmodel.OverView{
			Name:     "低频存储",
			Code:     "STANDARD_IA",
			Value:    STANDARDIAUsedCap,
			Unit:     "B",
			UnitType: "storage",
		},
	}
	hostOverview.StorageUsedOverview = append(hostOverview.StorageUsedOverview, storageUsedOverview...)

	// 存储总容量
	var (
		capTotal     = 0.00
		capUseRate   = ""
		capUsed      = 0.00
		capAvailable = 0.00
	)
	CapacityTotal, err := prom.GetCapTotal(bucket.Region, "ks3", currentTime)
	CapacityUsedTotal, err := prom.GetCapUsed(bucket.Region, "ks3", currentTime)

	if err == nil {
		if len(CapacityTotal.Result) > 0 && len(CapacityTotal.Result[0].Values) > 0 {
			value := CapacityTotal.Result[0].Values[len(CapacityTotal.Result[0].Values)-1].([]interface{})
			v1, _ := strconv.ParseFloat(value[1].(string), 64)
			//v1, _ := strconv.ParseFloat(CapacityTotal.Result[0].Value, 64)
			capTotal, _ = strconv.ParseFloat(fmt.Sprintf("%.0f", v1), 64)

		}
		if len(CapacityUsedTotal.Result) > 0 && len(CapacityUsedTotal.Result[0].Values) > 0 {
			value := CapacityUsedTotal.Result[0].Values[len(CapacityUsedTotal.Result[0].Values)-1].([]interface{})
			v2, _ := strconv.ParseFloat(value[1].(string), 64)
			//v2, _ := strconv.ParseFloat(CapacityUsed.Result[0].Value, 64)
			//capUsed = v2
			capUsed, _ = strconv.ParseFloat(fmt.Sprintf("%.0f", v2), 64)
		}
	}
	if capTotal > 0 && capUsed <= capTotal {
		capUseRate = Strval((capUsed / capTotal) * 100)
		capAvailable = capTotal - capUsed
	}
	views := []resourcepoolmodel.OverView{}
	views = append(views, resourcepoolmodel.OverView{
		Name:  "使用率",
		Code:  "capUseRate",
		Value: capUseRate,
		Unit:  "%",
	})
	views = append(views, resourcepoolmodel.OverView{
		Name:  "使用量",
		Code:  "capUsed",
		Value: capUsed,
		Unit:  "GB",
	})
	views = append(views, resourcepoolmodel.OverView{
		Name:  "剩余量",
		Code:  "capAvailable",
		Value: capAvailable,
		Unit:  "GB",
	})
	// views = append(views, resourcepoolmodel.OverView{
	// 	Name:  "分配量",
	// 	Code:  "distribution",
	// 	Value: STANDARDUsedCap + ARCHIVEUsedCap + STANDARD_IAUsedCap,
	// 	Unit:  "GB",
	// })
	totalStorage := resourcepoolmodel.ObjectDistributedOverView{
		Name:        "存储总量",
		Code:        "storageTotal",
		Value:       capTotal,
		Unit:        "GB",
		Distributed: views,
	}
	hostOverview.BucketTotalStorageOverview = totalStorage
	return hostOverview, err
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/resourcepool/blockstorageservice.go
```golang
package resourcepoolservice

import (
	"context"
	"encoding/json"
	"fmt"
	"github.com/go-redis/redis/v8"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"math"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"sync"
	"time"

	alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"

	"k8s.io/klog/v2"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"

	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	prometheusModel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/prometheus"
	resourcepoolmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/resourcepool"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	prom "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	block "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/block"
	temp "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/resourcePool"
)

type IBlockPoolService interface {
	GetBlockPoolMetric(string) []resourcepoolmodel.MetricT
	//GetServerHardwareMetric(string) (servermodels.HardWare, error)
	//GetSwitchMetricLine(*switchmodels.SwitchMetricLineQuery) (map[string][]switchmodels.EchartType, error)
	GetBlockPoolOverview(*resourcepoolmodel.BlockPoolOverviewQuery) (resourcepoolmodel.BlockOverView, error)
	GetBlockPoolOverviewLine(*resourcepoolmodel.OverviewLineQuery) ([]resourcepoolmodel.OverViewLine, error)
	GetBlockPoolList(*resourcepoolmodel.BlockPoolListQuery) (resourcepoolmodel.BlockStoragesResult, error)
	GetBlockPoolUsageList(resourcepoolmodel.BlockStorageUseageQuery) (resourcepoolmodel.BlockStoragesUseageResult, error)
}

type BlockPoolService struct {
}

func NewBlockPoolService() *BlockPoolService {
	return &BlockPoolService{}
}

func (b *BlockPoolService) GetBlockPoolOverview(l *resourcepoolmodel.BlockPoolOverviewQuery) (res resourcepoolmodel.BlockOverView, err error) {
	klog.Info("blockoverview")
	if l.Region == "" {
		l.Region = "all"
	}
	//获取块存储列表
	param := resourcepoolmodel.BlockPoolListQuery{Region: l.Region, Az: []string{l.Az}, PageNo: 1, PageSize: 10, Name: l.Pool, ResourcePool: []string{l.DiskType}}
	BlockStorageDataResult, err := b.GetBlockPoolList(&param)
	if err != nil {
		klog.Error(err)
	}
	list := BlockStorageDataResult.DataList
	count := len(list)
	//获取告警数据
	alerts := make([]alertmanagermodel.OverviewAlert, 0, 4)
	queryParam := alertmanagermodel.AlertQuery{
		Filter: "",
		Module: "block",
	}
	if l.Region != "" && l.Region != "all" {
		queryParam.Filter = queryParam.Filter + "&filter=region=%22" + l.Region + "%22"
	}
	if l.DiskType != "" && l.DiskType != "all" {
		queryParam.ResourceSubTypeCode = []string{l.DiskType}
	}
	if l.Pool != "" {
		queryParam.AlertInstance = l.Pool
	}
	if l.Az != "" {
		queryParam.Az = []string{l.Az}
	}
	for i := 0; i < count; i++ {
		if l.DiskType == list[i].ResourcePool {
			queryParam.AlertInstance = list[i].Name
		}
	}
	alertList, err := alert.GetCommonAlertOverviewNum(queryParam)
	if err != nil {
		klog.Error(err)
	}
	alerts = append(alerts, alertList...)

	//资源池总览
	uu := resourcepoolmodel.BlockViewType{}
	u1 := resourcepoolmodel.EchartType{}
	u1.Info.Name = "资源池容量"
	u1.Info.ResourcePool = l.Pool
	u1.Info.Unit = "Byte"
	u1.Info.UnitType = "storage"
	e1 := services.ValueType{Name: "使用量"}
	e2 := services.ValueType{Name: "剩余量"}
	//capacity
	var totalDiskSize float64
	var usedDiskSize float64
	var avaDiskSize float64
	//capacity
	query := resourcepoolmodel.CMDBOverViewQuery{Region: l.Region, Az: l.Az, DiskType: l.DiskType}
	cmdbOverview, err := GetBlockStorageOverView(query)
	if err != nil {
		klog.Error(err)
		return res, nil
	}
	for _, v := range cmdbOverview.TotalStorageOverview {
		totalDiskSize += services.FormatFloat64(v.Value)
		for _, vv := range v.Distributed {
			if vv.Code == "used" {
				usedDiskSize += services.FormatFloat64(vv.Value)
			}
			if vv.Code == "avilable" {
				avaDiskSize += services.FormatFloat64(vv.Value)
			}
		}
	}
	e1.Value = floatGbToByte(usedDiskSize)
	e2.Value = floatGbToByte(avaDiskSize)
	u1.Values = append(u1.Values, e1, e2)
	u1.Info.Total = floatGbToByte(usedDiskSize + avaDiskSize)
	uu.List = append(uu.List, []resourcepoolmodel.EchartType{u1})
	//state
	//cmdbCount := services.GetTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "post")

	az := []string{}
	if l.Az == "all" || l.Az == "" {
		az = []string{}
	} else {
		az = append(az, l.Az)
	}
	// blockQuery := blockmodel.ListQuery{PageNo: 1, PageSize: cmdbCount, Region: "", Az: az, StorageType: []string{l.DiskType}, SearchKey: "pool", SearchValue: l.Pool}
	// bb, _ := block.GetResourcePoolList(&blockQuery)
	//bb, _ := cmdbmanager.GetCMDBBytes(l.Region, az)
	bb, _ := cmdbmanager.GetCMDBCloudDisk(l.Region, az, []string{l.DiskType})

	//sbList := bb.Data.DataList

	count1 := len(bb.Data.DataList)
	var (
		creating        = 0 //运行中
		available       = 0 //即将过期
		attaching       = 0 //已过期
		in_use          = 0 //故障中
		detaching       = 0 //已停止
		extending       = 0
		deleting        = 0 //运行中
		eerror          = 0 //即将过期
		error_attaching = 0 //已过期
		error_detaching = 0 //故障中
		error_deleting  = 0 //已停止
		error_extending = 0
		deleted         = 0 //故障中
		recycling       = 0 //已停止
		rollbacking     = 0
		unknow          = 0
	)
	for i := 0; i < len(bb.Data.DataList); i++ {
		switch bb.Data.DataList[i].UseStatus {
		case "creating":
			creating++
		case "available":
			available++
		case "attaching":
			attaching++
		case "in-use":
			in_use++
		case "detaching":
			detaching++
		case "extending":
			extending++
		case "deleting":
			deleting++
		case "error":
			eerror++
		case "error_attaching":
			error_attaching++
		case "error_detaching":
			error_detaching++
		case "error_deleting":
			error_deleting++
		case "error_extending":
			error_extending++
		case "deleted":
			deleted++
		case "recycling":
			recycling++
		case "rollbacking":
			rollbacking++
		default:
			unknow++
		}

	}

	u2 := resourcepoolmodel.EchartType{}
	u2.Info.Name = "块存储数量"
	u2.Info.ResourcePool = l.Pool
	u2.Info.Unit = "个"
	u2.Info.Total = strconv.Itoa(count1)
	//v1 := services.ValueType{Name: "创建中", Value: creating}
	//u2.Values = append(u2.Values, v1)
	v2 := services.ValueType{Name: "待挂载", Value: available}
	u2.Values = append(u2.Values, v2)
	//v3 := services.ValueType{Name: "挂载中", Value: attaching}
	//u2.Values = append(u2.Values, v3)
	v4 := services.ValueType{Name: "使用中", Value: in_use}
	u2.Values = append(u2.Values, v4)
	//v5 := services.ValueType{Name: "卸载中", Value: detaching}
	//u2.Values = append(u2.Values, v5)
	//v6 := services.ValueType{Name: "扩容中", Value: extending}
	//u2.Values = append(u2.Values, v6)
	//v7 := services.ValueType{Name: "删除中", Value: deleting}
	//u2.Values = append(u2.Values, v7)
	//v8 := services.ValueType{Name: "错误", Value: eerror}
	//u2.Values = append(u2.Values, v8)
	//v9 := services.ValueType{Name: "挂载失败", Value: error_attaching}
	//u2.Values = append(u2.Values, v9)
	//v10 := services.ValueType{Name: "卸载失败", Value: error_detaching}
	//u2.Values = append(u2.Values, v10)
	//v11 := services.ValueType{Name: "删除失败", Value: error_deleting}
	//u2.Values = append(u2.Values, v11)
	//v12 := services.ValueType{Name: "扩容失败", Value: error_extending}
	//u2.Values = append(u2.Values, v12)
	//v13 := services.ValueType{Name: "已删除", Value: deleted}
	//u2.Values = append(u2.Values, v13)
	//v14 := services.ValueType{Name: "回收中", Value: recycling}
	//u2.Values = append(u2.Values, v14)
	//v15 := services.ValueType{Name: "回滚中", Value: rollbacking}
	//u2.Values = append(u2.Values, v15)
	//v16 := services.ValueType{Name: "未知", Value: unknow}
	//u2.Values = append(u2.Values, v16)

	uu.List = append(uu.List, []resourcepoolmodel.EchartType{u2})
	res = resourcepoolmodel.BlockOverView{l.Region, l.Az, alerts, uu}

	return res, err
}

func (b *BlockPoolService) GetBlockPoolOverviewLine(t *resourcepoolmodel.OverviewLineQuery) ([]resourcepoolmodel.OverViewLine, error) {

	start1 := services.Strval(t.Start / 1000)
	//start2 := strconv.FormatFloat(start1/1000.0, 'f', 3, 64)
	end1 := services.Strval(t.End / 1000)
	//end2 := strconv.FormatFloat(end1/1000.0, 'f', 3, 64)
	//t := services.FormatTime(end1 - start1)
	lable := services.BuildCommonCondition(t.Region, t.Az)

	if t.Step == "" {
		t.Step = "120"
	}
	responseMetric := []resourcepoolmodel.OverViewLine{}
	for i := 0; i < len(t.Name); i++ {
		switch t.Name[i] {
		case "stockCapacity":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i]}
			query := temp.NewPoolMetics(lable, "", "").ToString("block_pool_storage_stock")

			l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, query)

			for j := 0; j < len(l); j++ {
				rr := resourcepoolmodel.EchartType{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				rr.Info.Name = lll["name"].(string)

				vv := prom.PrometheusResultToValue2(l[j])
				rr.Values = services.PromeForRangeValue(vv)

				r.Echarts = append(r.Echarts, rr)
			}
			responseMetric = append(responseMetric, r)
		case "total":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i]}
			query := temp.NewPoolMetics(lable, "", "").ToString("block_pool_disk_count")
			l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, query)

			for j := 0; j < len(l); j++ {
				rr := resourcepoolmodel.EchartType{}

				//ll := l[j].(map[string]interface{})
				//lll := ll["metric"].(map[string]interface{})

				rr.Info.Name = "totalCapacity"

				vv := prom.PrometheusResultToValue2(l[j])
				rr.Values = services.PromeForRangeValue(vv)

				r.Echarts = append(r.Echarts, rr)
			}
			responseMetric = append(responseMetric, r)
		case "unMount":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i]}
			l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, ``)

			for j := 0; j < len(l); j++ {
				rr := resourcepoolmodel.EchartType{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				rr.Info.Name = lll["name"].(string)

				vv := prom.PrometheusResultToValue2(l[j])
				rr.Values = services.PromeForRangeValue(vv)

				r.Echarts = append(r.Echarts, rr)
			}
			responseMetric = append(responseMetric, r)
		case "health":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Unit: "%"}
			l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, ``)

			for j := 0; j < len(l); j++ {
				rr := resourcepoolmodel.EchartType{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				rr.Info.Name = lll["name"].(string)

				vv := prom.PrometheusResultToValue2(l[j])
				rr.Values = services.PromeForRangeValue(vv)

				r.Echarts = append(r.Echarts, rr)
			}
			responseMetric = append(responseMetric, r)
		case "ioNum":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i]}
			query := temp.NewPoolMetics(lable, "", "").ToString("block_pool_req_count")
			l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, query)

			for j := 0; j < len(l); j++ {
				rr := resourcepoolmodel.EchartType{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				rr.Info.Name = lll["name"].(string)

				vv := prom.PrometheusResultToValue2(l[j])
				rr.Values = services.PromeForRangeValue(vv)

				r.Echarts = append(r.Echarts, rr)
			}
			responseMetric = append(responseMetric, r)
		case "ioDelay":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i]}
			query := temp.NewPoolMetics(lable, "", "").ToString("block_pool_io_avg_delay")
			l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, query)

			for j := 0; j < len(l); j++ {
				rr := resourcepoolmodel.EchartType{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				rr.Info.Name = lll["name"].(string)

				vv := prom.PrometheusResultToValue2(l[j])
				rr.Values = services.PromeForRangeValue(vv)

				r.Echarts = append(r.Echarts, rr)
			}
			responseMetric = append(responseMetric, r)
		case "bond":
			r := resourcepoolmodel.OverViewLine{Name: t.Name[i], Unit: "%"}
			query := temp.NewPoolMetics(lable, "", "").ToString("block_pool_write_band")
			l, _ := prom.PrometheusQuery2(true, start1, end1, t.Step, query)

			for j := 0; j < len(l); j++ {
				rr := resourcepoolmodel.EchartType{}

				ll := l[j].(map[string]interface{})
				lll := ll["metric"].(map[string]interface{})

				rr.Info.Name = lll["name"].(string)

				vv := prom.PrometheusResultToValue2(l[j])
				rr.Values = services.PromeForRangeValue(vv)

				r.Echarts = append(r.Echarts, rr)
			}
			responseMetric = append(responseMetric, r)
		}
	}
	return responseMetric, nil
}
func (b *BlockPoolService) GetBlockPoolList(t *resourcepoolmodel.BlockPoolListQuery) (resourcepoolmodel.BlockStoragesResult, error) {
	klog.Info("BlockPoolService.GetBlockPoolList")
	var (
		blockStoragesResult    resourcepoolmodel.BlockStoragesResult
		blockRes               []cmdbmodel.BlockRe
		blockStoragePoolResult cmdbmodel.BlockStoragePoolResult
	)

	ctx, cefl := context.WithTimeout(context.Background(), 5*time.Second)
	defer cefl()

	//从CMDB中获取资源池信息
	blockStoragePoolResult, err := cmdbmanager.GetBlockStorageResourcePoolList(t.Region, t.Name, t.Az, t.ResourcePool)
	if err != nil {
		klog.Error("get_blockStoragePoolResult_fail:", err)
		return blockStoragesResult, nil
	}
	blockRes = blockStoragePoolResult.Data.DataList
	currentTime := time.Now()
	blockStoragesResult.TotalCount = blockStoragePoolResult.Data.TotalCount
	for _, blockRe := range blockRes {
		//存储类型筛选
		if len(t.StorageType) != 0 {
			stateIn := services.In(t.StorageType, strings.ToLower(blockRe.ResourcePool))
			if !stateIn {
				continue
			}
		}
		//名称筛选
		name, _ := regexp.MatchString(t.Name, blockRe.Name)
		if !name {
			continue
		}
		var blockStorageMonitor resourcepoolmodel.BlockStorageMonitor
		blockStorageMonitor.Id = blockRe.Id
		blockStorageMonitor.Name = blockRe.Name
		blockStorageMonitor.Region = blockRe.RegionName
		blockStorageMonitor.RegionCode = blockRe.RegionCode
		blockStorageMonitor.Az = blockRe.AzName
		blockStorageMonitor.AzCode = blockRe.AzCode
		blockStorageMonitor.ResourcePool = blockRe.ResourcePool
		blockStorageMonitor.CreateTime = blockRe.CreateTime
		blockStorageMonitor.HostNumber = blockRe.HostNumber           //服务器数量
		blockStorageMonitor.CloudDiskNumber = blockRe.CloudDiskNumber // 块存储数量
		blockStorageMonitor.AlertAmount = alert.GetResourcePoolAlertNum(blockRe.RegionCode, blockRe.AzCode, "resourcePool", blockRe.ResourcePool, blockRe.Name)
		if blockStorageMonitor.CloudDiskNumber > 0 {
			blockStorageMonitor.ErrorRate, _ = strconv.ParseFloat(fmt.Sprintf("%.2f", float64(blockRe.CloudDiskErrNumber)/float64(blockStorageMonitor.CloudDiskNumber)), 64)
		}
		//总量
		CapacityTotal, err := prom.GetEbsCapTotal(blockRe.RegionCode, blockRe.AzCode, blockRe.Name, currentTime)
		if err != nil {
			klog.Error(err)
			return blockStoragesResult, nil
		}
		if len(CapacityTotal.Result) > 0 && len(CapacityTotal.Result[0].Values) > 0 {
			value := CapacityTotal.Result[0].Values[len(CapacityTotal.Result[0].Values)-1].([]interface{})
			v1, _ := strconv.ParseFloat(value[1].(string), 64)
			blockStorageMonitor.CapacityTotal = v1
		}
		//使用量
		CapacityUsed, err := prom.GetEbsCapUsed(blockRe.RegionCode, blockRe.AzCode, blockRe.Name, currentTime)
		if err != nil {
			klog.Error(err)
			return blockStoragesResult, nil
		}
		////使用率
		if len(CapacityUsed.Result) > 0 && len(CapacityUsed.Result[0].Values) > 0 {
			value := CapacityUsed.Result[0].Values[len(CapacityUsed.Result[0].Values)-1].([]interface{})
			v2, _ := strconv.ParseFloat(value[1].(string), 64)
			if blockStorageMonitor.CapacityTotal > 0 && blockStorageMonitor.CapacityTotal-v2 > 0 {
				blockStorageMonitor.CapacityAvailable = blockStorageMonitor.CapacityTotal - v2 //剩余量 = 总量-使用量
				v3, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", (v2/blockStorageMonitor.CapacityTotal)*100), 64)
				blockStorageMonitor.CapacityUsedRate = v3 //使用率
			}
		}
		blockStorageMonitor.MonitorStatus = "monitoring"
		if blockStorageMonitor.CapacityTotal <= 0 {
			blockStorageMonitor.MonitorStatus = "abnormal"
		}
		if len(t.MonitorStatus) != 0 {
			stateIn := services.In(t.MonitorStatus, blockRe.MonitorStatus)
			if !stateIn {
				continue
			}
		}
		if len(blockRe.Addresss) > 0 {
			ips := ""
			for _, ip := range blockRe.Addresss {
				if ip != "" {
					if ips == "" {
						ips = ip + ":9100"
					} else {
						ips = ips + "|" + ip + ":9100"
					}
				}
			}
			if ips != "" {
				metric := []string{"DiskIoReadsCompletedTotal"}
				diskIoReadsCompletedTotal := prom.QueryPhsicalMetric(ips, "", "", "", metric)
				metric = []string{"DiskIoWritesCompletedTotal"}
				diskIoWritesCompletedTotal := prom.QueryPhsicalMetric(ips, "", "", "", metric)
				metric = []string{"DiskIoReadtimeTotal"}
				diskIoReadtimeTotal := prom.QueryPhsicalMetric(ips, "", "", "", metric)
				metric = []string{"DiskIoWritetimeTotal"}
				diskIoWritetimeTotal := prom.QueryPhsicalMetric(ips, "", "", "", metric)
				//io 读/写吞吐
				blockStorageMonitor.IOInput = Strval(PrometheusResultToValue(diskIoReadsCompletedTotal[0].Value)) + "/" + Strval(PrometheusResultToValue(diskIoWritesCompletedTotal[0].Value))
				// io 读/写延时
				blockStorageMonitor.IODelay = Strval(PrometheusResultToValue(diskIoReadtimeTotal[0].Value)) + "/" + Strval(PrometheusResultToValue(diskIoWritetimeTotal[0].Value))
			}
		}
		var bandReadStr string
		var bandWriteStr string
		// 读带宽
		bandRead, err := client.VectorQuery(block.NewBlockMetics(blockRe.RegionCode, blockRe.AzCode, blockRe.Name).ToString("xuanwu_read_bw"))
		if err != nil {
			klog.Info(err)
		}
		redisReadKey := blockRe.Name + "bandRead"
		for _, v := range bandRead {
			if math.IsNaN(float64(v.Value)) {
				v.Value = 0
			}
			bandReadStr = strconv.FormatFloat(float64(v.Value), 'f', -1, 64)
			if bandReadStr != "" {
				_, setErr := client.SetNotExpire(ctx, redisReadKey, bandReadStr)
				if setErr != nil {
					klog.Infof("SetBandReadFial", setErr)
				}
			}
		}
		if bandReadStr == "" {
			bandReadStr1, _ := client.Get(ctx, redisReadKey, nil)
			bandReadStr = bandReadStr1
		}
		// 写带宽
		bandWrite, err := client.VectorQuery(block.NewBlockMetics(blockRe.RegionCode, blockRe.AzCode, blockRe.Name).ToString("xuanwu_write_bw"))
		if err != nil {
			klog.Info(err)
		}
		bandWriteKey := blockRe.Name + "bandWrite"
		for _, v := range bandWrite {
			if math.IsNaN(float64(v.Value)) {
				v.Value = 0
			}
			bandWriteStr = strconv.FormatFloat(float64(v.Value), 'f', -1, 64)
			fmt.Println("bandWriteStr", bandWriteStr)

			if bandWriteStr != "" {
				_, setErr := client.SetNotExpire(ctx, bandWriteKey, bandWriteStr)
				if setErr != nil {
					klog.Infof("SetBandWriteFial", setErr)
				}
			}
		}
		if bandWriteStr == "" {
			bandWriteStr1, _ := client.Get(ctx, bandWriteKey, nil)
			bandWriteStr = bandWriteStr1
		}
		//读写带宽
		blockStorageMonitor.Bandwidth = bandReadStr + "/" + bandWriteStr
		blockStoragesResult.DataList = append(blockStoragesResult.DataList, blockStorageMonitor)
	}

	//排序
	results := alert.Bucket{}
	for i := 0; i < len(blockStoragesResult.DataList); i++ {
		results.Slice = append(results.Slice, blockStoragesResult.DataList[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}
	if t.OrderCode == "" {
		t.OrderCode = "capacityUsedRate"
		t.OrderType = "desc"
	}
	if t.OrderCode != "" {
		switch t.OrderCode {
		case "capacityUsedRate":
			if t.OrderType != "" {
				switch t.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.BlockStorageMonitor).CapacityUsedRate < b.(resourcepoolmodel.BlockStorageMonitor).CapacityUsedRate
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.BlockStorageMonitor).CapacityUsedRate > b.(resourcepoolmodel.BlockStorageMonitor).CapacityUsedRate
					}
				}
			}

		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(blockStoragesResult.DataList); i++ {
		blockStoragesResult.DataList[i] = results.Slice[i].(resourcepoolmodel.BlockStorageMonitor)
	}
	//分页
	low := (t.PageNo - 1) * t.PageSize
	if low > len(blockStoragesResult.DataList) {
		return blockStoragesResult, nil
	}

	hight := low + t.PageSize
	if hight > len(blockStoragesResult.DataList) {
		hight = len(blockStoragesResult.DataList)
	}

	blockStoragesResult.PageNo = t.PageNo
	blockStoragesResult.PageSize = t.PageSize
	blockStoragesResult.TotalCount = len(blockStoragesResult.DataList)
	blockStoragesResult.DataList = blockStoragesResult.DataList[low:hight]
	return blockStoragesResult, err
}
func GetStoragePoolMonitorTargetLineList(query resourcepoolmodel.StorageMonitorTargetQuery) []resourcepoolmodel.StorageLineDataResult {
	responseMetric := prometheusModel.ResponseMetric{}

	lineDataList := []resourcepoolmodel.StorageLineDataResult{}
	for _, q := range query.List {
		query.Query = q
		lineData := resourcepoolmodel.StorageLineDataResult{}
		start, err := strconv.ParseFloat(query.Start, 64)
		if err != nil {
			return lineDataList
		}
		end, err := strconv.ParseFloat(query.End, 64)
		if err != nil {
			return lineDataList
		}
		step := services.TimeToStep(end - start)
		responseMetric = prom.GetStorageUseQuery(query.Region, query.Az, query.Name, query.Start, query.End, step, query.Query)

		lineData.Values = PrometheusResultToValue(responseMetric.Value)
		if query.Query == "CapRate" {
			lineData.Name = query.Name
		} else {
			lineData.Name = responseMetric.Metric
		}
		lineDataList = append(lineDataList, lineData)
	}
	return lineDataList
}

func (b *BlockPoolService) GetBlockPoolMetric(id string) (rst []resourcepoolmodel.MetricT) {
	q := resourcepoolmodel.BlockPoolListQuery{PageNo: 1, PageSize: 1000, Region: "all"}
	idd, _ := strconv.Atoi(id)
	list, err := b.GetBlockPoolList(&q)
	if err != nil {
		klog.Error(err)
		return
	}
	poolCapTotal := resourcepoolmodel.MetricT{
		ID:       id,
		Name:     "块存储池总容量",
		Unit:     "GB",
		UnitType: "strage",
		Kind:     "info",
	}

	poolCapAva := resourcepoolmodel.MetricT{
		ID:       id,
		Name:     "块存储池可用容量",
		Unit:     "GB",
		UnitType: "strage",
		Kind:     "info",
	}

	cloudDiskQuery := cmdbmodel.CloudDiskRequest{
		PageNo:   1,
		PageSize: int(^uint16(0)),
	}
	for i := 0; i < len(list.DataList); i++ {
		j := list.DataList[i]
		if j.Id == idd {
			cloudDiskQuery.Region = j.RegionCode
			cloudDiskQuery.Az = append(cloudDiskQuery.Az, j.AzCode)
			cloudDiskQuery.ResourcePool = j.Name
			poolCapTotal.Value = j.CapacityTotal
			poolCapAva.Value = j.CapacityAvailable
		}
	}

	//QueryBlockList
	//cmdb, err := cmdbmanager.GetCMDBBytes(region, az)

	cmdb, err := cmdbmanager.GetCMDBCloudDiskList(cloudDiskQuery)

	if err != nil {
		klog.Error(err)
		return
	}

	poolBlockNum := resourcepoolmodel.MetricT{
		ID:       id,
		Name:     "块存储总数",
		Unit:     "个",
		UnitType: "number",
		Value:    len(cmdb.Data.DataList),
		Kind:     "info",
	}
	poolBlockNumInUse := resourcepoolmodel.MetricT{
		ID:       id,
		Name:     "使用中块存储总数",
		Unit:     "个",
		UnitType: "number",
		Kind:     "info",
	}
	poolBlockNumAva := resourcepoolmodel.MetricT{
		ID:       id,
		Name:     "待挂载块存储总数",
		Unit:     "个",
		UnitType: "number",
		Kind:     "info",
	}
	var inUseNum, avaNum int64
	for i := 0; i < len(cmdb.Data.DataList); i++ {
		j := cmdb.Data.DataList[i]

		switch j.UseStatus {
		case "in-use":
			inUseNum++
		case "available":
			avaNum++
		}
	}
	poolBlockNumInUse.Value = inUseNum
	poolBlockNumAva.Value = avaNum

	rst = append(rst, poolCapTotal, poolCapAva, poolBlockNum, poolBlockNumInUse, poolBlockNumAva)

	return
}

func GetMonitorTargetLineListForStorage(storageMonitorTargetQuery resourcepoolmodel.StorageMonitorTargetQuery) []resourcepoolmodel.StorageLineDataResult {
	//var hostList []cmdbmodel.Host
	responseMetric := prometheusModel.ResponseMetric{}
	lineData := resourcepoolmodel.StorageLineDataResult{}
	lineDataList := []resourcepoolmodel.StorageLineDataResult{}
	//metrics := []string{"DiskIoReadsCompletedTotal", "DiskIoWritesCompletedTotal", "DiskIoReadtimeTotal", "DiskIoWritetimeTotal"}

	//if IsContain(metrics, storageMonitorTargetQuery.Query) {
	//metric := []string{}
	var hostList []cmdbmodel.Host
	//从cmdb中获取服务器列表
	hostList, err := cmdbmanager.GetHostListByResourcePoolName(storageMonitorTargetQuery.Name, "1", "10000")
	if err != nil {
		return lineDataList
	}
	if len(hostList) > 0 {
		ips := ""
		for _, host := range hostList {
			//从CMDB中获取服务器ip
			ip, err := cmdbmanager.GetHostDetailByHostname(host.Name)
			if err == nil && ip != "" {
				if ips == "" {
					ips = ip + ":9100"
				} else {
					ips = ips + "|" + ip + ":9100"
				}
			}
		}
		if strings.TrimSuffix(ips, ":9100") != "" {
			for _, q := range storageMonitorTargetQuery.List {
				//metric = append(metric, q)
				start, err := strconv.ParseFloat(storageMonitorTargetQuery.Start, 64)
				if err != nil {
					return lineDataList
				}
				end, err := strconv.ParseFloat(storageMonitorTargetQuery.End, 64)
				if err != nil {
					return lineDataList
				}
				step := services.TimeToStep(end - start)
				responseMetric = prom.QueryPhsicalMetric(ips, storageMonitorTargetQuery.Start, storageMonitorTargetQuery.End, step, []string{q})[0]

				lineData.Values = PrometheusResultToValue(responseMetric.Value)
				lineData.Name = responseMetric.Metric
				lineDataList = append(lineDataList, lineData)
			}

		}
	}
	//}

	return lineDataList

}

type Tenant struct {
	Id   string `json:"id"`
	Name string `json:"name"`
}

// 获取资源池管理-块存储资源池-库存list
//func (b *BlockPoolService) GetBlockPoolUsageList(t resourcepoolmodel.BlockStorageUseageQuery) (resourcepoolmodel.BlockStoragesUseageResult, error) {
//	klog.Infof("get GetBlockPoolUsageList param:", t)
//	//从CMDB中获取资源池信息
//	var blockStoragesResult resourcepoolmodel.BlockStoragesUseageResult
//	var blockRes []cmdbmodel.BlockRe
//	var blockStoragePoolResult cmdbmodel.BlockStoragePoolResult
//	resourcePool := t.StorageType
//	// if t.StorageType != "all" && t.StorageType != "" {
//	// 	resourcePool = append(resourcePool, t.StorageType)
//	// }
//	for i := range resourcePool {
//		resourcePool[i] = strings.ToLower(resourcePool[i])
//	}
//	if len(t.Name) > 0 {
//		for i := range t.Name {
//			blockStoragePoolResult, err := cmdbmanager.GetBlockStorageResourcePoolList(t.Region, t.Name[i], t.Az, resourcePool)
//			if err != nil {
//				klog.Info("get cmdbmanager.GetBlockStorageResourcePoolList fail name ")
//				return blockStoragesResult, err
//			}
//			blockRes = append(blockRes, blockStoragePoolResult.Data.DataList...)
//		}
//	} else {
//		blockStoragePoolResult, err := cmdbmanager.GetBlockStorageResourcePoolList(t.Region, "", t.Az, resourcePool)
//		if err != nil {
//			klog.Info("get cmdbmanager.GetBlockStorageResourcePoolList fail")
//			return blockStoragesResult, err
//		}
//		blockRes = append(blockRes, blockStoragePoolResult.Data.DataList...)
//	}
//
//	currentTime := time.Now()
//	if len(blockRes) > 0 {
//		blockStoragesResult.TotalCount = blockStoragePoolResult.Data.TotalCount
//		for _, blockRe := range blockRes {
//			klog.Infof("blockReName:", blockRe.Name)
//			var blockStorageMonitor resourcepoolmodel.BlockStorageUseage
//			blockStorageMonitor.Id = blockRe.Id
//			blockStorageMonitor.Name = blockRe.Name
//			blockStorageMonitor.Region = blockRe.RegionName
//			blockStorageMonitor.RegionCode = blockRe.RegionCode
//			blockStorageMonitor.Az = blockRe.AzName
//			blockStorageMonitor.ResourcePool = blockRe.ResourcePool
//			blockStorageMonitor.CreateTime = blockRe.CreateTime
//			CapacityTotal, err := prom.GetEbsCapTotal(blockRe.RegionCode, blockRe.AzCode, blockRe.Name, currentTime) // 总容量
//			if err != nil {
//				klog.Info("get prom块存储总容量失败")
//				return blockStoragesResult, err
//			}
//			CapacityUsed, err := prom.GetEbsCapUsed(blockRe.RegionCode, blockRe.AzCode, blockRe.Name, currentTime) // 使用率
//			if err != nil {
//				klog.Info("get prom块存储使用率失败")
//				return blockStoragesResult, err
//			}
//			// CapacityUsedRate, err := prom.GetCapRate(blockRe.RegionCode, config.ReasourcePoolMap[blockRe.Name], currentTime)
//			// if err != nil {
//			// 	return blockStoragesResult, err
//			// }
//			if len(CapacityTotal.Result) > 0 && len(CapacityTotal.Result[0].Values) > 0 {
//				value := CapacityTotal.Result[0].Values[len(CapacityTotal.Result[0].Values)-1].([]interface{})
//				v1, _ := strconv.ParseFloat(value[1].(string), 64)
//				//v1, _ := strconv.ParseFloat(CapacityTotal.Result[0].Value, 64)
//				blockStorageMonitor.CapacityTotal = v1
//			}
//			if len(CapacityUsed.Result) > 0 && len(CapacityUsed.Result[0].Values) > 0 {
//				value := CapacityUsed.Result[0].Values[len(CapacityUsed.Result[0].Values)-1].([]interface{})
//				v2, _ := strconv.ParseFloat(value[1].(string), 64)
//				//v2, _ := strconv.ParseFloat(CapacityUsed.Result[0].Value, 64)
//				if blockStorageMonitor.CapacityTotal > 0 && blockStorageMonitor.CapacityTotal-v2 > 0 {
//					blockStorageMonitor.CapacityAvailable = blockStorageMonitor.CapacityTotal - v2 // 剩余量
//					v3, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", (v2/blockStorageMonitor.CapacityTotal)*100), 64)
//					blockStorageMonitor.CapacityUsedRate = v3
//				}
//			}
//			if err != nil {
//				klog.Errorf("get cmdbmanager.GetBlockStock err : %s", err)
//			}
//			// if len(CapacityUsedRate.Result) > 0 && CapacityUsedRate.Result[0].Value != "NaN" {
//			// 	v3, _ := strconv.ParseFloat(CapacityUsedRate.Result[0].Value, 64)
//			// 	vv3 := prom.FormValue(v3)
//			// 	blockStorageMonitor.CapacityUsedRate = vv3.(float64)
//			// }
//
//			// todo 获取库存数据
//			klog.Info("getstock:", blockRe.Name)
//
//			var stock cmdbmodel.GetPoolStock
//			var clusters cmdbmodel.GetPoolClusters
//
//			if blockRe.Name == "ssd3.0" {
//				blockRe.Name = "ssd3"
//			}
//
//			ctx, cefl := context.WithTimeout(context.Background(), 3*time.Minute)
//			defer cefl()
//
//			azIdStr := "az" + strconv.Itoa(blockRe.AzId)
//			stockKey := fmt.Sprintf("block_storage_name_%s_%s", azIdStr, blockRe.Name)
//			stock = HGetStockRedis(ctx, stockKey, "getStock")
//			if len(stock.EBSServers) == 0 {
//				klog.Info("未走缓存stock查接口")
//
//				stock1, stockErr := cmdbmanager.GetBlockStock(blockRe.StockUrl)
//				if stockErr != nil {
//					klog.Errorf("Failed to get GetBlockStock information:", stockErr)
//					blockStoragesResult.DataList = append(blockStoragesResult.DataList, blockStorageMonitor)
//					continue
//				}
//				stock = stock1
//				HsetStockRedis(ctx, stockKey, "getStock", stock)
//			}
//			clusters = HGetClustersRedis(ctx, stockKey, "getClusters")
//			if len(clusters) == 0 {
//				klog.Info("未走缓存clusters查接口")
//				clusters1, clustersErr := cmdbmanager.GetBlockClusters(blockRe.MetricUrl)
//				if clustersErr != nil {
//					klog.Errorf("Failed to get GetBlockClusters information:", clustersErr)
//					blockStoragesResult.DataList = append(blockStoragesResult.DataList, blockStorageMonitor)
//					continue
//				}
//				clusters = clusters1
//				HsetClustersRedis(ctx, stockKey, "getClusters", clusters)
//			}
//
//			if len(stock.EBSServers) == 0 || len(clusters) == 0 {
//				klog.Info("未获取到库存数据")
//				blockStoragesResult.DataList = append(blockStoragesResult.DataList, blockStorageMonitor)
//				continue
//			}
//			ips := []string{}
//			highestDiskList := []int{}
//			for _, v := range stock.EBSServers {
//				ips = append(ips, v.ServerAddress)
//				highest := strings.Trim(v.DiskUsed, "%")
//				highestInt, _ := strconv.Atoi(highest)
//				highestDiskList = append(highestDiskList, highestInt)
//			}
//			serverAddress := services.RemoveDuplicateElement(ips)
//			highestDisk := services.Maximum(highestDiskList)
//
//			var size int
//			var dosage int
//			var unitTotal int
//			var unitUsed int
//			for _, item := range stock.EBSServers {
//				total := strings.Trim(item.DiskTotal, "GiB")
//				free := strings.Trim(item.DiskFree, "GiB")
//				diskTotal, _ := strconv.Atoi(total)
//				diskFree, _ := strconv.Atoi(free)
//				size += diskTotal
//				dosage += diskFree
//				unitTotal += item.TotalCU
//				unitUsed += item.UsedCU
//			}
//
//			logicalSize := clusters[0].TotalDiskCapacity / 3 //逻辑大小
//			logicalUsage := clusters[0].TotalUsedSpace / 3   // 逻辑用量
//
//			physicalSize := size / 3
//			physicalDosage := (size - dosage) / 3
//			blockStorageMonitor.ServersNum = len(serverAddress) //去重复之后服务器数量
//			blockStorageMonitor.PhysicalSize = physicalSize     // 物理大小 （单副本）
//			blockStorageMonitor.PhysicalDosage = physicalDosage // 物理用量 （单副本）
//
//			physicalRWRatio, _ := strconv.ParseFloat(services.Strval(float64(physicalDosage)/float64(physicalSize)), 64)
//			blockStorageMonitor.PhysicalRWRatio = parseFloatNaN(physicalRWRatio) //物理读写比
//
//			writeRateUp, _ := strconv.ParseFloat(services.Strval(float64(logicalSize)/float64(physicalSize)), 64)
//			blockStorageMonitor.WriteRateUp = parseFloatNaN(writeRateUp) //写入率上限
//			blockStorageMonitor.HighestDisk = highestDisk                // 最高盘
//			blockStorageMonitor.OpenNum = stock.OpenNum                  // 开盘个数
//
//			vdiOpenNum := services.FormatFileSize(int64(stock.VdiOpenNum))
//			vdiWriteNum := services.FormatFileSize(int64(stock.VdiWriteNum))
//			blockStorageMonitor.VdiOpenNum = vdiOpenNum   //vdi开盘量
//			blockStorageMonitor.VdiWriteNum = vdiWriteNum //vdi写入量
//
//			Oversold, _ := strconv.ParseFloat(services.Strval(float64(stock.VdiWriteNum)/float64(stock.VdiOpenNum)), 64)
//			blockStorageMonitor.Oversold = parseFloatNaN(Oversold) // 超卖率
//			blockStorageMonitor.UnitTotal = unitTotal              // unit总量
//			blockStorageMonitor.UnitUsed = unitUsed                //unit可用
//			unitRate, _ := strconv.ParseFloat(services.Strval(float64(unitUsed)/float64(unitTotal)), 64)
//			blockStorageMonitor.UnitRate = parseFloatNaN(unitRate) //unit使用率
//
//			vdi, _ := strconv.ParseFloat(strings.Trim(vdiOpenNum, "GB"), 64)
//			salesRate, _ := strconv.ParseFloat(services.Strval(vdi/float64(logicalSize/3)), 64)
//			blockStorageMonitor.SalesRate = parseFloatNaN(salesRate)        // 售卖率
//			blockStorageMonitor.Saleable = (logicalSize - logicalUsage) / 3 //可售卖
//			blockStorageMonitor.LogicalSize = logicalSize                   // 逻辑大小
//			blockStorageMonitor.LogicalUsage = logicalUsage                 // 逻辑用量
//
//			blockStoragesResult.DataList = append(blockStoragesResult.DataList, blockStorageMonitor)
//		}
//	}
//
//	//排序
//	results := alert.Bucket{}
//	for i := 0; i < len(blockStoragesResult.DataList); i++ {
//		results.Slice = append(results.Slice, blockStoragesResult.DataList[i])
//	}
//	time_by := func(a, b interface{}) bool {
//		return true
//	}
//	if t.OrderCode == "" {
//		t.OrderCode = "createTime"
//		t.OrderType = "desc"
//	}
//	if t.OrderCode != "" {
//		switch t.OrderCode {
//		case "capacityTotal":
//			if t.OrderType != "" {
//				switch t.OrderType {
//				case "asc":
//					time_by = func(a, b interface{}) bool {
//						return a.(resourcepoolmodel.BlockStorageUseage).CapacityTotal < b.(resourcepoolmodel.BlockStorageUseage).CapacityTotal
//					}
//				case "desc":
//					time_by = func(a, b interface{}) bool {
//						return a.(resourcepoolmodel.BlockStorageUseage).CapacityTotal > b.(resourcepoolmodel.BlockStorageUseage).CapacityTotal
//					}
//				}
//			}
//		case "capacityAvailable":
//			if t.OrderType != "" {
//				switch t.OrderType {
//				case "asc":
//					time_by = func(a, b interface{}) bool {
//						return a.(resourcepoolmodel.BlockStorageUseage).CapacityAvailable < b.(resourcepoolmodel.BlockStorageUseage).CapacityAvailable
//					}
//				case "desc":
//					time_by = func(a, b interface{}) bool {
//						return a.(resourcepoolmodel.BlockStorageUseage).CapacityAvailable > b.(resourcepoolmodel.BlockStorageUseage).CapacityAvailable
//					}
//				}
//			}
//		case "capacityUsedRate":
//			if t.OrderType != "" {
//				switch t.OrderType {
//				case "asc":
//					time_by = func(a, b interface{}) bool {
//						return a.(resourcepoolmodel.BlockStorageUseage).CapacityUsedRate < b.(resourcepoolmodel.BlockStorageUseage).CapacityUsedRate
//					}
//				case "desc":
//					time_by = func(a, b interface{}) bool {
//						return a.(resourcepoolmodel.BlockStorageUseage).CapacityUsedRate > b.(resourcepoolmodel.BlockStorageUseage).CapacityUsedRate
//					}
//				}
//			}
//		case "createTime":
//			if t.OrderType != "" {
//				switch t.OrderType {
//				case "asc":
//					time_by = func(a, b interface{}) bool {
//						return a.(resourcepoolmodel.BlockStorageUseage).CreateTime < b.(resourcepoolmodel.BlockStorageUseage).CreateTime
//					}
//				case "desc":
//					time_by = func(a, b interface{}) bool {
//						return a.(resourcepoolmodel.BlockStorageUseage).CreateTime > b.(resourcepoolmodel.BlockStorageUseage).CreateTime
//					}
//				}
//			}
//
//		}
//
//	}
//
//	results.By = time_by
//
//	sort.Sort(results)
//	for i := 0; i < len(blockStoragesResult.DataList); i++ {
//		blockStoragesResult.DataList[i] = results.Slice[i].(resourcepoolmodel.BlockStorageUseage)
//	}
//	//分页
//	low := (t.PageNo - 1) * t.PageSize
//	if low > len(blockStoragesResult.DataList) {
//		return blockStoragesResult, nil
//	}
//
//	hight := low + t.PageSize
//	if hight > len(blockStoragesResult.DataList) {
//		hight = len(blockStoragesResult.DataList)
//	}
//
//	blockStoragesResult.PageNo = t.PageNo
//	blockStoragesResult.PageSize = t.PageSize
//	blockStoragesResult.TotalCount = len(blockStoragesResult.DataList)
//	blockStoragesResult.DataList = blockStoragesResult.DataList[low:hight]
//
//	return blockStoragesResult, nil
//}

// GetBlockPoolUsageList 上面注释的为之前的写法
func (b *BlockPoolService) GetBlockPoolUsageList(t resourcepoolmodel.BlockStorageUseageQuery) (resourcepoolmodel.BlockStoragesUseageResult, error) {
	klog.Infof("get GetBlockPoolUsageList param:", t)
	//从CMDB中获取资源池信息
	var blockStoragesResult resourcepoolmodel.BlockStoragesUseageResult
	var blockRes []cmdbmodel.BlockRe
	var blockStoragePoolResult cmdbmodel.BlockStoragePoolResult
	resourcePool := t.StorageType

	for i := range resourcePool {
		resourcePool[i] = strings.ToLower(resourcePool[i])
	}
	if len(t.Name) > 0 {
		for i := range t.Name {
			blockStoragePoolResult, err := cmdbmanager.GetBlockStorageResourcePoolList(t.Region, t.Name[i], t.Az, resourcePool)
			if err != nil {
				klog.Info("get cmdbmanager.GetBlockStorageResourcePoolList fail name ")
				return blockStoragesResult, err
			}
			blockRes = append(blockRes, blockStoragePoolResult.Data.DataList...)
		}
	} else {
		blockStoragePoolResult, err := cmdbmanager.GetBlockStorageResourcePoolList(t.Region, "", t.Az, resourcePool)
		if err != nil {
			klog.Info("get cmdbmanager.GetBlockStorageResourcePoolList fail")
			return blockStoragesResult, err
		}
		blockRes = append(blockRes, blockStoragePoolResult.Data.DataList...)
	}

	if len(blockRes) > 0 {
		blockStoragesResult.TotalCount = blockStoragePoolResult.Data.TotalCount
		for _, blockRe := range blockRes {
			klog.Infof("blockReName:", blockRe.Name)
			var blockStorageMonitor resourcepoolmodel.BlockStorageUseage
			blockStorageMonitor.Id = blockRe.Id
			blockStorageMonitor.Name = blockRe.Name
			blockStorageMonitor.Region = blockRe.RegionName
			blockStorageMonitor.RegionCode = blockRe.RegionCode
			blockStorageMonitor.Az = blockRe.AzName
			blockStorageMonitor.ResourcePool = blockRe.ResourcePool
			blockStorageMonitor.CreateTime = blockRe.CreateTime

			apiHost := strings.TrimLeft(strings.TrimRight(blockRe.StockUrl, "/ebs/stock"), "http://")
			storageClient := client.NewStorageApiClient(apiHost)
			ebsCap, err := storageClient.GetEbsCap()
			if err != nil {
				klog.Errorf("GetEbsCap err : %s", err.Error())
			}
			blockStorageMonitor.CapacityTotal = float64(ebsCap.TotalDiskCapacity)                             //总容量
			blockStorageMonitor.CapacityAvailable = float64(ebsCap.TotalDiskCapacity - ebsCap.TotalUsedSpace) //剩余量
			if ebsCap.TotalDiskCapacity > 0 {
				blockStorageMonitor.CapacityUsedRate, _ = strconv.ParseFloat(fmt.Sprintf("%.2f", (float64(ebsCap.TotalUsedSpace)/float64(ebsCap.TotalDiskCapacity))*100), 64)
			} else {
				blockStorageMonitor.CapacityUsedRate = 0 //使用率
			}
			vdiNames, err := storageClient.GetEbsVdiNameList()
			if err != nil {
				klog.Errorf("GetEbsVdiNameList err : %s", err.Error())
			}
			blockStorageMonitor.OpenNum = len(vdiNames)
			ebsServers, err := storageClient.GetEbsServerList()
			if err != nil {
				klog.Errorf("GetEbsServerList err : %s", err.Error())
			}
			blockStorageMonitor.ServersNum = len(getEBSServerIPList(ebsServers)) //服务器数量

			physicalSizeAll, physicalUsageAll, physicalRWRatio, highestDisk, unitTotal, unitUsed := stockCount(ebsServers)
			blockStorageMonitor.PhysicalSize = int(physicalSizeAll / 3)    // 物理大小 （单副本）
			blockStorageMonitor.PhysicalDosage = int(physicalUsageAll / 3) // 物理用量 （单副本）
			blockStorageMonitor.PhysicalSizeAll = physicalSizeAll
			blockStorageMonitor.PhysicalUsageAll = physicalUsageAll
			blockStorageMonitor.PhysicalRWRatio = physicalRWRatio
			blockStorageMonitor.LogicalSize = int(ebsCap.TotalDiskCapacity / 3) //逻辑大小（单副本）
			blockStorageMonitor.LogicalUsage = int(ebsCap.TotalUsedSpace / 3)   //逻辑用量（单副本）

			tabletConf, err := storageClient.GetEbsTabletConfig()
			if err != nil {
				klog.Errorf("GetEbsTabletConfig err : %s", err.Error())
			}
			reserveSize := tabletConf.ReserveSpace * countEBSDiskStore(ebsServers)
			//可售卖 ？可售卖=逻辑大小（单副本）-逻辑用量（单副本）-磁盘保留量
			blockStorageMonitor.Saleable = blockStorageMonitor.LogicalSize - blockStorageMonitor.LogicalUsage - int(reserveSize)

			var vdiOpenSize, vdiWriteSize, snapshotSize int64
			//for _, vdiName := range vdiNames {
			//	vdiInfo, err := storageClient.GetEbsVdiInfo(vdiName)
			//	if err != nil {
			//		klog.Errorf("GetEbsTabletConfig err : %s", err.Error())
			//		continue
			//	}
			//	vdiOpenSize += vdiInfo.Size
			//	vdiWriteSize += vdiInfo.UsedSize
			//	snapshotSize += sumSnapshotSize(vdiInfo.Snapshots)
			//}

			vdiInfos := getVdiInfoList(vdiNames, storageClient)
			for _, vdiInfo := range vdiInfos {
				vdiOpenSize += vdiInfo.Size
				vdiWriteSize += vdiInfo.UsedSize
				snapshotSize += sumSnapshotSize(vdiInfo.Snapshots)
			}

			blockStorageMonitor.AllocatedSize = vdiOpenSize + snapshotSize
			allocatedSizeGb := blockStorageMonitor.AllocatedSize / (1024 * 1024 * 1024)
			if blockStorageMonitor.LogicalSize > 0 {
				blockStorageMonitor.SalesRate, _ = strconv.ParseFloat(services.Strval(float64(allocatedSizeGb)/float64(blockStorageMonitor.LogicalSize)), 64)
			}
			blockStorageMonitor.VdiOpenNum = services.FormatFileSize(vdiOpenSize)   //vdi开盘量
			blockStorageMonitor.VdiWriteNum = services.FormatFileSize(vdiWriteSize) //vdi写入量
			blockStorageMonitor.SnapshotSize = snapshotSize                         //快照容量，单位byte
			Oversold, _ := strconv.ParseFloat(services.Strval(float64(vdiWriteSize)/float64(vdiOpenSize)), 64)
			blockStorageMonitor.Oversold = parseFloatNaN(Oversold)   // 资源使用比，原超卖率
			blockStorageMonitor.HighestDisk = highestDisk            //最高盘
			blockStorageMonitor.UnitTotal = int(unitTotal)           //unit总量
			blockStorageMonitor.UnitUsed = int(unitTotal - unitUsed) //unit可用
			blockStorageMonitor.UnitRate, _ = strconv.ParseFloat(services.Strval(float64(unitUsed)/float64(unitTotal)), 64)
			writeRateUp, _ := strconv.ParseFloat(services.Strval(float64(blockStorageMonitor.LogicalSize)/float64(blockStorageMonitor.PhysicalSize)), 64)
			blockStorageMonitor.WriteRateUp = parseFloatNaN(writeRateUp) //写入率上限
			blockStoragesResult.DataList = append(blockStoragesResult.DataList, blockStorageMonitor)
		}
	}

	//排序
	results := alert.Bucket{}
	for i := 0; i < len(blockStoragesResult.DataList); i++ {
		results.Slice = append(results.Slice, blockStoragesResult.DataList[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}
	if t.OrderCode == "" {
		t.OrderCode = "createTime"
		t.OrderType = "desc"
	}
	if t.OrderCode != "" {
		switch t.OrderCode {
		case "capacityTotal":
			if t.OrderType != "" {
				switch t.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.BlockStorageUseage).CapacityTotal < b.(resourcepoolmodel.BlockStorageUseage).CapacityTotal
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.BlockStorageUseage).CapacityTotal > b.(resourcepoolmodel.BlockStorageUseage).CapacityTotal
					}
				}
			}
		case "capacityAvailable":
			if t.OrderType != "" {
				switch t.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.BlockStorageUseage).CapacityAvailable < b.(resourcepoolmodel.BlockStorageUseage).CapacityAvailable
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.BlockStorageUseage).CapacityAvailable > b.(resourcepoolmodel.BlockStorageUseage).CapacityAvailable
					}
				}
			}
		case "capacityUsedRate":
			if t.OrderType != "" {
				switch t.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.BlockStorageUseage).CapacityUsedRate < b.(resourcepoolmodel.BlockStorageUseage).CapacityUsedRate
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.BlockStorageUseage).CapacityUsedRate > b.(resourcepoolmodel.BlockStorageUseage).CapacityUsedRate
					}
				}
			}
		case "createTime":
			if t.OrderType != "" {
				switch t.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.BlockStorageUseage).CreateTime < b.(resourcepoolmodel.BlockStorageUseage).CreateTime
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(resourcepoolmodel.BlockStorageUseage).CreateTime > b.(resourcepoolmodel.BlockStorageUseage).CreateTime
					}
				}
			}

		}

	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(blockStoragesResult.DataList); i++ {
		blockStoragesResult.DataList[i] = results.Slice[i].(resourcepoolmodel.BlockStorageUseage)
	}
	//分页
	low := (t.PageNo - 1) * t.PageSize
	if low > len(blockStoragesResult.DataList) {
		return blockStoragesResult, nil
	}

	hight := low + t.PageSize
	if hight > len(blockStoragesResult.DataList) {
		hight = len(blockStoragesResult.DataList)
	}

	blockStoragesResult.PageNo = t.PageNo
	blockStoragesResult.PageSize = t.PageSize
	blockStoragesResult.TotalCount = len(blockStoragesResult.DataList)
	blockStoragesResult.DataList = blockStoragesResult.DataList[low:hight]

	return blockStoragesResult, nil
}

func getVdiInfoList(vdiNames []string, storageClient *client.StorageApiClient) (vdiInfoList []*client.VdiInfo) {
	var lock sync.Mutex
	var wg1 sync.WaitGroup
	for _, vdiName := range vdiNames {
		wg1.Add(1)
		go func(storageClient *client.StorageApiClient, vn string) {
			defer wg1.Done()
			vdiInfo, err := storageClient.GetEbsVdiInfo(vn)
			if err != nil {
				klog.Errorf("GetEbsTabletConfig err : %s", err.Error())
				return
			}
			lock.Lock()
			vdiInfoList = append(vdiInfoList, vdiInfo)
			lock.Unlock()
		}(storageClient, vdiName)

	}
	wg1.Wait()
	return
}

func sumSnapshotSize(snapshots []*client.Snapshot) (size int64) {
	for _, snapshot := range snapshots {
		size += snapshot.Size
	}
	return
}

func countEBSDiskStore(servers []*client.EBSServer) (count int64) {
	for _, store := range servers {
		if store.CacheStore == 0 {
			count++
		}
	}
	return
}

func stockCount(servers []*client.EBSServer) (physicalSizeAll, physicalUsageAll int64, physicalRWRatio float64, highestDisk int, unitTotal, unitUsed int64) {
	var physicalFreeAll int64

	for _, server := range servers {
		total := strings.Trim(server.DiskTotal, "GiB")
		free := strings.Trim(server.DiskFree, "GiB")
		used := strings.Trim(server.DiskUsed, "%")

		diskTotal, _ := strconv.ParseInt(total, 10, 64)
		diskFree, _ := strconv.ParseInt(free, 10, 64)
		diskUsed, _ := strconv.Atoi(used)
		physicalSizeAll += diskTotal
		physicalFreeAll += diskFree
		if diskUsed > highestDisk {
			highestDisk = diskUsed
		}
		unitTotal += int64(server.TotalCU)
		unitUsed += int64(server.UsedCU)
	}

	physicalUsageAll = physicalSizeAll - physicalFreeAll
	if physicalSizeAll > 0 {
		physicalRWRatio, _ = strconv.ParseFloat(services.Strval(float64(physicalUsageAll)/float64(physicalSizeAll)), 64)
	} else {
		physicalRWRatio = float64(0)
	}

	return
}

func getEBSServerIPList(servers []*client.EBSServer) []string {
	list := make([]string, 0)
	ipMap := make(map[string]string, 0)

	for _, server := range servers {
		addr := strings.Split(server.ServerAddress, ":")
		if len(addr) < 2 {
			continue
		}
		ip := addr[0]
		ipMap[ip] = ""
	}
	for ip, _ := range ipMap {
		list = append(list, ip)
	}
	return list
}

// NaN 会导致json解析失败，处理为0
func parseFloatNaN(f float64) float64 {
	if fmt.Sprintf("%v", f) == "NaN" {
		return float64(0)
	}
	return f
}

// 获取资源管理-块存储资源池-概览页面数据
func GetBlockStorageOverView(query resourcepoolmodel.CMDBOverViewQuery) (resourcepoolmodel.CMDBBlockStorageOverview, error) {
	//aggregateID := request.PathParameter("id")

	//res := []server.PhysicalHostData{}
	var hostOverview resourcepoolmodel.CMDBBlockStorageOverview
	currentTime := time.Now()
	azList := []string{}
	if query.Az != "" && query.Az != "all" {
		azList = append(azList, query.Az)
	}
	var resourcePool []string
	if query.DiskType != "" {
		resourcePool = append(resourcePool, query.DiskType)
	}
	// 获取块存储资源池列表
	blockStoragePoolResult, err := cmdbmanager.GetBlockStorageResourcePoolList(query.Region, "", azList, resourcePool)
	fmt.Println("blockStoragePoolResult", blockStoragePoolResult)
	fmt.Println("len", len(blockStoragePoolResult.Data.DataList))
	sum := 0 // 云硬盘数量
	cloudDiskQuery := cmdbmodel.CloudDiskRequest{
		Region: query.Region,
		Az:     azList, //query.Az,
	}
	//获取云产品块存储列表
	bb, err := cmdbmanager.GetCMDBCloudDiskListAll(cloudDiskQuery)
	if err != nil {
		klog.Infof("GetCMDBCloudDiskListAll err:%s", err)
		return hostOverview, err
	}
	sbList := bb.Data.DataList
	for _, blockStoragePool := range blockStoragePoolResult.Data.DataList {
		if query.DiskType != "" && query.DiskType != blockStoragePool.ResourcePool { // 过滤资源池
			continue
		}
		overView := resourcepoolmodel.OverView{}
		blockDistributedOverView := resourcepoolmodel.BlockDistributedOverView{}
		switch blockStoragePool.ResourcePool {
		case "ssd3.0":
			overView.Name = "云硬盘3.0(SSD)"
		// case "ssd2.0":
		// 	overView.Name = "云硬盘2.0(SSD)"
		case "ehdd":
			overView.Name = "高效云盘"
			// case "sata2.0":
			// 	overView.Name = "云硬盘2.0(SATA)"
		}
		overView.Unit = "个"
		overView.Code = blockStoragePool.ResourcePool
		overView.Value = blockStoragePool.CloudDiskNumber
		sum += blockStoragePool.CloudDiskNumber //云硬盘数量
		blockDistributedOverView, _ = GetBlockStorageCapAll(blockStoragePool.RegionCode, blockStoragePool.AzCode, blockStoragePool.Name, overView.Name, blockStoragePool.ResourcePool, currentTime)
		distributionCapOverView := GetCloudDiskDistributionCap(blockStoragePool.Name, sbList, blockDistributedOverView)
		blockDistributedOverView.Distributed = append(blockDistributedOverView.Distributed, distributionCapOverView)
		hostOverview.TotalStorageOverview = append(hostOverview.TotalStorageOverview, blockDistributedOverView)
		hostOverview.VMCountOverview = append(hostOverview.VMCountOverview, overView)
	}
	//添加云硬盘2.0(SATA)
	// overView := resourcepoolmodel.OverView{
	// 	Name:  "云硬盘2.0(SATA)",
	// 	Code:  "sata2.0",
	// 	Unit:  "个",
	// 	Value: 0,
	// }
	// hostOverview.VMCountOverview = append(hostOverview.VMCountOverview, overView)
	hostOverview.HostCountOverview = resourcepoolmodel.ChartBaseOverview{
		Name:  "总数",
		Value: sum,
		Unit:  "个",
		Code:  "count",
	}
	return hostOverview, err
}

func GetBlockStorageCapAll(region, az, reasourcePool, name, code string, currentTime time.Time) (resourcepoolmodel.BlockDistributedOverView, error) {
	blockDistributedOverView := resourcepoolmodel.BlockDistributedOverView{
		Name:  name,
		Code:  code,
		Value: 0,
		Unit:  "GB",
	}
	CapacityTotal, err := prom.GetEbsCapTotal(region, az, reasourcePool, currentTime) //磁盘总容量
	if err != nil {
		return blockDistributedOverView, err
	}
	CapacityUsed, err := prom.GetEbsCapUsed(region, az, reasourcePool, currentTime) // 磁盘使用率
	if err != nil {
		return blockDistributedOverView, err
	}
	var total float64
	var used float64
	//获取磁盘使用量
	if len(CapacityTotal.Result) > 0 && len(CapacityTotal.Result[0].Values) > 0 {
		value := CapacityTotal.Result[0].Values[len(CapacityTotal.Result[0].Values)-1].([]interface{})
		v1, _ := strconv.ParseFloat(value[1].(string), 64)
		//blockDistributedOverView.Name = name
		//blockDistributedOverView.Code = code
		blockDistributedOverView.Value = v1
		//blockDistributedOverView.Unit = "GB"
		total = v1
	}
	usedOverView := resourcepoolmodel.OverView{
		Code:  "used",
		Name:  "使用量",
		Value: 0,
		Unit:  "GB",
	}
	if len(CapacityUsed.Result) > 0 && len(CapacityUsed.Result[0].Values) > 0 {
		value := CapacityUsed.Result[0].Values[len(CapacityUsed.Result[0].Values)-1].([]interface{})
		v2, _ := strconv.ParseFloat(value[1].(string), 64)
		//v2, _ := strconv.ParseFloat(CapacityUsed.Result[0].Value, 64)

		// usedOverView.Code = "used"
		// usedOverView.Name = "使用量"
		usedOverView.Value = v2
		// usedOverView.Unit = "GB"
		used = v2
	}
	blockDistributedOverView.Distributed = append(blockDistributedOverView.Distributed, usedOverView)
	useRateOverView := resourcepoolmodel.OverView{
		Code:  "useRate",
		Name:  "使用率",
		Value: 0,
		Unit:  "%",
	}
	avilableOverView := resourcepoolmodel.OverView{
		Code:  "avilable",
		Name:  "剩余量",
		Value: 0,
		Unit:  "GB",
	}

	if total > 0 {
		// useRateOverView.Code = "useRate"
		// useRateOverView.Name = "使用率"
		useRateOverView.Value = Strval((used / total) * 100)
		//useRateOverView.Unit = "%"

		// avilableOverView.Code = "avilable"
		// avilableOverView.Name = "剩余量"
		avilableOverView.Value = total - used
		//avilableOverView.Unit = "GB"
	}
	blockDistributedOverView.Distributed = append(blockDistributedOverView.Distributed, useRateOverView)
	blockDistributedOverView.Distributed = append(blockDistributedOverView.Distributed, avilableOverView)
	return blockDistributedOverView, err
}
func GetCloudDiskDistributionCap(reasourcePool string, cloudDiskList []cmdbmodel.CloudDiskData, blockDistributedOverView resourcepoolmodel.BlockDistributedOverView) resourcepoolmodel.OverView {
	distributionCap := 0
	klog.Infof("distributionCap start cap:%d", distributionCap)
	count := len(cloudDiskList)
	for i := 0; i < count; i++ {
		if cloudDiskList[i].UseStatus == "deleted" || cloudDiskList[i].UseStatus == "error" || cloudDiskList[i].ResourcePool != reasourcePool {
			continue
		}
		distributionCap += cloudDiskList[i].Size
	}
	klog.Infof("distributionCap end cap:%d", distributionCap)

	distributionCapOverView := resourcepoolmodel.OverView{}
	distributionCapOverView.Code = "distribution"
	distributionCapOverView.Name = "分配量"
	distributionCapOverView.Value = distributionCap
	distributionCapOverView.Unit = "GB"
	//blockDistributedOverView.Distributed = append(blockDistributedOverView.Distributed, distributionCapOverView)
	klog.Infof("distributionCapOverView:%s", distributionCapOverView)
	return distributionCapOverView

}

// Strval 获取变量的字符串值
// 浮点型 3.0将会转换成字符串3, "3"
// 非数值或字符类型的变量将会被转换成JSON格式字符串
func Strval(value interface{}) string {
	// interface 转 string
	var key string
	if value == nil {
		return key
	}

	switch value.(type) {
	case float64:
		ft := value.(float64)
		key = strconv.FormatFloat(ft, 'f', 2, 64)
	case float32:
		ft := value.(float32)
		key = strconv.FormatFloat(float64(ft), 'f', 2, 64)
	case int:
		it := value.(int)
		key = strconv.Itoa(it)
	case uint:
		it := value.(uint)
		key = strconv.Itoa(int(it))
	case int8:
		it := value.(int8)
		key = strconv.Itoa(int(it))
	case uint8:
		it := value.(uint8)
		key = strconv.Itoa(int(it))
	case int16:
		it := value.(int16)
		key = strconv.Itoa(int(it))
	case uint16:
		it := value.(uint16)
		key = strconv.Itoa(int(it))
	case int32:
		it := value.(int32)
		key = strconv.Itoa(int(it))
	case uint32:
		it := value.(uint32)
		key = strconv.Itoa(int(it))
	case int64:
		it := value.(int64)
		key = strconv.FormatInt(it, 10)
	case uint64:
		it := value.(uint64)
		key = strconv.FormatUint(it, 10)
	case string:
		key = value.(string)
	case []byte:
		key = string(value.([]byte))
	case []interface{}:
		float, _ := strconv.ParseFloat(Strval(value.([]interface{})[1]), 64)
		key = string(Strval(float))
	default:
		newValue, _ := json.Marshal(value)
		key = string(newValue)
	}

	return key
}
func IsContain(items []string, item string) bool {
	for _, eachItem := range items {
		if eachItem == item {
			return true
		}
	}
	return false
}

// func TimeToStep(timeSiza float64) (size string) {
// 	if timeSiza >= 0 {

// 		if timeSiza <= (3600.0 * 24.0 * 2) {
// 			return "1m"
// 		} else if timeSiza <= (3600.0 * 24.0 * 7) {
// 			return "1h"
// 		} else {
// 			return "1d"
// 		}
// 	}
// 	return ""
// }

func floatGbToByte(size float64) int64 {
	return int64(size * 1024 * 1024 * 1024)
}

func HGetStockRedis(ctx context.Context, k, field string) cmdbmodel.GetPoolStock {

	var res cmdbmodel.GetPoolStock
	rs, err := client.HGet(ctx, k, field)
	if err == redis.Nil {
		return res
		klog.Error("gredis.HGet Unmarshal failure:", err.Error())
	}
	if err != nil {
		klog.Error("gredis.HGet read from redis failure:", err.Error())
	}
	err = json.Unmarshal([]byte(rs), &res)
	if err != nil {
		klog.Error("gredis.HGet Unmarshal failure:", err.Error())
	}
	return res
}

func HGetClustersRedis(ctx context.Context, k, field string) cmdbmodel.GetPoolClusters {

	var res cmdbmodel.GetPoolClusters
	rs, err := client.HGet(ctx, k, field)
	if err == redis.Nil {
		return res
		klog.Error("gredis.HGet Unmarshal failure:", err.Error())
	}
	if err != nil {
		klog.Error("gredis.HGet read from redis failure:", err.Error())
	}
	err = json.Unmarshal([]byte(rs), &res)
	if err != nil {
		klog.Error("gredis.HGet Unmarshal failure:", err.Error())
	}
	return res
}

func HsetStockRedis(ctx context.Context, key, field string, ReidsValue cmdbmodel.GetPoolStock) error {

	valueJson, _ := json.Marshal(ReidsValue)
	_, err := client.HSet(ctx, key, field, valueJson)

	if err != nil {
		klog.Error("HsetStockRedis failed to obtain redis data:", err.Error())
	}
	isExpire, expireErr := client.Expire(ctx, key, 86400*7)
	if isExpire == false {
		klog.Error("HsetStockRedis Failed to set expiration time")
	}
	if expireErr != nil {
		klog.Error("HsetStockRedis Failed to set expiration time err :", expireErr.Error())
	}
	return nil
}

func HsetClustersRedis(ctx context.Context, key, field string, ReidsValue cmdbmodel.GetPoolClusters) error {

	valueJson, _ := json.Marshal(ReidsValue)
	_, err := client.HSet(ctx, key, field, valueJson)

	if err != nil {
		klog.Error("HsetStockRedis failed to obtain redis data:", err.Error())
	}
	isExpire, expireErr := client.Expire(ctx, key, 86400*7)
	if isExpire == false {
		klog.Error("HsetStockRedis Failed to set expiration time")
	}
	if expireErr != nil {
		klog.Error("HsetStockRedis Failed to set expiration time err :", expireErr.Error())
	}
	return nil
}

//
//func HsetClustersRedis(key ,field string,ReidsValue cmdbmodel.GetPoolClusters) error {
//
//	ctx, cefl := context.WithTimeout(context.Background(), 5*time.Second)
//	defer cefl()
//
//	valueJson, _ := json.Marshal(ReidsValue)
//	red,err :=client.HSet(ctx,key,field,string(valueJson))
//	fmt.Println("red",red)
//	if err != nil{
//		klog.Error("Hsetclusterredis failed to obtain redis data:", err.Error())
//	}
//	isExpire,expireErr :=client.Expire(ctx,key,60)//86400*7
//	if isExpire == false{
//		klog.Error("HsetStockRedis Failed to set expiration time")
//	}
//	if expireErr != nil{
//		klog.Error("HsetStockRedis Failed to set expiration time err :",expireErr.Error())
//	}
//
//	return nil
//}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/ktsmanager/handler.go
```golang
package ktsmanager

import (
	"encoding/json"
	"fmt"
	cm "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"io"
	"io/ioutil"
	"net/http"
	"os"
	"strconv"
	"strings"
	"time"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	services "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	prome "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	"golang.org/x/net/proxy"
	"k8s.io/klog/v2"
)

type Valu struct {
	Metric map[string]string `json:"metric"`
	Value  []interface{}     `json:"value"`
}
type Data struct {
	Metric string `json:"metric"`
	Value  []Valu `json:"value"`
}

func QueryVmMetric(id, start, end string, metrics []string) []MetricResult {

	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBKNew(end1 - start1) //降采样
	responseMetric := make([]MetricResult, 0, 10)

	for i := 0; i < len(metrics); i++ {

		switch metrics[i] {
		case "MysqlCpuRate": //mysqlCpu使用率
			r := MetricResult{Name: "MysqlCpuRate", Metric: "MysqlCpuRate"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.cpu_used_percent" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			fmt.Println("=====")
			fmt.Printf("999999 %+v", rangeRange)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)

		case "MysqlMemRate": //mysql内存使用率
			r := MetricResult{Name: "MysqlMemRate", Metric: "MysqlMemRate"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.memory_used_percent" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "MysqlIopsRead": //IopsRead
			r := MetricResult{Name: "MysqlIopsRead", Metric: "MysqlIopsRead"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.riops" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)

			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "MysqlIopsWrite": //IopsWrite
			r := MetricResult{Name: "MysqlIopsWrite", Metric: "MysqlIopsWrite"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.wiops" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "MysqlLinkRunning": //当前活跃连接数
			r := MetricResult{Name: "MysqlLinkRunning", Metric: "MysqlLinkRunning"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.threads_running" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)

		case "MysqlLinkConnected": //当前连接数
			r := MetricResult{Name: "MysqlLinkConnected", Metric: "MysqlLinkConnected"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.threads_connected" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "MysqlBytesReceived": //网络输入吞吐量
			r := MetricResult{Name: "MysqlBytesReceived", Metric: "MysqlBytesReceived"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.bytes_received" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "MysqlBytesSent": //网络输出吞吐量
			r := MetricResult{Name: "MysqlBytesSent", Metric: "MysqlBytesSent"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.bytes_sent" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "MysqlOps": //MysqlOps
			r := MetricResult{Name: "MysqlOps", Metric: "MysqlOps"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.qps" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)

		case "MysqlTps": //MysqlTps
			r := MetricResult{Name: "MysqlTps", Metric: "MysqlTps"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.tps" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "RedisCpuLoad": //Redis Cpu使用率
			r := MetricResult{Name: "Cpu使用率", Metric: "RedisCpuLoad"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.cpu_load" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "RedisMemoryLoad": //Redis内存使用率
			r := MetricResult{Name: "内存使用率", Metric: "RedisMemoryLoad"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.memory_load" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "RedisIntranetInRatio": //入流量使用率
			r := MetricResult{Name: "入流量使用率", Metric: "RedisIntranetInRatio"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.intranet_in_ratio" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "RedisIntranetOutRatio": //Redis出流量使用率
			r := MetricResult{Name: "出流量使用率", Metric: "RedisIntranetOutRatio"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.intranet_out_ratio" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "RedisConnectionUsage": //Redis 连接数使用率
			r := MetricResult{Name: "连接数使用率", Metric: "RedisConnectionUsage"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.connection_usage" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "RedisHitRate": //Redis 缓存命中率
			r := MetricResult{Name: "缓存命中率", Metric: "RedisHitRate"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.hit_rate" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "RedisSlowlogLen": //Redis 慢查询数量
			r := MetricResult{Name: "缓存命中率", Metric: "RedisSlowlogLen"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.slowlog_len" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "RedisUsedMemory": //redis 已使用内存
			r := MetricResult{Name: "RedisUsedMemory", Metric: "RedisUsedMemory"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.usedmemory" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "SlbBpsIn": //load 负载均衡流量 入网带宽
			r := MetricResult{Name: "SlbBpsIn", Metric: "SlbBpsIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.bps.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "SlbBpsOut": //load 负载均衡流量 出网带宽
			r := MetricResult{Name: "SlbBpsOut", Metric: "SlbBpsOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.bps.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "SlbPpsIn": //load 负载均衡每秒收发包次数 每秒流入包数
			r := MetricResult{Name: "每秒流入包数", Metric: "SlbPpsIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.pps.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "SlbPpsOut": //load 负载均衡每秒收发包次数 每秒流出包数
			r := MetricResult{Name: "每秒流出包数", Metric: "SlbPpsOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.pps.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "SlbCps": //load 每秒新建连接数
			r := MetricResult{Name: "每秒新建连接数", Metric: "SlbPpsOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.cps" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "SlbActiveconn": //load 每秒新建连接数
			r := MetricResult{Name: "活跃连接数", Metric: "SlbActiveconn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.activeconn" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "SlbConcurrentconn": //load 并发连接数
			r := MetricResult{Name: "并发连接数", Metric: "SlbConcurrentconn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.concurrentconn" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "SlbInactiveconn": //load 每秒新建连接数
			r := MetricResult{Name: "不活跃连接数", Metric: "SlbInactiveconn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.inactiveconn" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "NatBpsIn": //nat 入网带宽
			r := MetricResult{Name: "NatBpsIn", Metric: "NatBpsIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.bps.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "NatBpsOut": // nat 出网带宽
			r := MetricResult{Name: "NatBpsOut", Metric: "NatBpsOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.bps.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "NatBpsInPublic": //nat 入网带宽(公网)
			r := MetricResult{Name: "NatBpsInPublic", Metric: "NatBpsInPublic"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.public.bps.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "NatBpsOutPublic": // nat 出网带宽(公网)
			r := MetricResult{Name: "NatBpsOutPublic", Metric: "NatBpsOutPublic"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.public.bps.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "NatPpsIn": //nat 每秒流入包数
			r := MetricResult{Name: "NatPpsIn", Metric: "NatPpsIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.pps.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "NatPpsOut": // nat 每秒流出包数
			r := MetricResult{Name: "NatPpsOut", Metric: "NatPpsOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.pps.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "NatPpsInPublic": //nat 每秒流入包数(公网)
			r := MetricResult{Name: "NatPpsInPublic", Metric: "NatPpsInPublic"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.public.pps.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "NatPpsOutPublic": // nat 每秒流出包数(公网)
			r := MetricResult{Name: "NatPpsOutPublic", Metric: "NatPpsOutPublic"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.public.pps.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "EipBpsIn": //load eip 入网带宽
			r := MetricResult{Name: "入网带宽", Metric: "EipBpsIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.bps.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "EipBpsOut": //load eip 出网带宽
			r := MetricResult{Name: "出网带宽", Metric: "EipBpsOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.bps.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "EipPpsIn": //load 每秒流入包数
			r := MetricResult{Name: "每秒流入包数", Metric: "EipPpsIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.pps.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "EipPpsOut": //load 每秒流出包数
			r := MetricResult{Name: "每秒流出包数", Metric: "EipPpsOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.pps.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "EipUtilizationIn": //load  eip 入向带宽使用百分比
			r := MetricResult{Name: "入向带宽使用百分比", Metric: "EipUtilizationIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.utilization.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "EipUtilizationOut": //load eip  出向带宽使用百分比
			r := MetricResult{Name: "出向带宽使用百分比", Metric: "EipUtilizationOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.utilization.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top load tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "CPULoad":
			//ls := []Line{}
			r := MetricResult{Name: "CPULoad", Metric: "CPULoad"}
			tag1 := map[string]string{
				"host": id,
			}
			last := LastQuery{
				Metric: "cpu.utilizition.total" + "." + id,
				Tags:   tag1,
			}
			c, err := TSDBLastQuery(last)
			if err != nil {
				klog.Errorf("top CPULoad tsdb 查询错误，err: %s", err)
			}
			if len(c) > 0 {
				cc, _ := strconv.ParseFloat(c[0].Value, 64)
				r.Value = services.FormPercent(cc / 100)
			}

			responseMetric = append(responseMetric, r)
		case "CPULoadAvg":
			klog.Info("CPULoadAvg")
			r := MetricResult{Name: "CPULoadAvg", Metric: "CPULoadAvg"}
			tag := map[string]string{
				"host": id,
			}
			//tag := map[string]string{}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "cpu.utilizition.total" + "." + id,
				Tags:       tag,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top CPULoadAvg tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}

			responseMetric = append(responseMetric, r)

		case "MemLoadAvg":
			//ls := []Line{}
			r := MetricResult{Name: "MemLoadAvg", Metric: "MemLoadAvg"}
			tag1 := map[string]string{
				//"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "memory.utilizition.total" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top MemLoadAvg tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}

			responseMetric = append(responseMetric, r)

		case "DiskLoadAvg":
			//ls := []Line{}
			r := MetricResult{Name: "diskLoadAvg", Metric: "diskLoadAvg"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "/",
				"p2":   "pused",
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vfs.fs.size" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top DiskLoadAvg tsdb 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}

			responseMetric = append(responseMetric, r)
		case "NetInAvg":
			//ls := []Line{}
			r := MetricResult{Name: "NetInAvg", Metric: "NetInAvg"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "eth0",
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "net.if.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top NetInAvg tsdb 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}

			responseMetric = append(responseMetric, r)
		case "NetOutAvg":
			//ls := []Line{}
			r := MetricResult{Name: "NetOutAvg", Metric: "NetOutAvg"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "eth0",
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "net.if.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top NetOutAvg tsdb 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}

			responseMetric = append(responseMetric, r)
		case "MemoryUse":
			r := MetricResult{Name: "MemoryUse", Metric: "MemoryUse"}
			tag1 := map[string]string{
				"host": id,
			}
			last := LastQuery{
				Metric: "memory.utilizition.total" + "." + id,
				Tags:   tag1,
			}
			c, _ := TSDBLastQuery(last)
			if len(c) > 0 {
				cc, _ := strconv.ParseFloat(c[0].Value, 64)
				r.Value = services.FormPercent(cc / 100)
			}

			responseMetric = append(responseMetric, r)
		case "DiskFree":
			r := MetricResult{Name: "DiskFree", Metric: "DiskFree"}

			tagUser := map[string]string{
				"host": id,
				"p1":   "/",
				"p2":   "pused",
			}
			lastUse := LastQuery{
				Metric: "vfs.fs.size" + "." + id,
				Tags:   tagUser,
			}
			u, _ := TSDBLastQuery(lastUse)
			if len(u) > 0 {
				usePercent, _ := strconv.ParseFloat(u[0].Value, 64)

				r.Value = services.Form2(usePercent / 100)
			}
			responseMetric = append(responseMetric, r)
		case "DiskCapacity":
			r := MetricResult{Name: "DiskCapacity", Metric: "DiskCapacity"}

			total := map[string]string{
				"host": id,
				"p1":   "/",
				"p2":   "total",
			}
			lastUse := LastQuery{
				Metric: "vfs.fs.size" + "." + id,
				Tags:   total,
			}
			u, _ := TSDBLastQuery(lastUse)
			if len(u) > 0 {
				//usePercent, _ := strconv.ParseFloat(u[0].Value, 64)

				r.Value = u[0].Value
			}
			responseMetric = append(responseMetric, r)
		case "DiskCapacityRange":
			r := MetricResult{Name: "总量", Metric: "DiskCapacityRange"}

			total := map[string]string{
				"host": id,
				"p1":   "/",
				"p2":   "total",
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vfs.fs.size" + "." + id,
				Tags:       total,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
			}
			responseMetric = append(responseMetric, r)
		case "DiskUsedRange":
			r := MetricResult{Name: "使用量", Metric: "DiskUsedRange"}

			total := map[string]string{
				//"host": id,
				//"p1":   "/",
				//"p2":   "pused",
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vfs.fs.size" + "." + id,
				Tags:       total,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top DiskUsedRange tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "DiskFreeRange":
			r := MetricResult{Name: "剩余量", Metric: "DiskFreeRange"}

			total := map[string]string{
				"host": id,
				"p1":   "/",
				"p2":   "free",
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vfs.fs.size" + "." + id,
				Tags:       total,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
			}
			responseMetric = append(responseMetric, r)
		case "DiskUsed":
			r := MetricResult{Name: "DiskUsed", Metric: "DiskUsed"}

			total := map[string]string{
				"host": id,
				"p1":   "/",
				"p2":   "pused",
			}
			lastUse := LastQuery{
				Metric: "vfs.fs.size" + "." + id,
				Tags:   total,
			}
			u, _ := TSDBLastQuery(lastUse)
			if len(u) > 0 {
				//usePercent, _ := strconv.ParseFloat(u[0].Value, 64)

				r.Value = u[0].Value

				responseMetric = append(responseMetric, r)
			}
		case "NetIn":
			r := MetricResult{Name: "NetIn", Metric: "NetIn"}
			//total
			tagTotal := map[string]string{
				"host": id,
				"p1":   "eth0",
				"p2":   "packets",
			}
			lastTotal := LastQuery{
				Metric: "net.if.in" + "." + id,
				Tags:   tagTotal,
			}
			t, _ := TSDBLastQuery(lastTotal)
			if len(t) > 0 {
				//in, _ := strconv.ParseFloat(t[0].Value, 64)
				r.Value = prome.FormValue(t[0].Value)

			}
			responseMetric = append(responseMetric, r)

		case "NetOut":
			r := MetricResult{Name: "NetOut", Metric: "NetOut"}
			//total
			tagTotal := map[string]string{
				"host": id,
				"p1":   "eth0",
				"p2":   "packets",
			}
			lastTotal := LastQuery{
				Metric: "net.if.out" + "." + id,
				Tags:   tagTotal,
			}
			t, _ := TSDBLastQuery(lastTotal)
			if len(t) > 0 {
				//out, _ := strconv.ParseFloat(t[0].Value, 64)
				r.Value = prome.FormValue(t[0].Value)
			}

			responseMetric = append(responseMetric, r)
		case "Disk":
			r := MetricResult{MountPoint: "/", Metric: "Disk", Type: "ext4"}
			metric := make(map[string]string, 10)
			metric["mountpoint"] = "/"
			metric["fstype"] = ""
			value := make([]interface{}, 0, 2)
			tag1 := map[string]string{
				"host": id,
				"p1":   "/",
				"p2":   "pused",
			}
			lastQ := LastQuery{
				Metric: "vfs.fs.size" + "." + id,
				Tags:   tag1,
			}
			t, _ := TSDBLastQuery(lastQ)
			if len(t) > 0 {
				value = append(value, 1628560584.113)
				value = append(value, t[0].Value)
				//r.Value = prome.FormValue(t[0].Value)
				//out, _ := strconv.ParseFloat(t[0].Value, 64)
				//r.Current = services.FormatSize(out)
			}
			vv := Valu{Metric: metric, Value: value}
			data := Data{Metric: "Disk"}
			data.Value = append(data.Value, vv)
			r.Value = data.Value

			responseMetric = append(responseMetric, r)
		case "CPUMode":
			//r := MetricResult{Name: metrics[i]}
			//total
			tags := make([]map[string]string, 0, 10)

			SystemTag := map[string]string{
				"host": id,
				"p1":   "all",
				"p2":   "system",
				"p3":   "avg1",
			}
			tags = append(tags, SystemTag)
			UserTag := map[string]string{
				"host": id,
				"p1":   "all",
				"p2":   "user",
				"p3":   "avg1",
			}
			tags = append(tags, UserTag)
			SoftIrqTag := map[string]string{
				"host": id,
				"p1":   "all",
				"p2":   "softirq",
				"p3":   "avg1",
			}
			tags = append(tags, SoftIrqTag)
			IrqTag := map[string]string{
				"host": id,
				"p1":   "all",
				"p2":   "irq",
				"p3":   "avg1",
			}
			tags = append(tags, IrqTag)
			IoWaitTag := map[string]string{
				"host": id,
				"p1":   "all",
				"p2":   "iowait",
				"p3":   "avg1",
			}
			tags = append(tags, IoWaitTag)
			IdleTag := map[string]string{
				"host": id,
				"p1":   "all",
				"p2":   "idle",
				"p3":   "avg1",
			}
			tags = append(tags, IdleTag)
			NiceTag := map[string]string{
				"host": id,
				"p1":   "all",
				"p2":   "nice",
				"p3":   "avg1",
			}
			tags = append(tags, NiceTag)
			StealTag := map[string]string{
				"host": id,
				"p1":   "all",
				"p2":   "steal",
				"p3":   "avg1",
			}
			tags = append(tags, StealTag)
			//avg1Tag := map[string]string{
			//	"host": id,
			//	"p1":   "all",
			//	"p2":   "avg1",
			//}
			//tags = append(tags, avg1Tag)
			//avg5Tag := map[string]string{
			//	"host": id,
			//	"p1":   "all",
			//	"p2":   "avg5",
			//}
			//tags = append(tags, avg5Tag)
			//avg15Tag := map[string]string{
			//	"host": id,
			//	"p1":   "all",
			//	"p2":   "avg15",
			//}
			//tags = append(tags, avg15Tag)
			for j := 0; j < len(tags); j++ {
				jj := tags[j]
				r := MetricResult{Name: jj["p2"]}
				rangeQ := RangeQuery{
					Aggregator: "sum",
					Metric:     "system.cpu.util" + "." + id,
					Tags:       tags[j],
					Downsample: step,
				}
				rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
				if len(rangeRange) > 0 {
					r.Value = KtsResultToValue(rangeRange[0].Dps)
					ss := KtsGetSlice(rangeRange[0].Dps)
					r.Avg = services.Form2(getAvg(ss))
				}
				lastQ := LastQuery{
					Metric: "system.cpu.util" + "." + id,
					Tags:   tags[j],
				}
				t, _ := TSDBLastQuery(lastQ)
				if len(t) > 0 {
					out, _ := strconv.ParseFloat(t[0].Value, 64)
					r.Current = formatResult(out)
				}

				responseMetric = append(responseMetric, r)
			}

		case "Free":
			r := MetricResult{Name: "free"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "used",
			}
			last := RangeQuery{
				Aggregator: "sum",
				Metric:     "vm.memory.size" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			c, _ := TSDBRangeQuery(start, end, last)
			if len(c) > 0 {
				r.Value = KtsResultToValue(c[0].Dps)
			}
			lastQ := LastQuery{
				Metric: "vm.memory.size" + "." + id,
				Tags:   tag1,
			}
			t, _ := TSDBLastQuery(lastQ)
			if len(t) > 0 {
				out, _ := strconv.ParseFloat(t[0].Value, 64)
				r.Current = services.FormatSize(out)
			}

			responseMetric = append(responseMetric, r)
		case "Total":
			r := MetricResult{Name: "Total"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "total",
			}
			last := RangeQuery{
				Aggregator: "sum",
				Metric:     "vm.memory.size" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			p, _ := TSDBRangeQuery(start, end, last)
			if len(p) > 0 {
				r.Value = KtsResultToValue(p[0].Dps)
			}
			lastQ := LastQuery{
				Metric: "vm.memory.size" + "." + id,
				Tags:   tag1,
			}
			t, _ := TSDBLastQuery(lastQ)
			if len(t) > 0 {
				out, _ := strconv.ParseFloat(t[0].Value, 64)
				r.Current = services.FormatSize(out)
			}
			responseMetric = append(responseMetric, r)
		case "ErrDropIn":
			r := MetricResult{Name: "PacketIn"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "eth0",
				"p2":   "packets",
			}
			last := RangeQuery{
				Aggregator: "sum",
				Metric:     "net.if.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			p, _ := TSDBRangeQuery(start, end, last)
			if len(p) > 0 {
				r.Value = KtsResultToValue(p[0].Dps)
				ss := KtsGetSlice(p[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
			}
			responseMetric = append(responseMetric, r)
		case "ErrDropOut":
			r := MetricResult{Name: "PacketOut"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "eth0",
				"p2":   "packets",
			}
			last := RangeQuery{
				Aggregator: "sum",
				Metric:     "net.if.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			p, _ := TSDBRangeQuery(start, end, last)
			if len(p) > 0 {
				r.Value = KtsResultToValue(p[0].Dps)
				ss := KtsGetSlice(p[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
			}
			responseMetric = append(responseMetric, r)
		case "Receive":
			r := MetricResult{Name: "netIn"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "eth0",
			}
			last := RangeQuery{
				Aggregator: "sum",
				Metric:     "net.if.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			p, _ := TSDBRangeQuery(start, end, last)
			if len(p) > 0 {
				r.Value = KtsResultToValue(p[0].Dps)
				ss := KtsGetSlice(p[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
			}
			responseMetric = append(responseMetric, r)
		case "Transmit":
			r := MetricResult{Name: "netOut"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "eth0",
			}
			last := RangeQuery{
				Aggregator: "sum",
				Metric:     "net.if.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			p, _ := TSDBRangeQuery(start, end, last)
			if len(p) > 0 {
				r.Value = KtsResultToValue(p[0].Dps)
				ss := KtsGetSlice(p[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
			}
			responseMetric = append(responseMetric, r)
		case "file":
			r := MetricResult{Name: "/"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "/",
				"p2":   "free",
			}
			rangeRange := RangeQuery{
				Aggregator: "sum",
				Metric:     "vfs.fs.size" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			p, _ := TSDBRangeQuery(start, end, rangeRange)
			if len(p) > 0 {
				r.Value = KtsResultToValue(p[0].Dps)
			}
			lastQ := LastQuery{
				Metric: "vfs.fs.size" + "." + id,
				Tags:   tag1,
			}
			t, _ := TSDBLastQuery(lastQ)
			if len(t) > 0 {
				out, _ := strconv.ParseFloat(t[0].Value, 64)
				r.Current = services.FormatSize(out)
			}
			responseMetric = append(responseMetric, r)
		case "Read":
			read := MetricResult{Name: "读带宽"}
			s := strings.Split(metrics[i], ":")
			vdd := ""
			if len(s) == 2 {
				vdd = s[1]
			} else {
				vdd = "vda"
			}
			tag1 := map[string]string{
				"host": id,
				"p1":   vdd,
			}
			last := RangeQuery{
				Aggregator: "sum",
				Metric:     "disk.read.Bps" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			p, _ := TSDBRangeQuery(start, end, last)
			if len(p) > 0 {
				read.Value = KtsResultToValue(p[0].Dps)
				ss := KtsGetSlice(p[0].Dps)
				read.Max = services.FormatSize(getMax(ss))
				read.Min = services.FormatSize(getMin(ss))
				read.Avg = services.Form2(getAvg(ss))
			}
			lastQ := LastQuery{
				Metric: "disk.read.Bps" + "." + id,
				Tags:   tag1,
			}
			t, _ := TSDBLastQuery(lastQ)
			if len(t) > 0 {
				out, _ := strconv.ParseFloat(t[0].Value, 64)
				read.Current = services.FormatSize(out)
			}
			responseMetric = append(responseMetric, read)
		case "Write":
			write := MetricResult{Name: "写带宽"}
			s := strings.Split(metrics[i], ":")
			vdd := ""
			if len(s) == 2 {
				vdd = s[1]
			} else {
				vdd = "vda"
			}
			tag2 := map[string]string{
				"host": id,
				"p1":   vdd,
			}
			last2 := RangeQuery{
				Aggregator: "sum",
				Metric:     "disk.write.Bps" + "." + id,
				Tags:       tag2,
				Downsample: step,
			}
			p2, _ := TSDBRangeQuery(start, end, last2)
			if len(p2) > 0 {
				write.Value = KtsResultToValue(p2[0].Dps)
				ss := KtsGetSlice(p2[0].Dps)
				write.Max = services.FormatSize(getMax(ss))
				write.Min = services.FormatSize(getMin(ss))
				write.Avg = services.Form2(getAvg(ss))
			}
			lastQ := LastQuery{
				Metric: "disk.write.Bps" + "." + id,
				Tags:   tag2,
			}
			t, _ := TSDBLastQuery(lastQ)
			if len(t) > 0 {
				out, _ := strconv.ParseFloat(t[0].Value, 64)
				write.Current = services.FormatSize(out)
			}
			responseMetric = append(responseMetric, write)
		case "read":
			read := MetricResult{Name: "VdaR"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "vda",
			}
			last := RangeQuery{
				Aggregator: "sum",
				Metric:     "disk.read.ops" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			p, _ := TSDBRangeQuery(start, end, last)
			if len(p) > 0 {
				read.Value = KtsResultToValue(p[0].Dps)
				ss := KtsGetSlice(p[0].Dps)
				read.Max = services.Form2(getMax(ss))
				read.Min = services.Form2(getMin(ss))
				read.Avg = services.Form2(getAvg(ss))
			}
			lastQ := LastQuery{
				Metric: "disk.read.ops" + "." + id,
				Tags:   tag1,
			}
			t, _ := TSDBLastQuery(lastQ)
			if len(t) > 0 {
				out, _ := strconv.ParseFloat(t[0].Value, 64)
				read.Current = out
			}
			responseMetric = append(responseMetric, read)
		case "write":
			write := MetricResult{Name: "VdaW"}
			tag2 := map[string]string{
				"host": id,
				"p1":   "vda",
			}
			last2 := RangeQuery{
				Aggregator: "sum",
				Metric:     "disk.write.ops" + "." + id,
				Tags:       tag2,
				Downsample: step,
			}
			p2, _ := TSDBRangeQuery(start, end, last2)
			if len(p2) > 0 {
				write.Value = KtsResultToValue(p2[0].Dps)
				ss := KtsGetSlice(p2[0].Dps)
				write.Max = services.Form2(getMax(ss))
				write.Min = services.Form2(getMin(ss))
				write.Avg = services.Form2(getAvg(ss))
			}
			lastQ := LastQuery{
				Metric: "disk.write.ops" + "." + id,
				Tags:   tag2,
			}
			t, _ := TSDBLastQuery(lastQ)
			if len(t) > 0 {
				out, _ := strconv.ParseFloat(t[0].Value, 64)
				write.Current = out
			}
			responseMetric = append(responseMetric, write)
		case "BLockBpsRead":
			read := MetricResult{Name: "VdaR"}
			s := strings.Split(metrics[i], ":")
			vdd := ""
			if len(s) == 2 {
				vdd = s[1]
			} else {
				vdd = "vda"
			}
			tag1 := map[string]string{
				"host": id,
				"p1":   vdd,
			}
			last := RangeQuery{
				Aggregator: "sum",
				Metric:     "disk.read.Bps" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			p, _ := TSDBRangeQuery(start, end, last)
			if len(p) > 0 {
				read.Value = KtsResultToValue(p[0].Dps)
				ss := KtsGetSlice(p[0].Dps)
				read.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, read)
		case "BLockBpsWrite":
			write := MetricResult{Name: "VdaW"}
			s := strings.Split(metrics[i], ":")
			vdd := ""
			if len(s) == 2 {
				vdd = s[1]
			} else {
				vdd = "vda"
			}
			tag2 := map[string]string{
				"host": id,
				"p1":   vdd,
			}
			last2 := RangeQuery{
				Aggregator: "sum",
				Metric:     "disk.write.Bps" + "." + id,
				Tags:       tag2,
				Downsample: step,
			}
			p2, _ := TSDBRangeQuery(start, end, last2)
			if len(p2) > 0 {
				write.Value = KtsResultToValue(p2[0].Dps)
				ss := KtsGetSlice(p2[0].Dps)
				write.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, write)
		case "BLockOpsRead":
			read := MetricResult{Name: "VdaR"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "vda",
			}
			last := RangeQuery{
				Aggregator: "sum",
				Metric:     "disk.read.ops" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			p, _ := TSDBRangeQuery(start, end, last)
			if len(p) > 0 {
				read.Value = KtsResultToValue(p[0].Dps)
				ss := KtsGetSlice(p[0].Dps)
				read.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, read)
		case "BLockOpsWrite":
			write := MetricResult{Name: "VdaW"}
			tag2 := map[string]string{
				"host": id,
				"p1":   "vda",
			}
			last2 := RangeQuery{
				Aggregator: "sum",
				Metric:     "disk.write.ops" + "." + id,
				Tags:       tag2,
				Downsample: step,
			}
			p2, _ := TSDBRangeQuery(start, end, last2)
			if len(p2) > 0 {
				write.Value = KtsResultToValue(p2[0].Dps)
				ss := KtsGetSlice(p2[0].Dps)
				write.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, write)
		case "readAwait":
			read := MetricResult{Name: "读延时"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "vda",
			}
			last := RangeQuery{
				Aggregator: "sum",
				Metric:     "disk.read.await" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			p, _ := TSDBRangeQuery(start, end, last)
			if len(p) > 0 {
				read.Value = KtsResultToValue(p[0].Dps)
				ss := KtsGetSlice(p[0].Dps)
				read.Max = services.Form2(getMax(ss))
				read.Min = services.Form2(getMin(ss))
				read.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, read)
		case "writeAwait":
			write := MetricResult{Name: "写延时"}
			tag2 := map[string]string{
				"host": id,
				"p1":   "vda",
			}
			last2 := RangeQuery{
				Aggregator: "sum",
				Metric:     "disk.write.await" + "." + id,
				Tags:       tag2,
				Downsample: step,
			}
			p2, _ := TSDBRangeQuery(start, end, last2)
			if len(p2) > 0 {
				write.Value = KtsResultToValue(p2[0].Dps)
				ss := KtsGetSlice(p2[0].Dps)
				write.Max = services.Form2(getMax(ss))
				write.Min = services.Form2(getMin(ss))
				write.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, write)

		case "diskPUsedRange":
			vmDetail, err := cm.GetCMDBVmDetail(id)
			if err != nil {
				klog.Errorf("GetCMDBVmDetail 查询错误，err: %s", err)
				return responseMetric
			}
			if vmDetail.Code != 200 {
				klog.Errorf("GetCMDBVmDetail 查询错误，response code: %s", vmDetail.Code)
				return responseMetric
			}
			metricDir := vmDetail.Data.MetricDir
			if len(metricDir) == 0 {
				metricDir = append(metricDir, "/")
			}
			//id = "5b09313e-052e-4bf3-bd8c-1b63a5b69fac"
			for _, dir := range metricDir {
				r := MetricResult{Name: dir}
				tag1 := map[string]string{
					"host": id,
					"p1":   dir,
					"p2":   "pused",
				}
				last := RangeQuery{
					Aggregator: "sum",
					Metric:     "vfs.fs.size" + "." + id,
					Tags:       tag1,
					Downsample: step,
				}
				p, _ := TSDBRangeQuery(start, end, last)
				if len(p) > 0 {
					r.Value = KtsResultToValue(p[0].Dps)
					ss := KtsGetSlice(p[0].Dps)
					//r.Max = services.FormatSize(getMax(ss))
					//r.Min = services.FormatSize(getMin(ss))
					r.Current = ss[0]

				}
				responseMetric = append(responseMetric, r)
			}
		}

	}

	return responseMetric
}

func QueryVmMetriLine(id, start, end string, metrics []string) []MetricResult {

	start1, _ := strconv.ParseFloat(start, 64)
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDB(end1 - start1)
	responseMetric := []MetricResult{}
	for i := 0; i < len(metrics); i++ {
		switch metrics[i] {
		case "redisCpuLoad": //redisCpu使用率
			r := MetricResult{Name: "Cpu使用率", Metric: "RedisCpuLoad"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.cpu_load" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "redisMemoryLoad": //redis内存使用率
			r := MetricResult{Name: "内存使用率", Metric: "redisMemoryLoad"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.memory_load" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "redisUsedMemory": //redis已使用内存
			r := MetricResult{Name: "已使用内存", Metric: "RedisUsedMemory"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.usedmemory" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "qps": //mysqlCpu使用率
			r := MetricResult{Name: "qps", Metric: "qps"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.qps" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)

		case "tps": //mysql内存使用率
			r := MetricResult{Name: "tps", Metric: "tps"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.tps" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)

		case "com_delete": //delete操作数
			r := MetricResult{Name: "com_delete", Metric: "com_delete"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.com_delete" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "com_select": //com_select操作数
			r := MetricResult{Name: "com_select", Metric: "com_select"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.com_select" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "com_update": //com_update操作数
			r := MetricResult{Name: "com_update", Metric: "com_update"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.com_update" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "com_insert": //com_insert操作数
			r := MetricResult{Name: "com_insert", Metric: "com_insert"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.com_insert" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "com_replace": //com_replace操作数
			r := MetricResult{Name: "com_replace", Metric: "com_replace"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.com_replace" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "select_scan": //全表扫描数
			r := MetricResult{Name: "select_scan", Metric: "select_scan"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.select_scan" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "slow_queries": //慢查询数
			r := MetricResult{Name: "slow_queries", Metric: "slow_queries"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.slow_queries" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "handler_read_rnd_next": //请求下一行数
			r := MetricResult{Name: "handler_read_rnd_next", Metric: "handler_read_rnd_next"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.handler_read_rnd_next" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "handler_rollback": //内部回滚数
			r := MetricResult{Name: "handler_rollback", Metric: "handler_rollback"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.handler_rollback" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "handler_commit": //内部提交数
			r := MetricResult{Name: "handler_commit", Metric: "handler_commit"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.handler_commit" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "table_locks_waited": //表锁次数
			r := MetricResult{Name: "table_locks_waited", Metric: "table_locks_waited"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.table_locks_waited" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "cpu_used_percent": //CPU使用率
			r := MetricResult{Name: "cpu_used_percent", Metric: "cpu_used_percent"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.cpu_used_percent" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if id == "kscrds--cc9a78ba-0907-4a46-89f1-2a1d6cc4d407" {
				klog.Infof("mysqlid:%s-rangeRange:%v", "cc9a78ba-0907-4a46-89f1-2a1d6cc4d407", rangeRange)
			}
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			if id == "kscrds--cc9a78ba-0907-4a46-89f1-2a1d6cc4d407" {
				klog.Infof("rangeRangeDps%v", rangeRange[0].Dps)
				klog.Infof("mysqlLIne%v", r)
			}
			responseMetric = append(responseMetric, r)
		case "memory_used_percent": //内存使用率
			r := MetricResult{Name: "memory_used_percent", Metric: "memory_used_percent"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.memory_used_percent" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "resident_memory_size": //内存使用量
			r := MetricResult{Name: "resident_memory_size", Metric: "resident_memory_size"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.resident_memory_size" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "rbps": //读io
			r := MetricResult{Name: "rbps", Metric: "rbps"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.rbps" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "wbps": //写io
			r := MetricResult{Name: "wbps", Metric: "wbps"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.wbps" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "riops": //读iops
			r := MetricResult{Name: "riops", Metric: "riops"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.riops" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "wiops": //写iops
			r := MetricResult{Name: "wiops", Metric: "wiops"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.wiops" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "bytes_sent": //网络吞吐 实例每秒出流量
			r := MetricResult{Name: "bytes_sent", Metric: "bytes_sent"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.bytes_sent" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "bytes_received": //网络吞吐 实例每秒入流量
			r := MetricResult{Name: "bytes_received", Metric: "bytes_received"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.bytes_received" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "max_connections": //最大连接数
			r := MetricResult{Name: "max_connections", Metric: "max_connections"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.max_connections" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "threads_running": //当前活跃连接数
			r := MetricResult{Name: "threads_running", Metric: "threads_running"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.threads_running" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "threads_connected": //当前连接数
			r := MetricResult{Name: "threads_connected", Metric: "threads_connected"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.threads_connected" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "qcache_hit_ratio": //query cache命中率
			r := MetricResult{Name: "query cache命中率", Metric: "qcache_hit_ratio"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.qcache_hit_ratio" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "qcache_used_percent": //query cache使用率
			r := MetricResult{Name: "query cache使用率", Metric: "qcache_hit_ratio"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.qcache_hit_ratio" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "innodb_data_fsyncs": //InnoDB fsync次数
			r := MetricResult{Name: "InnoDB fsync次数", Metric: "innodb_data_fsyncs"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.innodb_data_fsyncs" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "innodb_data_reads": //InnoDB磁盘读次数
			r := MetricResult{Name: "InnoDB磁盘读次数", Metric: "innodb_data_reads"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.innodb_data_reads" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "innodb_data_writes": //InnoDB磁盘写次数
			r := MetricResult{Name: "InnoDB磁盘写次数", Metric: "innodb_data_writes"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.innodb_data_writes" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "innodb_buffer_pool_hit_ratio": //InnoDB缓存命中率
			r := MetricResult{Name: "InnoDB缓存命中率", Metric: "innodb_buffer_pool_hit_ratio"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.innodb_buffer_pool_hit_ratio" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "innodb_buffer_pool_pages_free": //InnoDB 空页数
			r := MetricResult{Name: "InnoDB 空页数", Metric: "innodb_buffer_pool_pages_free"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.innodb_buffer_pool_pages_free" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "innodb_buffer_pool_pages_total": //InnoDB 总页数
			r := MetricResult{Name: "InnoDB 总页数", Metric: "innodb_buffer_pool_pages_total"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.innodb_buffer_pool_pages_total" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "innodb_buffer_pool_read_requests": //InnoDB 逻辑读
			r := MetricResult{Name: "InnoDB 逻辑读", Metric: "innodb_buffer_pool_read_requests"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.innodb_buffer_pool_read_requests" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "innodb_buffer_pool_reads": //InnoDB 物理读
			r := MetricResult{Name: "InnoDB 物理读", Metric: "innodb_buffer_pool_reads"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.innodb_buffer_pool_reads" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "innodb_buffer_pool_use_ratio": //InnoDB 缓存使用率
			r := MetricResult{Name: "InnoDB 缓存使用率", Metric: "innodb_buffer_pool_use_ratio"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.innodb_buffer_pool_use_ratio" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "innodb_num_open_files": //当前 InnoDB 打开文件数量
			r := MetricResult{Name: "当前 InnoDB 打开文件数量", Metric: "innodb_num_open_files"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.innodb_num_open_files" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "innodb_data_read": //InnoDB 读取量
			r := MetricResult{Name: "InnoDB 读取量", Metric: "innodb_data_read"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.innodb_data_read" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "innodb_data_written": //InnoDB 写入量
			r := MetricResult{Name: "InnoDB 写入量", Metric: "innodb_data_written"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.innodb_data_written" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "myisam_keycache_readhit_ration": //MyISAM读命中率
			r := MetricResult{Name: "MyISAM读命中率", Metric: "myisam_keycache_readhit_ration"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.myisam_keycache_readhit_ration" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "myisam_keycache_writehit_ration": //MyISAM写命中率
			r := MetricResult{Name: "MyISAM写命中率", Metric: "myisam_keycache_writehit_ration"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.myisam_keycache_writehit_ration" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		case "myisam_keycache_used_percent": //MyISAM缓存使用率
			r := MetricResult{Name: "MyISAM缓存使用率", Metric: "myisam_keycache_used_percent"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.myisam_keycache_used_percent" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, _ := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Max = services.FormatSize(getMax(ss))
				r.Min = services.FormatSize(getMin(ss))
				r.Avg = services.Form2(getAvg(ss))
			}
			responseMetric = append(responseMetric, r)
		}

	}

	return responseMetric
}

func TSDBLastQuery(query LastQuery) ([]QueryResult, error) {
	c := http.Client{}
	c.Timeout = 2 * time.Second
	//buf := []byte{}
	//tags := map[string]string{
	//	"host": id,
	//}
	url := "http://" + config.TsdbServer + "/api/query/last"
	klog.Infof("TsdbUrl %s", url)
	//query := LastQuery{
	//	Metric: metric + "." + id,
	//	Tags:   tags,
	//}
	q := TSDBQueryBody{
		Queries:      []LastQuery{query},
		ResolveNames: true,
		BackScan:     24,
	}

	jsons, _ := json.Marshal(q)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	//klog.Infof("Tsdb param  %s", result)
	//klog.Infof("Tsdb url  %s", url)
	resp, err := c.Post(url, "application/json", jsoninfo)

	if err != nil {
		klog.Errorf("Failed to get Tsdb data ，err: %s", err.Error())
		return nil, err
	}
	defer resp.Body.Close()
	body, _ := io.ReadAll(resp.Body)
	//klog.Infof("Get Tsdb resp  %s", string(body))
	r := make([]QueryResult, 1)
	er := json.Unmarshal(body, &r)
	if er != nil {
		klog.Errorf("Failed to parse Tsdb data ，err: %s", err)
		return nil, er
	}
	return r, nil
}

func TSDBRangeQuery(start, end string, query RangeQuery) ([]QueryRangeResult, error) {

	c := http.Client{Timeout: time.Second * 3}

	q := TSDBQueryRangeBody{
		Start:   start,
		End:     end,
		Queries: []RangeQuery{query},
	}
	url := "http://" + config.TsdbServer + "/api/query"
	//url := "http://10.178.80.125:4243/api/query"
	//klog.Infof("TsdbUrl %s", url)
	jsons, _ := json.Marshal(q)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	//klog.Infof("Tsdb param  %s", result)

	resp, err := c.Post(url, "application/json", jsoninfo)
	if err != nil {
		klog.Errorf("Failed to get Tsdb data ，err: %s", err)
		return nil, err
	}
	defer resp.Body.Close()
	body, _ := io.ReadAll(resp.Body)
	//klog.Infof("Get Tsdb resp  %s", string(body))
	r := make([]QueryRangeResult, 1)
	err = json.Unmarshal(body, &r)
	if err != nil {
		//klog.Errorf("Failed to parse Tsdb data ，err: %v, body: %v", err, string(body))
		return nil, err
	}
	return r, nil
}

//	func GetVmStateByIp(ip string) (string, error) {
//		c := http.Client{}
//		prome := new(Prometheus)
//		resp, err := c.Get("http://" + config.GetDefaultUrl(config.PrometheusService) + "/api/v1/targets")
//		if err != nil {
//			return "", err
//		}
//
//		b, _ := io.ReadAll(resp.Body)
//		json.Unmarshal(b, prome)
//
//		state := ""
//		for i := 0; i < len(prome.Data.ActiveTargets); i++ {
//			fmt.Printf("instance= %s\n", prome.Data.ActiveTargets[i].Labels.Instance)
//			if pp := strings.Split(prome.Data.ActiveTargets[i].Labels.Instance, ":"); pp[0] == ip {
//				fmt.Printf("%s, health: %s", pp[0], prome.Data.ActiveTargets[i].Health)
//				state = strings.ToUpper(prome.Data.ActiveTargets[i].Health)
//				break
//			} else {
//				state = "DOWN"
//			}
//		}
//		return state, nil
//	}
//
// 拉卡拉代理
func TSDBLastQuerySOCKS5(query LastQuery) ([]QueryResult, error) {

	dialer, err := proxy.SOCKS5("tcp", "127.0.0.1:6000", nil, proxy.Direct)
	if err != nil {
		klog.Info(os.Stderr, "can't connect to the proxy:", err)
	}
	httpTransport := &http.Transport{}
	httpClient := &http.Client{Transport: httpTransport}
	httpTransport.Dial = dialer.Dial
	testUrl := "http://" + "10.255.20.25:4243" + "/api/query/last"

	q := TSDBQueryBody{
		Queries:      []LastQuery{query},
		ResolveNames: true,
		BackScan:     24,
	}

	jsons, _ := json.Marshal(q)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	r := make([]QueryResult, 1)
	klog.Infof("tsdb param json %s", result)
	klog.Infof("tsdb url %s", testUrl)
	resp, err1 := httpClient.Post(testUrl, "application/json", jsoninfo)
	klog.Infof("tsdb resp %s", resp)
	if resp == nil {
		return []QueryResult{}, err1
	}
	if err != nil {
		klog.Errorf("Failed to get Tsdb data ，err: %s", err)
		return nil, err
	}
	defer resp.Body.Close()
	body, _ := ioutil.ReadAll(resp.Body)
	klog.Info("body", fmt.Sprintf("%s\n", body))
	er := json.Unmarshal(body, &r)
	if er != nil {
		klog.Errorf("Failed to parse Tsdb data ，err: %s", err)
		return nil, er
	}
	return r, nil
}

// 拉卡拉代理
func TSDBRangeQuerySOCKS5(start, end string, query RangeQuery) ([]QueryRangeResult, error) {

	dialer, err := proxy.SOCKS5("tcp", "127.0.0.1:6000", nil, proxy.Direct)
	if err != nil {
		klog.Info(os.Stderr, "can't connect to the proxy:", err)
	}
	httpTransport := &http.Transport{}
	httpClient := &http.Client{Transport: httpTransport}
	httpTransport.Dial = dialer.Dial
	url := "http://" + "10.255.20.25:4243" + "/api/query"
	q := TSDBQueryRangeBody{
		Start:   start,
		End:     end,
		Queries: []RangeQuery{query},
	}

	jsons, _ := json.Marshal(q)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	klog.Infof("tsdb param json %s", result)
	klog.Infof("tsdb url %s", url)
	resp, err := httpClient.Post(url, "application/json", jsoninfo)
	fmt.Printf("resprespresprespresprespresp %+v", resp)
	klog.Infof("tsdb resp %v", resp)
	if resp == nil {
		return []QueryRangeResult{}, err
	}
	if err != nil {
		klog.Errorf("Failed to get Tsdb data ，err: %s", err)
		return nil, err
	}
	body, _ := io.ReadAll(resp.Body)
	klog.Infof("response body: %s", string(body))
	r := make([]QueryRangeResult, 1)
	er := json.Unmarshal(body, &r)
	if er != nil {
		klog.Errorf("Failed to parse Tsdb data ，err: %s", err)
		return nil, er
	}
	//fmt.Printf("res %+v",r)
	return r, nil
}

//func TSDBLastQueryBatch(querys ...LastQuery) (map[string]QueryResult, error) {
//
//	dialer, err := proxy.SOCKS5("tcp", "127.0.0.1:6000", nil, proxy.Direct)
//	if err != nil {
//		klog.Info(os.Stderr, "can't connect to the proxy:", err)
//	}
//	httpTransport := &http.Transport{}
//	httpClient := &http.Client{Transport: httpTransport}
//	httpTransport.Dial = dialer.Dial
//	testUrl := "http://" + "10.255.20.25:4243" + "/api/query/last"
//
//	q := TSDBQueryBody{
//		Queries:      querys,
//		ResolveNames: true,
//		BackScan:     24,
//	}
//
//	jsons, _ := json.Marshal(q)
//	result := string(jsons)
//	jsoninfo := strings.NewReader(result)
//	fmt.Println("jsoninfo", jsoninfo)
//
//	metricValues := make([]QueryResult, 1)
//
//	resp, err1 := httpClient.Post(testUrl, "application/json", jsoninfo)
//
//	if err != nil {
//		klog.Info("err1err1err1err1err1", err1)
//	}
//	defer resp.Body.Close()
//	body, _ := ioutil.ReadAll(resp.Body)
//	klog.Info("body", fmt.Sprintf("%s\n", body))
//	er := json.Unmarshal(body, &metricValues)
//	if er != nil {
//		klog.Info("ererererer", er)
//	}
//	rst := make(map[string]QueryResult, 0)
//	for i, _ := range metricValues {
//		rst[metricValues[i].Metric] = metricValues[i]
//	}
//	return rst, nil
//}

func TSDBLastQueryBatch(querys ...LastQuery) (map[string]QueryResult, error) {

	c := http.Client{}
	c.Timeout = 2 * time.Second

	url := "http://" + config.TsdbServer + "/api/query/last"
	//url := "http://10.178.80.125:4243/api/query/last"
	klog.Infof("url:", url)
	q := TSDBQueryBody{
		Queries:      querys,
		ResolveNames: true,
		BackScan:     24,
	}

	jsons, _ := json.Marshal(q)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	klog.Infof("Tsdb param  %s", result)
	resp, err := c.Post(url, "application/json", jsoninfo)
	if err != nil {
		klog.Error(err.Error())
		return nil, err
	}
	body, _ := io.ReadAll(resp.Body)
	klog.Infof("tsdb response result is %s", string(body))

	metricValues := make([]QueryResult, 1)
	er := json.Unmarshal(body, &metricValues)
	if er != nil {
		klog.Errorf("tsdb json 解析异常：%s", er.Error())
		return nil, er
	}
	rst := make(map[string]QueryResult, 0)
	for i, _ := range metricValues {
		rst[metricValues[i].Metric] = metricValues[i]
	}
	return rst, nil
}

func TSDBLastQueryBatchBase(querys ...LastQuery) ([]QueryResult, error) {

	c := http.Client{}
	c.Timeout = 2 * time.Second

	url := "http://" + config.TsdbServer + "/api/query/last"
	//url := "http://10.178.80.125:4243/api/query/last"
	klog.Infof("url:", url)
	q := TSDBQueryBody{
		Queries:      querys,
		ResolveNames: true,
		BackScan:     24,
	}

	jsons, _ := json.Marshal(q)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	klog.Infof("Tsdb param  %s", result)
	resp, err := c.Post(url, "application/json", jsoninfo)
	if err != nil {
		klog.Error(err.Error())
		return nil, err
	}
	body, _ := io.ReadAll(resp.Body)
	klog.Infof("tsdb response result is %s", string(body))

	metricValues := make([]QueryResult, 1)
	er := json.Unmarshal(body, &metricValues)
	if er != nil {
		klog.Errorf("tsdb json 解析异常：%s", er.Error())
		return nil, er
	}

	return metricValues, nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/ktsmanager/tsdb_test.go
```golang
package ktsmanager

import (
	"fmt"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	"strconv"
	"testing"
)

func TestTSDBRangeQuerySOCKS5(t *testing.T) {

	start := "1652079162"
	end := "1652080962"
	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDB(end1 - start1)

	tag1 := map[string]string{
		//"host": "6faf9056-3978-4824-930a-e94ef9f337b6",
		//"p1":   "/",
		//"p2":   "pused",
		//"p1": "eth0",
	}
	rangeQ := RangeQuery{
		Aggregator: "sum",
		Metric:     "net.if.in.6faf9056-3978-4824-930a-e94ef9f337b6",
		//Metric:     "vfs.fs.size.6faf9056-3978-4824-930a-e94ef9f337b6",
		//Metric:     "cpu.utilizition.total.6faf9056-3978-4824-930a-e94ef9f337b6",
		Tags:       tag1,
		Downsample: step,
	}

	for i := 0; i < 900; i++ {
		_, err := TSDBRangeQuerySOCKS5(start, end, rangeQ)
		if err != nil {
			t.Logf("Errorf: %s", err)
		}
		//t.Logf("Final Result: %+v", rangeRange)
	}

}

func TestQueryVmMetric(t *testing.T) {
	result := QueryVmMetric("5b09313e-052e-4bf3-bd8c-1b63a5b69fac", "1657636334.572", "1657679534.572", []string{"diskPUsedRange"})
	fmt.Println(result)
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/ktsmanager/util.go
```golang
package ktsmanager

import (
	"fmt"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"sort"
	"strconv"
)

func KtsResultToValue(r interface{}) interface{} {

	result := make([][]interface{}, 0, 500)
	rst := make([][]interface{}, 0, 500)
	value := r.(map[string]interface{})

	for k, v := range value {
		//fmt.Println("v.type")
		//fmt.Println("reflect.TypeOf(value):", reflect.TypeOf(v))
		//var fv = map[string]float64{}
		var fv float64
		switch v.(type) {
		//rv := reflect.ValueOf(v)
		//kind := rv.Kind()
		case string:
			vv, _ := strconv.ParseFloat(v.(string), 64)
			ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", vv), 64)
			//value[k] = ss

			fv = ss
		case float64:
			ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", v.(float64)), 64)
			fv = ss

		}
		value[k] = fv
		res := make([]interface{}, 0, 2)
		//kk, _ := strconv.ParseFloat(k, 64)
		kk, _ := strconv.Atoi(k)
		res = append(res, kk)
		res = append(res, fv)
		result = append(result, res)

		rst = KtsValueOrder(result, "asc")

		//ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", v), 64)
		//v = ss
	}
	return rst
}

func KtsResultToFrontValue(r interface{}) interface{} {

	result := make([][]interface{}, 0, 500)
	rst := make([][]interface{}, 0, 500)
	value := r.(map[string]interface{})

	for k, v := range value {
		//fmt.Println("v.type")
		//fmt.Println("reflect.TypeOf(value):", reflect.TypeOf(v))
		//var fv = map[string]float64{}
		var fv float64
		switch v.(type) {
		//rv := reflect.ValueOf(v)
		//kind := rv.Kind()
		case string:
			vv, _ := strconv.ParseFloat(v.(string), 64)
			ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", vv), 64)
			//value[k] = ss

			fv = ss
		case float64:
			ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", v.(float64)), 64)
			fv = ss

		}
		value[k] = fv
		res := make([]interface{}, 0, 2)
		//kk, _ := strconv.ParseFloat(k, 64)
		kk, _ := strconv.Atoi(k)
		res = append(res, kk)
		res = append(res, fv)
		result = append(result, res)
		rst = KtsValueOrder(result, "asc")

		//ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", v), 64)
		//v = ss
	}
	return rst
}

func KtsResultToValues(r interface{}) []services.ValueType {

	result := make([]services.ValueType, 0, 500)
	//rst := make([]services.ValueType, 0, 500)
	value := r.(map[string]interface{})

	for k, v := range value {
		//fmt.Println("v.type")
		//fmt.Println("reflect.TypeOf(value):", reflect.TypeOf(v))
		//var fv = map[string]float64{}
		var fv float64
		switch v.(type) {
		//rv := reflect.ValueOf(v)
		//kind := rv.Kind()
		case string:
			vv, _ := strconv.ParseFloat(v.(string), 64)
			ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", vv), 64)
			//value[k] = ss

			fv = ss
		case float64:
			ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", v.(float64)), 64)
			fv = ss

		}
		value[k] = fv
		//res := make([]interface{}, 0, 2)

		//kk, _ := strconv.ParseFloat(k, 64)
		kk, _ := strconv.Atoi(k)
		// res = append(res, kk)
		// res = append(res, fv)
		res := services.ValueType{Name: kk, TimeSteamp: kk, Value: fv}
		result = append(result, res)
		//rst = KtsValueOrder(result, "asc")

		//ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", v), 64)
		//v = ss
	}
	return result
}

func formatResult(v interface{}) interface{} {

	switch v.(type) {
	//rv := reflect.ValueOf(v)
	//kind := rv.Kind()
	case string:
		vv, _ := strconv.ParseFloat(v.(string), 64)
		ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", vv), 64)
		return ss
	case float64:
		ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", v.(float64)), 64)

		return ss
	}

	//ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", v), 64)

	return ""
}

func KtsGetSlice(r interface{}) []float64 {
	var result []float64

	value := r.(map[string]interface{})
	for _, v := range value {
		//v := value[i].([]interface{})
		switch v.(type) {
		case string:
			vv, _ := strconv.ParseFloat(v.(string), 64)
			//ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", vv), 64)
			//sss := services.FormatSize(ss)
			//v[1] = sss
			result = append(result, vv)
		case float64:
			ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", v.(float64)), 64)
			//sss := services.FormatSize(ss)
			//v[1] = sss
			result = append(result, ss)
		}
	}
	//result = res.(string)

	return result
}

//func KtsGetSlice1(r interface{}) []float64 {
//	var result []float64
//
//	valu := r.(map[string]interface{})
//	if Data, o := valu["value"]; o {
//		value := Data.(map[string]interface{})
//		for _, v := range value {
//			//v := value[i].([]interface{})
//			switch v.(type) {
//			case string:
//				vv, _ := strconv.ParseFloat(v.(string), 64)
//				//ss, _ := strconv.ParseFloat(fmt.Sprintf("%.4f", vv), 64)
//				//sss := services.FormatSize(ss)
//				//v[1] = sss
//				result = append(result, vv)
//			case float64:
//				ss, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", v.(float64)), 64)
//				//sss := services.FormatSize(ss)
//				//v[1] = sss
//				result = append(result, ss)
//			}
//		}
//		//result = res.(string)
//	}
//
//	return result
//}

func getMax(vals []float64) float64 {
	if len(vals) > 0 {
		var max = vals[0]
		for _, val := range vals {
			if val > max {
				max = val
			}
		}
		return max
	}
	return 0
}

func getMin(vals []float64) float64 {
	if len(vals) > 0 {
		var min = vals[0]
		for _, val := range vals {
			if val < min {
				min = val
			}
		}
		return min
	}
	return 0
}

func getAvg(vals []float64) float64 {
	if len(vals) > 0 {
		l := len(vals)
		sum := 0.0
		for _, val := range vals {
			sum += val / float64(l)
		}
		return sum
	}
	return 0
}


// interval
//[30/6 60/12]  []int{6,12}
//[10m 180]  []int{18}
//[720 1440 10080] []int{12，24，168}
//[43200] []int{30}

func GetAvgSliceOld(interval []int, vals []float64) map[int]float64 {
	var m = make(map[int]float64)

	if len(vals) == 1 && len(interval) >= 0 {
		m[interval[0]] = vals[0]
		return m
	}
	var step = len(vals) / len(interval)
	var end = len(vals)
	var start = end - step
	for _, duration := range interval {
		var arr = vals[start:end]
		// 求和
		sum := 0.0
		for _, item := range arr {
			sum += item
		}
		// 求平均数
		var avg = sum / float64(end-start)
		avgAA, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", avg), 64)
		m[duration] = avgAA

		start -= step
	}

	return m
}
func GetAvgSlice(interval []int, vals []float64) map[int]float64 {
	var m = make(map[int]float64)

	if len(vals) == 1 && len(interval) >= 0 {
		m[interval[0]] = vals[0]
		return m
	}
	var end = len(vals)
	for _, duration := range interval {
		start := end-duration
		var arr = vals[start:end]
		// 求和
		sum := 0.0
		for _, item := range arr {
			sum += item
		}
		// 求平均数
		var avg = sum / float64(duration)
		avgAA, _ := strconv.ParseFloat(fmt.Sprintf("%.2f", avg), 64)
		m[duration] = avgAA
	}
	return m
}


func GetKtsRangeValueAvg(vals []float64) float64 {
	if len(vals) > 0 {
		l := len(vals)
		sum := 0.0
		for _, val := range vals {
			sum += val / float64(l)
		}
		return sum
	}
	return 0
}

func KtsValueOrder(in [][]interface{}, code string) [][]interface{} {
	results := alert.Bucket{}
	for i := 0; i < len(in); i++ {
		results.Slice = append(results.Slice, in[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	switch code {
	case "asc":
		time_by = func(a, b interface{}) bool {
			aa := a.([]interface{})
			bb := b.([]interface{})
			//aa, _ := strconv.ParseFloat(services.Strval(a.(CmdbTopVm).Value), 64)
			//bb, _ := strconv.ParseFloat(services.Strval(b.(CmdbTopVm).Value), 64)
			return aa[0].(int) < bb[0].(int)
		}
	case "desc":
		time_by = func(a, b interface{}) bool {
			aa := a.([]interface{})
			bb := b.([]interface{})
			//aa, _ := strconv.ParseFloat(services.Strval(a.(CmdbTopVm).Value), 64)
			//bb, _ := strconv.ParseFloat(services.Strval(b.(CmdbTopVm).Value), 64)
			return aa[0].(int) > bb[0].(int)
		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(in); i++ {
		in[i] = results.Slice[i].([]interface{})
	}
	return in
}

func KtsValueToOrder(in []services.ValueType, code string) []services.ValueType {
	results := alert.Bucket{}
	for i := 0; i < len(in); i++ {
		results.Slice = append(results.Slice, in[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	switch code {
	case "asc":
		time_by = func(a, b interface{}) bool {
			aa := a.(services.ValueType).Value
			bb := b.(services.ValueType).Value
			//aa, _ := strconv.ParseFloat(services.Strval(a.(CmdbTopVm).Value), 64)
			//bb, _ := strconv.ParseFloat(services.Strval(b.(CmdbTopVm).Value), 64)
			return aa.(float64) < bb.(float64)
		}
	case "desc":
		time_by = func(a, b interface{}) bool {
			aa := a.(services.ValueType).Value
			bb := b.(services.ValueType).Value
			//aa, _ := strconv.ParseFloat(services.Strval(a.(CmdbTopVm).Value), 64)
			//bb, _ := strconv.ParseFloat(services.Strval(b.(CmdbTopVm).Value), 64)
			return aa.(float64) > bb.(float64)
		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(in); i++ {
		in[i] = results.Slice[i].(services.ValueType)
	}
	return in
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/ktsmanager/model.go
```golang
package ktsmanager

type ResponseMetric struct {
	Metric     string      `json:"metric"`
	Value      interface{} `json:"value"`
	CPUModeAvg interface{} `json:"cpuModeAvg"`
	Curren     interface{} `json:"curren"`
	Min        interface{} `json:"min"`
	Max        interface{} `json:"max"`
	Avg        interface{} `json:"avg"`
}

type MetricResult struct {
	Type       interface{} `json:"type"`
	MountPoint interface{} `json:"mountpoint"`
	Metric     interface{} `json:"metric"`
	Name       interface{} `json:"name"`
	Current    interface{} `json:"current"`
	Avg        interface{} `json:"avg"`
	Max        interface{} `json:"max"`
	Min        interface{} `json:"min"`
	Value      interface{} `json:"value"`
}


type MetricResultNew struct {
	Type       interface{} `json:"type"`
	MountPoint interface{} `json:"mountpoint"`
	Metric     interface{} `json:"metric"`
	Name       interface{} `json:"name"`
	Current    interface{} `json:"current"`
	Avg        map[int]float64 `json:"avg"`
	Max        interface{} `json:"max"`
	Min        interface{} `json:"min"`
	Value      interface{} `json:"value"`
}



type TSDBQueryRangeBody struct {
	Start   string       `json:"start"`
	End     string       `json:"end"`
	Queries []RangeQuery `json:"queries"`
	//Instance    string       `json:"instance"`
	//PointNumber int       `json:"pointNumber"`
	//Lines       []Line       `json:"lines"`
}

type Line struct {
	Instance    string            `json:"instance"`
	Legend      string            `json:"legend"`
	Lineid      int               `json:"lineid"`
	Metric      string            `json:"metric"`
	Producttype int               `json:"producttype"`
	Tags        map[string]string `json:"tags"`
}

type QueryResult struct {
	Metric    string      `json:"metric"`
	Timestamp interface{} `json:"timestamp"`
	Value     string      `json:"value"`
	Tsuid     string      `json:"tsuid"`
}

type TSDBQueryBody struct {
	ResolveNames bool        `json:"resolveNames"`
	BackScan     int         `json:"backScan"`
	Queries      []LastQuery `json:"queries"`
}

type QueryRangeResult struct {
	Metric string      `json:"metric"`
	Dps    interface{} `json:"dps"`
}

type RangeQuery struct {
	Aggregator string            `json:"aggregator"`
	Metric     string            `json:"metric"`
	Tags       map[string]string `json:"tags"`
	Downsample string            `json:"downsample"`
}

type LastQuery struct {
	Metric string            `json:"metric"`
	Tags   map[string]string `json:"tags"`
}

type QueryList struct {
	List []string `json:"list"`
}

type TimeResult struct {
	TimeStamp interface{} `json:"timeStamp"`
	Result    interface{} `json:"result"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/ktsmanager/open_tsdb.go
```golang
package ktsmanager

import (
	"fmt"
	"strconv"
	"strings"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	"k8s.io/klog/v2"
)

func QueryVmMetricTop(id, start, end string, metrics []string, interval []int) []MetricResultNew {

	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBKNew(end1 - start1) //降采样
	responseMetric := make([]MetricResultNew, 0, 10)

	for i := 0; i < len(metrics); i++ {
		switch metrics[i] {
		case "CPULoadAvg":
			klog.Info("CPULoadAvg")
			r := MetricResultNew{Name: "CPULoadAvg", Metric: "CPULoadAvg"}
			tag := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "cpu.utilizition.total" + "." + id,
				Tags:       tag,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top CPULoadAvg tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "MemLoadAvg":
			r := MetricResultNew{Name: "MemLoadAvg", Metric: "MemLoadAvg"}
			tag1 := map[string]string{
				//"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "memory.utilizition.total" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top MemLoadAvg tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "DiskUsedRange":
			r := MetricResultNew{Name: "使用率", Metric: "DiskUsedRange"}
			total := map[string]string{
				"host": id,
				"p1":   "/",
				"p2":   "pused",
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vfs.fs.size" + "." + id,
				Tags:       total,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top DiskUsedRange tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "NetInAvg":
			r := MetricResultNew{Name: "NetInAvg", Metric: "NetInAvg"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "eth0",
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "net.if.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			klog.Infof("NetInAvgrangeRange %+v",rangeRange)
			if err != nil {
				klog.Errorf("top NetInAvg tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
				klog.Infof("NetInAvgGetAvgSlice %+v",r.Avg)
			}
			responseMetric = append(responseMetric, r)
		case "NetOutAvg":
			r := MetricResultNew{Name: "NetOutAvg", Metric: "NetOutAvg"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "eth0",
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "net.if.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			klog.Infof("NetOutAvgrangeRange %+v",rangeRange)
			if err != nil {
				klog.Errorf("top NetOutAvg tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
				klog.Infof("NetOutAvgGetAvgSlice %+v",r.Avg)
			}

			responseMetric = append(responseMetric, r)
		}

	}

	return responseMetric

}

func QueryBlockMetricTop(id, start, end string, metrics []string, interval []int) []MetricResultNew {
	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBKNew(end1 - start1) //降采样
	responseMetric := make([]MetricResultNew, 0, 10)

	for i := 0; i < len(metrics); i++ {
		switch metrics[i] {
		case "BwInAvg":
			klog.Info("BwInAvg")
			write := MetricResultNew{Name: "VdaW", Metric: "VdaW"}
			s := strings.Split(metrics[i], ":")
			vdd := ""
			if len(s) == 2 {
				vdd = s[1]
			} else {
				vdd = "vda"
			}
			tag2 := map[string]string{
				"host": id,
				"p1":   vdd,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "disk.write.Bps" + "." + id,
				Tags:       tag2,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top VdaW tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				write.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, write)
		case "BwOutAvg":
			klog.Info("BwOutAvg")
			read := MetricResultNew{Name: "VdaR", Metric: "VdaR"}
			s := strings.Split(metrics[i], ":")
			vdd := ""
			if len(s) == 2 {
				vdd = s[1]
			} else {
				vdd = "vda"
			}
			tag1 := map[string]string{
				"host": id,
				"p1":   vdd,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "disk.read.Bps" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top BackendOut tsdb 查询错误, err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				read.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, read)
		case "IOIn":
			klog.Info("IOIn")
			r := MetricResultNew{Name: "VdaW", Metric: "VdaW"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "vda",
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "disk.write.ops" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top IOIn tsdb 查询错误, err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "IOOut":
			klog.Info("IOOut")
			r := MetricResultNew{Name: "VdaR", Metric: "VdaR"}
			tag1 := map[string]string{
				"host": id,
				"p1":   "vda",
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "disk.read.ops" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top IOOut tsdb 查询错误, err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				r.Value = KtsResultToValue(rangeRange[0].Dps)
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		}
	}

	return responseMetric
}

func QueryRedisMetricTop(id, start, end string, metrics []string, interval []int) []MetricResultNew {

	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBKNew(end1 - start1) //降采样
	responseMetric := make([]MetricResultNew, 0, 10)
	id = fmt.Sprintf("ksckcs--%s", id) // 这里必须要加上前缀，才能从tsdb中拿到数据

	for i := 0; i < len(metrics); i++ {
		switch metrics[i] {

		case "RedisCpuLoad": //Redis Cpu使用率
			r := MetricResultNew{Name: "Cpu使用率", Metric: "RedisCpuLoad"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.cpu_load" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "RedisMemoryLoad": //Redis内存使用率
			r := MetricResultNew{Name: "内存使用率", Metric: "RedisMemoryLoad"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.memory_load" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "RedisIntranetInRatio": //入流量使用率
			r := MetricResultNew{Name: "入流量使用率", Metric: "RedisIntranetInRatio"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.intranet_in_ratio" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "RedisIntranetOutRatio": //Redis出流量使用率
			r := MetricResultNew{Name: "出流量使用率", Metric: "RedisIntranetOutRatio"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.intranet_out_ratio" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "RedisConnectionUsage": //Redis 连接数使用率
			r := MetricResultNew{Name: "连接数使用率", Metric: "RedisConnectionUsage"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.connection_usage" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "RedisHitRate": //Redis 缓存命中率
			r := MetricResultNew{Name: "缓存命中率", Metric: "RedisHitRate"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.hit_rate" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "RedisSlowlogLen": //Redis 慢查询数量
			r := MetricResultNew{Name: "缓存命中率", Metric: "RedisSlowlogLen"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.slowlog_len" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "RedisUsedMemory": //redis 已使用内存
			r := MetricResultNew{Name: "RedisUsedMemory", Metric: "RedisUsedMemory"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "kcs.usedmemory" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top redis tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		}
	}

	return responseMetric
}

func QueryNatMetricTop(id, start, end string, metrics []string, interval []int) []MetricResultNew {
	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBKNew(end1 - start1) //降采样
	responseMetric := make([]MetricResultNew, 0, 10)

	for i := 0; i < len(metrics); i++ {
		switch metrics[i] {
		case "NatBpsIn":
			r := MetricResultNew{Name: "NatBpsIn", Metric: "NatBpsIn"}
			tag1 := map[string]string{
				"host": "kscnat--" + id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.bps.in" + "." + "kscnat--" + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top Nat tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "NatBpsOut":
			r := MetricResultNew{Name: "NatBpsOut", Metric: "NatBpsOut"}
			tag1 := map[string]string{
				"host": "kscnat--" + id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.bps.out" + "." + "kscnat--" + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			klog.Info(rangeRange)
			if err != nil {
				klog.Errorf("top Nat tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "NatPpsIn":
			r := MetricResultNew{Name: "NatPpsIn", Metric: "NatPpsIn"}
			tag1 := map[string]string{
				"host": "kscnat--" + id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.pps.in" + "." + "kscnat--" + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top Nat tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "NatPpsOut":
			r := MetricResultNew{Name: "NatPpsOut", Metric: "NatPpsOut"}
			tag1 := map[string]string{
				"host": "kscnat--" + id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.pps.out" + "." + "kscnat--" + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top Nat tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "NatBpsInPublic":
			r := MetricResultNew{Name: "NatBpsInPublic", Metric: "NatBpsInPublic"}
			tag1 := map[string]string{
				"host": "kscnat--" + id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.public.bps.in" + "." + "kscnat--" + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top Nat tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "NatBpsOutPublic":
			r := MetricResultNew{Name: "NatBpsOutPublic", Metric: "NatBpsOutPublic"}
			tag1 := map[string]string{
				"host": "kscnat--" + id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.public.bps.out" + "." + "kscnat--" + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top Nat tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "NatPpsInPublic":
			r := MetricResultNew{Name: "NatPpsInPublic", Metric: "NatPpsInPublic"}
			tag1 := map[string]string{
				"host": "kscnat--" + id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.public.pps.in" + "." + "kscnat--" + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top Nat tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "NatPpsOutPublic":
			r := MetricResultNew{Name: "NatPpsOutPublic", Metric: "NatPpsOutPublic"}
			tag1 := map[string]string{
				"host": "kscnat--" + id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "vpc.nat.public.pps.out" + "." + "kscnat--" + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top Nat tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		}
	}
	return responseMetric
}

func QueryMysqlMetricTop(id, start, end string, metrics []string, interval []int) []MetricResultNew {

	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBKNew(end1 - start1) //降采样
	responseMetric := make([]MetricResultNew, 0, 10)
	id = fmt.Sprintf("kscrds--%s", id) // 这里必须要加上前缀，才能从tsdb中拿到数据
	//klog.Info("changed id", id)

	for i := 0; i < len(metrics); i++ {
		switch metrics[i] {
		case "MysqlCpuRate": // Cpu使用率
			r := MetricResultNew{Name: "MysqlCpuRate", Metric: "MysqlCpuRate"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.cpu_used_percent" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "MysqlMemRate": // mysql内存使用率
			r := MetricResultNew{Name: "MysqlMemRate", Metric: "MysqlMemRate"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.memory_used_percent" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "MysqlIopsRead": // IopsRead
			r := MetricResultNew{Name: "MysqlIopsRead", Metric: "MysqlIopsRead"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.riops" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "MysqlIopsWrite": // IopsWrite
			r := MetricResultNew{Name: "MysqlIopsWrite", Metric: "MysqlIopsWrite"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.wiops" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "MysqlLinkRunning": // 当前活跃连接数
			r := MetricResultNew{Name: "MysqlLinkRunning", Metric: "MysqlLinkRunning"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.threads_running" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			responseMetric = append(responseMetric, r)
		case "MysqlLinkConnected": // 当前连接数
			r := MetricResultNew{Name: "MysqlLinkConnected", Metric: "MysqlLinkConnected"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.threads_connected" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "MysqlBytesReceived": // 网络输入吞吐量
			r := MetricResultNew{Name: "MysqlBytesReceived", Metric: "MysqlBytesReceived"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.bytes_received" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "MysqlBytesSent": // 网络输出吞吐量
			r := MetricResultNew{Name: "MysqlBytesSent", Metric: "MysqlBytesSent"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.bytes_sent" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "MysqlOps": // MysqlOps
			r := MetricResultNew{Name: "MysqlOps", Metric: "MysqlOps"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.qps" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "MysqlTps": //MysqlTps
			r := MetricResultNew{Name: "MysqlTps", Metric: "MysqlTps"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "rds.tps" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top mysql tsdb metrics 查询错误，err: %s", err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		}
	}
	return responseMetric
}

func QueryLoadMetricTop(id, start, end string, metrics []string, interval []int) []MetricResultNew {
	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBKNew(end1 - start1) //降采样
	responseMetric := make([]MetricResultNew, 0, 10)

	for i := 0; i < len(metrics); i++ {
		switch metrics[i] {
		case "SlbBpsIn": //load 负载均衡流量 入网带宽
			id = "ksclb---" + id // lb id需要加前缀 ksclb---
			r := MetricResultNew{Name: "SlbBpsIn", Metric: "SlbBpsIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.bps.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top %s tsdb metrics 查询错误, err: %s", metrics[i], err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "SlbBpsOut": //load 负载均衡流量 出网带宽
			id = "ksclb---" + id
			r := MetricResultNew{Name: "SlbBpsOut", Metric: "SlbBpsOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.bps.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top %s tsdb metrics 查询错误, err: %s", metrics[i], err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "SlbPpsIn": //load 负载均衡每秒收发包次数 每秒流入包数
			id = "ksclb---" + id
			r := MetricResultNew{Name: "每秒流入包数", Metric: "SlbPpsIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.pps.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top %s tsdb metrics 查询错误, err: %s", metrics[i], err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "SlbPpsOut": //load 负载均衡每秒收发包次数 每秒流出包数
			id = "ksclb---" + id
			r := MetricResultNew{Name: "每秒流出包数", Metric: "SlbPpsOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.pps.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top %s tsdb metrics 查询错误, err: %s", metrics[i], err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "SlbCps": //load 每秒新建连接数
			id = "ksclb---" + id
			r := MetricResultNew{Name: "每秒新建连接数", Metric: "SlbPpsOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.cps" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top %s tsdb metrics 查询错误, err: %s", metrics[i], err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "SlbActiveconn": //load 每秒新建连接数
			id = "ksclb---" + id
			r := MetricResultNew{Name: "活跃连接数", Metric: "SlbActiveconn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.activeconn" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top %s tsdb metrics 查询错误, err: %s", metrics[i], err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "SlbConcurrentconn": //load 并发连接数
			id = "ksclb---" + id
			r := MetricResultNew{Name: "并发连接数", Metric: "SlbConcurrentconn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.concurrentconn" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top %s tsdb metrics 查询错误, err: %s", metrics[i], err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "SlbInactiveconn": //load 每秒新建连接数
			id = "ksclb---" + id
			r := MetricResultNew{Name: "不活跃连接数", Metric: "SlbInactiveconn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "slb.inactiveconn" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top %s tsdb metrics 查询错误, err: %s", metrics[i], err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "EipBpsIn": //load eip 入网带宽
			id = "ksceip--" + id // eip id 需加前缀 ksceip--
			r := MetricResultNew{Name: "入网带宽", Metric: "EipBpsIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.bps.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top %s tsdb metrics 查询错误, err: %s", metrics[i], err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "EipBpsOut": //load eip 出网带宽
			id = "ksceip--" + id
			r := MetricResultNew{Name: "出网带宽", Metric: "EipBpsOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.bps.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top %s tsdb metrics 查询错误, err: %s", metrics[i], err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "EipPpsIn": //load 每秒流入包数
			id = "ksceip--" + id
			r := MetricResultNew{Name: "每秒流入包数", Metric: "EipPpsIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.pps.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top %s tsdb metrics 查询错误, err: %s", metrics[i], err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "EipPpsOut": //load 每秒流出包数
			id = "ksceip--" + id
			r := MetricResultNew{Name: "每秒流出包数", Metric: "EipPpsOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.pps.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top %s tsdb metrics 查询错误, err: %s", metrics[i], err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "EipUtilizationIn": //load  eip 入向带宽使用百分比
			id = "ksceip--" + id
			r := MetricResultNew{Name: "入向带宽使用百分比", Metric: "EipUtilizationIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.utilization.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top %s tsdb metrics 查询错误, err: %s", metrics[i], err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "EipUtilizationOut": //load eip  出向带宽使用百分比
			id = "ksceip--" + id
			r := MetricResultNew{Name: "出向带宽使用百分比", Metric: "EipUtilizationOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.utilization.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top %s tsdb metrics 查询错误, err: %s", metrics[i], err)
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		}
	}
	return responseMetric
}

//获取Eip监控数据
func QueryEipMetricTop(id, start, end string, metrics []string, interval []int) []MetricResultNew {

	start1, _ := strconv.ParseFloat(start, 64) //字符串转换成时间戳
	end1, _ := strconv.ParseFloat(end, 64)
	step := services.TimeToStepForTSDBKNew(end1 - start1) //降采样
	responseMetric := make([]MetricResultNew, 0, 10)

	for i := 0; i < len(metrics); i++ {
		switch metrics[i] {
		case "EipUtilizationOut":
			klog.Info("EipUtilizationOut")
			r := MetricResultNew{Name: "出向带宽使用百分比", Metric: "EipUtilizationOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.utilization.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top EipUtilizationOut tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "EipUtilizationIn":
			klog.Info("EipUtilizationIn")
			r := MetricResultNew{Name: "入向带宽使用百分比", Metric: "EipUtilizationIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.utilization.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top EipUtilizationIn tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "EipPpsOut":
			klog.Info("EipPpsOut")
			r := MetricResultNew{Name: "每秒流出包数", Metric: "EipPpsOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.pps.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top EipPpsOut tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "EipPpsIn":
			klog.Info("EipPpsIn")
			r := MetricResultNew{Name: "每秒流入包数", Metric: "EipPpsIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.pps.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top EipPpsIn tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "EipBpsOut":
			klog.Info("EipBpsOut")
			r := MetricResultNew{Name: "出网带宽", Metric: "EipBpsOut"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.bps.out" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top EipBpsOut tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		case "EipBpsIn":
			klog.Info("EipPpsIn")
			r := MetricResultNew{Name: "入网带宽", Metric: "EipBpsIn"}
			tag1 := map[string]string{
				"host": id,
			}
			rangeQ := RangeQuery{
				Aggregator: "sum",
				Metric:     "eip.bps.in" + "." + id,
				Tags:       tag1,
				Downsample: step,
			}
			rangeRange, err := TSDBRangeQuery(start, end, rangeQ)
			if err != nil {
				klog.Errorf("top EipBpsIn tsdb 查询错误，err: %s", err)
				return nil
			}
			if len(rangeRange) > 0 {
				ss := KtsGetSlice(rangeRange[0].Dps)
				r.Avg = GetAvgSlice(interval, ss)
			}
			responseMetric = append(responseMetric, r)
		}

	}

	return responseMetric

}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cmdbmanager/instance.go
```golang
package cmdbmanager

import (
	"bytes"
	"encoding/json"
	"errors"
	"fmt"
	client2 "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/process"
	"io"
	"k8s.io/klog/v2"
	"net/http"
	"strings"
)

type QueryServiceInstanceListParams struct {
	//regionCode, azCode, searchName string, searchSvcIds []int, pageSize, pageNo int
	Region       string   `json:"region"`
	Az           []string `json:"az"`
	SearchName   string   `json:"searchName"`
	SearchSvcIds []int    `json:"searchSvcIds"`
	PageSize     int      `json:"pageSize"`
	PageNo       int      `json:"pageNo"`
	SortField    string   `json:"sortField"`
	SortType     string   `json:"sortType"`
	HostName     string   `json:"HostName"`
}

//根据服务ID获取服务实例列表
func ServiceInstanceList(params QueryServiceInstanceListParams) (data InstanceResultData, err error) {
	url := fmt.Sprintf("http://%s/cmdb/v1/instance/businessManagement/serviceInstanceList",
		config.GetDefaultUrl(config.CMDBService))
	bs, err := json.Marshal(params)
	if err != nil {
		klog.Error("json.Marshal get error")
		return data, err
	}
	resp, err := http.Post(url, "application/json", bytes.NewBuffer(bs))
	if err != nil {
		klog.Error("http get error url=", url, ",err=", err, ",resp=", resp)
		return data, err
	}
	defer resp.Body.Close()
	respInstance, _ := io.ReadAll(resp.Body)
	var instanceResult InstanceResult
	err = json.Unmarshal(respInstance, &instanceResult)
	if err != nil {
		klog.Error("json unmarshal url=", url, ",err=", err, ",resp=", resp)
		return data, err
	}
	//异常逻辑
	if instanceResult.Code != 200 {
		err = errors.New(instanceResult.Message)
		return data, err
	}
	data = instanceResult.Data
	//没有数据
	if len(instanceResult.Data.DataList) <= 0 {
		return data, err
	}
	return data, err
}

//查询结果
type ResultValue struct {
	Id        int
	CmdValue  float64
	PortValue float64
}

const ProcessExporterPort = 9256

func ProcessListState(ps []ServiceProcess, ip string) (processState map[int]ResultValue) {
	//进程查询namedprocess_namegroup_states{ groupname=~"map\\[:/usr/bin/nova-api\\]|map\\[:mysqld\\]",instance="10.177.9.26:9256",state="Sleeping"}
	processState = make(map[int]ResultValue)
	//进程
	var (
		groups   []string
		state    = "Sleeping"
		groupMap = make(map[string]int) //记录group => id, 查询出prometheus label后方便定位到id
	)
	//端口
	var (
		ports   []string
		portMap = make(map[string]int) //记录port => id
	)
	klog.Infof("ps: %v, ip:%v", ps, ip)
	//组合查询query
	for _, v := range ps {
		if len(v.Cmd) > 0 {
			cmd := fmt.Sprintf(`map\\[:%s\\]`, v.Cmd)
			groups = append(groups, cmd)
			groupMap[fmt.Sprintf("map[:%s]", v.Cmd)] = v.Id
		}
		if len(v.Port) > 0 {
			target := fmt.Sprintf("%s:%s", ip, v.Port)
			ports = append(ports, target)
			portMap[target] = v.Id
		}
		processState[v.Id] = ResultValue{
			Id:        v.Id,
			CmdValue:  0,
			PortValue: 0,
		}
	}
	//批量查询有cmd的结果
	if len(groups) > 0 {
		processTpl := process.NewMetrics(fmt.Sprintf("%s:%d", ip, ProcessExporterPort), strings.Join(groups, "|"), state, "")
		sql := processTpl.ToString(process.Namedprocess_namegroup_states)
		results, err := client2.VectorQuery(sql)
		if err != nil {
			klog.Errorf("query prometheus error %v", err)
			return
		}
		klog.Infof("prometheus result:%v", results)
		for _, v := range results {
			group, ok := v.Metric["groupname"]
			if !ok {
				continue
			}
			id := groupMap[string(group)]
			println(groupMap)
			result, ok := processState[id]
			if !ok {
				continue
			}
			//记录该id是否为bool
			result.CmdValue = float64(v.Value)
			processState[id] = result
		}
	}

	//端口查询probe_success{target=~"10.177.9.11:22|10.177.9.11:3306"}
	if len(ports) > 0 {
		processTpl := process.NewMetrics(strings.Join(ports, "|"), "", "", "")
		sql := processTpl.ToString(process.Probe_success)
		results, err := client2.VectorQuery(sql)
		if err != nil {
			klog.Errorf("query prometheus error, %v", err)
			return
		}
		for _, v := range results {
			target, ok := v.Metric["target"]
			if !ok {
				continue
			}
			id := portMap[string(target)]
			result, ok := processState[id]
			if !ok {
				continue
			}
			//记录该id是否为bool
			result.PortValue = float64(v.Value)
			processState[id] = result
		}
	}
	return
}

func ContainerList(ns, pod string) ([]cmdbmodel.Container, error) {
	c := http.Client{}
	url := fmt.Sprintf("http://%s/cmdb/v1/instance/businessManagement/containerList/ns/%s/pod/%s",
		config.GetDefaultUrl(config.CMDBService), ns, pod)

	containerList := make([]cmdbmodel.Container, 0)
	resp, err := c.Get(url)
	if err != nil {
		return containerList, err
	}
	rst := cmdbmodel.ContainerResult{}
	b, _ := io.ReadAll(resp.Body)
	err = json.Unmarshal(b, &rst)
	if err != nil {
		return containerList, err
	}
	if rst.Code != 200 {
		return containerList, errors.New("containerList not response 200 error")
	}
	containerList = rst.Data
	return containerList, nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cmdbmanager/cmdbservice.go
```golang
package cmdbmanager

import (
	"encoding/json"
	"fmt"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/bm"
	switchmodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/physicalSwitch"
	"io"
	"io/ioutil"
	"net/http"
	"net/url"
	"strconv"
	"strings"
	"time"

	"k8s.io/klog/v2"

	"github.com/pkg/errors"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	cmdbmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/cmdbservice"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

// 从cmdb的api中获取所有的物理机的服务器列表
func GetAllPhysicalHostList(name, region string, az, lab []string) (PhysicalHostResult, error) {
	c := http.Client{}
	cmdbCount := services.GetTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/physicalHost", "post")
	AllResult := PhysicalHostResult{Data: PhysicalHostDataResult{DataList: make([]PhysicalHostData, 0, cmdbCount)}}
	//var hosts []cmdbmodel.Host
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/physicalHost" //?pageNo=1&pageSize=10000"
	hostUrlPost := PhysicalHostUrlPost{
		PageNo:   1,
		PageSize: cmdbCount,
		Region:   region,
		//针对cmdb多选，目前这边先注释
		Az:   az,
		Lab:  lab,
		Name: name,
	}
	fmt.Printf("hostUrlPosthostUrlPost %+v", hostUrlPost)
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)
	//resp, err := c.Get(url)
	if err != nil {
		fmt.Println(err)
		return AllResult, err
	}

	b, _ := io.ReadAll(res.Body)

	e := json.Unmarshal(b, &AllResult)

	if e != nil {
		return AllResult, err
	}
	if AllResult.Code != 200 {
		return AllResult, errors.Errorf("get data from nova cmdb error!")
	}
	//hosts = rsStructForUnmarshal.Data.DataList

	return AllResult, nil
}

// 从cmdb的api中获取所有的物理机的服务器详情
func GetAllPhysicalHostInfo(param GetPhysicalHostInfo) (PhysicalHostResult, error) {
	c := http.Client{}
	cmdbCount := services.GetTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/physicalHost", "post")
	AllResult := PhysicalHostResult{Data: PhysicalHostDataResult{DataList: make([]PhysicalHostData, 0, cmdbCount)}}

	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/physicalHost" //?pageNo=1&pageSize=10000"

	jsons, _ := json.Marshal(param)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)
	//resp, err := c.Get(url)
	if err != nil {
		fmt.Println(err)
		return AllResult, err
	}

	b, _ := io.ReadAll(res.Body)

	e := json.Unmarshal(b, &AllResult)

	if e != nil {
		return AllResult, err
	}
	if AllResult.Code != 200 {
		return AllResult, errors.Errorf("get data from nova cmdb error!")
	}
	//hosts = rsStructForUnmarshal.Data.DataList

	return AllResult, nil
}

func GetphysicalHostHardware(sn string) (Hardware, error) {
	c := http.Client{}
	rst := HardwareResp{}
	url := fmt.Sprintf("http://%s/cmdb/v1/instance/physicalHostHardware?sn=%s", config.GetDefaultUrl(config.CMDBService), sn)

	res, err := c.Get(url)

	//resp, err := c.Get(url)
	if err != nil {
		klog.Error(err)
		return rst.Data, err
	}

	b, _ := io.ReadAll(res.Body)

	e := json.Unmarshal(b, &rst)

	if e != nil {
		return rst.Data, err
	}
	if rst.Code != 200 {
		return rst.Data, errors.Errorf("get data from nova cmdb error!")
	}
	//hosts = rsStructForUnmarshal.Data.DataList

	return rst.Data, nil
}

// 获取对象存储资源池列表
func GetObjectStorageResourcePoolList(region string, az string, name string, pageNo string, pageSize string) (cmdbmodel.ObjectStoragePoolResult, error) {
	rsStructForUnmarshal := cmdbmodel.ObjectStoragePoolResult{}
	var b []byte
	poolName := "objectStoragePool"
	b, err := GetResourcePoolList(region, az, name, pageNo, pageSize, poolName)
	err = json.Unmarshal(b, &rsStructForUnmarshal)
	if err != nil {
		return rsStructForUnmarshal, err
	}
	if rsStructForUnmarshal.Code != 200 {
		return rsStructForUnmarshal, errors.Errorf("get data from nova cmdb error!")
	}
	return rsStructForUnmarshal, err
}

// 获取块存储资源池列表
func GetBlockStorageResourcePoolList(region, name string, az, rp []string) (cmdbmodel.BlockStoragePoolResult, error) {
	rsStructForUnmarshal := cmdbmodel.BlockStoragePoolResult{}

	c := http.Client{}
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/blockStoragePool"
	klog.Info("url")
	klog.Info(url)
	hostUrlPost := cmdbmodel.BlockReUrlPost{
		PageNo:       1,
		PageSize:     10,
		RegionCode:   region, //"all",
		AzCode:       az,     //"all",
		Name:         name,
		ResourcePool: rp,
	}
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	res, err := c.Post(url, "application/json", jsoninfo)

	if err != nil {
		fmt.Println(err)
		return rsStructForUnmarshal, err
	}

	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rsStructForUnmarshal)

	klog.Info("rsStructForUnmarshal")
	if err != nil {
		return rsStructForUnmarshal, err
	}
	if rsStructForUnmarshal.Code != 200 {
		return rsStructForUnmarshal, errors.Errorf("get data from nova cmdb error!")
	}
	return rsStructForUnmarshal, err
}

// 获取计算资源池列表
func GetAggragateResourcePoolList(region string, az []string, name string, pageNo string, pageSize string) (cmdbmodel.ComputerPoolResult, error) {
	rst := cmdbmodel.ComputerPoolResult{}
	//var b []byte
	c := http.Client{}
	pageNoInt, _ := strconv.Atoi(pageNo)
	pageSizeInt, _ := strconv.Atoi(pageSize)
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/computePool"
	hostUrlPost := ComputerPoolListPost{
		Region:   region,
		Az:       az,
		PageNo:   pageNoInt,
		PageSize: pageSizeInt,
	}
	hostUrlPost.PageNo, _ = strconv.Atoi(pageNo)
	hostUrlPost.PageSize, _ = strconv.Atoi(pageSize)
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)
	//res, err := c.Get("http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/computePool" + "?pageNo=" + pageNo + "&pageSize=" + pageSize + "&region=" + region +
	//"&az=" + az + "&name=" + name)
	if err != nil {
		klog.Error(err)
	}

	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rst)
	if err != nil {
		klog.Error(err)
	}
	if rst.Code != 200 {
		klog.Info("get data from nova cmdb error!")
	}
	return rst, err

}

// 获取计算资源池的所有名称
func GetComputerPoolNameList(region string, az []string, name string, pageNo string, pageSize string) ([]string, error) {
	rstt := cmdbmodel.ComputerPoolResult{}
	rst := []string{}
	//var b []byte
	c := http.Client{}
	pageNoInt, _ := strconv.Atoi(pageNo)
	pageSizeInt, _ := strconv.Atoi(pageSize)
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/computePool"
	hostUrlPost := ComputerPoolListPost{
		Region:   region,
		Az:       az,
		Name:     name,
		PageNo:   pageNoInt,
		PageSize: pageSizeInt,
	}
	hostUrlPost.PageNo, _ = strconv.Atoi(pageNo)
	hostUrlPost.PageSize, _ = strconv.Atoi(pageSize)
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)
	//res, err := c.Get("http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/computePool" + "?pageNo=" + pageNo + "&pageSize=" + pageSize + "&region=" + region +
	//"&az=" + az + "&name=" + name)
	if err != nil {
		fmt.Println("err" + err.Error())
		return rst, err
	}

	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rstt)
	if err != nil {
		return rst, err
	}
	if rstt.Code != 200 {
		return rst, errors.Errorf("get data from nova cmdb error!")
	}

	for i := 0; i < rstt.Data.TotalCount; i++ {
		rst = append(rst, rstt.Data.DataList[i].Name)
	}
	return rst, err

}

// 根据region参数从cmdb的api中获取计算，块存储，对象存储资源池列表
func PostResourcePoolList(region string, az string, name string, pageNo string, pageSize string, poolName string) ([]byte, error) {
	c := http.Client{}

	var b []byte
	//var aggregates []Aggregates
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/" + poolName
	hostUrlPost := PoolUrlPost{
		RegionCode: region,
		AzCode:     az,
		Name:       name,
	}
	hostUrlPost.PageNo, _ = strconv.Atoi(pageNo)
	hostUrlPost.PageSize, _ = strconv.Atoi(pageSize)
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)
	if err != nil {
		fmt.Println("err" + err.Error())
		return b, err
	}

	b, _ = io.ReadAll(res.Body)

	return b, nil
}
func GetResourcePoolList(region string, az string, name string, pageNo string, pageSize string, poolName string) ([]byte, error) {
	c := http.Client{}

	var b []byte
	res, err := c.Get("http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/" + poolName + "?pageNo=" + pageNo + "&pageSize=" + pageSize + "&region=" + region +
		"&az=" + az)
	if err != nil {
		fmt.Println("err" + err.Error())
		return b, err
	}

	b, _ = io.ReadAll(res.Body)

	return b, nil
}

// 根据id参数从cmdb的api中获取计算资源池对应的服务器列表
func GetHostListByResourcePool(id string) (cmdbmodel.HostsResult, error) {
	c := http.Client{}
	rsStructForUnmarshal := cmdbmodel.HostsResult{}
	//var hosts []cmdbmodel.Host
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/computePool/" + id + "/hosts" //?pageNo=1&pageSize=10000"
	cmdbCount := services.GetTotalCount(url, "post")
	hostUrlPost := cmdbmodel.HostUrlPost{
		PageNo:   1,
		PageSize: cmdbCount,
	}
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)

	//resp, err := c.Get(url)
	if err != nil {
		fmt.Println(err)
		return rsStructForUnmarshal, err
	}

	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rsStructForUnmarshal)

	if err != nil {
		return rsStructForUnmarshal, err
	}
	if rsStructForUnmarshal.Code != 200 {
		return rsStructForUnmarshal, errors.Errorf("get data from nova cmdb error!")
	}
	//hosts = rsStructForUnmarshal.Data.DataList
	return rsStructForUnmarshal, nil
}

// 根据id参数从cmdb的api中获取计算资源池对应的云主机列表
func GetVmListByResourcePool(id string) (cmdbmodel.VmsResult, error) {
	c := http.Client{}
	rsStructForUnmarshal := cmdbmodel.VmsResult{}
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/computePool/" + id + "/vms"
	vmUrlPost := cmdbmodel.VmUrlPost{
		PageNo:   1,
		PageSize: 10000,
	}
	jsons, _ := json.Marshal(vmUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)

	//resp, err := c.Get(url)
	if err != nil {
		fmt.Println(err)
		return rsStructForUnmarshal, err
	}

	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rsStructForUnmarshal)

	if err != nil {
		return rsStructForUnmarshal, err
	}
	if rsStructForUnmarshal.Code != 200 {
		return rsStructForUnmarshal, errors.Errorf("get data from nova cmdb error!")
	}
	//hosts = rsStructForUnmarshal.Data.DataList
	return rsStructForUnmarshal, nil
}

// 根据id参数从cmdb的api中获取块存储，对象存储资源池对应的服务器列表
func GetHostListByResourcePoolName(name, pageNo, pageSize string) ([]cmdbmodel.Host, error) {
	c := http.Client{}
	rsStructForUnmarshal := cmdbmodel.HostsResult{}
	var hosts []cmdbmodel.Host
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/objectStoragePool/" + name // + "?pageNo=" + pageNo + "&pageSize=" + pageSize
	hostUrlPost := cmdbmodel.HostUrlPost{
		PageNo:   1,
		PageSize: 10000,
	}
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)
	//resp, err := c.Get(url)
	if err != nil {
		return hosts, err
	}

	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rsStructForUnmarshal)

	if err != nil {
		return hosts, err
	}
	if rsStructForUnmarshal.Code != 200 {
		return hosts, errors.Errorf("get data from nova cmdb error!")
	}
	hosts = rsStructForUnmarshal.Data.DataList
	return hosts, nil
}

// 根据hostname参数从cmdb的api中获取服务器详细信息主要是ip
func GetHostDetailByHostname(hostname string) (string, error) {
	c := http.Client{}
	rsStructForUnmarshal := cmdbmodel.HostDetailResult{}
	var hostIp string
	resp, err := c.Get("http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/physicalHostDetail/" + hostname)
	if err != nil {
		return hostIp, err
	}

	b, _ := io.ReadAll(resp.Body)
	err = json.Unmarshal(b, &rsStructForUnmarshal)
	if err != nil {
		return hostIp, err
	}
	if rsStructForUnmarshal.Code != 200 {
		return hostIp, errors.Errorf("get data from nova cmdb error!")
	}
	hostIp = rsStructForUnmarshal.Data.ManagementIP
	return hostIp, nil
}

// 根据hostname参数从cmdb的api中获取服务器详细信息主要是ip
func GetHostDetailByIP(ip string) (cmdbmodel.PhysicalHostData, error) {
	c := http.Client{}
	var physicalHost cmdbmodel.PhysicalHostData
	request := cmdbmodel.HostListQuery{}
	request.IpArray = []string{ip}
	jsons, _ := json.Marshal(request)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/getHostsByIpArray"

	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)

	if err != nil {
		return physicalHost, err
	}

	b, _ := io.ReadAll(res.Body)
	var rst cmdbmodel.PhysicalHostListResult
	err = json.Unmarshal(b, &rst)

	if err != nil {
		return physicalHost, err
	}
	if rst.Data.DataList != nil && len(rst.Data.DataList) > 0 {
		physicalHost = rst.Data.DataList[0]
	}
	return physicalHost, err
}

// 根据hostname参数从cmdb的api中获取服务器详细信息主要是ip
func GetResourceData() (cmdbmodel.ResourceList, error) {
	c := http.Client{}
	rsStructForUnmarshal := cmdbmodel.ResourceResult{}
	var ResourceList cmdbmodel.ResourceList
	resp, err := c.Get("http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/basic/getResourceList")
	if err != nil {
		return ResourceList, err
	}

	b, _ := io.ReadAll(resp.Body)
	err = json.Unmarshal(b, &rsStructForUnmarshal)
	if err != nil {
		return ResourceList, err
	}
	if rsStructForUnmarshal.Code != 200 {
		return ResourceList, errors.Errorf("get data from nova cmdb error!")
	}
	ResourceList = rsStructForUnmarshal.Data
	return ResourceList, nil
}

// 获取Bucket列表
func GetBucketList(bucket cmdbmodel.BucketRequest) (cmdbmodel.ObjectStoragePoolBucket, error) {
	rsStructForUnmarshal := cmdbmodel.ObjectStoragePoolBucketResult{}
	//var b []byte

	c := http.Client{}
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/bucket" //?pageNo=1&pageSize=10000"

	jsons, _ := json.Marshal(bucket)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)

	//resp, err := c.Get(url)
	if err != nil {
		fmt.Println(err)
		return rsStructForUnmarshal.Data, err
	}

	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rsStructForUnmarshal)

	if err != nil {
		return rsStructForUnmarshal.Data, err
	}
	return rsStructForUnmarshal.Data, err
}

// 云产品块存储列表
func GetCMDBBytes(region string, az []string) (cmdbmodel.BlockCMDBResult, error) {
	cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "post")
	//ms := MonitorBlocks{DataList: make([]MonitorBlock, 0, cmdbCount)}
	cmdb := cmdbmodel.BlockCMDBResult{Data: cmdbmodel.CmdbBlocks{DataList: make([]cmdbmodel.CloudDiskData, 0, cmdbCount)}}
	var b []byte
	c := http.Client{}
	hostUrlPost := cmdbmodel.BlockListPost{
		PageNo:   1,
		PageSize: cmdbCount,
		Region:   region,
		Az:       az,
		//cmdb.Data.TotalCount = services.GetTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "post")
	}
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	klog.Infof("clouddisk post params: %s", result)

	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "application/json", jsoninfo)

	if err != nil {
		return cmdb, err
	}

	b, _ = io.ReadAll(resp.Body)
	e := json.Unmarshal(b, &cmdb)
	if e != nil {
		return cmdb, e
	}
	return cmdb, nil

}

func GetCMDBCloudDisk(region string, az, diskType []string) (cmdbmodel.BlockCMDBResult, error) {
	cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "post")
	//ms := MonitorBlocks{DataList: make([]MonitorBlock, 0, cmdbCount)}
	cmdb := cmdbmodel.BlockCMDBResult{Data: cmdbmodel.CmdbBlocks{DataList: make([]cmdbmodel.CloudDiskData, 0, cmdbCount)}}
	var b []byte
	c := http.Client{}
	hostUrlPost := cmdbmodel.BlockListPost{
		PageNo:           1,
		PageSize:         cmdbCount,
		Region:           region,
		Az:               az,
		ResourcePoolType: diskType,
		//cmdb.Data.TotalCount = services.GetTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "post")
	}
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "application/json", jsoninfo)

	if err != nil {
		return cmdb, err
	}

	b, _ = io.ReadAll(resp.Body)
	e := json.Unmarshal(b, &cmdb)
	if e != nil {
		return cmdb, e
	}
	return cmdb, nil

}

// 云产品云主机详情
func GetCMDBCloudDiskDetail(cloudDiskId string) (cmdbmodel.CloudDiskDataDetail, error) {
	result := cmdbmodel.CloudDiskDataDetail{}
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/clouddisk/" + cloudDiskId
	request, err := http.NewRequest("GET", url, nil)
	if err != nil {
		klog.Errorf("CloudDiskDataDetail err:%v", err)
		return result, err
	}
	client := &http.Client{}
	response, err := client.Do(request)
	if err != nil {
		klog.Errorf("client.Do(request) err:%v/n", err)
		return result, err
	}
	bt, err := ioutil.ReadAll(response.Body)
	if err != nil {
		klog.Errorf("ioutil.ReadAll(response.Body) err:%v/n", err)
		return result, err
	}
	err = json.Unmarshal(bt, &result)
	_ = response.Body.Close()

	return result, nil
}

func GetCMDBCloudDiskListAll(cloudDiskQuery cmdbmodel.CloudDiskRequest) (cmdbmodel.BlockCMDBResult, error) {
	//pageSize := cloudDiskQuery.PageSize
	cloudDiskQuery.PageSize = 1
	cloudDiskQuery.PageNo = 1
	cloudDiskTotalForCount, err := GetCMDBCloudDiskList(cloudDiskQuery)
	if err != nil {
		return cloudDiskTotalForCount, err
	}
	cloudDiskQuery.PageSize = cloudDiskTotalForCount.Data.TotalCount
	cloudDiskTotalList, err := GetCMDBCloudDiskList(cloudDiskQuery)
	if err != nil {
		return cloudDiskTotalForCount, err
	}
	return cloudDiskTotalList, err
}

// 云产品块存储列表
func GetCMDBCloudDiskList(cloudDiskQuery cmdbmodel.CloudDiskRequest) (cmdbmodel.BlockCMDBResult, error) {
	cmdb := cmdbmodel.BlockCMDBResult{Data: cmdbmodel.CmdbBlocks{DataList: make([]cmdbmodel.CloudDiskData, 0, 0)}}
	var b []byte
	c := http.Client{}

	jsons, _ := json.Marshal(cloudDiskQuery)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "application/json", jsoninfo)

	if err != nil {
		return cmdb, err
	}

	b, _ = io.ReadAll(resp.Body)
	e := json.Unmarshal(b, &cmdb)
	if e != nil {
		return cmdb, e
	}
	return cmdb, nil

}

// 云产品云主机列表
func GetCMDBVmList(q cmdbmodel.VmListPost) (cmdbmodel.CMDBVmResult, error) {
	c := http.Client{}
	cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/computePool/vm", "post")
	//cs := CmdbVms{}
	cmdbData := cmdbmodel.CmdbVms{
		DataList: make([]cmdbmodel.CmdbVm, 0, cmdbCount),
	}
	cmdb := cmdbmodel.CMDBVmResult{Data: cmdbData}
	if q.PageSize == 0 {
		q.PageSize = cmdbCount
	}

	jsons, _ := json.Marshal(q)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	klog.Infof("url: %s", "http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/computePool/vm")
	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/computePool/vm", "application/json", jsoninfo)

	if err != nil {
		fmt.Println("err" + err.Error())
		return cmdb, err
	}

	b, _ := io.ReadAll(resp.Body)
	err = json.Unmarshal(b, &cmdb)
	if err != nil {
		return cmdb, err
	}

	return cmdb, nil
}

func GetCMDBBlockList(q cmdbmodel.BlockListPost) (cmdbmodel.CMDBBlockResult, error) {
	c := http.Client{}
	cmdbCount := services.GetBlockAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "post")
	cmdbData := cmdbmodel.CmdbBlocks{
		DataList: make([]cmdbmodel.CloudDiskData, 0, cmdbCount),
	}

	cmdb := cmdbmodel.CMDBBlockResult{Data: cmdbData}
	if q.PageSize == 0 {
		q.PageSize = cmdbCount
	}
	jsons, _ := json.Marshal(q)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	klog.Infof("url: %s", "http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk")
	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/clouddisk", "application/json", jsoninfo)

	if err != nil {
		fmt.Println("err" + err.Error())
		return cmdb, err
	}

	b, _ := io.ReadAll(resp.Body)

	err = json.Unmarshal(b, &cmdb)
	if err != nil {
		return cmdb, err
	}

	return cmdb, nil
}

// 云产品NAT列表
func GetCMDBNatList(q cmdbmodel.NatListPost) (cmdbmodel.CMDBNatResult, error) {
	c := http.Client{}
	cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/nat/cloudProduct/natList", "post")
	klog.Info(cmdbCount)
	cmdbData := cmdbmodel.CmdbNats{
		DataList: make([]cmdbmodel.NatInfo, 0, cmdbCount),
	}
	cmdb := cmdbmodel.CMDBNatResult{Data: cmdbData}
	if q.PageSize == 0 {
		q.PageSize = 1000
	}
	jsons, _ := json.Marshal(q)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	klog.Infof("url: %s", "http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/nat/cloudProduct/natList")
	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/nat/cloudProduct/natList", "application/json", jsoninfo)

	if err != nil {
		fmt.Println("err" + err.Error())
		return cmdb, err
	}

	b, _ := io.ReadAll(resp.Body)

	err = json.Unmarshal(b, &cmdb)
	if err != nil {
		return cmdb, err
	}

	return cmdb, nil
}

// 云产品云主机详情
func GetCMDBVmDetail(vmId string) (cmdbmodel.CMDBVmDetailResult, error) {
	result := cmdbmodel.CMDBVmDetailResult{}
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/computePool/vm/" + vmId
	request, err := http.NewRequest("GET", url, nil)
	if err != nil {
		klog.Errorf("GetVmDetail err:%v", err)
		return result, err
	}
	client := &http.Client{}
	response, err := client.Do(request)
	if err != nil {
		klog.Errorf("client.Do(request) err:%v/n", err)
		return result, err
	}
	bt, err := ioutil.ReadAll(response.Body)
	if err != nil {
		klog.Errorf("ioutil.ReadAll(response.Body) err:%v/n", err)
		return result, err
	}
	err = json.Unmarshal(bt, &result)
	_ = response.Body.Close()

	return result, nil
}

// 获取网络资源池列表
func GetNetworkPoolList(param *NetworkPoolListPost) (cmdbmodel.NetworkPoolResult, error) {
	rst := cmdbmodel.NetworkPoolResult{}
	c := http.Client{}
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/networkPool/resourcePool/resourceList"
	hostUrlPost := NetworkPoolListPost{
		RegionCode: param.RegionCode,
		PageNo:     param.PageNo,
		PageSize:   param.PageSize,
		PoolName:   param.PoolName,
		PoolType:   param.PoolType,
		OrderCode:  param.OrderCode,
		OrderType:  param.OrderType,
		Type:       param.Type,
	}
	fmt.Printf("hostUrlPost %+v", hostUrlPost)
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)
	if err != nil {
		fmt.Println("err" + err.Error())
		return rst, err
	}

	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rst)
	if err != nil {
		return rst, err
	}
	if rst.Code != 200 {
		return rst, errors.Errorf("get data from nova cmdb error!")
	}
	return rst, err

}

// 获取网络资源服务器列表
func GetNetworkPhsicalServers(param *NetworkPoolListPost) (cmdbmodel.NetworkPhysicalListResult, error) {
	rst := cmdbmodel.NetworkPhysicalListResult{}
	c := http.Client{}
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/networkPool/resourcePool/phsicalServers"
	//url := "http://localhost/cmdb/v1/instance/networkPool/resourcePool/phsicalServers"
	hostUrlPost := NetworkPoolListPost{
		RegionCode: param.RegionCode,
		PageNo:     param.PageNo,
		PageSize:   param.PageSize,
		PoolName:   param.PoolName,
	}
	fmt.Printf("hostUrlPost %+v", hostUrlPost)
	jsons, _ := json.Marshal(hostUrlPost)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)
	if err != nil {
		fmt.Println("err" + err.Error())
		return rst, err
	}

	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rst)
	if err != nil {
		return rst, err
	}
	if rst.Code != 200 {
		return rst, errors.Errorf("get data from nova cmdb error!")
	}
	return rst, err

}

func GetNetworkPoolUsage(usageQuery cmdbmodel.NetWorkUsageQuery) (cmdbmodel.NetworkPoolUsageResult, error) {
	rst := cmdbmodel.NetworkPoolUsageResult{}
	c := http.Client{}
	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/networkPool/resourcePool/inventory"
	jsons, _ := json.Marshal(usageQuery)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	req, _ := http.NewRequest("POST", url, jsoninfo)
	req.Header.Add("Content-Type", "application/json")
	res, err := c.Do(req)
	if err != nil {
		fmt.Println("err" + err.Error())
		return rst, err
	}
	b, _ := io.ReadAll(res.Body)
	err = json.Unmarshal(b, &rst)
	if err != nil {
		return rst, err
	}
	if rst.Code != 200 {
		return rst, errors.Errorf("get data from nova cmdb error!")
	}
	return rst, err
}

// 获取所有的区域
func GetAllRegions() ([]cmdbmodel.RegionData, error) {
	var res = new(cmdbmodel.RegionRsp)
	services.DoGet(fmt.Sprintf("http://%s/cmdb/v1/instance/basic/getRegionList", config.GetDefaultUrl(config.CMDBService)), nil, res)
	return res.Data, nil
}

// 获取区域对应的可用区
func GetAllAzsByRegionCode(region string) ([]cmdbmodel.AzData, error) {
	var res = new(cmdbmodel.AzRsp)
	queryMap := make(map[string]string)
	if region != "" {
		queryMap["region"] = region
	}
	services.DoGet(fmt.Sprintf("http://%s/cmdb/v1/instance/basic/getAzList", config.GetDefaultUrl(config.CMDBService)), queryMap, res)
	return res.Data, nil
}
func GetAllAzs(regionList []cmdbmodel.RegionData) (azs []cmdbmodel.AzData, err error) {
	for i := 0; i < len(regionList); i++ {
		azList, err := GetAllAzsByRegionCode(regionList[i].RegionCode)
		if err != nil {
			klog.Errorln(err)
			err = nil
			continue
		}
		azs = append(azs, azList...)
	}
	return
}
func GetRegion(rg string, regionList []cmdbmodel.RegionData) (regionData cmdbmodel.RegionData) {
	for i := 0; i < len(regionList); i++ {
		if regionList[i].RegionCode == rg {
			return regionList[i]
		}
	}
	return
}
func GetAz(az string, azList []cmdbmodel.AzData) (azData cmdbmodel.AzData) {
	for i := 0; i < len(azList); i++ {
		if azList[i].AzCode == az {
			return azList[i]
		}
	}
	return
}

// 获取块存储资源池库存
func GetBlockStock(url string) (cmdbmodel.GetPoolStock, error) {
	c := http.Client{
		Timeout: 10 * time.Minute,
	}
	result := cmdbmodel.GetPoolStock{}
	//url := fmt.Sprintf("http://%s.%s.luban.sdns.galaxy.cloud:9000/ebs/stock", poolName, azIdStr)
	//url := "http://127.0.0.1:8088/ebs/stock"
	klog.Infof("get GetBlockStock url %s", url)
	resp, err := c.Get(url)
	klog.Infof("resp:%#v", resp)
	if err != nil {
		klog.Errorf("Error when get url: %s, %s", url, err)
		return result, err
	}
	if strings.HasPrefix(resp.Status, "5") || strings.HasPrefix(resp.Status, "4") {
		err = errors.New(fmt.Sprintf("Error when Get url=(%s) with %s status", url, resp.Status))
		klog.Error(err)
		return result, err
	}
	defer resp.Body.Close()
	b, _ := io.ReadAll(resp.Body)
	err = json.Unmarshal(b, &result)

	if err != nil {
		klog.Errorf("Error %s", err)
		return result, err
	}

	return result, nil
}

// 获取块存储资源池列表
func GetBlockClusters(url string) (cmdbmodel.GetPoolClusters, error) {
	result := cmdbmodel.GetPoolClusters{}

	//url := fmt.Sprintf("http://%s.%s.luban.sdns.galaxy.cloud:9000/ebs/metric", poolName, azIdStr)
	//url := "http://127.0.0.1:8088/ebs/metric"
	klog.Infof("get GetBlockMetric url %s", url)
	resp, err := http.Get(url)
	klog.Infof("resp:%#v", resp)
	if err != nil {
		klog.Errorf("Error when get url: %s, %s", url, err)
		return result, err
	}
	if strings.HasPrefix(resp.Status, "5") || strings.HasPrefix(resp.Status, "4") {
		err = errors.New(fmt.Sprintf("Error when Get url=(%s) with %s status", url, resp.Status))
		klog.Error(err)
		return result, err
	}
	defer resp.Body.Close()
	b, _ := io.ReadAll(resp.Body)
	err = json.Unmarshal(b, &result)

	if err != nil {
		klog.Errorf("Error %s", err)
		return result, err
	}

	return result, nil
}

// 获取负载均衡列表
func GetLbList(param cmdbmodel.GetLoadListParam) (cmdbmodel.LoadResult, error) {
	rst := cmdbmodel.LoadResult{}
	c := http.Client{}

	if param.PageSize == 0 {
		param.PageSize = int(^uint16(0))
	}

	//获取负载均衡列表
	param = cmdbmodel.GetLoadListParam{
		PageNo:           1,
		PageSize:         param.PageSize,
		Region:           param.Region,
		ResourcePoolName: param.ResourcePoolName,
	}

	jsons, _ := json.Marshal(param)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/lb/cloudProduct/lbList", "application/json", jsoninfo)

	if err != nil {
		fmt.Println("err" + err.Error())
		return rst, err
	}

	b, _ := io.ReadAll(resp.Body)

	err = json.Unmarshal(b, &rst)
	if err != nil {
		return rst, err
	}

	return rst, nil
}

// 获取NAT列表
func GetNatList(param cmdbmodel.GetNatListParam) (cmdbmodel.NatListResult, error) {
	rst := cmdbmodel.NatListResult{}
	c := http.Client{}

	// 获取NAT数量
	if param.PageSize == 0 {
		//natCount := services.GetTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/nat/cloudProduct/natList", "post")
		//klog.Info("natCount ", natCount)
		param.PageSize = int(^uint16(0))
	}
	jsons, _ := json.Marshal(param)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/nat/cloudProduct/natList", "application/json", jsoninfo)
	if err != nil {
		fmt.Println("err" + err.Error())
		return rst, err
	}

	b, _ := io.ReadAll(resp.Body)
	err = json.Unmarshal(b, &rst)
	if err != nil {
		return rst, err
	}
	return rst, nil
}

// 获取裸金属列表
func GetBmList(param bm.ListQuery) (cmdbmodel.BmListResult, error) {
	rst := cmdbmodel.BmListResult{}
	c := http.Client{}

	// 获取BM数量
	if param.PageSize == 0 {
		param.PageSize = int(^uint16(0))
	}
	jsons, _ := json.Marshal(param)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	fmt.Println("jsoninfo", jsoninfo)

	url := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/bm/cloudProduct/list"
	resp, err := c.Post(url, "application/json", jsoninfo)
	if err != nil {
		fmt.Println("err" + err.Error())
		return rst, err
	}
	b, _ := io.ReadAll(resp.Body)
	err = json.Unmarshal(b, &rst)
	if err != nil {
		return rst, err
	}
	return rst, nil
}

// 根据eip获取资源详情
func GetEipDetail(ipAddr string) (res cmdbmodel.EIPInfoResult, err error) {
	if ipAddr == "" {
		err = errors.New("ipAddr is empty of GetEipDetail!")
		return
	}
	url := fmt.Sprintf("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/eip/cloudProduct/instanceDetail?ipAddr=%s", ipAddr)
	klog.Infof("get GetEipDetail url: %s", url)
	resp, err := http.Get(url)
	if err != nil {
		klog.Errorf("Error occurs when get url: %s, %s", url, err)
		return
	}
	if strings.HasPrefix(resp.Status, "5") || strings.HasPrefix(resp.Status, "4") {
		err = errors.New(fmt.Sprintf("Error occurs when get url=(%s) with status code %s", url, resp.Status))
		klog.Error(err)
		return
	}

	defer resp.Body.Close()
	body, err := io.ReadAll(resp.Body)
	if err != nil {
		klog.Errorf("ReadAll error occurs! err: %s", err)
		return
	}

	err = json.Unmarshal(body, &res)
	if err != nil {
		klog.Errorf("Unmarshal error occurs! err: %s", err)
		return
	}

	return
}

//getRegions

func ReadRegionFromCMDB() (res cmdbmodel.RegionResponse, err error) {
	regionBody := cmdbmodel.RegionResponse{}
	httpClient := http.Client{}
	urlStr := "http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/basic/getRegions"

	reqURL, err := url.Parse(urlStr)
	if err != nil {
		klog.Errorf("fail to parse url: %s", err.Error())
		return regionBody, err
	}

	regionReq := http.Request{
		Method: http.MethodGet,
		URL:    reqURL,
	}
	resp, err := httpClient.Do(&regionReq)
	if err != nil {
		klog.Errorf("fail to send request: %s", err.Error())
		return regionBody, err
	}
	defer resp.Body.Close()

	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		klog.Errorf("fail to read body: %s", err.Error())
		return regionBody, err
	}

	err = json.Unmarshal(body, &regionBody)
	if err != nil {
		klog.Errorf("fail to unmarshal body: %s", err.Error())
		return regionBody, err
	}

	return regionBody, nil

}

// 获取交换机硬件数据
func GetSwitchPartsAndView(sn string) (res switchmodels.SwitchView, err error) {
	var (
		httpCli = &http.Client{}
		request *http.Request
		resp    *http.Response
		bytes   []byte
		result  switchmodels.Result
		data    map[string]interface{}
		ok      bool
		view    switchmodels.SwitchView
	)
	apiUrl := fmt.Sprintf("http://%s/cmdb/v1/instance/switch/getSwitchPartsAndView?sn=%s", config.GetDefaultUrl(config.CMDBService), sn)
	request, err = http.NewRequest("GET", apiUrl, nil)
	if err != nil {
		return
	}
	resp, err = httpCli.Do(request)
	if err != nil {
		return
	}
	defer resp.Body.Close()
	bytes, err = io.ReadAll(resp.Body)
	if err != nil {
		return
	}
	err = json.Unmarshal(bytes, &result)
	if err != nil {
		return
	}
	if data, ok = result.Data.(map[string]interface{}); !ok {
		err = errors.New("the type of result.Data if not map[string]interface{}")
		return
	}

	bytes, err = json.Marshal(data["view"])
	if err != nil {
		return
	}
	err = json.Unmarshal(bytes, &view)
	if err != nil {
		return
	}

	return view, nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cmdbmanager/model.go
```golang
package cmdbmanager

import (
	"time"
)

type ListQuery struct {
	PageNo   string `json:"pageNo"`
	PageSize string `json:"pageSize"`
	Id       string `json:"id"`
}

type PhyListQuery struct {
	PageNo   int `json:"pageNo"`
	PageSize int `json:"pageSize"`
	//Count    bool   `json:"count"`
	Region      string   `json:"region"`
	Az          []string `json:"az"`
	Lab         []string `json:"lab"`
	Pool        string   `json:"pool"`
	Name        string   `json:"name"`
	Sn          string   `json:"sn"`
	Ip          string   `json:"ip"`
	Label       string   `json:"label"`
	SearchKey   string   `json:"searchKey"`
	SearchValue string   `json:"searchValue"`
	State       string   `json:"state"`
	OrderCode   string   `json:"orderCode"`
	OrderType   string   `json:"orderType"`
	RunList     []string `json:"runList"`
	Pools       []string `json:"pools"`
}

type PhysicalHostUrlPost struct {
	PageNo   int      `json:"pageNo"`
	PageSize int      `json:"pageSize"`
	Region   string   `json:"region"`
	Az       []string `json:"az"`
	Lab      []string `json:"lab"`
	Name     string   `json:"name"`
}

type PoolUrlPost struct {
	PageNo     int    `json:"pageNo"`
	PageSize   int    `json:"pageSize"`
	RegionCode string `json:"regionCode"`
	AzCode     string `json:"azCode"`
	Name       string `json:"name"`
}

type ComputerPoolListPost struct {
	PageNo   int      `json:"pageNo"`
	PageSize int      `json:"pageSize"`
	Region   string   `json:"region"`
	Az       []string `json:"az"`
	Name     string   `json:"name"`
}

type NetworkPoolListPost struct {
	OrderCode  string   `json:"orderCode"`
	OrderType  string   `json:"orderType"`
	PageNo     int      `json:"pageNo"`
	PageSize   int      `json:"pageSize"`
	PoolName   string   `json:"poolName"` // 按资源池名称模糊搜索
	PoolType   []string `json:"poolType"` // 按资源池类型搜索，支持多个
	RegionCode string   `json:"regionCode"`
	Type       string   `json:"type"` // 默认为LB(负载均衡)；LB：负载均衡，EIP：弹性IP，NAT：NAT，BM：裸金属，SL：专线
}

type PageStruct struct {
	TotalCount int `json:"totalCount"`
	PageNo     int `json:"pageNo"`
	PageSize   int `json:"pageSize"`
}

//physical host
type PhysicalHostResult struct {
	Code    int                    `json:"code"`
	Message string                 `json:"message"`
	Data    PhysicalHostDataResult `json:"data"`
}
type PhysicalHostDataResult struct {
	RequestId string `json:"requestId"`
	PageStruct
	DataList []PhysicalHostData `json:"dataList"`
}

type PhysicalHostData struct {
	Name              string `json:"name"`
	Uid               string `json:"uid"`
	Runstatus         string `json:"runstatus"`
	AssignmentStatus  string `json:"assignmentStatus"`
	ResourcePoolType  string `json:"resourcePoolType"`
	ResourcePool      string `json:"resourcePool"`
	NodeType          string `json:"nodeType"`
	Node              string `json:"Node"`
	Service           string `json:"service"`
	HostRegionCode    string `json:"hostRegionCode"`
	HostRegionName    string `json:"hostRegionName"`
	HostAzCode        string `json:"hostAzCode"`
	HostAzName        string `json:"hostAzName"`
	HostLabCode       string `json:"hostLabCode"`
	HostLabName       string `json:"hostLabName"`
	HostRoomUid       string `json:"hostRoomUid"`
	HostRoomName      string `json:"hostRoomName"`
	HostCabinetUid    string `json:"hostCabinetUid"`
	HostCabinetName   string `json:"hostCabinetName"`
	HostRackUid       string `json:"hostRackUid"`
	HostRackName      string `json:"hostRackName"`
	HostUnitUid       string `json:"hostUnitUid"`
	HostUnitNumber    string `json:"hostUnitNumber"`
	Sn                string `json:"sn"`
	Ip                string `json:"ip"`
	ManagementIP      string `json:"managementIP"`
	OutbandIP         string `json:"outbandIP"`
	Power             string `json:"power"`
	UplinkSwitch      string `json:"uplinkSwitch"`
	MaintenanceDue    string `json:"maintenanceDue"`
	MaintenanceStatus string `json:"maintenanceStatus"`
	Assetsnumber      string `json:"assetsnumber"`
	InputMethod       string `json:"inputMethod"`
	Description       string `json:"description"`
	CreateTime        string `json:"createTime"`
	//
	CpuTotal int `json:"cpuTotal"`
	MemTotal int `json:"memoryTotal"`
}

type InstanceResult struct {
	Code    int    `json:"code"`
	Message string `json:"message"`
	Data    InstanceResultData
}

type InstanceResultData struct {
	TotalCount int        `json:"total"`
	DataList   []Instance `json:"dataList"`
}

const (
	INSTANCE_ERROR     int8 = -1 //实例运行状态异常
	INSTANCE_NORMAL    int8 = 1  //实例运行状态正常
	HOST_TYPE_PHYSICAL int8 = 0  //物理机
	HOST_TYPE_VIRTUAL  int8 = 1  //虚拟机
)

type Instance struct {
	Id           int              `json:"id"`     // ID
	Name         string           `json:"name"`   // 服务实例名称
	AzCode       string           `json:"azCode"` // az id
	AzName       string           `json:"azName"`
	RegionCode   string           `json:"regionCode"` // region id
	RegionName   string           `json:"regionName"`
	SvcId        int              `json:"svcId"` // 所属服务id
	ServiceName  string           `json:"serviceName"`
	ClassifyId   int              `json:"classifyId"` // 所属服务分类id
	HostId       int              `json:"hostId"`     // 所属主机id
	VmId         string           `json:"vmId"`
	HostIp       string           `json:"hostIp"`                                 // 服务器 管理IP 云主机 内网IP
	OutIp        string           `json:"outIp"`                                  // 服务器 带外IP 云主机 外网IP
	HostType     int8             `json:"hostType" description:"[0:服务器][1:云主机])"` // 所属主机类型(0:服务器;1:云主机)
	HostName     string           `json:"hostName"`
	HostTypeName string           `json:"hostTypeName"` // 所属主机类型名称
	Creator      string           `json:"creator"`      // 创建人
	CreateTime   time.Time        `json:"createTime"`
	Updater      string           `json:"updater"` // 修改人
	UpdateTime   time.Time        `json:"updateTime"`
	BuiltIn      int8             `json:"builtIn" description:"是否内置"`         // 是否为内置服务实例1内置2自定义
	ProcessCount int              `json:"processCount"`                       // 进程数
	ProcessList  []ServiceProcess `json:"processList"`                        //进程列表
	State        int8             `json:"state" description:"[1 正常] [-1 异常]"` //服务实例状态
	AlertCount   int              `json:"alertCount"`                         // 告警数量
	//AlertStrategy      string           `json:"alertStrategy"`                      // 告警策略
	AlertStrategyCount int    `json:"alertStrategyCount"` // 告警策略
	MaintenanceTags    string `json:"maintenanceTags"`    // 运维标签
}

type ServiceProcess struct {
	Id            int       `gorm:"column:id" json:"id"`                         // ID
	Name          string    `gorm:"column:name" json:"name"`                     // 名称
	Cmd           string    `gorm:"column:cmd" json:"cmd"`                       // process
	Port          string    `gorm:"column:port" json:"port"`                     // process端口
	Protocol      int16     `gorm:"column:protocol" json:"protocol"`             // process协议
	SvcInstanceId int       `gorm:"column:svc_instance_id" json:"svcInstanceId"` // 所属服务实例id
	Creator       string    `gorm:"column:creator" json:"creator"`               // 创建人
	CreateTime    time.Time `gorm:"column:create_time;" json:"createTime"`
}

//server-hardware

type HardwareResp struct {
	Code    int      `json:"code"`
	Message string   `json:"message"`
	Data    Hardware `json:"data"`
}
type Hardware struct {
	Id            int                `json:"id" gorm:"column:id"`
	Sn            string             `json:"sn"`
	SysInfo       SysInfoSlice       `json:"sysInfos" gorm:"type:json"`
	BaseboardInfo BaseboardInfoSlice `json:"baseboardInfos" gorm:"type:json"`
	CpuInfo       CpuInfoSlice       `json:"cpuInfos" gorm:"type:json"`
	DiskInfo      DiskInfoSlice      `json:"diskInfos" gorm:"type:json"`
	GpuInfo       GpuInfoSlice       `json:"gpuInfos" gorm:"type:json"`
	MemoryInfo    MemoryInfoSlice    `json:"memoryInfos" gorm:"type:json"`
	NicInfo       NicInfoSlice       `json:"nicInfos" gorm:"type:json"`
	RaidInfo      RaidInfoSlice      `json:"raidInfos" gorm:"type:json"`
	WorkInfo      WorkInfoSlice      `json:"workInfos" gorm:"type:json"`
}
type (
	SysInfoSlice       []SysInfo
	BaseboardInfoSlice []BaseboardInfo
	CpuInfoSlice       []CpuInfo
	DiskInfoSlice      []DiskInfo
	GpuInfoSlice       []GpuInfo
	MemoryInfoSlice    []MemoryDeviceInfo
	NicInfoSlice       []NicInfo
	RaidInfoSlice      []RaidInfo
	WorkInfoSlice      []WorkInfo
)

type (
	SysInfo struct {
		Manufacturer      string `json:"manufacturer"`
		ProductName       string `json:"productName"`
		Version           string `json:"version"`
		SerialNumber      string `json:"serialNumber"`
		UUID              string `json:"uuid"`
		SystemProductName string `json:"systemProductName"`
	}
	BaseboardInfo struct {
		Model        string `json:"model"`        // 主板名称
		SerialNumber string `json:"serialNumber"` //序列号
		Manufacturer string `json:"manufacturer"` //制造商
	}
	CpuInfo struct {
		SocketDesignation string `json:"socketDesignation"`
		Model             string `json:"model"` // 型号名
		CoreCount         byte   `json:"coreCount"`
		ThreadCount       byte   `json:"threadCount"`
		CurrentSpeed      string `json:"currentSpeed"` // MHZ
		MaxSpeed          string `json:"maxSpeed"`     // MHZ
		L1dCache          string `json:"l1dCache"`
		L1iCache          string `json:"l1iCache"`
		L2Cache           string `json:"l2Cache"`
		L3Cache           string `json:"l3Cache"`
	}
	DiskInfo struct {
		flag         string
		Model        string `json:"model"`
		SerialNumber string `json:"serialNumber"`
		Size         string `json:"size"`
		DiskName     string `json:"diskName"` //硬盘名称
		Vendor       string `json:"vendor"`   // 厂商
		DiskType     string `json:"diskType"` // 硬盘类型
		DiskRate     string `json:"diskRate"` // 使用率
	}
	GpuInfo struct {
		id    string
		Model string `json:"model"`
		Size  string `json:"size"`
	}
	MemoryDeviceInfo struct {
		PartNumber        string `json:"partNumber"`
		Size              uint16 `json:"size"`
		TotalWidth        uint16 `json:"totalWidth"`
		DataWidth         uint16 `json:"dataWidth"`
		FormFactor        string `json:"formFactor"`
		DeviceSet         byte   `json:"deviceSet"`
		DeviceLocator     string `json:"deviceLocator"`
		BankLocator       string `json:"bankLocator"`
		MemoryType        string `json:"memoryType"`
		TypeDetail        string `json:"typeDetail"`
		Speed             uint16 `json:"speed"`
		Manufacturer      string `json:"manufacturer"`
		SerialNumber      string `json:"serialNumber"`
		AssetTag          string `json:"assetTag"`
		Attributes        byte   `json:"attributes"`
		ConfiguredVoltage uint16 `json:"configuredVoltage"`
	}
	NicInfo struct {
		Model string `json:"model"`
		Count int    `json:"count"`
	}
	RaidInfo struct {
		Model string `json:"model"`
		Count int    `json:"count"`
	}
	WorkInfo struct {
		Name         string `json:"name"`
		HealthStatus string `json:"healthStatus"` // 健康状态
		Product      string `json:"product"`      // 厂商
		Vendor       string `json:"vendor"`       // 型号
		Speed        string `json:"speed"`        // 速率
		Units        string `json:"units"`
		Size         int    `json:"size"`
		Mac          string `json:"mac"`
	}
)

type GetPhysicalHostInfo struct {
	MixDeploy         bool     `json:"MixDeploy"`
	AssignmentStatus  []string `json:"assignmentStatus"`
	Az                []string `json:"az"`
	CabinetID         []int    `json:"cabinetId"`
	ID                string   `json:"id"`
	InputMethod       []string `json:"inputMethod"`
	IP                string   `json:"ip"`
	Lab               []string `json:"lab"`
	MaintenanceStatus []string `json:"maintenanceStatus"`
	Name              string   `json:"name"`
	PageNo            int      `json:"pageNo"`
	PageSize          int      `json:"pageSize"`
	Region            []string `json:"region"`
	ResourcePool      string   `json:"resourcePool"`
	ResourcePoolType  []string `json:"resourcePoolType"`
	Room              []string `json:"room"`
	Runstatus         []string `json:"runstatus"`
	Sn                string   `json:"sn"`
	StorageType       string   `json:"storageType"`
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/cmdbmanager/cmdb_test.go
```golang
package cmdbmanager_test

import (
	"fmt"
	prom "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	"strconv"
	"testing"
	"time"
)

//func TestServiceInstanceList(t *testing.T) {
//	serviceId := 2
//	pageNo := 1
//	pageSize := 10
//	data, err := cmdbmanager.ServiceInstanceList(serviceId, pageNo, pageSize)
//	fmt.Println(data, err)
//}

func TestPrometheus(t *testing.T) {
	h, _ := time.ParseDuration("-1m")
	start := strconv.FormatInt(time.Now().Add(h).Unix(), 10)
	end := strconv.FormatInt(time.Now().Unix(), 10)
	query := `namedprocess_namegroup_states{job="process-nodes",groupname="map[:/usr/bin/nova-compute]",state="Sleeping"}`
	body, err := prom.PrometheusBasicQuery(true, start, end, "60", query)
	fmt.Println(string(body), err)
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/servicemonitor/service.go
```golang
package servicemonitor

import (
	"encoding/json"
	"errors"
	"fmt"
	"io/ioutil"
	"net/http"
	"sort"
	"strconv"
	"strings"
	"sync"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alarm"
	kts "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/ktsmanager"
	"k8s.io/klog/v2"

	alertmanagermodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	servicemodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/servicemonitor"
	services "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	containerTemp "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/container"
	processTemp "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/process"
)

// 获取服务列表
func GetServiceList(l servicemodel.ListQuery) (servicemodel.ServiceResult, error) {
	var serviceResult servicemodel.ServiceResult
	var serviceList []servicemodel.ServiceEntity
	//processList, err := GetServiceFromYaml()

	serviceInstances, err := cmdbmanager.ServiceInstanceList(
		cmdbmanager.QueryServiceInstanceListParams{
			SearchName: l.Name,
			Region:     l.Region,
			Az:         l.Az,
			PageSize:   -1, // -1是获取全量数据
			PageNo:     1,
		})
	if err != nil {
		return serviceResult, err
	}
	if serviceInstances.TotalCount <= 0 {
		return serviceResult, nil
	}
	serviceToServiceInstance := make(map[int][]*cmdbmanager.Instance)
	for i := 0; i < len(serviceInstances.DataList); i++ {
		ins := serviceToServiceInstance[serviceInstances.DataList[i].SvcId]
		serviceToServiceInstance[serviceInstances.DataList[i].SvcId] = append(ins, &serviceInstances.DataList[i])
	}
	var mutexForAlert sync.RWMutex
	var wg sync.WaitGroup
	for k, v := range serviceToServiceInstance {
		wg.Add(1)
		go func(k int, v []*cmdbmanager.Instance) {
			defer wg.Done()
			// 告警数量
			list, err := alertmanager.GetAlertsDataList(alertmanagermodel.AlertQuery{
				SvcId: strconv.Itoa(k),
			})
			if err != nil {
				klog.Errorf("GetAlertsDataList, err:%v", err)
				return
			}
			for i := 0; i < len(list.DataList); i++ {
				for j := 0; j < len(v); j++ {
					if list.DataList[i].SvcInstanceId == fmt.Sprintf("%v", v[j].Id) {
						mutexForAlert.Lock()
						v[j].AlertCount++
						mutexForAlert.Unlock()
					}
				}
			}
		}(k, v)
	}

	var mutexServiceList sync.RWMutex

	for _, serviceInstance := range serviceInstances.DataList {
		wg.Add(1)
		go func(serviceInstance cmdbmanager.Instance) {
			defer wg.Done()
			service := servicemodel.ServiceEntity{}
			service.BuiltIn = serviceInstance.BuiltIn
			service.Name = serviceInstance.Name
			if serviceInstance.HostType == 1 { // 云主机 外网IP
				service.PyhsicalHost = serviceInstance.OutIp
			} else { // 服务器 管理IP
				service.PyhsicalHost = serviceInstance.HostIp
			}
			service.VmId = serviceInstance.VmId
			service.Region = serviceInstance.RegionName
			service.Az = serviceInstance.AzName
			service.AlertNumber = serviceInstance.AlertCount
			if serviceInstance.BuiltIn == 0 {
				groupName, ipPort := getIpPortAndGroupName(serviceInstance.ProcessList, serviceInstance.HostIp)
				fmt.Printf("groupName:%v,ipPort:%v", groupName, ipPort)
				ip := fmt.Sprintf("%v:9256", serviceInstance.HostIp)
				nodeIp := fmt.Sprintf("%v:9100", serviceInstance.HostIp)
				processMetics := processTemp.NewMetrics(ip, groupName, "Sleeping", nodeIp)
				procesN, capRate, memoryRate, diskIOWrite, diskIORead := getProcessMetricsData(processMetics)
				service.ProcessNumber = fmt.Sprintf("%d/%v", len(serviceInstance.ProcessList), procesN)
				service.CpuUtilization = capRate
				service.MemUtilization = memoryRate
				service.DiskIO = diskIOWrite + "/" + diskIORead
				service.Cmdline = getCmdlineJoinStr(serviceInstance.ProcessList)
			} else {
				service.ProcessNumber = "1/1"
				service.DiskIO = "0/0"
				containerMetics := containerTemp.NewMetrics(strings.ToLower(serviceInstance.Name))
				cpuRate, memoryByte := getContainerMetricsData(containerMetics)
				cpuRateFloat, _ := strconv.ParseFloat(cpuRate, 64)
				service.CpuUtilization = strconv.FormatFloat(cpuRateFloat*100, 'f', 5, 32)
				memRate := getMemUtilization(service.PyhsicalHost, serviceInstance.VmId, memoryByte) * 100
				service.MemUtilization = strconv.FormatFloat(memRate, 'f', 5, 32)
			}

			service.RunState = "normal"

			stateMap := cmdbmanager.ProcessListState(serviceInstance.ProcessList, serviceInstance.HostIp)
			for _, p := range serviceInstance.ProcessList {
				//statesCount := processState(p, v.HostIp)
				//if statesCount <= 0 {
				//	state = INSTANCE_ERROR
				//}
				m, ok := stateMap[p.Id]
				if !ok {
					service.RunState = "error"
					break
				}
				//判断如果有cmd 并且结果<=0，则为异常
				if len(p.Cmd) > 0 && m.CmdValue <= 0 {
					service.RunState = "error"
					break
				}
				if len(p.Port) > 0 && m.PortValue <= 0 {
					service.RunState = "error"
					break
				}
			}
			if len(l.RunState) <= 0 || (len(l.RunState) > 0 && services.In(l.RunState, service.RunState)) {
				mutexServiceList.Lock()
				serviceList = append(serviceList, service)
				mutexServiceList.Unlock()
			}
		}(serviceInstance)

	}

	wg.Wait()
	//order
	results := alertmanager.Bucket{}
	for i := 0; i < len(serviceList); i++ {
		results.Slice = append(results.Slice, serviceList[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	if l.OrderCode == "" {
		l.OrderCode = "cpuUtilization"
		l.OrderType = "desc"
	}
	if l.OrderCode != "" {
		switch l.OrderCode {
		case "cpuUtilization":
			if l.OrderType != "" {
				switch l.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						aa := a.(servicemodel.ServiceEntity).CpuUtilization
						aaa, _ := strconv.ParseFloat(aa, 64)

						bb := b.(servicemodel.ServiceEntity).CpuUtilization
						bbb, _ := strconv.ParseFloat(bb, 64)
						return aaa < bbb
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						aa := a.(servicemodel.ServiceEntity).CpuUtilization
						aaa, _ := strconv.ParseFloat(aa, 64)

						bb := b.(servicemodel.ServiceEntity).CpuUtilization
						bbb, _ := strconv.ParseFloat(bb, 64)
						return aaa > bbb
					}
				}
			}
		case "memUtilization":
			if l.OrderType != "" {
				switch l.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						aa := a.(servicemodel.ServiceEntity).MemUtilization
						aaa, _ := strconv.ParseFloat(aa, 64)

						bb := b.(servicemodel.ServiceEntity).MemUtilization
						bbb, _ := strconv.ParseFloat(bb, 64)
						return aaa < bbb
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						aa := a.(servicemodel.ServiceEntity).MemUtilization
						aaa, _ := strconv.ParseFloat(aa, 64)

						bb := b.(servicemodel.ServiceEntity).MemUtilization
						bbb, _ := strconv.ParseFloat(bb, 64)
						return aaa > bbb
					}
				}
			}
		case "diskIO":
			if l.OrderType != "" {
				switch l.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						aa := a.(servicemodel.ServiceEntity).DiskIO
						aaa, _ := strconv.ParseFloat(aa, 64)

						bb := b.(servicemodel.ServiceEntity).DiskIO
						bbb, _ := strconv.ParseFloat(bb, 64)
						return aaa < bbb
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						aa := a.(servicemodel.ServiceEntity).DiskIO
						aaa, _ := strconv.ParseFloat(aa, 64)

						bb := b.(servicemodel.ServiceEntity).DiskIO
						bbb, _ := strconv.ParseFloat(bb, 64)
						return aaa > bbb
					}
				}
			}
		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(results.Slice); i++ {
		serviceList[i] = results.Slice[i].(servicemodel.ServiceEntity)
	}
	serviceResult.DataList = serviceList

	//分页
	low := (l.PageNo - 1) * l.PageSize
	if low > len(serviceResult.DataList) {
		return serviceResult, nil
	}

	hight := low + l.PageSize
	if hight > len(serviceResult.DataList) {
		hight = len(serviceResult.DataList)
	}

	serviceResult.PageNo = l.PageNo
	serviceResult.PageSize = l.PageSize
	serviceResult.TotalCount = len(serviceResult.DataList)
	serviceResult.DataList = serviceResult.DataList[low:hight]

	//为了和进程列表的数据能对上
	//for _, entity := range serviceResult.DataList {
	//	if entity.BuiltIn == 0 {
	//		metricMap := GetMetricByProcessSum(entity.Cmdline, entity.PyhsicalHost)
	//		if metricMap["cpu"] > 0 {
	//			entity.CpuUtilization = fmt.Sprintf("%v", metricMap["cpu"])
	//		}
	//		if metricMap["mem"] > 0 {
	//			entity.MemUtilization = fmt.Sprintf("%v", metricMap["mem"])
	//		}
	//	}
	//}

	return serviceResult, err
}

func GetMetricByProcessSum(cmdJoin, ip string) map[string]float64 {
	rst := make(map[string]float64, 0)
	rst["cpu"] = 0
	rst["mem"] = 0

	cmdArr := strings.Split(cmdJoin, "|")
	for _, cmdline := range cmdArr {
		processResponseList, err := GetProcesssByAPI(cmdline, ip)
		if err != nil {
			continue
		}
		for _, processData := range processResponseList {
			rst["cpu"] += processData.Cpu
			rst["mem"] += processData.Memory

		}
	}
	return rst
}

// 获取服务监控-概览数据
func GetServiceOverView(region string) (servicemodel.OverView, error) {
	var overView servicemodel.OverView
	serviceInstances, err := cmdbmanager.ServiceInstanceList(
		cmdbmanager.QueryServiceInstanceListParams{
			Region: region,
			//Az:         l.Az,
			PageSize: -1, // -1是获取全量数据
			PageNo:   1,
		})
	if err != nil {
		return overView, err
	}
	if serviceInstances.TotalCount <= 0 {
		return overView, nil
	}
	//var serviceList []servicemodel.ServiceEntity
	serviceList := serviceInstances.DataList

	var mutexForAlert sync.RWMutex
	var mutexForProcessState sync.RWMutex
	var wg sync.WaitGroup

	wg.Add(1)
	//监控告警overview
	go func() {
		defer wg.Done()
		queryParam := alertmanagermodel.AlertQuery{
			// Filter: "",
			Region: region,
			Module: "service",
		}
		alertlist, err := alertmanager.GetCommonAlertOverviewNum(queryParam)
		if err != nil {
			klog.Errorf("alertmanager GetAlertsDataListPage fail,err: %v", err)
		}
		mutexForAlert.Lock()
		defer mutexForAlert.Unlock()
		overView.Alerts = append(overView.Alerts, alertlist...)
	}()

	normalCount := 0
	errorCount := 0

	for _, serviceInstance := range serviceList {
		wg.Add(1)
		go func(serviceInstance cmdbmanager.Instance) {
			defer wg.Done()
			runState := "normal"
			stateMap := cmdbmanager.ProcessListState(serviceInstance.ProcessList, serviceInstance.HostIp)
			for _, p := range serviceInstance.ProcessList {
				m, ok := stateMap[p.Id]
				if !ok {
					runState = "error"
				} else if len(p.Cmd) > 0 && m.CmdValue <= 0 {
					runState = "error"
				} else if len(p.Port) > 0 && m.PortValue <= 0 {
					runState = "error"
				}
			}
			mutexForProcessState.Lock()
			defer mutexForProcessState.Unlock()
			if runState == "normal" {
				normalCount++
			} else {
				errorCount++
			}
		}(serviceInstance)

	}

	wg.Wait()
	var stateData servicemodel.StateData
	info := servicemodel.Info{
		Name:   "服务",
		Code:   "",
		Kind:   "",
		Number: normalCount + errorCount,
		Unit:   "个",
	}

	stateData.Info = info
	stateData.Vlues = append(stateData.Vlues,
		servicemodel.StateEntity{Name: "服务异常", Code: "error", Value: errorCount, Unit: "个", Kind: "yellow"},
		servicemodel.StateEntity{Name: "服务正常", Code: "normal", Value: normalCount, Unit: "个", Kind: "blue"},
	)
	overView.State = stateData

	return overView, err
}

// 获取进程列表
func GetProcessList(listQuery servicemodel.ProcessListQuery) (servicemodel.ProcessResult, error) {
	var processResult servicemodel.ProcessResult
	var processList []servicemodel.ProcessEntity

	containerMetics := containerTemp.NewMetrics(strings.ToLower(listQuery.Name))
	cpuRate, memoryByte := getContainerMetricsData(containerMetics)

	klog.Infof("cpu rate is : %s, memory byte is : %s", cpuRate, memoryByte)
	if listQuery.Cmdline == "" {
		var containerInfo servicemodel.ProcessEntity
		containerInfo.Name = strings.ToLower(listQuery.Name)
		containerInfo.CpuUtilization, _ = strconv.ParseFloat(cpuRate, 64)
		containerInfo.MemUtilization = getMemUtilization(listQuery.Ip, listQuery.VmId, memoryByte)
		containerInfo.CpuUtilization = containerInfo.CpuUtilization * 100
		containerInfo.MemUtilization = containerInfo.MemUtilization * 100
		containerInfo.RunStatus = "正常"

		if len(listQuery.RunState) > 0 {
			stateIn := services.In(listQuery.RunState, "normal")
			if stateIn {
				processList = append(processList, containerInfo)
			}
		} else {
			processList = append(processList, containerInfo)
		}
	}

	if listQuery.Cmdline != "" && len(listQuery.Cmdline) > 0 {
		cmdArr := strings.Split(listQuery.Cmdline, "|")
		for _, cmdline := range cmdArr {
			processResponseList, err := GetProcesssByAPI(cmdline, listQuery.Ip)
			for _, processData := range processResponseList {

				runState := ""
				if processData.IsRunning {
					runState = "normal"
				} else {
					runState = "error"
				}
				//多选
				if len(listQuery.RunState) > 0 {
					stateIn := services.In(listQuery.RunState, runState)
					if !stateIn {
						continue
					}
				}

				var process servicemodel.ProcessEntity
				process.Cmdline = processData.Cmdline
				process.Name = processData.Name
				process.CpuUtilization = processData.Cpu
				process.MemUtilization = processData.Memory
				if processData.IsRunning == true {
					process.RunStatus = "正常"
				} else {
					process.RunStatus = "异常"
				}
				process.Pid = processData.Pid
				process.PPid = processData.PPid

				//为了数据和服务列表一致，使用率从promethues里取
				//groupName := fmt.Sprintf("map\\\\[:%v\\\\]", cmdline)
				//ip := fmt.Sprintf("%v:9100", listQuery.Ip)
				//nodeIp := fmt.Sprintf("%v:9256", listQuery.Ip)
				//processMetics := processTemp.NewMetrics(ip, groupName, "Sleeping", nodeIp)
				//_, capRate, memoryRate, _, _ := getProcessMetricsData(processMetics)
				//process.CpuUtilization, _ = strconv.ParseFloat(capRate, 64)
				//process.MemUtilization, _ = strconv.ParseFloat(memoryRate, 64)
				processList = append(processList, process)
			}
			if err != nil {
				fmt.Println(err)
				return processResult, err
			}
		}

	}

	//order
	results := alertmanager.Bucket{}
	//var ss []interface{}
	for i := 0; i < len(processList); i++ {
		results.Slice = append(results.Slice, processList[i])
	}
	//results.Slice = ss
	time_by := func(a, b interface{}) bool {
		return true
	}

	if listQuery.OrderCode == "" {
		listQuery.OrderCode = "cpuUtilization"
		listQuery.OrderType = "desc"
	}
	if listQuery.OrderCode != "" {
		switch listQuery.OrderCode {
		case "cpuUtilization":
			if listQuery.OrderType != "" {
				switch listQuery.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(servicemodel.ProcessEntity).CpuUtilization < b.(servicemodel.ProcessEntity).CpuUtilization
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(servicemodel.ProcessEntity).CpuUtilization > b.(servicemodel.ProcessEntity).CpuUtilization
					}
				}
			}
		case "memUtilization":
			if listQuery.OrderType != "" {
				switch listQuery.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(servicemodel.ProcessEntity).MemUtilization < b.(servicemodel.ProcessEntity).MemUtilization
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(servicemodel.ProcessEntity).MemUtilization > b.(servicemodel.ProcessEntity).MemUtilization
					}
				}
			}
		case "diskIO":
			if listQuery.OrderType != "" {
				switch listQuery.OrderType {
				case "asc":
					time_by = func(a, b interface{}) bool {
						return a.(servicemodel.ProcessEntity).DiskUtilization < b.(servicemodel.ProcessEntity).DiskUtilization
					}
				case "desc":
					time_by = func(a, b interface{}) bool {
						return a.(servicemodel.ProcessEntity).DiskUtilization > b.(servicemodel.ProcessEntity).DiskUtilization
					}
				}
			}
		}
	}

	results.By = time_by

	sort.Sort(results)
	var processListNew []servicemodel.ProcessEntity
	for i := 0; i < len(results.Slice); i++ {
		processListNew = append(processListNew, results.Slice[i].(servicemodel.ProcessEntity)) //results.Slice[i].(servicemodel.ProcessEntity)
	}
	processResult.DataList = processListNew

	//分页
	low := (listQuery.PageNo - 1) * listQuery.PageSize
	if low > len(processResult.DataList) {
		return processResult, nil
	}

	hight := low + listQuery.PageSize
	if hight > len(processResult.DataList) {
		hight = len(processResult.DataList)
	}

	processResult.PageNo = listQuery.PageNo
	processResult.PageSize = listQuery.PageSize
	processResult.TotalCount = len(processResult.DataList)
	processResult.DataList = processResult.DataList[low:hight]
	return processResult, nil
}

func GetProcesssByAPI(cmdLine, ip string) ([]ProcessData, error) {
	fmt.Println("http://" + ip + ":9999/v1/process/get?name=" + cmdLine)
	resp, err := http.Get("http://" + ip + ":9999/v1/process/get?name=" + cmdLine)
	newProcess := ProcessResponse{}
	if err != nil {
		klog.Errorf("GetProcesssByAPI got err:%v", err)
		return newProcess.Data, nil
	}
	defer resp.Body.Close()
	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		fmt.Println(err)
		return newProcess.Data, err
	}
	if len(body) == 0 { // 这里需要判断是否为空 不然会：unexpected end of JSON input
		return newProcess.Data, nil
	}
	err = json.Unmarshal(body, &newProcess)
	if err != nil {
		fmt.Println(err)
		return newProcess.Data, err
	}
	if newProcess.Code != 200 {
		return newProcess.Data, errors.New(newProcess.Message)
	}
	return newProcess.Data, err
}
func getIpPortAndGroupName(serviceProcessList []cmdbmanager.ServiceProcess, ip string) (groupName, ipPort string) {
	processCount := len(serviceProcessList)
	groupNameSlince := make([]string, 0, processCount)
	ipPortSlince := make([]string, 0, processCount)
	for i := 0; i < processCount; i++ {
		if serviceProcessList[i].Cmd != "" {
			groupNameSlince = append(groupNameSlince, fmt.Sprintf("map\\\\[:%v\\\\]", serviceProcessList[i].Cmd))
		} else if serviceProcessList[i].Name != "" {
			groupNameSlince = append(groupNameSlince, fmt.Sprintf("map\\\\[:%v\\\\]", serviceProcessList[i].Name))
		}
		if serviceProcessList[i].Port != "" {
			ipPortSlince = append(ipPortSlince, fmt.Sprintf("%v:%v", ip, serviceProcessList[i].Port))
		}
	}
	if len(groupNameSlince) > 0 {
		groupName = strings.Join(groupNameSlince, "|")
	}
	if len(ipPortSlince) > 0 {
		ipPort = strings.Join(ipPortSlince, "|")
	}
	return
}

func getCmdlineJoinStr(serviceProcessList []cmdbmanager.ServiceProcess) (cmdJoin string) {
	processCount := len(serviceProcessList)
	cmdSlince := make([]string, 0, processCount)
	for i := 0; i < processCount; i++ {
		if serviceProcessList[i].Cmd != "" {
			cmdSlince = append(cmdSlince, serviceProcessList[i].Cmd)
		} else if serviceProcessList[i].Name != "" {
			cmdSlince = append(cmdSlince, serviceProcessList[i].Name)
		}
	}
	if len(cmdSlince) > 0 {
		cmdJoin = strings.Join(cmdSlince, "|")
	}
	return
}

func getProcessMetricsData(processMetrics *processTemp.Metrics) (procesN, capRate, memoryRate, diskIOWrite, diskIORead string) {
	//获取进程数
	processNumSql := processMetrics.ToString(processTemp.Namedprocess_namegroup_num_procs)
	fmt.Println("processNumSql : ", processNumSql)
	procesN = getVectorQueryData(processNumSql)
	fmt.Println("processNumSql  result : ", procesN)
	//获取CPU使用率
	processCpuRateSql := processMetrics.ToString(processTemp.Namedprocess_namegroup_cpu_seconds_total)
	fmt.Println("processCpuRateSql : ", processCpuRateSql)
	capRate = getVectorQueryData(processCpuRateSql)
	fmt.Println("processCpuRateSql result: ", capRate)
	if capRate != "0" {
		fmt.Println("processCpuRateSql not zero : ", processCpuRateSql)
		fmt.Println("processCpuRateSql not zero result : ", capRate)
	}
	processMemRateSql := processMetrics.ToString(processTemp.Namedprocess_namegroup_memory_bytes)
	fmt.Println("processMemRateSql : ", processMemRateSql)
	memoryRate = getVectorQueryData(processMemRateSql)
	fmt.Println("processMemRateSql result: ", memoryRate)
	processDiskIOWRateSql := processMetrics.ToString(processTemp.Namedprocess_namegroup_write_bytes_total)
	fmt.Println("processDiskIOWRateSql : ", processDiskIOWRateSql)
	diskIOWrite = getVectorQueryData(processDiskIOWRateSql)
	fmt.Println("processDiskIOWRateSql result: ", diskIOWrite)
	processDiskIORRateSql := processMetrics.ToString(processTemp.Namedprocess_namegroup_read_bytes_total)
	fmt.Println("processDiskIORRateSql : ", processDiskIORRateSql)
	diskIORead = getVectorQueryData(processDiskIORRateSql)
	fmt.Println("processDiskIORRateSql result: ", diskIORead)
	return
}

func getContainerMetricsData(metric *containerTemp.Metrics) (capRate, memoryByte string) {
	cpuRateSql := metric.ToString(containerTemp.Container_cpu_usage_seconds_total)
	capRate = getVectorQueryData(cpuRateSql)
	memoryByte = getVectorQueryData(metric.ToString(containerTemp.Container_memory_usage_bytes))
	return
}

func getVectorQueryData(metricSql string) (res string) {
	labels, err := client.VectorQuery(metricSql)
	fmt.Println(err)
	var labelsFloat float64
	for _, v := range labels {
		labelsFloat += float64(v.Value)
	}
	res = fmt.Sprintf("%v", labelsFloat)
	return
}

type Service struct {
	Name        string   `yaml:"name"`
	CmdLine     []string `yaml:"cmdline"`
	ServiceName string   `yaml:"service_name"`
	Hosts       []string `yaml:"hosts"`
}

type ProcessData struct {
	Name      string  `json:"name"`
	User      string  `json:"user"`
	Pid       int     `json:"pid"`
	PPid      int     `json:"ppid"`
	Cpu       float64 `json:"cpu"`
	Memory    float64 `json:"memory"`
	IsRunning bool    `json:"isRunning"`
	Cmdline   string  `json:"cmdline"`
}

type ProcessResponse struct {
	Code    int           `json:"code"`
	Message string        `json:"messgae"`
	Data    []ProcessData `json:"data"`
}

type ServiceData struct {
	ProcessNames []Service `yaml:"process_names"`
}

func Strval(value interface{}) string {
	// interface 转 string
	var key string
	if value == nil {
		return key
	}
	switch value.(type) {
	case []interface{}:
		int64Value := Strval(value.([]interface{})[1])
		key = string(Strval(int64Value))
	default:
		newValue, _ := json.Marshal(value)
		key = string(newValue)
	}

	return key
}

func ServiceInstanceList(params cmdbmanager.QueryServiceInstanceListParams) (data cmdbmanager.InstanceResultData, err error) {
	//循环进程，去prometheus获取进程状态，判断如果有进程异常则为异常
	data, err = cmdbmanager.ServiceInstanceList(params)
	if err != nil {
		klog.Errorf("ServiceInstanceList err: %v", err)
		return data, err
	}
	var mutexForProcess sync.RWMutex
	var wgForProcess sync.WaitGroup

	serviceToServiceInstance := make(map[int][]*cmdbmanager.Instance)

	for i, v := range data.DataList {
		wgForProcess.Add(1)
		go func(i int, v cmdbmanager.Instance, data cmdbmanager.InstanceResultData, serviceToServiceInstance map[int][]*cmdbmanager.Instance) {
			defer wgForProcess.Done()

			state := cmdbmanager.INSTANCE_NORMAL // 初始值为正常运行
			stateMap := cmdbmanager.ProcessListState(v.ProcessList, v.HostIp)
			var stateList []int8 // 服务实例对应的所有进程状态列表
			for _, p := range v.ProcessList {
				//statesCount := processState(p, v.HostIp)
				//if statesCount <= 0 {
				//	state = INSTANCE_ERROR
				//}
				m, ok := stateMap[p.Id]
				if !ok {
					state = cmdbmanager.INSTANCE_ERROR
					break
				}
				if len(p.Cmd) == 0 && len(p.Port) == 0 {
					state = cmdbmanager.INSTANCE_ERROR
				} else if len(p.Cmd) > 0 && len(p.Port) > 0 {
					if m.CmdValue > 0 && m.PortValue > 0 {
						state = cmdbmanager.INSTANCE_NORMAL
					} else {
						state = cmdbmanager.INSTANCE_ERROR
					}
				} else if len(p.Cmd) > 0 {
					if m.CmdValue > 0 {
						state = cmdbmanager.INSTANCE_NORMAL
					} else {
						state = cmdbmanager.INSTANCE_ERROR
					}
				} else if len(p.Port) > 0 {
					if m.PortValue > 0 {
						state = cmdbmanager.INSTANCE_NORMAL
					} else {
						state = cmdbmanager.INSTANCE_ERROR
					}
				} else {
					state = cmdbmanager.INSTANCE_ERROR
				}
				stateList = append(stateList, state)
			}
			// 进程列表中有一个异常则服务实例为异常
			// 无进程默认为运行正常待后续修复（todo），无进程针对的是pod服务实例（通过接口创建可以无进程（前端创建服务实例必须有进程））
			if len(stateList) == 0 {
				state = cmdbmanager.INSTANCE_NORMAL
			} else {
				for _, v := range stateList {
					if v == cmdbmanager.INSTANCE_ERROR {
						state = cmdbmanager.INSTANCE_ERROR
						break
					}
				}
			}

			data.DataList[i].ProcessCount = len(v.ProcessList)
			data.DataList[i].State = state
			if data.DataList[i].HostType == cmdbmanager.HOST_TYPE_PHYSICAL {
				data.DataList[i].HostTypeName = "服务器"
			} else if data.DataList[i].HostType == cmdbmanager.HOST_TYPE_VIRTUAL {
				data.DataList[i].HostTypeName = "云主机"
			}
			mutexForProcess.Lock()
			defer mutexForProcess.Unlock()
			ins := serviceToServiceInstance[data.DataList[i].SvcId]
			serviceToServiceInstance[data.DataList[i].SvcId] = append(ins, &data.DataList[i])
		}(i, v, data, serviceToServiceInstance)

	}
	wgForProcess.Wait()

	// var mutexForAlert sync.RWMutex
	var wgForAlert sync.WaitGroup
	var mutexForAlert sync.RWMutex
	intSize := 32 << (^uint(0) >> 63)
	for k, v := range serviceToServiceInstance {

		wgForAlert.Add(1)
		go func(k int, v []*cmdbmanager.Instance) {
			defer wgForAlert.Done()

			// 告警数量
			list, err := alertmanager.GetAlertsDataList(alertmanagermodel.AlertQuery{
				SvcId: strconv.Itoa(k),
			})
			if err != nil {
				klog.Errorf("GetAlertsDataList, err:%v", err)
				return
			}
			for i := 0; i < len(list.DataList); i++ {
				for j := 0; j < len(v); j++ {
					//if list.DataList[i].SvcInstanceId == fmt.Sprintf("%v", v[j].Id) {
					//	v[j].AlertCount++
					//}
					//告警实例SvcInstanceId目前都是空的，只能匹配到svcId一级
					mutexForAlert.Lock()
					v[j].AlertCount++
					mutexForAlert.Unlock()
				}
			}
			// 告警策略（已下架）
			alarmList, err := alarm.GetAlarmList(alarm.ListAlarmPolicy{
				Page:             1,
				PageSize:         1<<(intSize-1) - 1,
				ResourceTypeList: []string{"service"},
				SearchKey:        "objectId",
				SearchValue:      fmt.Sprintf("%d", k),
			})
			if err != nil {
				klog.Errorf("GetAlarmList, err:%v", err)
				return
			}
			for i := 0; i < len(v); i++ {
				v[i].AlertStrategyCount = len(alarmList.Data.Data)
			}
		}(k, v)

	}
	wgForAlert.Wait()
	return data, nil
}

func getMemUtilization(ip, vmId, memoryByte string) float64 {
	if memorySize, err := strconv.ParseFloat(memoryByte, 64); err == nil {
		totalByte := int64(0)
		if vmId != "" && len(vmId) > 0 {
			lastQuery := kts.LastQuery{
				Metric: "vm.memory.size" + "." + vmId,
				Tags: map[string]string{
					"host": vmId,
					"p1":   "total",
				},
			}
			mem, _ := kts.TSDBLastQuery(lastQuery)
			if len(mem) > 0 {
				cc, _ := strconv.ParseInt(mem[0].Value, 10, 64)
				totalByte = cc
			}
		} else {
			host, _ := cmdbmanager.GetHostDetailByIP(ip)
			totalByte = int64(host.MemTotal * 1024)
		}
		if totalByte > 0 {
			return memorySize / float64(totalByte)
		}
	}
	return float64(0)
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/hardwaremonitor/ipmiServer.go
```golang
package hardwaremonitor
```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/alarm/alarmservice.go
```golang
package alarm

import (
	"bytes"
	"encoding/json"
	"errors"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"io/ioutil"
	"net/http"
	"time"
)

type ListAlarmPolicy struct {
	ResourceTypeList    []string `json:"resourceTypeList"`    // 资源类型
	ResourceSubTypeList []string `json:"resourceSubTypeList"` // 资源子类型
	ObjectId            string   `json:"objectId"`            //服务ID
	SearchKey           string   `json:"searchKey"`           // 搜索条件名，目前支持值为policyName、creator。
	SearchValue         string   `json:"searchValue"`         // 搜索条件值
	Page                int      `json:"page"`                // 查询页号
	PageSize            int      `json:"pageSize"`            // 查询页大小
}

type ListAlarmResult struct {
	Code int             `json:"code"`
	Data AlarmPolicyList `json:"data"`
}

type AlarmPolicyList struct {
	Total int                     `json:"total"`
	Data  []CreateAlarmPolicyBody `json:"data"`
}

type CreateAlarmPolicyBody struct {
	Name            string `json:"name" binding:"required"`            // 策略名称
	ResourceType    string `json:"resourceType" binding:"required"`    // 资源类型
	ResourceSubType string `json:"resourceSubType" binding:"required"` // 资源子类型
	Enabled         bool   `json:"enabled"`                            // 是否启用
	//Rule            []AlarmRule  `json:"rule" bindindg:"required,dive"`      // 告警规则列表
	RuleRelation string `json:"ruleRelation"` // 告警规则列表项间的逻辑运算规则
	RuleSQL      string `json:"ruleSQL"`      // 告警规则PromQL表达式
	//Resource        Resource     `json:"resource" binding:"required"`        // 添加的资源
	//Notice          []NoticeUser `json:"notice" binding:"required"`          // 告警接收人
	Creator      string    `json:"creator"`      // 告警创建人
	CreationTime time.Time `json:"creationTime"` // 告警创建时间
	Updater      string    `json:"updater"`      // 告警更新人
	UpdateTime   time.Time `json:"updateTime"`   // 告警更新时间
}

func GetAlarmList(params ListAlarmPolicy) (ListAlarmResult, error) {
	var (
		res ListAlarmResult
		err error
	)
	pam, err := json.Marshal(params)
	if err != nil {
		return res, err
	}
	request, err := http.NewRequest(http.MethodPost, "http://"+config.AlarmService+"/alarm/v1/policy/list", bytes.NewReader(pam))
	if err != nil {
		return res, err
	}

	//defer reqest.Body.Close()
	client := &http.Client{}
	response, err := client.Do(request)
	if err != nil {
		return res, err
	}
	body, err := ioutil.ReadAll(response.Body)
	if response.StatusCode != 200 {
		return res, errors.New(string(body))
	}
	if err != nil {
		return res, err
	}
	err = json.Unmarshal(body, &res)
	return res, err
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/physicalSwitch/interfaceDetailService.go
```golang
package physicalSwitch

import (
	"encoding/json"
	"errors"
	"fmt"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	switchmodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/physicalSwitch"
	"io"
	"k8s.io/klog/v2"
	"net/http"
	"net/url"
	"strconv"
	"strings"
	"time"
)

func (ps *PhysicalSwitchService) GetSwitchIfDetail(q *switchmodels.SwitchIfDetailParams) (switchmodels.InterfaceDetail, error) {
	klog.Info("PhysicalSwitchService GetSwitchIfDetail")
	var (
		runStatus        []string
		name             = "all"
		result           = switchmodels.InterfaceDetail{}
		interFaceSeries  switchmodels.CMDBInterfaceSeriesResult
		interFaceDetails switchmodels.CMDBInterfaceDetailsResult
		//speedDetails     []map[string]interface{}
		//operStatus       []map[string]interface{}
		//adminStatus      []map[string]interface{}
		//indexList []interface{}
		err error
	)
	if len(q.RunStatus) > 0 {
		runStatus = q.RunStatus
	}
	if q.Name != "" {
		name = q.Name
	}

	if q.Sn == "" {
		err = errors.New("sn cannot be empty")
		return result, err
	}
	if q.PageNo <= 0 {
		err = errors.New("invalid pageNo")
		return result, err
	}
	if q.PageSize <= 0 {
		err = errors.New("invalid pageSize")
		return result, err
	}
	klog.Infof("get switch interface detail ,runStatus: %s, name: %s", runStatus, name)
	postParam := map[string]interface{}{
		"pageSize": -1,
		"pageNo":   1,
		"sn":       q.Sn,
	}
	interFaceSeries, err = getCMDBSwitchIfSeries(fmt.Sprintf("http://%s/cmdb/v1/instance/switch/postSwitchInterfaceInfoList", config.GetDefaultUrl(config.CMDBService)), postParam)
	klog.Infof("interFaceSeries count", interFaceSeries.TotalCount)
	if err != nil {
		return result, err
	}
	if len(interFaceSeries.DataList) == 0 {
		klog.Warning("交换机接口详情列表为空")
	}
	interFaceDetails, err = getCMDBSwitchIfDetail(fmt.Sprintf("http://%s/cmdb/v1/instance/switch/postSwitchInterfaceDetails", config.GetDefaultUrl(config.CMDBService)), postParam)
	klog.Infof("interFaceDetails count", interFaceDetails)
	if err != nil {
		return result, err
	}
	if len(interFaceDetails.DataList) == 0 {
		klog.Warning("交换机接口细节列表为空")
	}
	//for _, v := range interFaceSeries.DataList {
	//	indexList = append(indexList, v.Index)
	//}

	//now, dataLens := time.Now(), len(interFaceSeries.DataList)
	//concat := concatParam(indexList)
	//speedParam := fmt.Sprintf("ifHighSpeed{ifIndex=~'%s'}", concat)
	//speedDetails, err = getIfSpeedDetail(speedParam, now, dataLens)
	//if err != nil {
	//	return result, err
	//}
	//operParam := fmt.Sprintf("ifOperStatus{ifIndex=~'%s'}", concat)
	//operStatus, err = getIfStatusDetail(operParam, now, dataLens)
	//if err != nil {
	//	return result, err
	//}
	//adminParam := fmt.Sprintf("ifAdminStatus{ifIndex=~'%s'}", concatParam(indexList))
	//adminStatus, err = getIfStatusDetail(adminParam, now, dataLens)
	//if err != nil {
	//	return result, err
	//}

	for _, detail := range interFaceDetails.DataList {
		state := statusMapping[detail.IfStatus]
		if len(runStatus) > 0 && !checkStatus(state, runStatus) {
			continue
		}
		if name != "all" && name != detail.IfName {
			continue
		}
		if detail.OrtherEndDevice != "" {
			fmt.Println(detail.OrtherEndDevice)
		}
		interFace := switchmodels.Interface{
			Index:         detail.IfIndex,
			Name:          detail.IfName,
			State:         state,
			InterFaceBand: detail.IfSpeed,
			InterFaceType: detail.IfType,
			Ip:            detail.IfIp,
			Mac:           detail.IfMac,
			NextDevice: switchmodels.NextDeviceDetail{ //对端设备
				Name:       detail.OrtherEndDevice,
				Interface:  detail.OrtherEndIf,
				DeviceType: detail.OrtherEndType,
				DeviceId:   detail.OrtherEndDeviceId,
			},
			//NextDevice:    nextDevice,
			NextInterface: detail.OrtherEndIf, //对端接口名称
			//OrtherEndType: detail.OrtherEndType,
			OrtherEndDesc: detail.OrtherEndDescr,
			NextDescr:     detail.OrtherEndDescr, //对端设备描述
		}
		result.DataList = append(result.DataList, interFace)
	}

	////从prometheus取值逻辑
	//for i := 0; i < dataLens; i++ {
	//	var (
	//		ifName string
	//		band   int
	//		aSta   int
	//		oSta   int
	//		status int
	//	)
	//	serier := interFaceSeries.DataList[i]
	//	detail := switchmodels.CMDBInterfaceDetails{}
	//	if i < len(interFaceDetails.DataList) {
	//		detail = interFaceDetails.DataList[i]
	//	}
	//	speed := speedDetails[i]
	//	oper := operStatus[i]
	//	admin := adminStatus[i]
	//	if oper != nil {
	//		ifName, _ = oper["ifName"].(string)
	//		oSta, _ = oper["status"].(int)
	//	}
	//	if admin != nil {
	//		ifName, _ = admin["ifName"].(string)
	//		oSta, _ = admin["status"].(int)
	//	}
	//	if speed != nil {
	//		ifName, _ = speed["ifName"].(string)
	//		band, _ = speed["ifBand"].(int)
	//	}
	//	if oSta == 2 || aSta == 2 {
	//		status = 2
	//	} else if oSta == 1 && aSta == 1 {
	//		status = 1
	//	} else if oSta == 0 && aSta > 0 {
	//		status = aSta
	//	} else if aSta == 0 && oSta > 0 {
	//		status = oSta
	//	} else {
	//		status = 4
	//	}
	//	state := statusMapping[status]
	//	if len(runStatus) > 0 && !checkStatus(state, runStatus) {
	//		continue
	//	}
	//	if name != "all" && name != ifName {
	//		continue
	//	}
	//	interFace := switchmodels.Interface{
	//		Index:         serier.Index,
	//		Name:          ifName,
	//		State:         state,
	//		InterFaceBand: band,
	//		InterFaceType: serier.InterfaceType,
	//		Ip:            detail.IfIp,
	//		Mac:           detail.IfMac,
	//		//NextDevice: detail.OrtherEndDevice,
	//		NextInterface: detail.OrtherEndIf,
	//		OrtherEndType: detail.OrtherEndType,
	//	}
	//	result.DataList = append(result.DataList, interFace)
	//}

	total := len(result.DataList)
	offset := (q.PageNo - 1) * q.PageSize
	limit := offset + q.PageSize
	if limit >= total {
		limit = total
	}
	result.DataList = result.DataList[offset:limit]
	result.TotalCount = total
	result.PageNo = q.PageNo
	result.PageSize = q.PageSize
	return result, nil
}

func getCMDBSwitchIfSeries(url string, postParam map[string]interface{}) (series switchmodels.CMDBInterfaceSeriesResult, err error) {
	klog.Info(url)
	c := http.Client{}
	var (
		seriesDate = &switchmodels.CMDBInterfaceSeriesData{}
		bytes      []byte
		resp       *http.Response
	)
	if bytes, err = json.Marshal(postParam); err != nil {
		return series, err
	}
	resp, err = c.Post(url, "application/json", strings.NewReader(string(bytes)))
	if err != nil {
		klog.Info(err)
		return series, err
	}
	bytes, err = io.ReadAll(resp.Body)
	if err != nil {
		klog.Info(err)
		return series, err
	}
	err = json.Unmarshal(bytes, &seriesDate)
	if err != nil {
		klog.Info(err)
		return series, err
	}
	series = seriesDate.Data
	return series, err
}

func getCMDBSwitchIfDetail(url string, postParam map[string]interface{}) (details switchmodels.CMDBInterfaceDetailsResult, err error) {
	klog.Info(url)
	c := http.Client{}
	var (
		detailData = &switchmodels.CMDBInterfaceDetailsData{}
		bytes      []byte
		resp       *http.Response
	)
	if bytes, err = json.Marshal(postParam); err != nil {
		return
	}
	resp, err = c.Post(url, "application/json", strings.NewReader(string(bytes)))
	if err != nil {
		klog.Info(err)
		return
	}
	bytes, err = io.ReadAll(resp.Body)
	if err != nil {
		klog.Info(err)
		return
	}
	err = json.Unmarshal(bytes, &detailData)
	if err != nil {
		klog.Info(err)
		return
	}
	details = detailData.Data
	return
}

func getIfSpeedDetail(param string, gtime time.Time, lens int) ([]map[string]interface{}, error) {
	var (
		data   map[string]interface{}
		resp   *http.Response
		bytes  []byte
		err    error
		result = make([]map[string]interface{}, lens)
	)
	api := "http://" + config.GetDefaultUrl(config.PrometheusService) + "/api/v1/query?query="
	pTime := "&time=" + fmt.Sprintf("%v", gtime.Unix())
	client := http.Client{}
	resp, err = client.Get(api + url.QueryEscape(param) + pTime)
	if err != nil {
		return result, err
	}

	bytes, err = io.ReadAll(resp.Body)
	if err != nil {
		return result, err
	}
	err = json.Unmarshal(bytes, &data)
	if err != nil {
		return result, err
	}

	if vCw, ok := data["data"]; ok {
		rateData := vCw.(map[string]interface{})
		if resultData, ok := rateData["result"]; ok {
			re := resultData.([]interface{})
			if len(re) > 0 {
				for _, resultD := range re {
					valu := resultD.(map[string]interface{})
					if metricData, ok := valu["metric"]; ok {
						var (
							intIndex int
							metric   map[string]interface{}
						)
						metric = metricData.(map[string]interface{})
						if ifIndex, ok := metric["ifIndex"]; ok {
							strIndex := ifIndex.(string)
							intIndex, _ = strconv.Atoi(strIndex)
							if intIndex > 0 && intIndex <= lens {
								metric["ifIndex"] = intIndex
								if valueData, ok := valu["value"]; ok {
									value := valueData.([]interface{})
									if speed, ok := value[1].(string); ok {
										ispeed, _ := strconv.Atoi(speed)
										metric["ifBand"] = ispeed
									}
								}
								result[intIndex-1] = metric
							}
						}
					}
				}
			}
		}
	}
	return result, err
}

func getIfStatusDetail(param string, gtime time.Time, lens int) ([]map[string]interface{}, error) {
	var (
		data   map[string]interface{}
		resp   *http.Response
		bytes  []byte
		err    error
		result = make([]map[string]interface{}, lens)
	)
	api := "http://" + config.GetDefaultUrl(config.PrometheusService) + "/api/v1/query?query="
	pTime := "&time=" + fmt.Sprintf("%v", gtime.Unix())
	client := http.Client{}
	resp, err = client.Get(api + url.QueryEscape(param) + pTime)
	if err != nil {
		return result, err
	}

	bytes, err = io.ReadAll(resp.Body)
	if err != nil {
		return result, err
	}
	err = json.Unmarshal(bytes, &data)
	if err != nil {
		return result, err
	}

	if vCw, ok := data["data"]; ok {
		rateData := vCw.(map[string]interface{})
		if resultData, ok := rateData["result"]; ok {
			re := resultData.([]interface{})
			if len(re) > 0 {
				for _, resultD := range re {
					valu := resultD.(map[string]interface{})
					if metricData, ok := valu["metric"]; ok {
						var (
							intIndex int
							metric   map[string]interface{}
						)
						metric = metricData.(map[string]interface{})
						if ifIndex, ok := metric["ifIndex"]; ok {
							strIndex := ifIndex.(string)
							intIndex, _ = strconv.Atoi(strIndex)
							if intIndex > 0 && intIndex <= lens {
								metric["ifIndex"] = intIndex
								if valueData, ok := valu["value"]; ok {
									value := valueData.([]interface{})
									if status, ok := value[1].(string); ok {
										v, _ := strconv.Atoi(status)
										metric["status"] = v
									}
								}
								result[intIndex-1] = metric
							}
						}
					}
				}
			}
		}
	}
	return result, err
}

func concatParam(indexies []interface{}) string {
	if len(indexies) == 0 {
		return ""
	}
	format := ""
	for i, _ := range indexies {
		if i == len(indexies)-1 {
			format += "%v"
			break
		}
		format += "%v|"
	}
	return fmt.Sprintf(format, indexies...)
}

//var statusMapping = map[int]string{
//	1: "up",
//	2: "down",
//	3: "testing",
//	4: "unknown",
//	5: "dormant",
//	6: "notPresent",
//	7: "lowerLayerDown",
//}
var statusMapping = map[int]string{
	1: "normal",
	2: "shutdown",
	3: "err",
	//1: "up",
	//2: "down",
	//3: "disconnect",
	//4: "error",
}

func checkStatus(state string, sliceStr []string) bool {
	for _, str := range sliceStr {
		if state == str {
			return true
		}
	}
	return false
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/physicalSwitch/metricsService.go
```golang
package physicalSwitch

import (
	"encoding/json"
	"fmt"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cmdbmanager"
	"io"
	"math"
	"net/http"
	"regexp"
	"sort"
	"strconv"
	"strings"
	"time"

	"github.com/pkg/errors"
	v1 "github.com/prometheus/client_golang/api/prometheus/v1"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	alertmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	switchmodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/physicalSwitch"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	prom "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/prometheusmanager"
	temp "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/physicalSwitch"
	"k8s.io/klog/v2"
)

type (
	IPhysicalSwitch interface {
		//GetIfNameArray(string) ([]string, error)
		GetIfNameArray(string) ([]map[string]string, error)
		GetSwitchMetric(string) (switchmodels.SwitchMetric, error)
		GetSwitchHardwareMetric(string) (switchmodels.HardWare, error)
		GetSwitchMetricLine(*switchmodels.SwitchMetricLineQuery) (map[string][]switchmodels.EchartType, error)
		GetSwitchOverview(*switchmodels.SwitchOverviewQuery) (switchmodels.OverView, error)
		GetSwitchOverviewTop(*switchmodels.SwitchOverviewTopQuery) ([]switchmodels.OverviewTopType, error)
		GetSwitchList(*switchmodels.SwitchListQuery) (switchmodels.SwitchListResult, error)
		GetSwitchIfDetail(*switchmodels.SwitchIfDetailParams) (switchmodels.InterfaceDetail, error)
		GetSwitchIfInfo(*switchmodels.InterfaceQuery) (switchmodels.IfDetailMetric, error)
		GetSwitchInterfaceList(*switchmodels.SwitchInterfaceListQuery) (switchmodels.InterfaceDetail, error)
		GetSwitchInterfaceLine(*switchmodels.SwitchInterfaceLineQuery) (switchmodels.IfMutilLineData, error)
		GetSwitchInterfaceSigleLine(*switchmodels.SwitchInterfaceLineQuery) ([]switchmodels.MetricLineType, error)
	}

	PhysicalSwitchService struct {
		PromClient *client.PromClient
	}
)

func NewPhysicalSwitchService() *PhysicalSwitchService {
	return &PhysicalSwitchService{
		PromClient: client.NewPromClient(),
	}
}

func (ps *PhysicalSwitchService) GetSwitchOverview(q *switchmodels.SwitchOverviewQuery) (rst switchmodels.OverView, err error) {
	klog.Infof("get switch metrics overview ,region: %s, azs: %q", q.Region, q.Az)
	if q.Region == "" {
		q.Region = "all"
	}
	az := []string{}
	if q.Az == "all" || q.Az == "" {
		az = []string{}
	} else {
		az = append(az, q.Az)
	}
	// 获取交换机列表
	cmdb, er := GetCMDBSwitchList(&switchmodels.SwitchListQuery{
		PageNo:   1,
		PageSize: 1000,
		Region:   q.Region,
		Az:       az,
	})
	if er != nil {
		return rst, er
	}

	// 获取服告警数据
	alerts := make([]alertmodel.OverviewAlert, 0, 4)
	alertPpram := alertmodel.AlertQuery{
		Module: "switch",
		Az:     az,
	}
	alertList, err := alert.GetCommonAlertOverviewNum(alertPpram)
	if err != nil {
		return rst, err
	}
	//交换机状态
	switchState := make([]switchmodels.StateType, 0, 2)
	UP := switchmodels.StateType{Prefix: "监控中", Unit: "个"}
	DOWN := switchmodels.StateType{Prefix: "监控异常", Unit: "个"}
	//交换机接口状态
	ifState := make([]switchmodels.StateType, 0, 4)
	ERR := switchmodels.StateType{Prefix: "故障", Unit: "个"}
	NORMAL := switchmodels.StateType{Prefix: "运行中", Unit: "个"}
	SHUTDOWN := switchmodels.StateType{Prefix: "关闭", Unit: "个"}
	//NOCONN := switchmodels.StateType{Prefix: "未连接", Unit: "个"}
	//硬件监控CPU/内存 故障数
	cpuErrNum := switchmodels.StateType{Prefix: "CPU故障数量", Unit: "个", Value: 0}
	memErrNum := switchmodels.StateType{Prefix: "内存故障数量", Unit: "个", Value: 0}

	for i := 0; i < cmdb.Data.TotalCount; i++ {
		swtichT := temp.NewSwitchMetics(cmdb.Data.DataList[i].OutBandIP, 0)
		sql := ""
		_, err := swtichT.Get(temp.Switch_up)
		if err == nil {
			sql = swtichT.ToString(temp.Switch_up)
		}
		up, _ := prom.PrometheusQuery2(false, "", "", "", sql)
		upUp := prom.PrometheusResultToValueForPercent(up)
		if len(upUp) > 0 && upUp[0].(float64) == 1 {
			UP.Number++
		} else {
			DOWN.Number++
		}
		//interface
		ifMap := GetSwitchIfStateDetail(cmdb.Data.DataList[i].Sn)
		for k, v := range ifMap {
			switch k {
			case "normal":
				NORMAL.Number += v
			case "shutdown":
				SHUTDOWN.Number += v
			case "err":
				ERR.Number += v
			}
		}
		//获取有cpu故障 和内存故障的交换机
		view, err := cmdbmanager.GetSwitchPartsAndView(cmdb.Data.DataList[i].Sn)
		if err != nil {
			klog.Errorf("GetSwitchPartsAndViewFail", err)
		}
		klog.Infof("GetSwitchCpuMemNum %+v", view)
		cpuNormal := float64(view.CpuHealth.AbNormal) // cpu故障数
		memNormal := float64(view.MemHealth.AbNormal) // 内存故障数
		if cpuNormal > 0 {
			cpuErrNum.Value += 1
		}
		if memNormal > 0 {
			memErrNum.Value += 1
		}
	}
	rst.Alerts = append(alerts, alertList...)                           //告警
	rst.SwitchState = append(switchState, DOWN, UP)                     //状态
	rst.IfState = append(ifState, ERR, NORMAL, SHUTDOWN)                //接口状态
	rst.HardwareState = append(rst.HardwareState, cpuErrNum, memErrNum) //硬件监控
	return rst, nil
}

func (ps *PhysicalSwitchService) GetSwitchOverviewTop(q *switchmodels.SwitchOverviewTopQuery) ([]switchmodels.OverviewTopType, error) {
	klog.Infof("get switch metrics overview ,region: %s, azs: %q", q.Region, q.Az)
	rst := make([]switchmodels.OverviewTopType, 0)
	topk, _ := strconv.Atoi(q.Topk)

	cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/switch/list", "post")

	if q.Region == "" {
		q.Region = "all"
	}
	az := []string{}
	if q.Az == "all" || q.Az == "" {
		az = []string{}
	} else {
		az = append(az, q.Az)
	}

	hostUrlPost := switchmodels.SwitchListQuery{
		PageNo:   1,
		PageSize: cmdbCount,
		Region:   q.Region,
		Az:       az,
	}
	cmdb, err := GetCMDBSwitchList(&hostUrlPost)
	if err != nil {
		return rst, err
	}

	values := make([]services.ValueType, 0)
	for i := 0; i < len(cmdb.Data.DataList); i++ {
		item := cmdb.Data.DataList[i]
		query := &switchmodels.SwitchIfDetailParams{PageNo: 1, PageSize: 1000, Sn: item.Sn}
		ifDetail, err := ps.GetSwitchIfDetail(query)
		klog.Infof("switch ifDetail", item.Sn, ifDetail)
		if err != nil {
			klog.Info(err)
		}
		for j := 0; j < len(ifDetail.DataList); j++ {
			jj := ifDetail.DataList[j]
			klog.Infof("switch interface %+v", jj)
			name := fmt.Sprintf("%s(%s)", jj.Name, item.Name)
			r := services.ValueType{Name: name, SubName: item.OutBandIP, Id: strconv.Itoa(jj.Index), Value: 0}
			values = append(values, r)
		}

	}

	klog.Infof("GetSwitchOverviewTop switch values %+v", values)

	//query
	step := services.TimeToStep(q.End/1e3 - q.Start/1e3)
	start := strconv.FormatFloat(q.Start/1e3, 'f', 3, 64)
	end := strconv.FormatFloat(q.End/1e3, 'f', 3, 64)
	// stepInt64 := services.FormatInt64(q.End/1e3 - q.Start/1e3)
	// startInt64 := services.FormatInt64(q.Start)
	// endInt64 := services.FormatInt64(q.End)
	for j := 0; j < len(q.Name); j++ {
		item := switchmodels.OverviewTopType{}
		switch q.Name[j] {
		case "errRateIn":
			item.Name = "接口错包率-接收"
			rr := switchmodels.EchartType{}
			for i := 0; i < len(values); i++ {
				o := values[i]
				index, _ := strconv.Atoi(o.Id)
				c, _ := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(o.SubName, index).ToString("switch_interface_in_errRate"))
				klog.Infof("接口错包率-接收 %+v", c)
				if len(c) > 0 {
					rr.Info.Name = "接口错包率-接收"
					rr.Info.UnitType = "percent"
					rr.Info.Unit = "%"
					s := services.GetPromValuesSlice(c[0])
					o.Value = services.FormPercent(services.GetPromValueAvg(s))
					if math.IsNaN(o.Value.(float64)) {
						o.Value = 0
					}
					values[i] = o
				}
				// values,err := client.MatrixQuery(temp.NewSwitchMetics(o.SubName, index).ToString("switch_interface_in_errRate"), v1.Range{
				// 	Start: time.Unix(startInt64, 0),
				// 	End:   time.Unix(endInt64, 0),
				// 	Step:  time.Duration(stepInt64),
				// })
				// if err != nil {
				// 	return
				// }

				// for _, i := range values {
				// 	r := eipmodels.Echart{}
				// 	info := eipmodels.MetricLineInfo{
				// 		Name:     string(i.Metric["cidr"]),
				// 		Unit:     "%",
				// 		UnitType: "percent",
				// 	}
				// 	for _, j := range i.Values {

				// 		rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: services.FormPercent(j.Value.String())}
				// 		r.Values = append(r.Values, rr)

				// 	}
				// 	r.Info = info
				// 	rst.Echarts = append(rst.Echarts, r)
				// }
			}
			klog.Infof("接口错包率-接收-InterfaceValueOrder %+v", values)
			out := InterfaceValueOrder(values, "desc")
			if len(out) >= topk {
				out = out[:topk]
			}
			rr.Values = append(rr.Values[:0], out...)
			item.Echarts = append(item.Echarts, rr)
			rst = append(rst, item)
		case "errRateOut":
			item.Name = "接口错包率-发送"
			rr := switchmodels.EchartType{}
			for i := 0; i < len(values); i++ {
				o := values[i]
				index, _ := strconv.Atoi(o.Id)
				c, _ := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(o.SubName, index).ToString("switch_interface_out_errRate"))
				klog.Infof("接口错包率-发送 %+v", c)
				if len(c) > 0 {
					rr.Info.Name = "接口错包率-发送"
					rr.Info.UnitType = "percent"
					rr.Info.Unit = "%"
					s := services.GetPromValuesSlice(c[0])
					o.Value = services.FormPercent(services.GetPromValueAvg(s))
					if math.IsNaN(o.Value.(float64)) {
						o.Value = 0
					}
					values[i] = o
				}
			}
			klog.Infof("接口错包率-发送-InterfaceValueOrder %+v", values)
			out := InterfaceValueOrder(values, "desc")
			if len(out) >= topk {
				out = out[:topk]
			}
			rr.Values = append(rr.Values[:0], out...)
			item.Echarts = append(item.Echarts, rr)
			rst = append(rst, item)
		case "dropRateIn":
			item.Name = "接口丢包率-接收"
			rr := switchmodels.EchartType{}
			for i := 0; i < len(values); i++ {
				o := values[i]
				index, _ := strconv.Atoi(o.Id)
				c, _ := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(o.SubName, index).ToString("switch_interface_in_dropRate"))
				if len(c) > 0 {
					rr.Info.Name = "接口丢包率-接收"
					rr.Info.UnitType = "percent"
					rr.Info.Unit = "%"
					s := services.GetPromValuesSlice(c[0])
					o.Value = services.FormPercent(services.GetPromValueAvg(s))
					if math.IsNaN(o.Value.(float64)) {
						o.Value = 0
					}
					values[i] = o
				}
			}

			out := InterfaceValueOrder(values, "desc")
			if len(out) >= topk {
				out = out[:topk]
			}
			rr.Values = append(rr.Values[:0], out...)
			item.Echarts = append(item.Echarts, rr)
			rst = append(rst, item)
		case "dropRateOut":
			item.Name = "接口丢包率-发送"
			rr := switchmodels.EchartType{}
			for i := 0; i < len(values); i++ {
				o := values[i]
				index, _ := strconv.Atoi(o.Id)
				c, _ := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(o.SubName, index).ToString("switch_interface_out_dropRate"))
				klog.Infof("接口丢包率-发送 %+v", c)
				if len(c) > 0 {
					rr.Info.Name = "接口丢包率-发送"
					rr.Info.UnitType = "percent"
					rr.Info.Unit = "%"
					s := services.GetPromValuesSlice(c[0])
					o.Value = services.FormPercent(services.GetPromValueAvg(s))
					if math.IsNaN(o.Value.(float64)) {
						o.Value = 0
					}
					values[i] = o
				}
			}
			klog.Infof("接口丢包率-发送—InterfaceValueOrder %+v", values)
			out := InterfaceValueOrder(values, "desc")
			if len(out) >= topk {
				out = out[:topk]
			}
			rr.Values = append(rr.Values[:0], out...)
			item.Echarts = append(item.Echarts, rr)
			rst = append(rst, item)
		case "bandRateIn":
			item.Name = "接口带宽利用率-接收"
			rr := switchmodels.EchartType{}
			for i := 0; i < len(values); i++ {
				o := values[i]
				index, _ := strconv.Atoi(o.Id)
				c, _ := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(o.SubName, index).ToString("switch_interface_in_flowRate"))
				if len(c) > 0 {
					rr.Info.Name = "接口带宽利用率-接收"
					rr.Info.UnitType = "percent"
					rr.Info.Unit = "%"
					s := services.GetPromValuesSlice(c[0])
					o.Value = services.FormPercent(services.GetPromValueAvg(s))
					if math.IsNaN(o.Value.(float64)) {
						o.Value = 0
					}
					values[i] = o
				}
			}
			out := InterfaceValueOrder(values, "desc")
			if len(out) >= topk {
				out = out[:topk]
			}
			klog.Infof("接口带宽利用率-接收", out)
			for outk, outv := range out {
				floatValue, err11 := outv.Value.(float64)
				if err11 == true {
					out[outk].Value = services.FormPercent(floatValue / 100)
				}
			}
			rr.Values = append(rr.Values[:0], out...)
			item.Echarts = append(item.Echarts, rr)
			rst = append(rst, item)
		case "bandRateOut":
			item.Name = "接口带宽利用率-发送"
			rr := switchmodels.EchartType{}
			for i := 0; i < len(values); i++ {
				o := values[i]
				index, _ := strconv.Atoi(o.Id)
				c, _ := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(o.SubName, index).ToString("switch_interface_out_flowRate"))
				if len(c) > 0 {
					rr.Info.Name = "接口带宽利用率-发送"
					rr.Info.UnitType = "percent"
					rr.Info.Unit = "%"
					s := services.GetPromValuesSlice(c[0])
					o.Value = services.FormPercent(services.GetPromValueAvg(s))
					if math.IsNaN(o.Value.(float64)) {
						o.Value = 0
					}
					values[i] = o
				}

			}

			out := InterfaceValueOrder(values, "desc")
			if len(out) >= topk {
				out = out[:topk]
			}
			klog.Infof("接口带宽利用率-发送", out)
			for outk, outv := range out {
				floatValue, err11 := outv.Value.(float64)
				if err11 == true {
					out[outk].Value = services.FormPercent(floatValue / 100)
				}
			}
			rr.Values = append(rr.Values[:0], out...)
			item.Echarts = append(item.Echarts, rr)
			rst = append(rst, item)
		case "cpuRate":
			item.Name = "cpu使用率"
			rr := switchmodels.EchartType{}
			for i := 0; i < len(cmdb.Data.DataList); i++ {
				o := cmdb.Data.DataList[i]
				ip := SwitchSnToIP("all", o.Sn)
				c, _ := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, 0).ToString("switch_cpu_usage_rate"))
				if len(c) > 0 {
					klog.Info("c")
					klog.Info(c[0])
					rr.Info.Name = "cpu使用率"
					rr.Info.UnitType = "percent"
					rr.Info.Unit = "%"
					s := services.GetPromValuesSlice(c[0])
					avg := services.FormPercent(services.GetPromValueAvg(s) / 100)
					if math.IsNaN(avg) {
						avg = 0
					}
					value := services.ValueType{Name: o.Name, Value: avg}
					rr.Values = append(rr.Values, value)
				}
			}

			out := InterfaceValueOrder(rr.Values, "desc")
			if len(out) >= topk {
				out = out[:topk]
			}
			rr.Values = append(rr.Values[0:0], out...)
			item.Echarts = append(item.Echarts, rr)
			rst = append(rst, item)
		case "memRate":
			item.Name = "内存使用率"
			rr := switchmodels.EchartType{}
			for i := 0; i < len(cmdb.Data.DataList); i++ {
				o := cmdb.Data.DataList[i]
				ip := SwitchSnToIP("all", o.Sn)
				c, _ := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, 0).ToString("switch_memory_usage_rate"))
				if len(c) > 0 {
					rr.Info.Name = "内存使用率"
					rr.Info.UnitType = "percent"
					rr.Info.Unit = "%"
					s := services.GetPromValuesSlice(c[0])
					avg := services.FormPercent(services.GetPromValueAvg(s) / 100)
					if math.IsNaN(avg) {
						avg = 0
					}
					value := services.ValueType{Name: o.Name, Value: avg}
					rr.Values = append(rr.Values, value)
				}
			}
			out := InterfaceValueOrder(rr.Values, "desc")
			if len(out) >= topk {
				out = out[:topk]
			}
			rr.Values = append(rr.Values[0:0], out...)
			item.Echarts = append(item.Echarts, rr)
			rst = append(rst, item)
		}
	}
	klog.Info("rst")
	return rst, nil
}

func (ps *PhysicalSwitchService) GetSwitchList(q *switchmodels.SwitchListQuery) (switchmodels.SwitchListResult, error) {
	klog.Infof("get switch metrics overview ,region: %s", q.Region)
	if q.SearchKey != "" && q.SearchValue != "" {
		switch q.SearchKey {
		case "name":
			q.Name = q.SearchValue
		case "sn":
			q.Sn = q.SearchValue
		}
	}

	if q.Region == "" {
		q.Region = "all"
	}
	if len(q.Az) == 0 {
		q.Az = []string{}
	}
	//todo test get demo swtich metrics
	//1, new galaxy cloud physical resource struct ,like physical server ,physical switch .......,set property field
	//2, get prometheus sql template string sql,include unit ......
	//3, get metrics by prometheus api

	// 获取交换机总数
	hostUrlPostCount := switchmodels.SwitchListQuery{
		PageNo:   1,
		PageSize: int(^uint16(0)),
		Region:   q.Region,
		Az:       q.Az,
		Name:     q.Name,
		Sn:       q.Sn,
	}
	switchCount, err := GetCMDBSwitchList(&hostUrlPostCount)

	rst := switchmodels.SwitchListResult{DataList: make([]switchmodels.Switch, 0, switchCount.Data.TotalCount)}
	// 获取交换机列表
	hostUrlPost := switchmodels.SwitchListQuery{
		PageNo:   1,
		PageSize: switchCount.Data.TotalCount,
		Region:   q.Region,
		Az:       q.Az,
		Name:     q.Name,
		Sn:       q.Sn,
	}
	cmdb, err := GetCMDBSwitchList(&hostUrlPost)
	if err != nil {
		return rst, err
	}
	cs := cmdb.Data

	if cmdb.Code != 200 {
		return rst, errors.Errorf("get data from nova cmdb error!")
	}
	count := len(cs.DataList)
	for i := 0; i < count; i++ {
		j := cs.DataList[i]
		m := switchmodels.Switch{
			ID:     j.Id,
			Ip:     j.OutBandIP,
			Name:   j.Name,
			Sn:     j.Sn,
			Region: j.RegionName,
			Az:     j.AzName,
			Label:  j.Label,
		}

		// snmp 状态
		m.SnmpState = "up"
		if j.SnmpStatus != 0 {
			m.SnmpState = "down"
		}
		if len(q.SnmpState) != 0 {
			snmpStateIn := services.In(q.SnmpState, m.SnmpState)
			if !snmpStateIn {
				continue
			}
		}
		//获取交换机运行状态
		up, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(j.OutBandIP, 0).ToString("switch_up"))
		upUp := prom.PrometheusResultToValueForPercent(up)
		if len(upUp) > 0 && upUp[0].(float64) == 1 {
			m.RunState = "up"
		} else {
			m.RunState = "down"
		}
		//运行状态多选
		klog.Infof("q.RunState: %v,m.RunState: %v", q.RunState, m.RunState)
		if len(q.RunState) != 0 {
			stateIn := services.In(q.RunState, m.RunState)
			if !stateIn {
				continue
			}
		}
		// 获取交换机cpu
		c, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(j.OutBandIP, 0).ToString("switch_cpu_usage_rate"))
		cc := prom.PrometheusResultToValueForPercent(c)
		if len(cc) > 0 {
			m.CpuLoad = cc[0].(float64) / 100
		}
		// 获取交换机内存
		mem, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(j.OutBandIP, 0).ToString("switch_memory_usage_rate"))
		mm := prom.PrometheusResultToValueForPercent(mem)
		if len(mm) > 0 {
			m.MemLoad = mm[0].(float64) / 100
		}

		ifMap := GetSwitchIfStateDetail(m.Sn)
		for k, v := range ifMap {
			switch k {
			case "err":
				m.ErrPortNum = v
			}
		}
		//获取cpu/mem 故障数
		//获取有cpu故障 和内存故障的交换机
		view, err := cmdbmanager.GetSwitchPartsAndView(cmdb.Data.DataList[i].Sn)
		if err != nil {
			klog.Errorf("GetSwitchPartsAndViewFail", err)
		}
		klog.Infof("GetSwitchCpuMemNum %+v", view)
		m.CpuErrNum = view.CpuHealth.AbNormal // cpu故障数
		m.MemErrNum = view.MemHealth.AbNormal // 内存故障数
		// 获取列表
		if q.CpuErrNum == "zero" && m.CpuErrNum > 0 { //筛选cpu故障数等于0的
			continue
		}
		if q.MemErrNum == "zero" && m.MemErrNum > 0 { //筛选mem故障数等于0的
			continue
		}
		if q.CpuErrNum == "nozero" && m.CpuErrNum == 0 { //筛选cpu故障数大于0的
			continue
		}
		if q.MemErrNum == "nozero" && m.MemErrNum == 0 { //筛选cpu故障数大于0的
			continue
		}
		rst.DataList = append(rst.DataList, m)
	}

	//order
	if q.OrderCode != "" && q.OrderType != "" {
		results := alert.Bucket{}
		for i := 0; i < len(rst.DataList); i++ {
			results.Slice = append(results.Slice, rst.DataList[i])
		}
		time_by := func(a, b interface{}) bool {
			return true
		}
		switch q.OrderCode {
		case "cpuLoad":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Switch).CpuLoad < b.(switchmodels.Switch).CpuLoad
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Switch).CpuLoad > b.(switchmodels.Switch).CpuLoad
				}
			}

		case "memLoad":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Switch).MemLoad < b.(switchmodels.Switch).MemLoad
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Switch).MemLoad > b.(switchmodels.Switch).MemLoad
				}
			}
		case "errPortNum":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Switch).ErrPortNum < b.(switchmodels.Switch).ErrPortNum
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Switch).ErrPortNum > b.(switchmodels.Switch).ErrPortNum
				}
			}
		}

		results.By = time_by

		sort.Sort(results)
		for i := 0; i < len(results.Slice); i++ {
			rst.DataList[i] = results.Slice[i].(switchmodels.Switch)
		}
	}

	low := (q.PageNo - 1) * q.PageSize
	if low > len(rst.DataList) {
		return rst, nil
	}

	hight := low + q.PageSize
	if hight > len(rst.DataList) {
		hight = len(rst.DataList)
	}

	rst.PageNo = q.PageNo
	rst.PageSize = q.PageSize
	rst.TotalCount = len(rst.DataList)
	rst.DataList = rst.DataList[low:hight]

	//告警数量
	for k, v := range rst.DataList {
		if v.Ip != "" {
			rst.DataList[k].AlertNumber = alert.GetResourcePoolAlertNum(v.Region, v.Az, "physicalResource", "physicalSwitch", v.Name)
		}
	}
	return rst, nil
}

func (ps *PhysicalSwitchService) GetSwitchMetric(sn string) (switchmodels.SwitchMetric, error) {
	klog.Infof("get switch metrics ,sn: %s", sn)

	rst := switchmodels.SwitchMetric{Sn: sn}
	ip := SwitchSnToIP("all", sn)

	cpuState := switchmodels.Info{
		Metric: "cpuLoad",
		Name:   "cpu使用率"}
	memState := switchmodels.Info{
		Metric: "memLoad",
		Name:   "内存使用率"}
	//if sn != "219801A12T9195Q000CC" {
	//	c, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(ip, 0).ToString("switch_cpu_usage_rate"))
	//	cc := prom.PrometheusResultToValueForPercent(c)
	//	if len(cc) > 0 {
	//		cpuState.Value = cc[0].(float64) / 100
	//	}
	//
	//	m, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(ip, 0).ToString("switch_memory_usage_rate"))
	//	mm := prom.PrometheusResultToValueForPercent(m)
	//	if len(mm) > 0 {
	//		memState.Value = mm[0].(float64) / 100
	//	}
	//}
	c, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(ip, 0).ToString("switch_cpu_usage_rate"))
	cc := prom.PrometheusResultToValueForPercent(c)
	if len(cc) > 0 {
		cpuState.Value = cc[0].(float64) / 100
	}

	m, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(ip, 0).ToString("switch_memory_usage_rate"))
	mm := prom.PrometheusResultToValueForPercent(m)
	if len(mm) > 0 {
		memState.Value = mm[0].(float64) / 100
	}
	rst.SwitchStates = append(rst.SwitchStates, cpuState, memState)

	//interface
	Normal := switchmodels.IfNum{Name: "正常接口"}
	Err := switchmodels.IfNum{Name: "故障接口"}
	Shutdown := switchmodels.IfNum{Name: "关闭接口"}
	//NoConn := switchmodels.IfNum{Name: "未连接口"}

	//block
	blocks := make([]switchmodels.Block, 0)

	//layOut := GetCmdbLayOut(sn)
	//klog.Info("layout")
	//klog.Info(layOut)
	//var Index int
	//if len(layOut) > 0 {
	//	Index = layOut[0].StartIndex
	//}
	//for i := 0; i < len(layOut); i++ {
	//	o := layOut[i]
	//	block := switchmodels.Block{BlockType: strings.ToLower(o.InterfaceType)}
	//
	//	for j := 1; j <= o.X; j++ {
	//
	//		blockLine := make([]switchmodels.IfState, 0)
	//		for n := 1; n <= o.Y; n++ {
	//			s := GenerateSwitchInterfaceState(GenerateAdminNum(ip, Index), GenerateOperNum(ip, Index))
	//			//interface_count
	//			switch s {
	//			case "normal":
	//				Normal.Number++
	//			case "noConn":
	//				NoConn.Number++
	//			case "shutdown":
	//				Shutdown.Number++
	//			case "err":
	//				Err.Number++
	//			}
	//			//interface_/count
	//			sigle := switchmodels.IfState{
	//				Index: Index,
	//				State: s,
	//			}
	//			blockLine = append(blockLine, sigle)
	//			Index++
	//		}
	//		block.IfList = append(block.IfList, blockLine)
	//	}
	//	blocks = append(blocks, block)
	//}
	//Blocks := make([]switchmodels.Block, 0)

	postParam := map[string]interface{}{
		"pageSize": -1,
		"pageNo":   1,
		"sn":       sn,
	}
	interFaceDetails, err := getCMDBSwitchIfDetail(fmt.Sprintf("http://%s/cmdb/v1/instance/switch/postSwitchInterfaceDetails", config.GetDefaultUrl(config.CMDBService)), postParam)
	//interFaceDetails, err := getCMDBSwitchIfDetail(fmt.Sprintf("http://%s/cmdb/v1/instance/switch/postSwitchInterfaceDetails", "localhost:8099"), postParam)
	if err != nil {
		klog.Errorf("获取交换机接口细节列表异常：%v", err)
	}
	if len(interFaceDetails.DataList) == 0 {
		klog.Warning("交换机接口细节列表为空")
	}
	//var blockLineMap = make(map[string][]switchmodels.IfState)
	//var blockLineMap = make(map[string]map[string][]switchmodels.IfState)
	var blockLineMap = make(map[string]map[string]switchmodels.IsStatus)
	//var Index int
	for _, detail := range interFaceDetails.DataList {
		//Index++
		state := statusMapping[detail.IfStatus]
		switch state {
		case "normal":
			Normal.Number++
		//case "noConn":
		//	NoConn.Number++
		case "shutdown":
			Shutdown.Number++
		case "err":
			Err.Number++
		}
		sigle := switchmodels.IfState{
			//Index: Index,
			Index: detail.IfIndex,
			State: state,
		}
		if detail.IfType != "" {
			if blockLineMap[detail.IfType] == nil {
				//blockLineMap[detail.IfType] = make(map[string][]switchmodels.IfState)
				blockLineMap[detail.IfType] = make(map[string]switchmodels.IsStatus)
			}
			if x := regexp.MustCompile("\\d").FindString(detail.IfName); x != "" {
				if blockLineMap[detail.IfType][x] == nil {
					blockLineMap[detail.IfType][x] = make(switchmodels.IsStatus, 0)
				}
				blockLineMap[detail.IfType][x] = append(blockLineMap[detail.IfType][x], sigle)
			}
		}
	}
	var keys []string
	for k := range blockLineMap {
		keys = append(keys, k)
	}
	sort.Strings(keys)
	for _, ifType := range keys {
		status := blockLineMap[ifType]
		if len(status) < 1 {
			continue
		}
		block := switchmodels.Block{BlockType: strings.ToLower(ifType)}
		var rows []string
		for row := range status {
			rows = append(rows, row)
		}
		sort.Strings(rows)
		for _, row := range rows {
			sort.Sort(status[row])
			block.IfList = append(block.IfList, status[row])
		}
		blocks = append(blocks, block)
	}
	//Blocks := make([]switchmodels.Block, 0)
	rst.IfStates = append(rst.IfStates, Normal, Err, Shutdown)
	rst.Blocks = blocks
	return rst, nil
}

func (s *PhysicalSwitchService) GetSwitchHardwareMetric(sn string) (rst switchmodels.HardWare, err error) {
	klog.Info("GetServerMetric")
	var (
		httpCli = &http.Client{}
		request *http.Request
		resp    *http.Response
		bytes   []byte
		result  switchmodels.Result
		data    map[string]interface{}
		ok      bool
		//values  []interface{}
		view switchmodels.SwitchView
	)
	apiUrl := fmt.Sprintf("http://%s/cmdb/v1/instance/switch/getSwitchPartsAndView?sn=%s", config.GetDefaultUrl(config.CMDBService), sn)
	request, err = http.NewRequest("GET", apiUrl, nil)
	if err != nil {
		return
	}
	resp, err = httpCli.Do(request)
	if err != nil {
		return
	}
	defer resp.Body.Close()
	bytes, err = io.ReadAll(resp.Body)
	if err != nil {
		return
	}
	err = json.Unmarshal(bytes, &result)
	if err != nil {
		return
	}
	if data, ok = result.Data.(map[string]interface{}); !ok {
		err = errors.New("the type of result.Data if not map[string]interface{}")
		return
	}

	bytes, err = json.Marshal(data["view"])
	if err != nil {
		return
	}
	err = json.Unmarshal(bytes, &view)
	if err != nil {
		return
	}
	//进/出风口
	inTemp := switchmodels.StateType{Name: "进风口温度", Value: float64(view.AirInLet)}
	rst.InTemp = append(rst.InTemp, inTemp)
	outTemp := switchmodels.StateType{Name: "出风口温度", Value: float64(view.AirOutLet)}
	rst.OutTemp = append(rst.OutTemp, outTemp)
	//cpu
	rst.CpuState = []switchmodels.StateType{
		{
			Name:  "正常",
			Value: float64(view.CpuHealth.Normal),
		}, {
			Name:  "告警",
			Value: float64(view.CpuHealth.Alarm),
		}, {
			Name:  "故障",
			Value: float64(view.CpuHealth.AbNormal),
		}, {
			Name:  "未知",
			Value: float64(view.CpuHealth.UnKnown),
		},
	}
	// cpuQuery := temp.NewSwitchMetics(sn, 0).ToString("ipmi_sensor_state_cpu_count_values")
	// cRst, err := client.VectorQuery(cpuQuery)
	// if err != nil {
	// 	klog.Info(err)
	// }
	// for _, v := range cRst {
	// 	if math.IsNaN(float64(v.Value)) {
	// 		v.Value = 0
	// 	}
	// 	vv := switchmodels.StateType{Name: string(v.Metric["state"]), Value: float64(v.Value)}
	// 	rst.CpuState = append(rst.CpuState, vv)
	// }
	//内存
	rst.MemState = []switchmodels.StateType{
		{
			Name:  "正常",
			Value: float64(view.MemHealth.Normal),
		}, {
			Name:  "告警",
			Value: float64(view.MemHealth.Alarm),
		}, {
			Name:  "故障",
			Value: float64(view.MemHealth.AbNormal),
		}, {
			Name:  "未知",
			Value: float64(view.MemHealth.UnKnown),
		},
	}
	// memQuery := temp.NewSwitchMetics(sn, 0).ToString("ipmi_sensor_state_memory_count_values")
	// mRst, err := client.VectorQuery(memQuery)
	// if err != nil {
	// 	klog.Info(err)
	// }
	// for _, v := range mRst {
	// 	if math.IsNaN(float64(v.Value)) {
	// 		v.Value = 0
	// 	}
	// 	vv := switchmodels.StateType{Name: string(v.Metric["state"]), Value: float64(v.Value)}
	// 	rst.MemState = append(rst.MemState, vv)
	// }

	//接口
	rst.IfState = []switchmodels.StateType{
		{
			Name:  "正常",
			Value: float64(view.IfHealth.Normal),
		},
		//{
		//	Name:  "未连接",
		//	Value: float64(view.IfHealth.Alarm),
		//},
		{
			Name:  "关闭",
			Value: float64(view.IfHealth.AbNormal),
		}, {
			Name:  "故障",
			Value: float64(view.IfHealth.UnKnown),
		},
	}
	//power
	rst.PowerState = []switchmodels.StateType{
		{
			Name:  "正常",
			Value: float64(view.PowerHealth.Normal),
		}, {
			Name:  "告警",
			Value: float64(view.PowerHealth.Alarm),
		}, {
			Name:  "故障",
			Value: float64(view.PowerHealth.AbNormal),
		}, {
			Name:  "未知",
			Value: float64(view.PowerHealth.UnKnown),
		},
	}
	// powerQuery := temp.NewSwitchMetics(sn, 0).ToString("ipmi_sensor_state_power_count_values")
	// pRst, err := client.VectorQuery(powerQuery)
	// if err != nil {
	// 	klog.Info(err)
	// }
	// for _, v := range pRst {
	// 	if math.IsNaN(float64(v.Value)) {
	// 		v.Value = 0
	// 	}
	// 	vv := switchmodels.StateType{Name: string(v.Metric["state"]), Value: float64(v.Value)}
	// 	rst.PowerState = append(rst.PowerState, vv)
	// }
	//fan
	rst.FanState = []switchmodels.StateType{
		{
			Name:  "正常",
			Value: float64(view.FanHealth.Normal),
		}, {
			Name:  "告警",
			Value: float64(view.FanHealth.Alarm),
		}, {
			Name:  "故障",
			Value: float64(view.FanHealth.AbNormal),
		}, {
			Name:  "未知",
			Value: float64(view.FanHealth.UnKnown),
		},
	}
	// fanQuery := temp.NewSwitchMetics(sn, 0).ToString("ipmi_sensor_state_fan_count_values")
	// fRst, err := client.VectorQuery(fanQuery)
	// if err != nil {
	// 	klog.Info(err)
	// }
	// for _, v := range fRst {
	// 	if math.IsNaN(float64(v.Value)) {
	// 		v.Value = 0
	// 	}
	// 	vv := switchmodels.StateType{Name: string(v.Metric["state"]), Value: float64(v.Value)}
	// 	rst.FanState = append(rst.FanState, vv)
	// }
	//list
	var boards []switchmodels.SwitchBoard
	bytes, err = json.Marshal(data["boards"])
	if err != nil {
		return
	}
	err = json.Unmarshal(bytes, &boards)
	if err != nil {
		return
	}
	for _, board := range boards {
		mainBoard := switchmodels.MainBoard{
			Name:          board.Name,
			State:         board.Health,
			Sn:            board.SerialNum,
			ProductNum:    board.PartNum,
			ProductTime:   board.ManufacturedDate,
			ProducFactory: board.MfgName,
		}
		rst.MainBoardList = append(rst.MainBoardList, mainBoard)
	}

	//cpulist
	rst.Cpu.CpuList = make([]switchmodels.Cpu, 0)
	rst.Cpu.Sum = 0

	//var cpus []switchmodels.SwitchCpu
	//bytes, err = json.Marshal(data["cpus"])
	//if err != nil {
	//	return
	//}
	//err = json.Unmarshal(bytes, &cpus)
	//if err != nil {
	//	return
	//}
	//for _, cpu := range cpus {
	//	xCpu := switchmodels.Cpu{
	//		Name:        cpu.Name,
	//		State:       cpu.Health,
	//		UsedRate:    cpu.Utilization,
	//		Temperature: cpu.Temperature,
	//		Model:       cpu.CpuType,
	//	}
	//	rst.Cpu.CpuList = append(rst.Cpu.CpuList, xCpu)
	//	rst.Cpu.Sum++
	//}

	// cpuList := temp.NewSwitchMetics(sn, 0).ToString("ipmi_sensor_state_cpu")
	// clRst, err := client.VectorQuery(cpuList)
	// if err != nil {
	// 	klog.Info(err)
	// }
	// for _, v := range clRst {
	// 	if math.IsNaN(float64(v.Value)) {
	// 		v.Value = 0
	// 	}
	// 	vv := switchmodels.Cpu{Name: string(v.Metric["name"]), State: float64(v.Value)}
	// 	rst.Cpu.CpuList = append(rst.Cpu.CpuList, vv)
	// }
	//内存
	rst.Mem.MemList = make([]switchmodels.MemoryDetail, 0)
	var mems []switchmodels.SwitchMemory
	bytes, err = json.Marshal(data["mems"])
	if err != nil {
		return
	}
	err = json.Unmarshal(bytes, &mems)
	if err != nil {
		return
	}
	var capsum int
	for _, mem := range mems {
		xMem := switchmodels.MemoryDetail{
			Name:          mem.Name,
			State:         mem.Health,
			UsedRate:      mem.Utilization,
			In:            getSwitchPartExist(mem.Exist),
			Position:      mem.Location,
			Channl:        mem.Tunnel,
			Slot:          mem.SlotNum,
			Model:         mem.MemType,
			Ranks:         mem.Ranks,
			Width:         mem.BitWide,
			Capacity:      mem.Capacity,
			Tech:          mem.Technology,
			Sn:            mem.SerialNum,
			ProductNum:    mem.PartNum,
			ProducFactory: mem.MfgName,
		}
		rst.Mem.MemList = append(rst.Mem.MemList, xMem)
		rst.Mem.Sum++
		capsum += mem.Capacity / 1024
	}
	rst.Mem.Capacity = strconv.Itoa(capsum)
	// memList := temp.NewSwitchMetics(sn, 0).ToString("ipmi_sensor_state_memory")
	// mlRst, err := client.VectorQuery(memList)
	// if err != nil {
	// 	klog.Info(err)
	// }
	// for _, v := range mlRst {
	// 	if math.IsNaN(float64(v.Value)) {
	// 		v.Value = 0
	// 	}
	// 	vv := switchmodels.MemoryDetail{Name: string(v.Metric["name"]), State: float64(v.Value)}
	// 	rst.Mem.MemList = append(rst.Mem.MemList, vv)
	// }

	//power
	rst.PowerList = make([]switchmodels.Power, 0)
	var powers []switchmodels.SwitchPower
	bytes, err = json.Marshal(data["powers"])
	if err != nil {
		return
	}
	err = json.Unmarshal(bytes, &powers)
	if err != nil {
		return
	}
	for _, power := range powers {
		xPower := switchmodels.Power{
			Id:              power.Name,
			State:           power.Health,
			In:              getSwitchPartExist(power.Exist),
			Temperature:     power.Temperature,
			RatedPower:      fmt.Sprintf("%dW", power.RatedPower),
			InputPower:      fmt.Sprintf("%dW", power.InPower),
			PowerInputModel: power.InModel,
			Model:           power.PowerType,
			FireWare:        power.FirmwareVersion,
			Sn:              power.SerialNum,
			ProductNum:      power.PartNum,
			ProducFactory:   power.MfgName,
		}
		rst.PowerList = append(rst.PowerList, xPower)
	}
	// powerList := temp.NewSwitchMetics(sn, 0).ToString("ipmi_sensor_state_power")
	// plRst, err := client.VectorQuery(powerList)
	// if err != nil {
	// 	klog.Info(err)
	// }
	// for _, v := range plRst {
	// 	if math.IsNaN(float64(v.Value)) {
	// 		v.Value = 0
	// 	}
	// 	vv := switchmodels.Power{Id: string(v.Metric["id"]), State: float64(v.Value)}
	// 	rst.PowerList = append(rst.PowerList, vv)
	// }
	//fan
	rst.FanList = make([]switchmodels.Fan, 0)
	var fans []switchmodels.SwitchFan
	bytes, err = json.Marshal(data["fans"])
	if err != nil {
		return
	}
	err = json.Unmarshal(bytes, &fans)
	if err != nil {
		return
	}
	for _, fan := range fans {
		xFan := switchmodels.Fan{
			Name:       fan.Name,
			State:      fan.Health,
			In:         getSwitchPartExist(fan.Exist),
			Speed:      fan.Speed,
			SpeedRate:  fan.SpeedRatio,
			Redundancy: getSwitchPartRedundancy(fan.Redundant),
		}
		rst.FanList = append(rst.FanList, xFan)
	}
	// fanList := temp.NewSwitchMetics(sn, 0).ToString("ipmi_fan_speed_rpm")
	// flRst, err := client.VectorQuery(fanList)
	// if err != nil {
	// 	klog.Info(err)
	// }
	// for _, v := range flRst {
	// 	if math.IsNaN(float64(v.Value)) {
	// 		v.Value = 0
	// 	}
	// 	vv := switchmodels.Fan{Name: string(v.Metric["name"]), Speed: float64(v.Value)}
	// 	rst.FanList = append(rst.FanList, vv)
	// }

	return

}

func MakeTimeStamp(start, end, step string) []string {
	sl := make([]string, 0)
	start1, _ := strconv.ParseFloat(start, 64)
	end1, _ := strconv.ParseFloat(end, 64)
	step1, _ := strconv.ParseFloat(step, 64)
	for {
		ss := strconv.FormatFloat(start1, 'f', -1, 64)
		sl = append(sl, ss)
		start1 += step1
		if start1 > end1 {
			break
		}
	}

	return sl
}

func (ps *PhysicalSwitchService) GetSwitchMetricLine(q *switchmodels.SwitchMetricLineQuery) (map[string][]switchmodels.EchartType, error) {
	klog.Infof("get switch metrics ,sn: %s", q.Sn)

	step := services.TimeToStep(q.End - q.Start)
	start := strconv.FormatFloat(q.Start, 'f', 3, 64)
	end := strconv.FormatFloat(q.End, 'f', 3, 64)
	ip := SwitchSnToIP("all", q.Sn)
	rst := make(map[string][]switchmodels.EchartType)
	for i := 0; i < len(q.List); i++ {
		switch q.List[i] {
		case "cpu":
			r := []switchmodels.EchartType{}
			l, _ := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, 0).ToString("switch_cpu_usage_rate"))

			for j := 0; j < len(l); j++ {
				rr := switchmodels.EchartType{}
				rr.Info.Name = "cpu使用率"
				rr.Info.UnitType = "percent"
				rr.Info.Unit = "%"

				vv := prom.PrometheusResultToValue2(l[j])
				rr.Values = services.RangeValueForForePercent(vv)
				r = append(r, rr)
			}

			// 补充开头
			for k, v := range r {
				if len(v.Values) == 0 {
					continue
				}
				repairFirstList := []services.ValueType{}
				first := v.Values[0].TimeSteamp.(float64)    // 实际第一条时间
				firstStep, _ := strconv.ParseFloat(step, 64) // 步长

				for n := q.Start; n < first; n += firstStep {
					repairFirst := services.ValueType{
						Name:       n,
						TimeSteamp: n,
						IsForecast: false,
						Day:        time.Unix(int64(n), 0).Format("2006-01-02 15:04:05"),
					}
					repairFirstList = append(repairFirstList, repairFirst)
				}
				r[k].Values = append(repairFirstList, v.Values...)
			}

			rst[q.List[i]] = r
		case "mem":
			r := []switchmodels.EchartType{}
			l, _ := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, 0).ToString("switch_memory_usage_rate"))

			for j := 0; j < len(l); j++ {
				rr := switchmodels.EchartType{}

				rr.Info.Name = "内存使用率"
				rr.Info.UnitType = "percent"
				rr.Info.Unit = "%"

				vv := prom.PrometheusResultToValue2(l[j])
				rr.Values = services.RangeValueForForePercent(vv)

				r = append(r, rr)
			}

			// 补充开头
			for k, v := range r {
				if len(v.Values) == 0 {
					continue
				}
				repairFirstList := []services.ValueType{}
				first := v.Values[0].TimeSteamp.(float64)    // 实际第一条时间
				firstStep, _ := strconv.ParseFloat(step, 64) // 步长

				for n := q.Start; n < first; n += firstStep {
					repairFirst := services.ValueType{
						Name:       n,
						TimeSteamp: n,
						IsForecast: false,
						Day:        time.Unix(int64(n), 0).Format("2006-01-02 15:04:05"),
					}
					repairFirstList = append(repairFirstList, repairFirst)
				}
				r[k].Values = append(repairFirstList, v.Values...)
			}

			rst[q.List[i]] = r
		case "power":
			r := []switchmodels.EchartType{}
			l, _ := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, 0).ToString("switch_power_usage_rate"))

			for j := 0; j < len(l); j++ {
				rr := switchmodels.EchartType{}

				rr.Info.Name = "电源功率"
				rr.Info.UnitType = "number"
				rr.Info.Unit = "w"
				rr.Info.Type = "markline"

				vv := prom.PrometheusResultToValue2(l[j])
				rr.Values = services.RangeValueForForePercent(vv)

				r = append(r, rr)
			}

			// 补充开头
			for k, v := range r {
				if len(v.Values) == 0 {
					continue
				}
				repairFirstList := []services.ValueType{}
				first := v.Values[0].TimeSteamp.(float64)    // 实际第一条时间
				firstStep, _ := strconv.ParseFloat(step, 64) // 步长

				for n := q.Start; n < first; n += firstStep {
					repairFirst := services.ValueType{
						Name:       n,
						TimeSteamp: n,
						IsForecast: false,
						Day:        time.Unix(int64(n), 0).Format("2006-01-02 15:04:05"),
					}
					repairFirstList = append(repairFirstList, repairFirst)
				}
				r[k].Values = append(repairFirstList, v.Values...)
			}
			rst[q.List[i]] = r
		}

	}

	return rst, nil
}

//func (ps *PhysicalSwitchService) GetIfNameArray(sn string) ([]string, error) {
func (ps *PhysicalSwitchService) GetIfNameArray(sn string) ([]map[string]string, error) {
	klog.Infof("get switch metrics ,sn: %s", sn)

	//rst := make([]string, 0)
	var rst []map[string]string
	q := &switchmodels.SwitchIfDetailParams{PageNo: 1, PageSize: 100, Sn: sn}
	interfaceDetail, err := ps.GetSwitchIfDetail(q)
	if err != nil {

		klog.Info(err)
		return rst, err
	} else {

		//for i := 0; i < interfaceDetail.TotalCount; i++ {
		//	rst = append(rst, interfaceDetail.DataList[i].Name)
		//}
		for _, detail := range interfaceDetail.DataList {
			//rst = append(rst, detail.Name)
			ifProfile := map[string]string{
				"name":  detail.Name,
				"index": strconv.Itoa(detail.Index),
			}
			rst = append(rst, ifProfile)
		}
	}

	return rst, nil
}

func (ps *PhysicalSwitchService) GetSwitchInterfaceList(q *switchmodels.SwitchInterfaceListQuery) (switchmodels.InterfaceDetail, error) {
	klog.Infof("get switch interface list ,sn: %s", q.Sn)
	//todo test get demo swtich metrics

	//1, new galaxy cloud physical resource struct ,like physical server ,physical switch .......,set property field
	//2, get prometheus sql template string sql,include unit ......
	//3, get metrics by prometheus api
	rst := switchmodels.InterfaceDetail{}
	switchIp := SwitchSnToIP("all", q.Sn)

	query := &switchmodels.SwitchIfDetailParams{PageNo: 1, PageSize: int(^uint16(0)), Sn: q.Sn}
	ifDetail, err := ps.GetSwitchIfDetail(query)
	if err != nil {

		klog.Info(err)
		return rst, err
	}

	//count := ifDetail.TotalCount
	//for i := 0; i < count; i++ {
	for _, v := range ifDetail.DataList {

		//j := ifDetail.DataList[i]
		j := v
		//多选

		// if len(l.Az) != 0 {
		// 	stateIn := services.In(l.Az, j.AzCode)
		// 	if !stateIn {
		// 		continue
		// 	}
		// }

		nb, _ := regexp.MatchString(q.Name, j.Name)
		//sb, _ := regexp.MatchString(q.Sn, j.Sn)
		if nb || q.Name == "" {
			m := switchmodels.Interface{
				Id:    j.Id,
				Index: j.Index,
				Name:  j.Name,
				Ip:    j.Ip,
				//NextDevice:    ReturnNextDevice(j.Index),
				NextDevice:    j.NextDevice,
				NextInterface: j.NextInterface,
				//State:         GenerateSwitchInterfaceState(GenerateAdminNum(switchIp, j.Index), GenerateOperNum(switchIp, j.Index)),
				State: j.State,
			}

			//多选
			if len(q.RunList) != 0 {
				stateIn := services.In(q.RunList, m.State)
				if !stateIn {
					continue
				}
			}

			//query
			bandOut, err := client.VectorQuery(temp.NewSwitchMetics(switchIp, j.Index).ToString("switch_interface_out_flowRate"))
			if err != nil {
				klog.Info(err)
			}
			for _, v := range bandOut {
				if math.IsNaN(float64(v.Value)) {
					v.Value = 0
				}
				m.OutBandPercent += services.FormPercent(float64(v.Value))
			}

			bandIn, err := client.VectorQuery(temp.NewSwitchMetics(switchIp, j.Index).ToString("switch_interface_in_flowRate"))
			if err != nil {
				klog.Info(err)
			}
			for _, v := range bandIn {
				if math.IsNaN(float64(v.Value)) {
					v.Value = 0
				}
				m.InBandPercent += services.FormPercent(float64(v.Value))
			}

			errOut, err := client.VectorQuery(temp.NewSwitchMetics(switchIp, j.Index).ToString("switch_interface_out_errRate"))
			if err != nil {
				klog.Info(err)
			}
			for _, v := range errOut {
				if math.IsNaN(float64(v.Value)) {
					v.Value = 0
				}
				m.OutErrPercent += services.FormPercent(float64(v.Value))
			}

			errIn, err := client.VectorQuery(temp.NewSwitchMetics(switchIp, j.Index).ToString("switch_interface_in_errRate"))
			if err != nil {
				klog.Info(err)
			}
			for _, v := range errIn {
				if math.IsNaN(float64(v.Value)) {
					v.Value = 0
				}
				m.InErrPercent += services.FormPercent(float64(v.Value))
			}

			dropOut, err := client.VectorQuery(temp.NewSwitchMetics(switchIp, j.Index).ToString("switch_interface_out_dropRate"))
			if err != nil {
				klog.Info(err)
			}
			for _, v := range dropOut {
				if math.IsNaN(float64(v.Value)) {
					v.Value = 0
				}
				m.OutDropPercent += services.FormPercent(float64(v.Value))
			}

			dropIn, err := client.VectorQuery(temp.NewSwitchMetics(switchIp, j.Index).ToString("switch_interface_in_dropRate"))
			if err != nil {
				klog.Info(err)
			}
			for _, v := range dropIn {
				if math.IsNaN(float64(v.Value)) {
					v.Value = 0
				}
				m.InDropPercent += services.FormPercent(float64(v.Value))
			}

			rst.DataList = append(rst.DataList, m)
		}

	}

	//rst.DataList = nil
	klog.Info("循环结束 rst长度", len(rst.DataList))

	//order
	if q.OrderCode != "" && q.OrderType != "" {
		klog.Info("order start")
		klog.Infof("orderCode: %s;orderType: %s", q.OrderCode, q.OrderType)
		results := alert.Bucket{}
		for i := 0; i < len(rst.DataList); i++ {
			results.Slice = append(results.Slice[:0], rst.DataList[i])
		}
		time_by := func(a, b interface{}) bool {
			return true
		}
		switch q.OrderCode {
		case "outBandPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Interface).OutBandPercent < b.(switchmodels.Interface).OutBandPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Interface).OutBandPercent > b.(switchmodels.Interface).OutBandPercent
				}
			}

		case "inBandPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Interface).InBandPercent < b.(switchmodels.Interface).InBandPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Interface).InBandPercent > b.(switchmodels.Interface).InBandPercent
				}
			}

		case "outErrPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Interface).OutErrPercent < b.(switchmodels.Interface).OutErrPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Interface).OutErrPercent > b.(switchmodels.Interface).OutErrPercent
				}
			}
		case "inErrPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Interface).OutErrPercent < b.(switchmodels.Interface).OutErrPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Interface).OutErrPercent > b.(switchmodels.Interface).OutErrPercent
				}
			}

		case "outDropPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Interface).OutDropPercent < b.(switchmodels.Interface).OutDropPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Interface).OutDropPercent > b.(switchmodels.Interface).OutDropPercent
				}
			}

		case "inDropPercent":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Interface).InDropPercent < b.(switchmodels.Interface).InDropPercent
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(switchmodels.Interface).InDropPercent > b.(switchmodels.Interface).InDropPercent
				}
			}
		}
		results.By = time_by

		sort.Sort(results)
		for i := 0; i < len(results.Slice); i++ {
			rst.DataList[i] = results.Slice[i].(switchmodels.Interface)
		}
	}

	//分页
	low := (q.PageNo - 1) * q.PageSize
	klog.Info("low", low)
	if low > len(rst.DataList) {
		return rst, nil
	}

	hight := low + q.PageSize
	if hight > len(rst.DataList) {
		hight = len(rst.DataList)
	}

	klog.Info("hight", hight)
	rst.PageNo = q.PageNo
	rst.PageSize = q.PageSize
	rst.TotalCount = len(rst.DataList)
	rst.DataList = rst.DataList[low:hight]

	return rst, nil
}

func (ps *PhysicalSwitchService) GetSwitchInterfaceLine(q *switchmodels.SwitchInterfaceLineQuery) (switchmodels.IfMutilLineData, error) {
	klog.Infof("get switch metrics ,sn: %s,index: %s", q.Sn, q.Index)
	klog.Info(q)
	rst := switchmodels.IfMutilLineData{}
	step := services.TimeToStep(q.End - q.Start)
	start := strconv.FormatFloat(q.Start, 'f', 3, 64)
	end := strconv.FormatFloat(q.End, 'f', 3, 64)
	ip := SwitchSnToIP("all", q.Sn)
	index, err := strconv.Atoi(q.Index)
	index++
	if err != nil {
		klog.Info(err)
		return rst, err
	}
	echarts := make([]switchmodels.Echart, 0)
	for i := 0; i < len(q.Name); i++ {
		switch q.Name[i] {
		case "inFlow":
			r := switchmodels.Echart{}
			l, proErr := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, index).ToString("switch_interface_in_flow"))
			if proErr != nil {
				klog.Errorf("接收速率 err:", proErr)
			}
			r.Info.Name = "接收速率"
			r.Info.Tyte = "line"
			r.Info.Index = 0
			r.Info.UnitType = "storage"
			r.Info.Unit = "bps"
			if len(l) > 0 {
				klog.Infof("接收速率", l[0])
				s := services.GetPromValuesSlice(l[0])
				r.Info.Min = services.FormatSizePerSecondForLittleB(services.GetPromValueMin(s))
				r.Info.Max = services.FormatSizePerSecondForLittleB(services.GetPromValueMax(s))
				r.Info.Avg = services.FormatSizePerSecondForLittleB(services.GetPromValueAvg(s))
				r.Info.Cur = services.FormatSizePerSecondForLittleB(s[0])
				vv := prom.PrometheusResultToValue2(l[0])
				r.Values = services.RangeValueForForePercent(vv)

			}
			echarts = append(echarts, r)
		case "outFlow":
			r := switchmodels.Echart{}
			l, proErr := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, index).ToString("switch_interface_out_flow"))
			if proErr != nil {
				klog.Errorf("发送速率 err:", proErr)
			}
			r.Info.Name = "发送速率"
			r.Info.Tyte = "line"
			r.Info.Index = 0
			r.Info.UnitType = "storage"
			r.Info.Unit = "bps"
			if len(l) > 0 {
				klog.Infof("发送速率", l[0])
				s := services.GetPromValuesSlice(l[0])
				r.Info.Min = services.FormatSizePerSecondForLittleB(services.GetPromValueMin(s))
				r.Info.Max = services.FormatSizePerSecondForLittleB(services.GetPromValueMax(s))
				r.Info.Avg = services.FormatSizePerSecondForLittleB(services.GetPromValueAvg(s))
				r.Info.Cur = services.FormatSizePerSecondForLittleB(s[0])
				vv := prom.PrometheusResultToValue2(l[0])
				r.Values = services.RangeValueForForePercent(vv)

			}
			echarts = append(echarts, r)
		case "inBandRate":
			r := switchmodels.Echart{}
			l, proErr := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, index).ToString("switch_interface_in_flowRate"))

			if proErr != nil {
				klog.Errorf("接收带宽利用率 err:", proErr)
			}
			r.Info.Name = "接收带宽利用率"
			r.Info.Tyte = "line"
			r.Info.Index = 1
			r.Info.UnitType = "percent"
			r.Info.Unit = "%"
			if len(l) > 0 {
				klog.Infof("接收带宽利用率", l[0])
				s := services.GetPromValuesSlice(l[0])
				r.Info.Min = services.FormPercentWithSign(services.GetPromValueMin(s))
				r.Info.Max = services.FormPercentWithSign(services.GetPromValueMax(s))
				r.Info.Avg = services.FormPercentWithSign(services.GetPromValueAvg(s))
				r.Info.Cur = services.FormatSizePerSecondForLittleB(s[0])
				vv := prom.PrometheusResultToValue2(l[0])
				r.Values = services.RangeValueForForePercent2(vv)

			}
			echarts = append(echarts, r)
		case "outBandRate":
			r := switchmodels.Echart{}
			l, proErr := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, index).ToString("switch_interface_out_flowRate"))

			if proErr != nil {
				klog.Errorf("发送带宽利用率 err:", proErr)
			}
			r.Info.Name = "发送带宽利用率"
			r.Info.Tyte = "line"
			r.Info.Index = 1
			r.Info.UnitType = "percent"
			r.Info.Unit = "%"
			if len(l) > 0 {
				klog.Infof("发送带宽利用率", l[0])
				s := services.GetPromValuesSlice(l[0])
				r.Info.Min = services.FormPercentWithSign(services.GetPromValueMin(s))
				r.Info.Max = services.FormPercentWithSign(services.GetPromValueMax(s))
				r.Info.Avg = services.FormPercentWithSign(services.GetPromValueAvg(s))
				r.Info.Cur = services.FormatSizePerSecondForLittleB(s[0])
				vv := prom.PrometheusResultToValue2(l[0])
				r.Values = services.RangeValueForForePercent2(vv)

			}
			echarts = append(echarts, r)
		case "inPackageRate":
			r := switchmodels.Echart{}
			l, proErr := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, index).ToString("switch_interface_in_packageNum"))

			if proErr != nil {
				klog.Errorf("接收包速率 err:", proErr)
			}
			r.Info.Name = "接收包速率"
			r.Info.Tyte = "line"
			r.Info.Index = 1
			r.Info.UnitType = "number"
			r.Info.Unit = "pps"
			if len(l) > 0 {
				klog.Infof("接收包速率", l[0])
				s := services.GetPromValuesSlice(l[0])
				r.Info.Min = fmt.Sprintf("%.2f%s", services.GetPromValueMin(s), "pps")
				r.Info.Max = fmt.Sprintf("%.2f%s", services.GetPromValueMax(s), "pps")
				r.Info.Avg = fmt.Sprintf("%.2f%s", services.GetPromValueAvg(s), "pps")
				r.Info.Cur = fmt.Sprintf("%.2f%s", s[0], "pps")
				vv := prom.PrometheusResultToValue2(l[0])
				r.Values = services.RangeValueForForePercent2(vv)
			}
			echarts = append(echarts, r)
		case "outPackageRate":
			r := switchmodels.Echart{}
			l, proErr := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, index).ToString("switch_interface_out_packageNum"))

			if proErr != nil {
				klog.Errorf("发送包速率 err:", proErr)
			}
			r.Info.Name = "发送包速率"
			r.Info.Tyte = "line"
			r.Info.Index = 1
			r.Info.UnitType = "number"
			r.Info.Unit = "pps"
			if len(l) > 0 {
				klog.Infof("发送包速率", l[0])
				s := services.GetPromValuesSlice(l[0])
				r.Info.Min = fmt.Sprintf("%.2f%s", services.GetPromValueMin(s), "pps")
				r.Info.Max = fmt.Sprintf("%.2f%s", services.GetPromValueMax(s), "pps")
				r.Info.Avg = fmt.Sprintf("%.2f%s", services.GetPromValueAvg(s), "pps")
				r.Info.Cur = fmt.Sprintf("%.2f%s", s[0], "pps")
				vv := prom.PrometheusResultToValue2(l[0])
				r.Values = services.RangeValueForForePercent2(vv)
			}
			echarts = append(echarts, r)
		case "inErrRate":
			r := switchmodels.Echart{}
			l, proErr := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, index).ToString("switch_interface_in_errRate"))

			if proErr != nil {
				klog.Errorf("接收错包率 err:", proErr)
			}

			r.Info.Name = "接收错包率"
			r.Info.Tyte = "line"
			r.Info.Index = 1
			r.Info.UnitType = "percent"
			r.Info.Unit = "%"
			if len(l) > 0 {
				klog.Infof("接收错包率", l[0])
				s := services.GetPromValuesSlice(l[0])
				r.Info.Min = services.FormPercentWithSign(services.GetPromValueMin(s))
				r.Info.Max = services.FormPercentWithSign(services.GetPromValueMax(s))
				r.Info.Avg = services.FormPercentWithSign(services.GetPromValueAvg(s))
				r.Info.Cur = services.FormPercentWithSign(s[0])
				vv := prom.PrometheusResultToValue2(l[0])
				r.Values = services.RangeValueForForePercent2(vv)

			}
			echarts = append(echarts, r)
		case "outErrRate":
			r := switchmodels.Echart{}
			l, proErr := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, index).ToString("switch_interface_out_errRate"))

			if proErr != nil {
				klog.Errorf("发送错包率 err:", proErr)
			}

			r.Info.Name = "发送错包率"
			r.Info.Tyte = "line"
			r.Info.Index = 1
			r.Info.UnitType = "percent"
			r.Info.Unit = "%"
			if len(l) > 0 {
				klog.Infof("发送错包率", l[0])
				s := services.GetPromValuesSlice(l[0])
				r.Info.Min = services.FormPercentWithSign(services.GetPromValueMin(s))
				r.Info.Max = services.FormPercentWithSign(services.GetPromValueMax(s))
				r.Info.Avg = services.FormPercentWithSign(services.GetPromValueAvg(s))
				r.Info.Cur = services.FormPercentWithSign(s[0])
				vv := prom.PrometheusResultToValue2(l[0])
				r.Values = services.RangeValueForForePercent2(vv)

			}
			echarts = append(echarts, r)
		case "inDropRate":
			r := switchmodels.Echart{}
			l, proErr := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, index).ToString("switch_interface_in_dropRate"))

			if proErr != nil {
				klog.Errorf("接收丢包率 err:", proErr)
			}
			r.Info.Name = "接收丢包率"
			r.Info.Tyte = "line"
			r.Info.Index = 1
			r.Info.UnitType = "percent"
			r.Info.Unit = "%"
			if len(l) > 0 {
				klog.Infof("接收丢包率", l[0])
				s := services.GetPromValuesSlice(l[0])
				r.Info.Min = services.FormPercentWithSign(services.GetPromValueMin(s))
				r.Info.Max = services.FormPercentWithSign(services.GetPromValueMax(s))
				r.Info.Avg = services.FormPercentWithSign(services.GetPromValueAvg(s))
				r.Info.Cur = services.FormPercentWithSign(s[0])
				vv := prom.PrometheusResultToValue2(l[0])
				r.Values = services.RangeValueForForePercent2(vv)

			}
			echarts = append(echarts, r)
		case "outDropRate":
			r := switchmodels.Echart{}
			l, proErr := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, index).ToString("switch_interface_out_dropRate"))

			if proErr != nil {
				klog.Errorf("发送丢包率 err:", proErr)
			}

			r.Info.Name = "发送丢包率"
			r.Info.Tyte = "line"
			r.Info.Index = 1
			r.Info.UnitType = "percent"
			r.Info.Unit = "%"
			if len(l) > 0 {
				klog.Infof("发送丢包率", l[0])
				s := services.GetPromValuesSlice(l[0])
				r.Info.Min = services.FormPercentWithSign(services.GetPromValueMin(s))
				r.Info.Max = services.FormPercentWithSign(services.GetPromValueMax(s))
				r.Info.Avg = services.FormPercentWithSign(services.GetPromValueAvg(s))
				r.Info.Cur = services.FormPercentWithSign(s[0])
				vv := prom.PrometheusResultToValue2(l[0])
				r.Values = services.RangeValueForForePercent2(vv)
			}
			echarts = append(echarts, r)
		case "inErrNum":
			r := switchmodels.Echart{}
			l, proErr := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, index).ToString("switch_interface_in_errNum"))

			if proErr != nil {
				klog.Errorf("每秒接收错包数 err:", proErr)
			}
			r.Info.Name = "每秒接收错包数"
			r.Info.Tyte = "line"
			r.Info.Index = 0
			r.Info.UnitType = "number"
			r.Info.Unit = "pps"
			if len(l) > 0 {
				klog.Infof("每秒接收错包数", l[0])
				s := services.GetPromValuesSlice(l[0])
				r.Info.Min = fmt.Sprintf("%.2f%s", services.GetPromValueMin(s), "pps")
				r.Info.Max = fmt.Sprintf("%.2f%s", services.GetPromValueMax(s), "pps")
				r.Info.Avg = fmt.Sprintf("%.2f%s", services.GetPromValueAvg(s), "pps")
				r.Info.Cur = fmt.Sprintf("%.2f%s", s[0], "pps")
				vv := prom.PrometheusResultToValue2(l[0])
				r.Values = services.RangeValueForForePercent2(vv)

			}
			echarts = append(echarts, r)
		case "outErrNum":
			r := switchmodels.Echart{}
			l, proErr := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, index).ToString("switch_interface_out_errNum"))

			if proErr != nil {
				klog.Errorf("每秒发送错包数 err:", proErr)
			}
			r.Info.Name = "每秒发送错包数"
			r.Info.Tyte = "line"
			r.Info.Index = 0
			r.Info.UnitType = "number"
			r.Info.Unit = "pps"
			if len(l) > 0 {
				klog.Infof("每秒发送错包数", l[0])
				s := services.GetPromValuesSlice(l[0])
				r.Info.Min = fmt.Sprintf("%.2f%s", services.GetPromValueMin(s), "pps")
				r.Info.Max = fmt.Sprintf("%.2f%s", services.GetPromValueMax(s), "pps")
				r.Info.Avg = fmt.Sprintf("%.2f%s", services.GetPromValueAvg(s), "pps")
				r.Info.Cur = fmt.Sprintf("%.2f%s", s[0], "pps")
				vv := prom.PrometheusResultToValue2(l[0])
				r.Values = services.RangeValueForForePercent2(vv)

			}
			echarts = append(echarts, r)
		case "inDropNum":
			r := switchmodels.Echart{}
			l, proErr := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, index).ToString("switch_interface_in_dropNum"))

			if proErr != nil {
				klog.Errorf("每秒接收丢包数 err:", proErr)
			}
			r.Info.Name = "每秒接收丢包数"
			r.Info.Tyte = "line"
			r.Info.Index = 0
			r.Info.UnitType = "number"
			r.Info.Unit = "pps"
			if len(l) > 0 {
				klog.Infof("每秒接收丢包数", l[0])
				s := services.GetPromValuesSlice(l[0])
				r.Info.Min = fmt.Sprintf("%.2f%s", services.GetPromValueMin(s), "pps")
				r.Info.Max = fmt.Sprintf("%.2f%s", services.GetPromValueMax(s), "pps")
				r.Info.Avg = fmt.Sprintf("%.2f%s", services.GetPromValueAvg(s), "pps")
				r.Info.Cur = fmt.Sprintf("%.2f%s", s[0], "pps")
				vv := prom.PrometheusResultToValue2(l[0])
				r.Values = services.RangeValueForForePercent2(vv)

			}
			echarts = append(echarts, r)
		case "outDropNum":
			r := switchmodels.Echart{}
			l, proErr := prom.PrometheusQuery2(true, start, end, step, temp.NewSwitchMetics(ip, index).ToString("switch_interface_out_dropNum"))

			if proErr != nil {
				klog.Errorf("每秒发送丢包数 err:", proErr)
			}
			r.Info.Name = "每秒发送丢包数"
			r.Info.Tyte = "line"
			r.Info.Index = 0
			r.Info.UnitType = "number"
			r.Info.Unit = "pps"
			if len(l) > 0 {
				klog.Infof("每秒发送丢包数", l[0])
				s := services.GetPromValuesSlice(l[0])
				r.Info.Min = fmt.Sprintf("%.2f%s", services.GetPromValueMin(s), "pps")
				r.Info.Max = fmt.Sprintf("%.2f%s", services.GetPromValueMax(s), "pps")
				r.Info.Avg = fmt.Sprintf("%.2f%s", services.GetPromValueAvg(s), "pps")
				r.Info.Cur = fmt.Sprintf("%.2f%s", s[0], "pps")
				vv := prom.PrometheusResultToValue2(l[0])
				r.Values = services.RangeValueForForePercent2(vv)

			}
			echarts = append(echarts, r)
		}

	}

	// 补充缺失时间
	for k, v := range echarts {
		if len(v.Values) == 0 {
			continue
		}
		repairFirstList := []services.ValueType{}
		first := v.Values[0].TimeSteamp.(float64)    // 实际第一条时间
		firstStep, _ := strconv.ParseFloat(step, 64) // 步长
		klog.Infof("firstTime", first, "firstStep", firstStep)
		for n := q.Start; n < first; n += firstStep {
			repairFirst := services.ValueType{
				Name:       n,
				TimeSteamp: n,
				IsForecast: false,
				Day:        time.Unix(int64(n), 0).Format("2006-01-02 15:04:05"),
			}
			repairFirstList = append(repairFirstList, repairFirst)
		}
		echarts[k].Values = append(repairFirstList, v.Values...)
	}

	rst.Echarts = echarts
	return rst, nil
}

func (ps *PhysicalSwitchService) GetSwitchIfInfo(q *switchmodels.InterfaceQuery) (switchmodels.IfDetailMetric, error) {
	klog.Infof("get interface metrics ,sn: %s,index: %s", q.Sn, q.Index)

	klog.Info(q)
	rst := switchmodels.IfDetailMetric{Index: q.Index}

	ip := SwitchSnToIP("all", q.Sn)
	index, err := strconv.Atoi(q.Index)
	if err != nil {
		klog.Info(err)
		return rst, err
	}
	//rst.State = GenerateSwitchInterfaceState(GenerateAdminNum(ip, index), GenerateOperNum(ip, index))
	rst.State = GenerateSwitchInterfaceState(q.Sn, q.Index)
	if rst.State == "normal" {
		inBandRate, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(ip, index).ToString("switch_interface_in_flowRate"))
		inBandRateRate := prom.PrometheusResultToValueForPercent(inBandRate)
		if len(inBandRateRate) > 0 {
			rst.InBandRate = inBandRateRate[0].(float64) / 100
		}

		outBandRate, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(ip, index).ToString("switch_interface_out_flowRate"))
		outBandRateRate := prom.PrometheusResultToValueForPercent(outBandRate)
		if len(outBandRateRate) > 0 {
			rst.OutBandRate = outBandRateRate[0].(float64) / 100
		}

		inErrRate, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(ip, index).ToString("switch_interface_in_errRate"))
		inErrRateRate := prom.PrometheusResultToValueForPercent(inErrRate)
		if len(inErrRateRate) > 0 {
			rst.InErrRate = inErrRateRate[0].(float64) / 100
		}

		outErrRate, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(ip, index).ToString("switch_interface_out_errRate"))
		outErrRateRate := prom.PrometheusResultToValueForPercent(outErrRate)
		if len(outErrRateRate) > 0 {
			rst.OutErrRate = outErrRateRate[0].(float64) / 100
		}

		inDropRate, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(ip, index).ToString("switch_interface_in_dropRate"))
		inDropRateRate := prom.PrometheusResultToValueForPercent(inDropRate)
		if len(inDropRateRate) > 0 {
			rst.InDropRate = inDropRateRate[0].(float64) / 100
		}

		outDropRate, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(ip, index).ToString("switch_interface_out_dropRate"))
		outDropRateRate := prom.PrometheusResultToValueForPercent(outDropRate)
		if len(outDropRateRate) > 0 {
			rst.OutDropRate = outDropRateRate[0].(float64) / 100
		}
	} else {
		rst.AlertNum = 0
		rst.InBandRate = "N/A"
		rst.OutBandRate = "N/A"
		rst.InErrRate = "N/A"
		rst.OutErrRate = "N/A"
		rst.InDropRate = "N/A"
		rst.OutDropRate = "N/A"
	}

	return rst, nil
}

var InterfaceSingleLineMap = map[string]func(start, end int64, ip, name string, index, step int) (switchmodels.MetricLineType, error){
	"inFlow":         InterfaceSingleLineInFlow,
	"outFlow":        InterfaceSingleLineOutFlow,
	"inBandRate":     InterfaceSingleLineOutFlow,
	"outBandRate":    InterfaceSingleLineInFlow,
	"inPackageRate":  InterfaceSingleLineOutFlow,
	"outPackageRate": InterfaceSingleLineOutFlow,
	"inErrRate":      InterfaceSingleLineInFlow,
	"ouErrRate":      InterfaceSingleLineOutFlow,
	"inDropRate":     InterfaceSingleLineOutFlow,
	"outDropRate":    InterfaceSingleLineInFlow,
	"inErrNum":       InterfaceSingleLineOutFlow,
	"outErrNum":      InterfaceSingleLineOutFlow,
	"inDropNum":      InterfaceSingleLineOutFlow,
	"outDropNum":     InterfaceSingleLineOutFlow,
}

func (ps *PhysicalSwitchService) GetSwitchInterfaceSigleLine(q *switchmodels.SwitchInterfaceLineQuery) ([]switchmodels.MetricLineType, error) {
	klog.Infof("get switch metrics ,sn: %s,index: %s", q.Sn, q.Index)

	klog.Info(q)
	rst := make([]switchmodels.MetricLineType, 0)
	step := services.TimeToStepForInt(int64(q.End) - int64(q.Start))
	start := int64(q.Start)
	end := int64(q.End)
	ip := SwitchSnToIP("all", q.Sn)
	index, err := strconv.Atoi(q.Index)
	if err != nil {
		klog.Info(err)
		return rst, err
	}

	for _, name := range q.Name {
		if op, ok := InterfaceSingleLineMap[name]; ok {
			result, errOp := op(start, end, ip, name, index, step)
			if errOp != nil {
				klog.Error(errOp)
				err = errOp
				continue
			}
			rst = append(rst, result)
		}
	}

	return rst, nil
}

func InterfaceSingleLineInFlow(start, end int64, ip, name string, index, step int) (rst switchmodels.MetricLineType, err error) {
	values, err := client.MatrixQuery(temp.NewSwitchMetics(ip, index).ToString("switch_interface_in_flow"), v1.Range{
		Start: time.Unix(start, 0),
		End:   time.Unix(end, 0),
		Step:  time.Duration(step) * time.Second,
	})
	if err != nil {
		return
	}

	rst.Name = "接收速率"
	for _, i := range values {
		r := switchmodels.Echart{}
		info := switchmodels.MetricLineInfo{
			//Name:     services.RegionCodeNameMap[string(i.Metric["region"])],
			Name:     name,
			Unit:     "bps",
			UnitType: "bps",
		}
		for _, j := range i.Values {

			rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: services.FormPercent(j.Value.String())}
			r.Values = append(r.Values, rr)

		}
		r.Info = info
		rst.Echarts = append(rst.Echarts, r)
	}

	return
}
func InterfaceSingleLineOutFlow(start, end int64, ip, name string, index, step int) (rst switchmodels.MetricLineType, err error) {

	values, err := client.MatrixQuery(temp.NewSwitchMetics(ip, index).ToString("switch_interface_out_flow"), v1.Range{
		Start: time.Unix(start, 0),
		End:   time.Unix(end, 0),
		Step:  time.Duration(step) * time.Second,
	})
	if err != nil {
		return
	}
	rst.Name = "发送速率"
	for _, i := range values {
		r := switchmodels.Echart{}
		info := switchmodels.MetricLineInfo{
			//Name:     services.RegionCodeNameMap[string(i.Metric["region"])],
			Name:     name,
			Unit:     "bps",
			UnitType: "bps",
		}
		for _, j := range i.Values {

			rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: services.FormPercent(j.Value.String())}
			r.Values = append(r.Values, rr)

		}
		r.Info = info
		rst.Echarts = append(rst.Echarts, r)
	}

	return rst, nil
}

func GetCMDBSwitchList(q *switchmodels.SwitchListQuery) (switchmodels.CMDBSwitchListResult, error) {
	c := http.Client{}
	cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/switch/list", "post")

	//cs := CmdbVms{}
	cmdbData := switchmodels.CmdbSwitchs{
		DataList: make([]switchmodels.SwitchNew, 0, cmdbCount),
	}
	cmdb := switchmodels.CMDBSwitchListResult{Data: cmdbData}

	jsons, _ := json.Marshal(q)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/switch/list", "application/json", jsoninfo)

	if err != nil {
		fmt.Println("err" + err.Error())
		return cmdb, err
	}

	b, _ := io.ReadAll(resp.Body)

	err = json.Unmarshal(b, &cmdb)
	if err != nil {
		return cmdb, err
	}

	return cmdb, nil
}

func SwitchSnToIP(region, sn string) string {
	cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/switch/list", "post")
	hostUrlPost := switchmodels.SwitchListQuery{
		PageNo:   1,
		PageSize: cmdbCount,
		Region:   region,
	}
	cmdb, err := GetCMDBSwitchList(&hostUrlPost)
	if err != nil {
		klog.Info(err)
		return ""
	}
	for i := 0; i < cmdbCount; i++ {
		j := cmdb.Data.DataList[i]
		if j.Sn == sn {
			return j.OutBandIP
		}
	}
	return ""
}

func GetCmdbLayOut(sn string) []switchmodels.SwitchInterfaceLayout {
	rst := []switchmodels.SwitchInterfaceLayout{}
	resp := switchmodels.CmdbInterfaceLayOutRes{}
	c := http.Client{}
	res, err := c.Get("http://" + config.GetDefaultUrl(config.CMDBService) + "/cmdb/v1/instance/switch/getInterfaceLayoutList?sn=" + sn)
	if err != nil {
		fmt.Println("err" + err.Error())
		return rst
	}
	b, _ := io.ReadAll(res.Body)

	err = json.Unmarshal(b, &resp)
	if err != nil {
		klog.Info(err)
		return rst
	}
	return resp.Data.DataList
}

//func GenerateSwitchInterfaceState(adminState, operState float64) string {
//	if adminState == 1 {
//		if operState == 1 || operState == 5 {
//			return "normal"
//		} else if operState == 6 {
//			return "noConn"
//		}
//	} else if adminState == 2 {
//		return "shutdown"
//	}
//
//	return "err"
//}
func GenerateSwitchInterfaceState(sn, index string) string {
	postParam := map[string]interface{}{
		"pageSize": -1,
		"pageNo":   1,
		"sn":       sn,
		"index":    index,
	}
	interFaceDetails, err := getCMDBSwitchIfDetail(fmt.Sprintf("http://%s/cmdb/v1/instance/switch/postSwitchInterfaceDetails", config.GetDefaultUrl(config.CMDBService)), postParam)
	if err != nil || len(interFaceDetails.DataList) == 0 {
		return "shutdown"
	}
	detail := interFaceDetails.DataList[0]
	return statusMapping[detail.IfStatus]
}

//func FromLayoutToInterfaceMetric
func GetIfMetrics(sn, index string) switchmodels.IfDetailMetric {
	rst := switchmodels.IfDetailMetric{Index: index}

	return rst
}

func GenerateAdminNum(ip string, index int) float64 {
	var rst float64
	admin, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(ip, index).ToString("switch_interface_admin_state"))
	aadmin := prom.PrometheusResultToValueForPercent(admin)
	if len(aadmin) > 0 {
		rst = aadmin[0].(float64)
		return rst
	}
	return 0
}

func GenerateOperNum(ip string, index int) float64 {
	var rst float64
	admin, _ := prom.PrometheusQuery2(false, "", "", "", temp.NewSwitchMetics(ip, index).ToString("switch_interface_oper_state"))
	aadmin := prom.PrometheusResultToValueForPercent(admin)
	if len(aadmin) > 0 {
		rst = aadmin[0].(float64)
		return rst
	}
	return 0
}

//func GetSwitchIfStateDetail(sn string) map[string]int {
//	rst := make(map[string]int, 4)
//	layOut := GetCmdbLayOut(sn)
//	ip := SwitchSnToIP("all", sn)
//	var Index int
//	if len(layOut) > 0 {
//		Index = layOut[0].StartIndex
//	}
//	for i := 0; i < len(layOut); i++ {
//		o := layOut[i]
//
//		for j := 1; j <= o.X; j++ {
//
//			for n := 1; n <= o.Y; n++ {
//				s := GenerateSwitchInterfaceState(GenerateAdminNum(ip, Index), GenerateOperNum(ip, Index))
//				switch s {
//				case "normal":
//					rst["normal"]++
//				case "noConn":
//					rst["noConn"]++
//				case "shutdown":
//					rst["shutdown"]++
//				case "err":
//					rst["err"]++
//				}
//				Index++
//			}
//		}
//	}
//	return rst
//}

func GetSwitchIfStateDetail(sn string) map[string]int {
	rst := make(map[string]int, 4)
	postParam := map[string]interface{}{
		"pageSize": -1,
		"pageNo":   1,
		"sn":       sn,
	}
	interFaceDetails, err := getCMDBSwitchIfDetail(fmt.Sprintf("http://%s/cmdb/v1/instance/switch/postSwitchInterfaceDetails", config.GetDefaultUrl(config.CMDBService)), postParam)
	if err != nil {
		klog.Errorf("获取交换机接口细节列表异常：%v", err)
	}
	if len(interFaceDetails.DataList) == 0 {
		klog.Warning("交换机接口细节列表为空")
	}
	for _, detail := range interFaceDetails.DataList {
		state := statusMapping[detail.IfStatus]
		switch state {
		case "normal":
			rst["normal"]++
		case "shutdown":
			rst["shutdown"]++
		case "err":
			rst["err"]++
		}
	}
	return rst
}

func ReturnNextDevice(id int) switchmodels.NextDeviceDetail {
	rst := switchmodels.NextDeviceDetail{}
	Nd1 := switchmodels.NextDeviceDetail{
		Name:       "",
		DeviceType: "",
		Interface:  "",
		Sn:         "",
		Ip:         "",
		State:      "",
	}
	Nd2 := switchmodels.NextDeviceDetail{
		Name:       "",
		DeviceType: "",
		Interface:  "",
		Sn:         "",
		Ip:         "",
		State:      "",
	}
	if id%2 == 0 {
		rst = Nd1
	} else {
		rst = Nd2
	}
	return rst
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/physicalSwitch/util.go
```golang
package physicalSwitch

import (
	"sort"
	"strconv"

	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
)

func InterfaceValueOrder(in []services.ValueType, code string) []services.ValueType {
	results := alert.Bucket{}
	for i := 0; i < len(in); i++ {
		results.Slice = append(results.Slice, in[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	switch code {
	case "asc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(services.ValueType).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(services.ValueType).Value), 64)
			return aa < bb
		}
	case "desc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(services.ValueType).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(services.ValueType).Value), 64)
			return aa > bb
		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(in); i++ {
		in[i] = results.Slice[i].(services.ValueType)
	}
	return in
}

func BlockInterfaceValueOrder(in []services.BlockValueType, code string) []services.BlockValueType {
	results := alert.Bucket{}
	for i := 0; i < len(in); i++ {
		results.Slice = append(results.Slice, in[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	switch code {
	case "asc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(services.BlockValueType).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(services.BlockValueType).Value), 64)
			return aa < bb
		}
	case "desc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(services.BlockValueType).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(services.BlockValueType).Value), 64)
			return aa > bb
		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(in); i++ {
		in[i] = results.Slice[i].(services.BlockValueType)
	}
	return in
}

func getSwitchPartExist(b bool) string {
	var In string = "不在位"
	if b {
		In = "在位"
	}
	return In
}
func getSwitchPartRedundancy(b bool) string {
	var In string = "不冗余"
	if b {
		In = "冗余"
	}
	return In
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/physicalSwitch/alertService.go
```golang
package physicalSwitch

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/eip/eipPool.go
```golang
package eip

import (
	"fmt"
	"regexp"
	"sort"
	"strings"
	"time"

	"github.com/pkg/errors"
	v1 "github.com/prometheus/client_golang/api/prometheus/v1"
	"github.com/prometheus/common/model"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	alertmodel "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/alertmanager"
	eipmodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/eip"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	temp "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/eip"
	"k8s.io/klog/v2"
)

type IEipPool interface {
	GetEipPoolOverview(*eipmodels.EipPoolOverviewQuery) (eipmodels.OverView, error)
	GetEipPoolOverviewLine(*eipmodels.EipPoolOverviewLineQuery) ([]eipmodels.OverviewLineData, error)
	GetEipPoolList(*eipmodels.EipPoolListQuery) (eipmodels.EipPoolListResult, error)
	GetEipPoolUsage(*eipmodels.EipPoolListQuery) (eipmodels.EipPoolUsageResult, error)
	GetEipPoolMetricLine(*eipmodels.EipPoolMetricLineQuery) ([]eipmodels.MetricLineType, error)
}

type EipPoolService struct {
}

func NewEipPoolService() *EipPoolService {
	return &EipPoolService{}
}

func (ps *EipPoolService) GetEipPoolOverview(q *eipmodels.EipPoolOverviewQuery) (eipmodels.OverView, error) {
	klog.Infof("get eipPool overview ,region: %s, azs: %q", q.Region, q.Az)
	//todo test get demo swtich metrics

	//1, new galaxy cloud physical resource struct ,like physical server ,physical switch .......,set property field
	//2, get prometheus sql template string sql,include unit ......
	//3, get metrics by prometheus api
	//alert
	rst := eipmodels.OverView{Region: string(q.Region), Az: string(q.Az)}
	alerts := make([]models.AlertType, 0, 4)
	p0 := models.AlertType{Name: "紧急告警", Level: "p0", Kind: "error", Number: 0, Unit: "个"}
	p1 := models.AlertType{Name: "重要告警", Level: "p1", Kind: "warn", Number: 0, Unit: "个"}
	p2 := models.AlertType{Name: "次要告警", Level: "p2", Kind: "minor", Number: 0, Unit: "个"}
	p3 := models.AlertType{Name: "提醒告警", Level: "p3", Kind: "info", Number: 0, Unit: "个"}
	resourceSubTypeCode := []string{"eipPool"}
	t := alertmodel.AlertQuery{PageNo: 1, PageSize: 10000, ResourceSubTypeCode: resourceSubTypeCode}

	res, err := alert.GetAlertsDataListPage(t)
	if err != nil {
		return rst, err
	}
	for _, item := range res.DataList {
		switch item.AlertLevel {
		case "p0":
			p0.Number++
		case "p1":
			p1.Number++
		case "p2":
			p2.Number++
		case "p3":
			p3.Number++
		}
	}
	alerts = append(alerts, p0, p1, p2, p3)

	rst.Alerts = alerts
	return rst, nil
}

var eipPoolOverviewLineMap = map[string]func(lable string, start, end int64, step int) (eipmodels.OverviewLineData, error){
	"used":        QueryPoolLineUsed,
	"outFlow":     QueryPoolLineOutFlow,
	"inFlow":      QueryPoolLineInFlow,
	"outPackages": QueryPoolLineOutPackages,
	"inPackages":  QueryPoolLineInPackages,
}

func buildCommonCondition(parameter *eipmodels.EipPoolOverviewLineQuery, extConditions ...string) string {
	var conditions []string
	if len(extConditions) > 0 {
		conditions = append(conditions, extConditions...)
	}
	if parameter.Az != "" && parameter.Az != "all" {
		conditions = append(conditions, "az=\""+parameter.Az+"\"")
	}
	if parameter.Region != "" && parameter.Region != "all" {
		conditions = append(conditions, "region=\""+parameter.Region+"\"")
	}
	var conditionStr string
	if len(conditions) > 0 {
		conditionStr = strings.Join(conditions, ",")
	}
	return conditionStr
}

func (ps *EipPoolService) GetEipPoolOverviewLine(q *eipmodels.EipPoolOverviewLineQuery) (rst []eipmodels.OverviewLineData, err error) {
	klog.Infof("get eipPool overview line ,region: %s, azs: %q", q.Region, q.Az)

	//rst := []eipmodels.OverviewLineData{}
	start := q.Start / 1e3
	end := q.End / 1e3
	step := services.TimeToStepForInt(end - start)
	klog.Errorf("start: %v; end: %v; step: %v", q.Start/1e3, q.End/1e3, step)
	lable := buildCommonCondition(q)
	//k, _ := strconv.Atoi(q.TopK)
	for _, name := range q.Name {
		if op, ok := eipPoolOverviewLineMap[name]; ok {
			result, errOp := op(lable, start, end, step)
			if errOp != nil {
				klog.Error(errOp)
				err = errOp
				continue
			}
			rst = append(rst, result)
		}
	}
	return
}

//eipPooloverviewLine
func QueryPoolLineUsed(lable string, start, end int64, step int) (rst eipmodels.OverviewLineData, err error) {

	//query
	var values model.Matrix
	if lable == "" {
		values, err = client.MatrixQuery(temp.NewEipPoolMetics("", "").ToString("eip_pool_used_rate_by_region"), v1.Range{
			Start: time.Unix(start, 0),
			End:   time.Unix(end, 0),
			Step:  time.Duration(step) * time.Second,
		})
		if err != nil {
			return
		}

		for _, i := range values {
			r := eipmodels.Echart{}
			info := eipmodels.MetricLineInfo{
				Name:     services.RegionCodeNameMap[string(i.Metric["region"])],
				Unit:     "%",
				UnitType: "percent",
			}
			for _, j := range i.Values {

				rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: services.FormPercent(j.Value.String())}
				r.Values = append(r.Values, rr)

			}
			r.Info = info
			rst.Echarts = append(rst.Echarts, r)
		}
	} else {
		values, err = client.MatrixQuery(temp.NewEipPoolMetics(lable, "").ToString("eip_pool_used_rate_by_netSegment"), v1.Range{
			Start: time.Unix(start, 0),
			End:   time.Unix(end, 0),
			Step:  time.Duration(step) * time.Second,
		})
		if err != nil {
			return
		}

		for _, i := range values {
			r := eipmodels.Echart{}
			info := eipmodels.MetricLineInfo{
				Name:     string(i.Metric["cidr"]),
				Unit:     "%",
				UnitType: "percent",
			}
			for _, j := range i.Values {

				rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: services.FormPercent(j.Value.String())}
				r.Values = append(r.Values, rr)

			}
			r.Info = info
			rst.Echarts = append(rst.Echarts, r)
		}
	}

	return
}

func QueryPoolLineOutFlow(lable string, start, end int64, step int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "出口流量",
		Unit:     "bps",
		UnitType: "storage",
	}

	//query
	var values model.Matrix
	if lable == "" {
		values, err = client.MatrixQuery(temp.NewEipPoolMetics("", "").ToString("eip_pool_used_rate_by_region"), v1.Range{
			Start: time.Unix(start, 0),
			End:   time.Unix(end, 0),
			Step:  time.Duration(step) * time.Second,
		})
		if err != nil {
			return
		}
	} else {
		values, err = client.MatrixQuery(temp.NewEipPoolMetics(lable, "").ToString("eip_pool_used_rate_by_netSegment"), v1.Range{
			Start: time.Unix(start, 0),
			End:   time.Unix(end, 0),
			Step:  time.Duration(step) * time.Second,
		})
		if err != nil {
			return
		}
	}

	for _, i := range values {
		for _, j := range i.Values {
			rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: fmt.Sprintf(".%4f", j.Value.String())}
			r.Values = append(r.Values, rr)
		}
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryPoolLineInFlow(lable string, start, end int64, step int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "入口流量",
		Unit:     "bps",
		UnitType: "storage",
	}
	//query
	var values model.Matrix
	if lable == "" {
		values, err = client.MatrixQuery(temp.NewEipPoolMetics("", "").ToString("eip_pool_used_rate_by_region"), v1.Range{
			Start: time.Unix(start, 0),
			End:   time.Unix(end, 0),
			Step: time.Duration(step) * time.Second,
		})
		if err != nil {
			return
		}
	} else {
		values, err = client.MatrixQuery(temp.NewEipPoolMetics(lable, "").ToString("eip_pool_used_rate_by_netSegment"), v1.Range{
			Start: time.Unix(start, 0),
			End:   time.Unix(end, 0),
			Step:  time.Duration(step) * time.Second,
		})
		if err != nil {
			return
		}
	}

	for _, i := range values {
		for _, j := range i.Values {
			rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: fmt.Sprintf(".%4f", j.Value.String())}
			r.Values = append(r.Values, rr)
		}
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryPoolLineOutPackages(lable string, start, end int64, step int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "每秒流出包数",
		Unit:     "pps",
		UnitType: "number",
	}

	//query
	var values model.Matrix
	if lable == "" {
		values, err = client.MatrixQuery(temp.NewEipPoolMetics("", "").ToString("eip_pool_used_rate_by_region"), v1.Range{
			Start: time.Unix(start, 0),
			End:   time.Unix(end, 0),
			Step:  15 * time.Second,
		})
		if err != nil {
			return
		}
	} else {
		values, err = client.MatrixQuery(temp.NewEipPoolMetics(lable, "").ToString("eip_pool_used_rate_by_netSegment"), v1.Range{
			Start: time.Unix(start, 0),
			End:   time.Unix(end, 0),
			Step:  15 * time.Second,
		})
		if err != nil {
			return
		}
	}

	for _, i := range values {
		for _, j := range i.Values {
			rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: fmt.Sprintf(".%4f", j.Value.String())}
			r.Values = append(r.Values, rr)
		}
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryPoolLineInPackages(lable string, start, end int64, step int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "每秒流入包数",
		Unit:     "pps",
		UnitType: "number",
	}

	//query
	var values model.Matrix
	if lable == "" {
		values, err = client.MatrixQuery(temp.NewEipPoolMetics("", "").ToString("eip_pool_used_rate_by_region"), v1.Range{
			Start: time.Unix(start, 0),
			End:   time.Unix(end, 0),
			Step:  15 * time.Second,
		})
		if err != nil {
			return
		}
	} else {
		values, err = client.MatrixQuery(temp.NewEipPoolMetics(lable, "").ToString("eip_pool_used_rate_by_netSegment"), v1.Range{
			Start: time.Unix(start, 0),
			End:   time.Unix(end, 0),
			Step:  15 * time.Second,
		})
		if err != nil {
			return
		}
	}

	for _, i := range values {
		for _, j := range i.Values {
			rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: fmt.Sprintf(".%4f", j.Value.String())}
			r.Values = append(r.Values, rr)
		}
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}

//eipPoolList
func (ps *EipPoolService) GetEipPoolList(q *eipmodels.EipPoolListQuery) (rst eipmodels.EipPoolListResult, err error) {
	klog.Infof("get eipPool overview ,region: %s, azs: %q", q.Region, q.Az)
	//rst := eipmodels.EipPoolListResult{}

	if q.SearchKey != "" && q.SearchValue != "" {
		switch q.SearchKey {
		case "pool":
			q.Pool = q.SearchValue
		}
	}

	hostUrlPost := eipmodels.EipPoolListQuery{}
	cmdb, err := GetCmdbEipPoolList(hostUrlPost)
	if err != nil {
		return
	}
	cs := cmdb.Data
	klog.Info("cs")
	klog.Info(cs)

	if cmdb.Code != 200 {
		err = errors.Errorf("get data from nova cmdb error!")
		return
	}
	count := len(cs.DataList)

	for i := 0; i < count; i++ {

		j := cs.DataList[i]
		pb, _ := regexp.MatchString(q.Pool, j.Cidr)
		if (pb || q.Pool == "") && (q.Region == j.RegionCode || q.Region == "") {
			m := eipmodels.EipPool{
				NetSegment:  j.Cidr,
				Region:      j.RegionName,
				EipTotal:    j.IpCount,
				IpUsedRate:  services.FormPercent(float64(j.UsedIpCount) / float64(j.IpCount)),
				IpAvaRate:   services.FormPercent(float64(j.RemainingIpCount) / float64(j.IpCount)),
				AlertNumber: 0,
				CreateTime:  j.CreateTime,
				Label:       "",
			}
			rst.DataList = append(rst.DataList, m)
		}

	}

	//order
	if q.OrderCode != "" && q.OrderType != "" {
		results := alert.Bucket{}
		for i := 0; i < len(rst.DataList); i++ {
			results.Slice = append(results.Slice, rst.DataList[i])
		}
		time_by := func(a, b interface{}) bool {
			return true
		}
		switch q.OrderCode {
		case "ipUsedRate":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(eipmodels.EipPool).IpUsedRate < b.(eipmodels.EipPool).IpUsedRate
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(eipmodels.EipPool).IpUsedRate > b.(eipmodels.EipPool).IpUsedRate
				}
			}

		case "ipAvaRate":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(eipmodels.EipPool).IpAvaRate < b.(eipmodels.EipPool).IpAvaRate
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(eipmodels.EipPool).IpAvaRate > b.(eipmodels.EipPool).IpAvaRate
				}
			}
		case "createTime":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return float64(a.(eipmodels.EipPool).CreateTime) < float64(b.(eipmodels.EipPool).CreateTime)
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return float64(a.(eipmodels.EipPool).CreateTime) > float64(b.(eipmodels.EipPool).CreateTime)
				}
			}
		}

		results.By = time_by

		sort.Sort(results)
		for i := 0; i < len(results.Slice); i++ {
			rst.DataList[i] = results.Slice[i].(eipmodels.EipPool)
		}
	}

	low := (q.PageNo - 1) * q.PageSize
	if low > len(rst.DataList) {
		return rst, nil
	}

	hight := low + q.PageSize
	if hight > len(rst.DataList) {
		hight = len(rst.DataList)
	}

	rst.PageNo = q.PageNo
	rst.PageSize = q.PageSize
	rst.TotalCount = len(rst.DataList)
	rst.DataList = rst.DataList[low:hight]

	return rst, nil
}

//库存列表
func (ps *EipPoolService) GetEipPoolUsage(q *eipmodels.EipPoolListQuery) (rst eipmodels.EipPoolUsageResult, err error) {
	klog.Infof("get eipPool overview ,region: %s, azs: %q", q.Region, q.Az)
	//rst := eipmodels.EipPoolListResult{}

	hostUrlPost := eipmodels.EipPoolListQuery{}
	cmdb, err := GetCmdbEipPoolList(hostUrlPost)
	if err != nil {
		return
	}
	cs := cmdb.Data
	klog.Info("cs")
	klog.Info(cs)

	if cmdb.Code != 200 {
		err = errors.Errorf("get data from nova cmdb error!")
		return
	}
	count := len(cs.DataList)

	for i := 0; i < count; i++ {

		j := cs.DataList[i]
		pb, _ := regexp.MatchString(q.Pool, j.Cidr)
		if (pb || q.Pool == "") && (q.Region == j.RegionCode || q.Region == "") {
			m := eipmodels.EipPoolUsage{
				Region:     j.RegionName,
				Pool:       j.Cidr,
				IpVersion:  j.IpVersion,
				IpTotal:    j.IpCount,
				UsedNum:    j.UsedIpCount,
				AvaNum:     j.RemainingIpCount,
				ReserveNum: j.RetainedIpCount,
				UsedRate:   services.FormPercent(float64(j.UsedIpCount) / float64(j.IpCount)),
				AvaRate:    services.FormPercent(float64(j.RemainingIpCount) / float64(j.IpCount)),
				CreateTime: j.CreateTime,
			}
			rst.DataList = append(rst.DataList, m)
		}

	}

	//order
	if q.OrderCode != "" && q.OrderType != "" {
		results := alert.Bucket{}
		for i := 0; i < len(rst.DataList); i++ {
			results.Slice = append(results.Slice, rst.DataList[i])
		}
		time_by := func(a, b interface{}) bool {
			return true
		}
		switch q.OrderCode {
		case "usedRate":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(eipmodels.EipPoolUsage).UsedRate < b.(eipmodels.EipPoolUsage).UsedRate
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(eipmodels.EipPoolUsage).UsedRate > b.(eipmodels.EipPoolUsage).UsedRate
				}
			}

		case "avaRate":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return a.(eipmodels.EipPoolUsage).AvaRate < b.(eipmodels.EipPoolUsage).AvaRate
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return a.(eipmodels.EipPoolUsage).AvaRate > b.(eipmodels.EipPoolUsage).AvaRate
				}
			}
		case "createTime":
			switch q.OrderType {
			case "asc":
				time_by = func(a, b interface{}) bool {
					return float64(a.(eipmodels.EipPoolUsage).CreateTime) < float64(b.(eipmodels.EipPoolUsage).CreateTime)
				}
			case "desc":
				time_by = func(a, b interface{}) bool {
					return float64(a.(eipmodels.EipPoolUsage).CreateTime) > float64(b.(eipmodels.EipPoolUsage).CreateTime)
				}
			}
		}

		results.By = time_by

		sort.Sort(results)
		for i := 0; i < len(results.Slice); i++ {
			rst.DataList[i] = results.Slice[i].(eipmodels.EipPoolUsage)
		}
	}

	low := (q.PageNo - 1) * q.PageSize
	if low > len(rst.DataList) {
		return rst, nil
	}

	hight := low + q.PageSize
	if hight > len(rst.DataList) {
		hight = len(rst.DataList)
	}

	rst.PageNo = q.PageNo
	rst.PageSize = q.PageSize
	rst.TotalCount = len(rst.DataList)
	rst.DataList = rst.DataList[low:hight]

	return rst, nil
}

var eipPoolMetricLineMap = map[string]func(id string, start, end int64, step int) (eipmodels.MetricLineType, error){
	"outFlow":     QueryPoolMetricLineOutFlow,
	"inFlow":      QueryPoolMetricLineInFlow,
	"outPackages": QueryPoolMetricLineOutPackages,
	"inPackages":  QueryPoolMetricLineInPackages,
}

func (ps *EipPoolService) GetEipPoolMetricLine(q *eipmodels.EipPoolMetricLineQuery) (rst []eipmodels.MetricLineType, err error) {
	klog.Infof("get eipPool metric ,ip: %s", q.NetSegment)

	step := services.TimeToStepForInt(q.End - q.Start)
	//k, _ := strconv.Atoi(q.TopK)
	for _, name := range q.Name {
		if op, ok := eipPoolMetricLineMap[name]; ok {
			result, errOp := op(q.NetSegment, q.Start, q.End, step)
			if errOp != nil {
				klog.Error(errOp)
				continue
			}
			rst = append(rst, result)
		}
	}
	return rst, nil
}

func QueryPoolMetricLineOutFlow(id string, start, end int64, step int) (rst eipmodels.MetricLineType, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "出口流量",
		Unit:     "bps",
		UnitType: "storage",
	}

	//query
	values, err := client.MatrixQuery(temp.NewEipPoolMetics("cn-shanghai-2", id).ToString("eip_pool_used_rate_by_netSegment"), v1.Range{
		Start: time.Unix(start, 0),
		End:   time.Unix(end, 0),
		Step:  15 * time.Second,
	})
	if err != nil {
		return
	}

	for _, i := range values {
		for _, j := range i.Values {
			rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: fmt.Sprintf(".%4f", j.Value.String())}
			r.Values = append(r.Values, rr)
		}
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryPoolMetricLineInFlow(id string, start, end int64, step int) (rst eipmodels.MetricLineType, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "入口流量",
		Unit:     "bps",
		UnitType: "storage",
	}

	//query
	values, err := client.MatrixQuery(temp.NewEipPoolMetics("cn-shanghai-2", id).ToString("eip_pool_used_rate_by_netSegment"), v1.Range{
		Start: time.Unix(start, 0),
		End:   time.Unix(end, 0),
		Step:  15 * time.Second,
	})
	if err != nil {
		return
	}

	for _, i := range values {
		for _, j := range i.Values {
			rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: fmt.Sprintf(".%4f", j.Value.String())}
			r.Values = append(r.Values, rr)
		}
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryPoolMetricLineOutPackages(id string, start, end int64, step int) (rst eipmodels.MetricLineType, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "每秒流出包数",
		Unit:     "pps",
		UnitType: "number",
	}

	//query
	values, err := client.MatrixQuery(temp.NewEipPoolMetics("cn-shanghai-2", id).ToString("eip_pool_used_rate_by_netSegment"), v1.Range{
		Start: time.Unix(start, 0),
		End:   time.Unix(end, 0),
		Step:  15 * time.Second,
	})
	if err != nil {
		return
	}

	for _, i := range values {
		for _, j := range i.Values {
			rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: fmt.Sprintf(".%4f", j.Value.String())}
			r.Values = append(r.Values, rr)
		}
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryPoolMetricLineInPackages(id string, start, end int64, step int) (rst eipmodels.MetricLineType, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "每秒流入包数",
		Unit:     "pps",
		UnitType: "number",
	}

	//query
	values, err := client.MatrixQuery(temp.NewEipPoolMetics("cn-shanghai-2", id).ToString("eip_pool_used_rate_by_netSegment"), v1.Range{
		Start: time.Unix(start, 0),
		End:   time.Unix(end, 0),
		Step:  15 * time.Second,
	})
	if err != nil {
		return
	}

	for _, i := range values {
		for _, j := range i.Values {
			rr := services.ValueType{Name: j.Timestamp.String(), TimeSteamp: j.Timestamp.String(), Value: fmt.Sprintf(".%4f", j.Value.String())}
			r.Values = append(r.Values, rr)
		}
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/eip/util.go
```golang
package eip

import (
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"strings"

	"github.com/pkg/errors"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	eipmodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/eip"
	"k8s.io/klog/v2"
	//"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
)

func GetCmdbEipCount(param eipmodels.EipListQuery) (int, error) {
	klog.Infof("GetCmdbEipCount paramq %+v", param)
	c := http.Client{}
	cmdb := eipmodels.CmdbEipListResponse{}
	request := eipmodels.EipListQuery{
		PageNo:     1,
		PageSize:   1,
		BoundState: param.BoundState,
		//BoundType:  param.BoundType,
	}
	jsons, _ := json.Marshal(request)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/eip/cloudProduct/eipList", "application/json", jsoninfo)
	if err != nil {
		fmt.Println("err" + err.Error())
		return 0, err
	}
	b, _ := io.ReadAll(resp.Body)

	err = json.Unmarshal(b, &cmdb)
	if err != nil {
		return 0, err
	}
	klog.Infof("GetCmdbEipBoundStateCount  %+v", cmdb.Data.TotalCount)
	return cmdb.Data.TotalCount, nil
}

func GetCmdbEipList(q eipmodels.EipListQuery) (eipmodels.CmdbEipListResponse, error) {
	c := http.Client{}
	klog.Infof("q eipmodels.EipListQuery  %+v", q)
	cmdb := eipmodels.CmdbEipListResponse{}
	count, countErr := GetCmdbEipCount(q)
	if count == 0 {
		klog.Errorf("Failed to get EIP conut %d", count)
		return cmdb, nil
	}
	if countErr != nil {
		klog.Errorf("Failed to get EIP conut  countErr %+v", countErr)
		return cmdb, countErr
	}

	if q.PageSize == 0 { // 未传PageSize 获取全部数据
		q.PageSize = count
	}

	jsons, _ := json.Marshal(q)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)
	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/eip/cloudProduct/eipList", "application/json", jsoninfo)

	if err != nil {
		fmt.Println("err" + err.Error())
		return cmdb, err
	}

	b, _ := io.ReadAll(resp.Body)

	err = json.Unmarshal(b, &cmdb)
	if err != nil {
		return cmdb, err
	}
	return cmdb, nil
}

func GetCmdbEipPoolList(q eipmodels.EipPoolListQuery) (eipmodels.CmdbEipPoolListResponse, error) {
	c := http.Client{}
	klog.Info("q")
	klog.Info(q)
	//cmdbCount := services.GetMutilAzTotalCount("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/switch/list", "post")

	//cs := CmdbVms{}
	// cmdbData := switchmodels.CmdbSwitchs{
	// 	DataList: make([]switchmodels.SwitchNew, 0, cmdbCount),
	// }

	cmdb := eipmodels.CmdbEipPoolListResponse{}
	count, countErr := GetCmdbEipCount(eipmodels.EipListQuery{})
	if count == 0 {
		klog.Errorf("Failed to get EIP conut %d", count)
		return cmdb, nil
	}
	if countErr != nil {
		klog.Errorf("Failed to get EIP conut  countErr %+v", countErr)
		return cmdb, countErr
	}

	request := eipmodels.CmdbEipPoolListQuery{PageNo: 1, PageSize: count}
	jsons, _ := json.Marshal(request)
	result := string(jsons)
	jsoninfo := strings.NewReader(result)

	resp, err := c.Post("http://"+config.GetDefaultUrl(config.CMDBService)+"/cmdb/v1/instance/eip/resourcePool/resourceList", "application/json", jsoninfo)

	if err != nil {
		fmt.Println("err" + err.Error())
		return cmdb, err
	}

	b, _ := io.ReadAll(resp.Body)

	err = json.Unmarshal(b, &cmdb)
	if err != nil {
		return cmdb, err
	}

	return cmdb, nil
}

func GenerateEipToIdMap() (map[string]string, error) {

	rst := make(map[string]string)
	hostUrlPost := eipmodels.EipListQuery{}
	cmdb, err := GetCmdbEipList(hostUrlPost)
	if err != nil {
		return rst, err
	}
	cs := cmdb.Data

	if cmdb.Code != 200 {
		err = errors.Errorf("get data from nova cmdb error!")
		return rst, err
	}
	count := len(cs.DataList)
	klog.Infof("eipcount:%d", count)

	for i := 0; i < count; i++ {

		j := cs.DataList[i]
		if j.IpAddr != "" && j.Id != "" && j.BoundState == 3 {
			rst[j.IpAddr] = "ksceip--" + j.Id
		}

		// for _, v := range rst.NetSegmentList {
		// 	if v == j.Cidr {
		// 		continue
		// 	} else {
		// 		rst.NetSegmentList = append(rst.NetSegmentList, j.Cidr)
		// 	}
		// }

	}
	return rst, nil
}

func GenerateEipToIdMapByNetSegment(netSegment string) (map[string]string, error) {

	rst := make(map[string]string)
	hostUrlPost := eipmodels.EipListQuery{}
	cmdb, err := GetCmdbEipList(hostUrlPost)
	if err != nil {
		return rst, err
	}
	cs := cmdb.Data
	klog.Info("cs")
	klog.Info(cs)

	if cmdb.Code != 200 {
		err = errors.Errorf("get data from nova cmdb error!")
		return rst, err
	}
	count := len(cs.DataList)

	for i := 0; i < count; i++ {

		j := cs.DataList[i]
		if (j.IpAddr == "" || j.BoundId == "") && (j.Cidr == netSegment) {

			rst[j.IpAddr] = j.BoundId
		}

	}
	return rst, nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/eip/eip.go
```golang
package eip

import (
	"context"
	"encoding/json"
	"fmt"
	"github.com/go-redis/redis/v8"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/client"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models"
	eipmodels "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/models/eip"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	alert "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/alertmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/cloudproduct"
	kts "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/ktsmanager"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services/physicalSwitch"
	temp "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/template/opentsdb"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/utils"
	"k8s.io/klog/v2"
	"sort"
	"strconv"
	"strings"
	"sync"
	"time"
	// "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/services"
	// "gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
)

type IEip interface {
	GetEipOverview(*eipmodels.EipOverviewQuery) (eipmodels.OverView, error)
	GetEipOverviewLine(*eipmodels.EipOverviewLineQuery) ([]eipmodels.OverviewLineData, error)
	GetEipTopNew(*eipmodels.EipOverviewLineQuery) ([]eipmodels.OverviewLineData, error)
	GetEipOverviewTop(*eipmodels.EipOverviewLineQuery) ([]eipmodels.OverviewLineData, error)
	GetEipList(*eipmodels.EipListQuery) (eipmodels.EipListResult, error)
	GetEiprEsourcesList() ([]eipmodels.Clusters, error)
	GetEipMetricLine(*eipmodels.EipMetricLineQuery) ([]eipmodels.MetricLineType, error)
}

type EipService struct {
}

func NewEipService() *EipService {
	return &EipService{}
}

func (ps *EipService) GetEipTopNew(param *eipmodels.EipOverviewLineQuery) ([]eipmodels.OverviewLineData, error) {
	ctx, cefl := context.WithTimeout(context.Background(), 5*time.Minute)
	defer cefl()

	//获取时间间隔
	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	topK, _ := strconv.ParseInt(param.TopK, 10, 64)

	//获取redis集合Key
	param1 := cloudproduct.GetResourceRedisKeyParam{
		ResourceType: config.CloudEipResource,
		Region:       param.Region,
		Az:           param.Az,
		IntervalStr:  intervalStr,
	}
	redisKeyList, err := cloudproduct.GetResourceRedisKeyList(&param1)
	if err != nil {
		return []eipmodels.OverviewLineData{}, err
	}
	klog.Infof("redisKeyList %+v", redisKeyList)

	rst := make([]eipmodels.OverviewLineData, 0, 4)
	name := param.Name
	for i := 0; i < len(name); i++ {
		switch name[i] {
		case "outBandRate":
			r := eipmodels.OverviewLineData{Name: name[i], Unit: "%"}
			rr := eipmodels.Echart{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			//rr.Info.UnitType = "percent"

			var eipOutBandLit []services.ValueType
			vmCpuKeys := redisKeyList["EipUtilizationOut"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmCpuKeys {
				//获取集合数据
				eipListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]services.ValueType, len(eipListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(eipListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				eipOutBandLit = append(eipOutBandLit, vmlist...)
			}

			eipOutBandCont := len(eipOutBandLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(eipOutBandCont) > topK {
				//排序
				eipOutBandLit = physicalSwitch.InterfaceValueOrder(eipOutBandLit, "desc")
				if int64(len(eipOutBandLit)) >= topK {
					eipOutBandLit = eipOutBandLit[:topK]
				}
			}
			rr.Values = eipOutBandLit
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "inBandRate":
			r := eipmodels.OverviewLineData{Name: name[i], Unit: "%"}
			rr := eipmodels.Echart{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "%"
			//rr.Info.UnitType = "percent"

			var eipOutBandLit []services.ValueType
			vmCpuKeys := redisKeyList["EipUtilizationIn"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmCpuKeys {
				//获取集合数据
				eipListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]services.ValueType, len(eipListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(eipListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				eipOutBandLit = append(eipOutBandLit, vmlist...)
			}

			eipOutBandCont := len(eipOutBandLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(eipOutBandCont) > topK {
				//排序
				eipOutBandLit = physicalSwitch.InterfaceValueOrder(eipOutBandLit, "desc")
				if int64(len(eipOutBandLit)) >= topK {
					eipOutBandLit = eipOutBandLit[:topK]
				}
			}
			rr.Values = eipOutBandLit
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "outFlow":
			r := eipmodels.OverviewLineData{Name: name[i], Unit: "bps"}
			rr := eipmodels.Echart{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "bps"
			rr.Info.UnitType = "storage"

			var eipOutBandLit []services.ValueType
			vmCpuKeys := redisKeyList["EipPpsOut"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmCpuKeys {
				//获取集合数据
				eipListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]services.ValueType, len(eipListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(eipListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				eipOutBandLit = append(eipOutBandLit, vmlist...)
			}

			eipOutBandCont := len(eipOutBandLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(eipOutBandCont) > topK {
				//排序
				eipOutBandLit = physicalSwitch.InterfaceValueOrder(eipOutBandLit, "desc")
				if int64(len(eipOutBandLit)) >= topK {
					eipOutBandLit = eipOutBandLit[:topK]
				}
			}
			rr.Values = eipOutBandLit
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "inFlow":
			r := eipmodels.OverviewLineData{Name: name[i], Unit: "bps"}
			rr := eipmodels.Echart{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "bps"
			rr.Info.UnitType = "storage"

			var eipOutBandLit []services.ValueType
			vmCpuKeys := redisKeyList["EipPpsIn"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmCpuKeys {
				//获取集合数据
				eipListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]services.ValueType, len(eipListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(eipListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				eipOutBandLit = append(eipOutBandLit, vmlist...)
			}

			eipOutBandCont := len(eipOutBandLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(eipOutBandCont) > topK {
				//排序
				eipOutBandLit = physicalSwitch.InterfaceValueOrder(eipOutBandLit, "desc")
				if int64(len(eipOutBandLit)) >= topK {
					eipOutBandLit = eipOutBandLit[:topK]
				}
			}
			rr.Values = eipOutBandLit
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "outPackages":
			r := eipmodels.OverviewLineData{Name: name[i], Unit: "pps"}
			rr := eipmodels.Echart{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "pps"
			rr.Info.UnitType = "number"
			var eipOutBandLit []services.ValueType
			vmCpuKeys := redisKeyList["EipBpsOut"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmCpuKeys {
				//获取集合数据
				eipListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]services.ValueType, len(eipListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(eipListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				eipOutBandLit = append(eipOutBandLit, vmlist...)
			}

			eipOutBandCont := len(eipOutBandLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(eipOutBandCont) > topK {
				//排序
				eipOutBandLit = physicalSwitch.InterfaceValueOrder(eipOutBandLit, "desc")
				if int64(len(eipOutBandLit)) >= topK {
					eipOutBandLit = eipOutBandLit[:topK]
				}
			}
			rr.Values = eipOutBandLit
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		case "inPackages":
			r := eipmodels.OverviewLineData{Name: name[i], Unit: "pps"}
			rr := eipmodels.Echart{}
			rr.Info.Name = name[i]
			rr.Info.Unit = "pps"
			rr.Info.UnitType = "number"

			var eipOutBandLit []services.ValueType
			vmCpuKeys := redisKeyList["EipBpsIn"] //获取当前metric Key
			//根据key循环获取集合数据
			for _, key := range vmCpuKeys {
				//获取集合数据
				eipListStr, _ := client.ZRevRange(ctx, key, 0, topK-1)
				var vmlist = make([]services.ValueType, len(eipListStr))
				//解析成json
				vmSliceStr := "[" + strings.Join(eipListStr, ",") + "]"
				err := json.Unmarshal([]byte(vmSliceStr), &vmlist)
				if err != nil {
					klog.Errorf("err ", err)
				}
				if len(vmlist) == 0 {
					continue
				}
				eipOutBandLit = append(eipOutBandLit, vmlist...)
			}

			eipOutBandCont := len(eipOutBandLit)
			//如果集合数据长度超出topK 获取所有key集合数据内数据并且排序
			if int64(eipOutBandCont) > topK {
				//排序
				eipOutBandLit = physicalSwitch.InterfaceValueOrder(eipOutBandLit, "desc")
				if int64(len(eipOutBandLit)) >= topK {
					eipOutBandLit = eipOutBandLit[:topK]
				}
			}
			rr.Values = eipOutBandLit
			r.Echarts = append(r.Echarts, rr)
			rst = append(rst, r)
		}
	}

	return rst, nil
}

func (ps *EipService) GetEipOverviewTop(param *eipmodels.EipOverviewLineQuery) (rst []eipmodels.OverviewLineData, err error) {
	interval := (param.End - param.Start) / 1000 / 60
	intervalStr := strconv.Itoa(int(interval))
	var nameStr string
	for _, v := range param.Name {
		nameStr += v + "_"
	}

	key := "eip_overviewTop"
	fieldKey := "name_" + nameStr + "topk_" + param.TopK + "_interval_" + intervalStr + "_region" + param.Region + "_Az" + param.Az
	klog.Infof("eip OverviewTop fieldKey", fieldKey)

	redisCon := config.RedisConfig
	var rdb *redis.Client
	rdb = redis.NewClient(&redis.Options{
		Addr:       redisCon["Host"].(string),
		Password:   redisCon["Password"].(string),
		DB:         redisCon["Db"].(int),
		MaxRetries: redisCon["MaxRetries"].(int),
	})

	cache, err := utils.NewRedisCache(rdb, key)
	if err != nil {
		klog.Error("get utils.NewRedisCache failed", err)
		return []eipmodels.OverviewLineData{}, nil
	}
	result, err := rdb.Ping(context.Background()).Result()
	if err != nil {
		klog.Error("Ping redis failed", err)
		return []eipmodels.OverviewLineData{}, nil
	}

	klog.Infof("result %s", result)
	after := time.After(time.Second * 60)

	for {
		select {
		case <-time.After(time.Second):
			data, err := cache.GetData(context.Background(), fieldKey, GetEipTop(param), time.Minute*10)
			if err != nil {
				klog.Error("eip GetData err ", err)
			}
			if data == "" {
				continue
			}
			var list []eipmodels.OverviewLineData
			ee := json.Unmarshal([]byte(data), &list)
			if ee != nil {
				klog.Error("Parsing JSON failed", ee)
			}

			klog.Infof("data:%s", list)
			return list, nil
		case <-after:
			return []eipmodels.OverviewLineData{}, nil
		}
	}

	return rst, nil
}

func GetEipTop(param *eipmodels.EipOverviewLineQuery) func() (data string, err error) {
	klog.Info("GetEipTop")
	return func() (data string, err error) {

		rst := make([]eipmodels.OverviewLineData, 0, 4)

		start := strconv.FormatFloat(param.Start/1000, 'f', 3, 64)
		end := strconv.FormatFloat(param.End/1000, 'f', 3, 64)
		topk, _ := strconv.Atoi(param.TopK)

		if param.Region == "" {
			param.Region = "all"
		}
		az := []string{}
		if param.Az == "all" || param.Az == "" {
			az = []string{}
		} else {
			az = append(az, param.Az)
		}

		hostUrlPost := eipmodels.EipListQuery{
			PageNo:     1,
			Region:     param.Region,
			Az:         az,
			BoundState: []int{3}, // 只获取以绑定以分配的
		}

		cmdbEip, err := GetCmdbEipList(hostUrlPost)
		list := cmdbEip.Data.DataList
		count := len(cmdbEip.Data.DataList)
		klog.Infof("csNum %d", count)

		var eipList []eipmodels.EipTop

		for _, v := range list {
			if v.IpAddr != "" && v.Id != "" {
				eipInfo := eipmodels.EipTop{}
				eipInfo.ID = "ksceip--" + v.Id
				eipInfo.Name = v.IpAddr
				eipList = append(eipList, eipInfo)
			}

		}

		for _, name := range param.Name {
			if op, ok := EipOverviewTopMapK[name]; ok {
				result, errOp := op(eipList, name, start, end, topk)
				if errOp != nil {
					klog.Error(errOp)
					continue
				}
				rst = append(rst, result...)
			}
		}
		resq, _ := json.Marshal(rst)
		return string(resq), nil
	}
}

var EipOverviewTopMapK = map[string]func(list []eipmodels.EipTop, name, start, end string, k int) ([]eipmodels.OverviewLineData, error){
	"outBandRate": QueryTopOutBandRateNew, //出向带宽使用百分比
	"inBandRate":  QueryTopInBandRateNew,  // 入向带宽使用百分比
	"outFlow":     QueryTopOutFlowNew,     // 出网流量
	"inFlow":      QueryTopInFlowNew,      // 入网流量
	"outPackages": QueryTopOutPackagesNew, // 每秒流出包数
	"inPackages":  QueryTopInPackagesNew,  //每秒流入包数
}

//topk 出向带宽使用百分比
func QueryTopOutBandRateNew(list []eipmodels.EipTop, name, start, end string, topk int) ([]eipmodels.OverviewLineData, error) {
	klog.Info("outBandRate", "出向带宽使用百分比")

	rst := make([]eipmodels.OverviewLineData, 0, 4)
	result := eipmodels.OverviewLineData{Name: name, Unit: "%"}

	// 出向带宽使用百分比
	echarts := eipmodels.Echart{}
	echarts.Info.Name = "出向带宽使用百分比"
	echarts.Info.Unit = "%"
	//echarts.Info.UnitType = "percent"
	for j := 0; j < len(list); j++ {
		metric := []string{"EipUtilizationOut"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := EipValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := services.ValueType{Value: valueFloat, Name: out[o].Name, Id: out[o].ID}
		echarts.Values = append(echarts.Values, v)
	}
	result.Echarts = append(result.Echarts, echarts)

	rst = append(rst, result)

	return rst, nil
}

//topk  入向带宽使用百分比
func QueryTopInBandRateNew(list []eipmodels.EipTop, name, start, end string, topk int) ([]eipmodels.OverviewLineData, error) {
	klog.Info("inBandRate", "入向带宽使用百分比")

	rst := make([]eipmodels.OverviewLineData, 0, 4)
	result := eipmodels.OverviewLineData{Name: name, Unit: "%"}

	// 出向带宽使用百分比
	echarts := eipmodels.Echart{}
	echarts.Info.Name = "入向带宽使用百分比"
	echarts.Info.Unit = "%"
	echarts.Info.UnitType = "percent"
	for j := 0; j < len(list); j++ {
		metric := []string{"EipUtilizationIn"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := EipValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := services.ValueType{Value: valueFloat, Name: out[o].Name, Id: out[o].ID}
		echarts.Values = append(echarts.Values, v)
	}
	result.Echarts = append(result.Echarts, echarts)

	rst = append(rst, result)

	return rst, nil
}

//topk  出网流量
func QueryTopOutFlowNew(list []eipmodels.EipTop, name, start, end string, topk int) ([]eipmodels.OverviewLineData, error) {
	klog.Info("outFlow", "出网流量")

	rst := make([]eipmodels.OverviewLineData, 0, 4)
	result := eipmodels.OverviewLineData{Name: name, Unit: "%"}

	echarts := eipmodels.Echart{}
	echarts.Info.Name = "出网流量"
	echarts.Info.Unit = "pps"
	echarts.Info.UnitType = "storage"
	for j := 0; j < len(list); j++ {
		metric := []string{"EipPpsOut"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := EipValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := services.ValueType{Value: valueFloat, Name: out[o].Name, Id: out[o].ID}
		echarts.Values = append(echarts.Values, v)
	}
	result.Echarts = append(result.Echarts, echarts)

	rst = append(rst, result)

	return rst, nil
}

//topk  入网流量
func QueryTopInFlowNew(list []eipmodels.EipTop, name, start, end string, topk int) ([]eipmodels.OverviewLineData, error) {
	klog.Info("InFlow", "入网流量")

	rst := make([]eipmodels.OverviewLineData, 0, 4)
	result := eipmodels.OverviewLineData{Name: name, Unit: "%"}

	echarts := eipmodels.Echart{}
	echarts.Info.Name = "入网流量"
	echarts.Info.Unit = "pps"
	echarts.Info.UnitType = "storage"
	for j := 0; j < len(list); j++ {
		metric := []string{"EipPpsIn"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := EipValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := services.ValueType{Value: valueFloat, Name: out[o].Name, Id: out[o].ID}
		echarts.Values = append(echarts.Values, v)
	}
	result.Echarts = append(result.Echarts, echarts)

	rst = append(rst, result)

	return rst, nil
}

//topk  每秒流出包数
func QueryTopOutPackagesNew(list []eipmodels.EipTop, name, start, end string, topk int) ([]eipmodels.OverviewLineData, error) {
	klog.Info("outPackages", "每秒流出包数")

	rst := make([]eipmodels.OverviewLineData, 0, 4)
	result := eipmodels.OverviewLineData{Name: name, Unit: "%"}

	echarts := eipmodels.Echart{}
	echarts.Info.Name = "入网流量"
	echarts.Info.Unit = "bps"
	echarts.Info.UnitType = "storage"
	for j := 0; j < len(list); j++ {
		metric := []string{"EipBpsOut"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := EipValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := services.ValueType{Value: valueFloat, Name: out[o].Name, Id: out[o].ID}
		echarts.Values = append(echarts.Values, v)
	}
	result.Echarts = append(result.Echarts, echarts)

	rst = append(rst, result)

	return rst, nil
}

//topk  每秒流入包数
func QueryTopInPackagesNew(list []eipmodels.EipTop, name, start, end string, topk int) ([]eipmodels.OverviewLineData, error) {
	klog.Info("inPackages", "每秒流入包数")

	rst := make([]eipmodels.OverviewLineData, 0, 4)
	result := eipmodels.OverviewLineData{Name: name, Unit: "%"}

	echarts := eipmodels.Echart{}
	echarts.Info.Name = "每秒流入包数"
	echarts.Info.Unit = "bps"
	echarts.Info.UnitType = "storage"
	for j := 0; j < len(list); j++ {
		metric := []string{"EipBpsIn"}
		oo := kts.QueryVmMetric(list[j].ID, start, end, metric)
		if len(oo) > 0 {
			list[j].Value = oo[0].Avg
		}
	}
	out := EipValueOrder(list, "desc")
	if len(out) >= topk {
		out = out[:topk]
	}
	for o := 0; o < len(out); o++ {
		valueFloat, _ := strconv.ParseFloat(services.Strval(out[o].Value), 64)
		v := services.ValueType{Value: valueFloat, Name: out[o].Name, Id: out[o].ID}
		echarts.Values = append(echarts.Values, v)
	}
	result.Echarts = append(result.Echarts, echarts)

	rst = append(rst, result)

	return rst, nil
}

func EipValueOrder(in []eipmodels.EipTop, code string) []eipmodels.EipTop {
	results := alert.Bucket{}
	for i := 0; i < len(in); i++ {
		results.Slice = append(results.Slice, in[i])
	}
	time_by := func(a, b interface{}) bool {
		return true
	}

	switch code {
	case "asc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(eipmodels.EipTop).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(eipmodels.EipTop).Value), 64)
			return aa < bb
		}
	case "desc":
		time_by = func(a, b interface{}) bool {
			aa, _ := strconv.ParseFloat(services.Strval(a.(eipmodels.EipTop).Value), 64)
			bb, _ := strconv.ParseFloat(services.Strval(b.(eipmodels.EipTop).Value), 64)
			return aa > bb
		}
	}

	results.By = time_by

	sort.Sort(results)
	for i := 0; i < len(in); i++ {
		in[i] = results.Slice[i].(eipmodels.EipTop)
	}
	return in
}

func (ps *EipService) GetEipOverview(q *eipmodels.EipOverviewQuery) (eipmodels.OverView, error) {
	klog.Infof("get eipPool overview ,region: %s, azs: %q", q.Region, q.Az)
	rst := eipmodels.OverView{Region: string(q.Region), Az: string(q.Az)}
	p0 := models.AlertType{Name: "紧急告警", Level: "p0", Kind: "error", Number: 0, Unit: "个"}
	p1 := models.AlertType{Name: "重要告警", Level: "p1", Kind: "warn", Number: 0, Unit: "个"}
	p2 := models.AlertType{Name: "次要告警", Level: "p2", Kind: "minor", Number: 0, Unit: "个"}
	p3 := models.AlertType{Name: "提醒告警", Level: "p3", Kind: "info", Number: 0, Unit: "个"}

	rst.Alerts = append(rst.Alerts, p0, p1, p2, p3)
	// resourceSubTypeCode := []string{}
	// t := alertmodel.AlertQuery{PageNo: 1, PageSize: 10000, ResourceSubTypeCode: resourceSubTypeCode}

	// res, err := alert.GetAlertsDataListPage(t)
	// if err != nil {
	// 	return rst, err
	// }
	// for _, item := range res.DataList {
	// 	switch item.AlertLevel {
	// 	case "p0":
	// 		p0.Number++
	// 	case "p1":
	// 		p1.Number++
	// 	case "p2":
	// 		p2.Number++
	// 	case "p3":
	// 		p3.Number++
	// 	}
	// }
	//query mysql
	db := services.MakeMysqlClient()
	defer db.Close()
	p0Count, err := db.Exec("select count(*) from alarm_history where producttype=4")
	if err != nil {
		klog.Error(err)
		return rst, nil
	}
	rst.Alerts[0].Number, err = p0Count.LastInsertId()
	if err != nil {
		klog.Error(err)
		return rst, nil
	}

	return rst, nil
}

var eipOverviewTopMap = map[string]func(id, start, end, step string, k int) (eipmodels.OverviewLineData, error){
	"outBandRate": QueryTopOutBandRate,
	"inBandRate":  QueryTopInBandRate,
	"outFlow":     QueryTopOutFlow,
	"inFlow":      QueryTopInFlow,
	"outPackages": QueryTopOutPackages,
	"inPackages":  QueryTopInPackages,
}

var eipOverviewTopMapK = map[string]func(id, start, end, step string, k int) (eipmodels.OverviewLineData, error){
	"outBandRate": QueryTopOutBandRateK,
	"inBandRate":  QueryTopInBandRateK,
	"outFlow":     QueryTopOutFlowK,
	"inFlow":      QueryTopInFlowK,
	"outPackages": QueryTopOutPackagesK,
	"inPackages":  QueryTopInPackagesK,
}

func (ps *EipService) GetEipOverviewLine(q *eipmodels.EipOverviewLineQuery) (rst []eipmodels.OverviewLineData, err error) {
	klog.Infof("get eipPool overviewLine ,region: %s, azs: %q", q.Region, q.Az)
	start := strconv.FormatFloat(q.Start/1000, 'f', 3, 64)
	end := strconv.FormatFloat(q.End/1000, 'f', 3, 64)
	step := services.TimeToStep(q.End - q.Start)
	k, _ := strconv.Atoi(q.TopK)

	//rst := []eipmodels.OverviewLineData{}
	for _, name := range q.Name {
		if op, ok := eipOverviewTopMapK[name]; ok {
			result, errOp := op(name, start, end, step, k)
			if errOp != nil {
				klog.Error(errOp)
				continue
			}
			rst = append(rst, result)
		}
	}

	return
}

//topk
func QueryTopOutBandRateK(id, start, end, step string, k int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "出口向带宽使用百分比",
		Unit:     "%",
		UnitType: "percent",
	}

	//query
	eipMap, err := GenerateEipToIdMap()
	if err != nil {
		return
	}
	if len(eipMap) > 0 {
		//用来判断并发任务是否全部完成
		ipNums := len(eipMap)
		klog.Infof("the count of eip is: %d", ipNums)
		isCompl := make(chan struct{})
		flags := make(chan struct{})
		go func() {
			for i := 0; i < ipNums; i++ {
				flags <- struct{}{}
			}
			close(flags)
			isCompl <- struct{}{}
		}()

		//批量从tsdb中查询数据
		timer := time.NewTimer(time.Second * config.MaxEipSearchDuration)
		lock := sync.Mutex{}
		ctx, cancel := context.WithCancel(context.Background())
		concurrencyLimit := make(chan struct{}, config.ConcurrencyLimit)
		for k, v := range eipMap {
			tags := map[string]string{
				"host": v,
			}
			rangeQ := kts.RangeQuery{
				Aggregator: "sum",
				Metric:     temp.OpenTsdbMetricsMap["eip_band_rate_out"].Sql + "." + v,
				Tags:       tags,
			}
			concurrencyLimit <- struct{}{}
			go func(ctx context.Context, k string) {
				defer func() {
					<-concurrencyLimit
				}()
				select {
				case <-ctx.Done():
					klog.Info("Task canceled")
					return
				default:
					rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
					klog.Infof("rangeRst: %+v", rangeRst)
					if rangeRst != nil && len(rangeRst) > 0 {
						ss := kts.KtsGetSlice(rangeRst[0].Dps)
						avg := services.Form2(kts.GetKtsRangeValueAvg(ss))
						coloum := services.ValueType{Name: k, TimeSteamp: k, Value: avg}
						lock.Lock()
						r.Values = append(r.Values, coloum)
						lock.Unlock()
					}
					<-flags //完成一次数据处理
				}
			}(ctx, k)
		}

		select {
		case <-timer.C:
			klog.Info("Get Metric Data Timeout!")
			cancel()
		case <-isCompl:
			klog.Info("All tasks completed !!!")
			cancel()
		}
	}
	orderRst := kts.KtsValueToOrder(r.Values, "decs")
	klog.Infof("ordered result of eip_band_rate_out: %+v", orderRst)
	if len(orderRst) >= k {
		r.Values = append(r.Values[:0], orderRst[:k]...)
	} else {
		r.Values = append(r.Values, orderRst...)
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryTopInBandRateK(id, start, end, step string, k int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "入口向带宽使用百分比",
		Unit:     "%",
		UnitType: "percent",
	}

	//query
	eipMap, err := GenerateEipToIdMap()
	if err != nil {
		return
	}
	if len(eipMap) > 0 {
		//用来判断并发任务是否全部完成
		ipNums := len(eipMap)
		isCompl := make(chan struct{})
		flags := make(chan struct{})
		go func() {
			for i := 0; i < ipNums; i++ {
				flags <- struct{}{}
			}
			close(flags)
			isCompl <- struct{}{}
		}()

		//批量从tsdb中查询数据
		timer := time.NewTimer(time.Second * config.MaxEipSearchDuration)
		lock := sync.Mutex{}
		ctx, cancel := context.WithCancel(context.Background())
		concurrencyLimit := make(chan struct{}, config.ConcurrencyLimit)
		for k, v := range eipMap {
			tags := map[string]string{
				"host": v,
			}
			rangeQ := kts.RangeQuery{
				Aggregator: "sum",
				Metric:     temp.OpenTsdbMetricsMap["eip_band_rate_in"].Sql + "." + v,
				Tags:       tags,
			}
			concurrencyLimit <- struct{}{}
			go func(ctx context.Context, k string) {
				defer func() {
					<-concurrencyLimit
				}()
				select {
				case <-ctx.Done():
					klog.Info("Task canceled")
					return
				default:
					rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
					if rangeRst != nil && len(rangeRst) > 0 {
						ss := kts.KtsGetSlice(rangeRst[0].Dps)
						avg := services.Form2(kts.GetKtsRangeValueAvg(ss))
						coloum := services.ValueType{Name: k, TimeSteamp: k, Value: avg}
						lock.Lock()
						r.Values = append(r.Values, coloum)
						lock.Unlock()
					}
					<-flags
				}
			}(ctx, k)
		}

		select {
		case <-timer.C:
			klog.Info("Get Metric Data Timeout!")
			cancel()
		case <-isCompl:
			klog.Info("All tasks completed !!!")
			cancel()
		}
	}
	orderRst := kts.KtsValueToOrder(r.Values, "decs")
	//klog.Infof("ordered result of eip_band_rate_in: %+v", orderRst)
	if len(orderRst) >= k {
		r.Values = append(r.Values[:0], orderRst[:k]...)
	} else {
		r.Values = append(r.Values, orderRst...)
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryTopOutFlowK(id, start, end, step string, k int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "出口流量",
		Unit:     "bps",
		UnitType: "storage",
	}

	//query
	eipMap, err := GenerateEipToIdMap()
	if err != nil {
		return
	}

	if len(eipMap) > 0 {

		//所有任务是否完成的标记
		ipNums := len(eipMap)
		isCompl := make(chan struct{})
		flags := make(chan struct{})
		go func() {
			for i := 0; i < ipNums; i++ {
				flags <- struct{}{}
			}
			close(flags)
			isCompl <- struct{}{}
		}()

		//批量从tsdb中查询数据
		timer := time.NewTimer(time.Second * config.MaxEipSearchDuration)
		ctx, cancel := context.WithCancel(context.Background())
		lock := sync.Mutex{}
		concurrencyLimit := make(chan struct{}, config.ConcurrencyLimit)
		for k, v := range eipMap {
			tags := map[string]string{
				"host": v,
			}
			rangeQ := kts.RangeQuery{
				Aggregator: "sum",
				Metric:     temp.OpenTsdbMetricsMap["eip_pps_out"].Sql + "." + v,
				Tags:       tags,
			}

			concurrencyLimit <- struct{}{}
			go func(ctx context.Context, k string) {
				defer func() {
					<-concurrencyLimit
				}()
				select {
				case <-ctx.Done():
					klog.Info("Task canceled")
					return
				default:
					rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
					if rangeRst != nil && len(rangeRst) > 0 {
						ss := kts.KtsGetSlice(rangeRst[0].Dps)
						avg := services.Form2(kts.GetKtsRangeValueAvg(ss))
						coloum := services.ValueType{Name: k, TimeSteamp: k, Value: avg}
						lock.Lock()
						r.Values = append(r.Values, coloum)
						lock.Unlock()
					}
					<-flags
				}
			}(ctx, k)
		}
		select {
		case <-timer.C:
			klog.Info("Get Metric Data Timeout!")
			cancel()
		case <-isCompl:
			klog.Info("All tasks completed")
			cancel()
		}
	}
	orderRst := kts.KtsValueToOrder(r.Values, "decs")
	//klog.Infof("ordered result of eip_pps_out: %+v", orderRst)
	if len(orderRst) >= k {
		r.Values = append(r.Values[:0], orderRst[:k]...)
	} else {
		r.Values = append(r.Values, orderRst...)
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryTopInFlowK(id, start, end, step string, k int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "入口流量",
		Unit:     "bps",
		UnitType: "storage",
	}

	//query
	eipMap, err := GenerateEipToIdMap()
	if err != nil {
		return
	}
	if len(eipMap) > 0 {
		//所有任务是否完成的标记
		ipNums := len(eipMap)
		isCompl := make(chan struct{})
		flags := make(chan struct{})
		go func() {
			for i := 0; i < ipNums; i++ {
				flags <- struct{}{}
			}
			close(flags)
			isCompl <- struct{}{}
		}()
		//批量从tsdb中查询数据
		timer := time.NewTimer(time.Second * config.MaxEipSearchDuration)
		ctx, cancel := context.WithCancel(context.Background())
		lock := sync.Mutex{}
		concurrencyLimit := make(chan struct{}, config.ConcurrencyLimit)
		for k, v := range eipMap {
			tags := map[string]string{
				"host": v,
			}
			rangeQ := kts.RangeQuery{
				Aggregator: "sum",
				Metric:     temp.OpenTsdbMetricsMap["eip_pps_in"].Sql + "." + v,
				Tags:       tags,
			}

			concurrencyLimit <- struct{}{}
			go func(ctx context.Context, k string) {
				defer func() {
					<-concurrencyLimit
				}()
				select {
				case <-ctx.Done():
					klog.Info("Task canceled")
					return
				default:
					rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
					if rangeRst != nil && len(rangeRst) > 0 {
						ss := kts.KtsGetSlice(rangeRst[0].Dps)
						avg := services.Form2(kts.GetKtsRangeValueAvg(ss))
						coloum := services.ValueType{Name: k, TimeSteamp: k, Value: avg}
						lock.Lock()
						r.Values = append(r.Values, coloum)
						lock.Unlock()
					}
					<-flags
				}
			}(ctx, k)
		}
		select {
		case <-timer.C:
			klog.Info("Get Metric Data Timeout!")
			cancel()
		case <-isCompl:
			klog.Info("All tasks completed")
			cancel()
		}
	}
	orderRst := kts.KtsValueToOrder(r.Values, "decs")
	//klog.Infof("ordered result of eip_pps_in: %+v", orderRst)
	if len(orderRst) >= k {
		r.Values = append(r.Values[:0], orderRst[:k]...)
	} else {
		r.Values = append(r.Values, orderRst...)
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryTopOutPackagesK(id, start, end, step string, k int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "每秒流出包数",
		Unit:     "pps",
		UnitType: "number",
	}

	//query
	eipMap, err := GenerateEipToIdMap()
	if err != nil {
		return
	}
	if len(eipMap) > 0 {
		//所有任务是否完成的标记
		ipNums := len(eipMap)
		isCompl := make(chan struct{})
		flags := make(chan struct{})
		go func() {
			for i := 0; i < ipNums; i++ {
				flags <- struct{}{}
			}
			close(flags)
			isCompl <- struct{}{}
		}()
		//批量从tsdb中查询数据
		timer := time.NewTimer(time.Second * config.MaxEipSearchDuration)
		ctx, cancel := context.WithCancel(context.Background())
		lock := sync.Mutex{}
		concurrencyLimit := make(chan struct{}, config.ConcurrencyLimit)
		for k, v := range eipMap {
			tags := map[string]string{
				"host": v,
			}
			rangeQ := kts.RangeQuery{
				Aggregator: "sum",
				Metric:     temp.OpenTsdbMetricsMap["eip_flow_out"].Sql + "." + v,
				Tags:       tags,
			}

			concurrencyLimit <- struct{}{}
			go func(ctx context.Context, k string) {
				defer func() {
					<-concurrencyLimit
				}()
				select {
				case <-ctx.Done():
					klog.Info("Task canceled")
					return
				default:
					rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
					if rangeRst != nil && len(rangeRst) > 0 {
						ss := kts.KtsGetSlice(rangeRst[0].Dps)
						avg := services.Form2(kts.GetKtsRangeValueAvg(ss))
						coloum := services.ValueType{Name: k, TimeSteamp: k, Value: avg}
						lock.Lock()
						r.Values = append(r.Values, coloum)
						lock.Unlock()
					}
					<-flags
				}
			}(ctx, k)
		}
		select {
		case <-timer.C:
			klog.Info("Get Metric Data Timeout!")
			cancel()
		case <-isCompl:
			klog.Info("All tasks completed !!!")
			cancel()
		}
	}
	orderRst := kts.KtsValueToOrder(r.Values, "decs")
	//klog.Infof("ordered result of eip_flow_out: %+v", orderRst)
	if len(orderRst) >= k {
		r.Values = append(r.Values[:0], orderRst[:k]...)
	} else {
		r.Values = append(r.Values, orderRst...)
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryTopInPackagesK(id, start, end, step string, k int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "每秒流入包数",
		Unit:     "pps",
		UnitType: "number",
	}

	//query
	eipMap, err := GenerateEipToIdMap()
	if err != nil {
		return
	}
	if len(eipMap) > 0 {
		//用来判断并发任务是否全部完成
		ipNums := len(eipMap)
		isCompl := make(chan struct{})
		flags := make(chan struct{})
		go func() {
			for i := 0; i < ipNums; i++ {
				flags <- struct{}{}
			}
			close(flags)
			isCompl <- struct{}{}
		}()
		//批量从tsdb中查询数据
		lock := sync.Mutex{}
		timer := time.NewTimer(time.Second * config.MaxEipSearchDuration)
		ctx, cancel := context.WithCancel(context.Background())
		concurrencyLimit := make(chan struct{}, config.ConcurrencyLimit)
		for k, v := range eipMap {
			tags := map[string]string{
				"host": v,
			}
			rangeQ := kts.RangeQuery{
				Aggregator: "sum",
				Metric:     temp.OpenTsdbMetricsMap["eip_flow_in"].Sql + "." + v,
				Tags:       tags,
			}

			concurrencyLimit <- struct{}{}
			go func(ctx context.Context, k string) {
				defer func() {
					<-concurrencyLimit
				}()
				select {
				case <-ctx.Done():
					klog.Info("Task canceled")
					return
				default:
					rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
					if rangeRst != nil && len(rangeRst) > 0 {
						ss := kts.KtsGetSlice(rangeRst[0].Dps)
						avg := services.Form2(kts.GetKtsRangeValueAvg(ss))
						coloum := services.ValueType{Name: k, TimeSteamp: k, Value: avg}
						lock.Lock()
						r.Values = append(r.Values, coloum)
						lock.Unlock()
					}
					<-flags
				}
			}(ctx, k)
		}
		select {
		case <-timer.C:
			klog.Info("Get Metric Data Timeout!")
			cancel()
		case <-isCompl:
			klog.Info("All tasks completed")
			cancel()
		}
	}
	orderRst := kts.KtsValueToOrder(r.Values, "decs")
	//klog.Infof("ordered result of eip_flow_in: %+v", orderRst)
	if len(orderRst) >= k {
		r.Values = append(r.Values[:0], orderRst[:k]...)
	} else {
		r.Values = append(r.Values, orderRst...)
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}

//top
func QueryTopOutBandRate(id, start, end, step string, k int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "出口向带宽使用百分比",
		Unit:     "%",
		UnitType: "percent",
	}

	//query
	eipMap, err := GenerateEipToIdMap()
	if err != nil {
		return
	}
	if len(eipMap) > 0 {
		for k, v := range eipMap {
			tags := map[string]string{
				"host": v,
			}
			rangeQ := kts.RangeQuery{
				Aggregator: "sum",
				Metric:     temp.OpenTsdbMetricsMap["eip_band_rate_out"].Sql + "." + v,
				Tags:       tags,
			}
			rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRst) > 0 {
				ss := kts.KtsGetSlice(rangeRst[0].Dps)
				avg := services.Form2(kts.GetKtsRangeValueAvg(ss))
				coloum := services.ValueType{Name: k, TimeSteamp: k, Value: avg}
				r.Values = append(r.Values, coloum)
			}
		}
	}
	orderRst := kts.KtsValueToOrder(r.Values, "decs")
	if len(orderRst) >= k {
		r.Values = append(r.Values[:0], orderRst[:k]...)
	} else {
		r.Values = append(r.Values, orderRst...)
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryTopInBandRate(id, start, end, step string, k int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "入口向带宽使用百分比",
		Unit:     "%",
		UnitType: "percent",
	}

	//query
	eipMap, err := GenerateEipToIdMap()
	if err != nil {
		return
	}
	if len(eipMap) > 0 {
		for k, v := range eipMap {
			tags := map[string]string{
				"host": v,
			}
			rangeQ := kts.RangeQuery{
				Aggregator: "sum",
				Metric:     temp.OpenTsdbMetricsMap["eip_band_rate_in"].Sql + "." + v,
				Tags:       tags,
			}
			rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRst) > 0 {
				ss := kts.KtsGetSlice(rangeRst[0].Dps)
				avg := services.Form2(kts.GetKtsRangeValueAvg(ss))
				coloum := services.ValueType{Name: k, TimeSteamp: k, Value: avg}
				r.Values = append(r.Values, coloum)
			}
		}
	}
	orderRst := kts.KtsValueToOrder(r.Values, "decs")
	if len(orderRst) >= k {
		r.Values = append(r.Values[:0], orderRst[:k]...)
	} else {
		r.Values = append(r.Values, orderRst...)
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryTopOutFlow(id, start, end, step string, k int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "出口流量",
		Unit:     "bps",
		UnitType: "storage",
	}

	//query
	eipMap, err := GenerateEipToIdMap()
	if err != nil {
		return
	}

	if len(eipMap) > 0 {
		for k, v := range eipMap {
			tags := map[string]string{
				"host": v,
			}
			rangeQ := kts.RangeQuery{
				Aggregator: "sum",
				Metric:     temp.OpenTsdbMetricsMap["eip_pps_out"].Sql + "." + v,
				Tags:       tags,
			}
			rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRst) > 0 {
				ss := kts.KtsGetSlice(rangeRst[0].Dps)
				avg := services.Form2(kts.GetKtsRangeValueAvg(ss))
				coloum := services.ValueType{Name: k, TimeSteamp: k, Value: avg}
				r.Values = append(r.Values, coloum)

			}
		}
	}
	orderRst := kts.KtsValueToOrder(r.Values, "decs")
	if len(orderRst) >= k {
		r.Values = append(r.Values[:0], orderRst[:k]...)
	} else {
		r.Values = append(r.Values, orderRst...)
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryTopInFlow(id, start, end, step string, k int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "入口流量",
		Unit:     "bps",
		UnitType: "storage",
	}

	//query
	eipMap, err := GenerateEipToIdMap()
	if err != nil {
		return
	}
	if len(eipMap) > 0 {
		for k, v := range eipMap {
			tags := map[string]string{
				"host": v,
			}
			rangeQ := kts.RangeQuery{
				Aggregator: "sum",
				Metric:     temp.OpenTsdbMetricsMap["eip_pps_in"].Sql + "." + v,
				Tags:       tags,
			}
			rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRst) > 0 {
				ss := kts.KtsGetSlice(rangeRst[0].Dps)
				avg := services.Form2(kts.GetKtsRangeValueAvg(ss))
				coloum := services.ValueType{Name: k, TimeSteamp: k, Value: avg}
				r.Values = append(r.Values, coloum)

			}
		}
	}
	orderRst := kts.KtsValueToOrder(r.Values, "decs")
	if len(orderRst) >= k {
		r.Values = append(r.Values[:0], orderRst[:k]...)
	} else {
		r.Values = append(r.Values, orderRst...)
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryTopOutPackages(id, start, end, step string, k int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "每秒流出包数",
		Unit:     "pps",
		UnitType: "number",
	}

	//query
	eipMap, err := GenerateEipToIdMap()
	if err != nil {
		return
	}
	if len(eipMap) > 0 {

		for k, v := range eipMap {
			tags := map[string]string{
				"host": v,
			}
			rangeQ := kts.RangeQuery{
				Aggregator: "sum",
				Metric:     temp.OpenTsdbMetricsMap["eip_flow_out"].Sql + "." + v,
				Tags:       tags,
			}
			rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRst) > 0 {
				ss := kts.KtsGetSlice(rangeRst[0].Dps)
				avg := services.Form2(kts.GetKtsRangeValueAvg(ss))
				coloum := services.ValueType{Name: k, TimeSteamp: k, Value: avg}
				r.Values = append(r.Values, coloum)

			}
		}
	}
	orderRst := kts.KtsValueToOrder(r.Values, "decs")
	if len(orderRst) >= k {
		r.Values = append(r.Values[:0], orderRst[:k]...)
	} else {
		r.Values = append(r.Values, orderRst...)
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryTopInPackages(id, start, end, step string, k int) (rst eipmodels.OverviewLineData, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "每秒流入包数",
		Unit:     "pps",
		UnitType: "number",
	}

	//query
	eipMap, err := GenerateEipToIdMap()
	if err != nil {
		return
	}
	if len(eipMap) > 0 {
		for k, v := range eipMap {
			tags := map[string]string{
				"host": v,
			}
			rangeQ := kts.RangeQuery{
				Aggregator: "sum",
				Metric:     temp.OpenTsdbMetricsMap["eip_flow_in"].Sql + "." + v,
				Tags:       tags,
			}
			rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
			if len(rangeRst) > 0 {
				ss := kts.KtsGetSlice(rangeRst[0].Dps)
				avg := services.Form2(kts.GetKtsRangeValueAvg(ss))
				coloum := services.ValueType{Name: k, TimeSteamp: k, Value: avg}
				r.Values = append(r.Values, coloum)

			}
		}
	}
	orderRst := kts.KtsValueToOrder(r.Values, "decs")
	if len(orderRst) >= k {
		r.Values = append(r.Values[:0], orderRst[:k]...)
	} else {
		r.Values = append(r.Values, orderRst...)
	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}

var BandStateMap = map[int]string{
	0: "reserver",
	1: "unallocated",
	2: "unband",
	3: "banded",
}

func (ps *EipService) GetEiprEsourcesList() (rst []eipmodels.Clusters, err error) {

	klog.Info("GetEiprEsourcesList")
	ctx, cefl := context.WithTimeout(context.Background(), 5*time.Second)
	defer cefl()
	clustersList, err := client.Get(ctx, "cmdb_eip_clusters_list", nil)
	err = json.Unmarshal([]byte(clustersList), &rst)
	return rst, err
}

func (ps *EipService) GetEipList(q *eipmodels.EipListQuery) (rst eipmodels.EipListResult, err error) {
	klog.Infof("get eipPool overview ,region: %s, azs: %q", q.Region, q.Az)
	//筛选
	if q.SearchKey != "" && q.SearchValue != "" {
		switch q.SearchKey {
		case "ip":
			q.Ip = q.SearchValue
		}
	}
	// 运行状态
	var boundState []int
	if len(q.State) != 0 {
		for _, v := range q.State {
			switch v {
			case "banded": //已绑定
				boundState = append(boundState, 3)
			case "unband": //已分配未绑定
				boundState = append(boundState, 2)
			case "unallocated": //未分配
				boundState = append(boundState, 1)
			case "reserver": //保留
				boundState = append(boundState, 0)
			}
		}
	}
	// region 转换
	if q.Region == "cn-shanghai-2" {
		q.Region = "SHPBSRegionOne"
	}
	hostUrlPost := eipmodels.EipListQuery{
		Region:      q.Region,
		PageNo:      q.PageNo,
		PageSize:    q.PageSize,
		SearchType:  "ipAddr", //q.SearchValue ,//筛选条件
		SearchValue: q.Ip,
		BoundState:  boundState,   // 绑定状态
		Cidr:        q.NetSegment, //所属网段
		WayType:     q.LineType,   // 线路类型
		PoolName:    q.PoolName,   // 资源池名称
	}
	cmdb, err := GetCmdbEipList(hostUrlPost)
	fmt.Println("cmdbcmdbcmdb", cmdb.Data.DataList)
	if err != nil {
		klog.Error(err)
		return rst, nil
	}
	cs := cmdb.Data
	klog.Infof("csNum: %d", len(cs.DataList))

	if cmdb.Code != 200 {
		klog.Info("get data from nova cmdb error!")
		return rst, nil
	}

	for _, j := range cs.DataList {

		xgwCluster := map[string]string{
			"4": "xgw_eip_default",
			"6": "xgw_eip_ipv6_1",
		}
		m := eipmodels.Eip{
			Id:         j.Id,
			XgwCluster: xgwCluster[j.IpVersion],
			Eip:        j.IpAddr,
			State:      BandStateMap[j.BoundState],
			Region:     j.RegionName,
			NetSegment: j.Cidr,
			LineType:   j.WayType,
			BandWidth:  j.Bandwidth,
			IpVersion:  j.IpVersion,
			HostId:     j.BoundId,
			CreateTime: j.CreateTime,
		}

		//segMentMap
		if !services.In(rst.NetSegmentList, j.Cidr) {
			rst.NetSegmentList = append(rst.NetSegmentList, j.Cidr)
		}
		//已绑定ip才有监控数据
		if j.BoundState == 3 {
			//todo 批量获取监控数据
			eipId := "ksceip--" + m.Id
			klog.Infof("弹性IP id:%s", m.Id)

			//outBandRate  出向带宽利用率
			outBandRateQuery := kts.LastQuery{
				Metric: "eip.utilization.out" + "." + eipId,
				Tags: map[string]string{
					"host": eipId,
				},
			}
			//inBandRate  入向带宽利用率
			inBandRateQuery := kts.LastQuery{
				Metric: "eip.utilization.in" + "." + eipId,
				Tags: map[string]string{
					"host": eipId,
				},
			}
			//outFlow 出网流量
			outFlowQuery := kts.LastQuery{
				Metric: "eip.bps.out" + "." + eipId,
				Tags: map[string]string{
					"host": eipId,
				},
			}
			//inFlow 入网流量
			inFlowQuery := kts.LastQuery{
				Metric: "eip.bps.in" + "." + eipId,
				Tags: map[string]string{
					"host": eipId,
				},
			}
			//outPackages 每秒流出包数
			outPackagesQuery := kts.LastQuery{
				Metric: "eip.pps.out" + "." + eipId,
				Tags: map[string]string{
					"host": eipId,
				},
			}
			//inPackages 每秒流入包数
			inPackagesQuery := kts.LastQuery{
				Metric: "eip.pps.in" + "." + eipId,
				Tags: map[string]string{
					"host": eipId,
				},
			}
			var queries = []kts.LastQuery{outBandRateQuery, inBandRateQuery, outFlowQuery, inFlowQuery, outPackagesQuery, inPackagesQuery}
			//批量获取数据
			metrics, err := kts.TSDBLastQueryBatch(queries...)
			if err != nil {
				klog.Error("err", err)
			}

			outBandRate := metrics[outBandRateQuery.Metric].Value
			inBandRate := metrics[inBandRateQuery.Metric].Value
			outFlow := metrics[outFlowQuery.Metric].Value
			inFlow := metrics[inFlowQuery.Metric].Value
			outPackages := metrics[outPackagesQuery.Metric].Value
			inPackages := metrics[inPackagesQuery.Metric].Value

			//出入带宽百分比
			voutBandRate, _ := strconv.ParseFloat(outBandRate, 64)
			m.OutBandRate = services.FormPercent(voutBandRate / 1e2)
			vinBandRate, _ := strconv.ParseFloat(inBandRate, 64)
			m.InBandRate = services.FormPercent(vinBandRate / 1e2)
			//出入网流量
			voutFlow, _ := strconv.ParseFloat(outFlow, 64)
			m.OutFlow = voutFlow
			vinFlow, _ := strconv.ParseFloat(inFlow, 64)
			m.InFlow = vinFlow
			//每秒流出入包数
			voutPackages, _ := strconv.ParseFloat(outPackages, 64)
			m.OutPackages = voutPackages
			vinPackages, _ := strconv.ParseFloat(inPackages, 64)
			m.InPackages = vinPackages

			//修复outBandRate不存在，导致所有监控都无法取到问题
			if metrics == nil {
				var flowQueries = []kts.LastQuery{outFlowQuery, inFlowQuery}
				//批量获取数据
				flowMetrics, err := kts.TSDBLastQueryBatch(flowQueries...)
				if err != nil {
					klog.Error("第二次取数据 err", err)
				}
				outFlow = flowMetrics[outFlowQuery.Metric].Value
				inFlow = flowMetrics[inFlowQuery.Metric].Value
				//出入网流量
				voutFlow, _ := strconv.ParseFloat(outFlow, 64)
				m.OutFlow = voutFlow
				vinFlow, _ := strconv.ParseFloat(inFlow, 64)
				m.InFlow = vinFlow
			}

		}
		rst.DataList = append(rst.DataList, m)
	}

	rst.PageStruct.TotalCount = cs.TotalCount
	rst.PageStruct.PageNo = q.PageNo
	rst.PageStruct.PageSize = q.PageSize

	//count := len(cs.DataList)
	//for i := 0; i < count; i++ {
	//
	//	j := cs.DataList[i]
	//	//多选
	//	if len(q.State) > 0 { // 状态
	//
	//		klog.Infof("q.State: %v,State: %v", q.State, BandStateMap[j.BoundState])
	//
	//		stateIn := services.In(q.State, BandStateMap[j.BoundState])
	//		if !stateIn {
	//			continue
	//		}
	//	}
	//	if len(q.NetSegment) > 0 { // 所属网段
	//
	//		klog.Infof("q.Netsegment: %v,State: %v", q.NetSegment, j.Cidr)
	//
	//		stateIn := services.In(q.NetSegment, j.Cidr)
	//		if !stateIn {
	//			continue
	//		}
	//	}
	//	if len(q.LineType) > 0 { //线路类型
	//
	//		klog.Infof("q.LineType: %v,lineType: %v", q.LineType, strings.ToLower(j.WayType))
	//
	//		stateIn := services.In(q.LineType, strings.ToLower(j.WayType))
	//		if !stateIn {
	//			continue
	//		}
	//	}
	//	if len(q.XgwCluster) > 0 { // 资源池
	//		klog.Infof("q.XgwCluster: %v,XgwCluster: %v", q.XgwCluster, strings.ToLower(j.XgwCluster))
	//
	//		xgwClusterIn := services.In(q.XgwCluster, strings.ToLower(j.XgwCluster))
	//		if !xgwClusterIn {
	//			continue
	//		}
	//
	//	}
	//
	//	ib, _ := regexp.MatchString(q.Ip, j.IpAddr)
	//	if (ib || q.Ip == "") && (q.Region == j.RegionCode || q.Region == "") {
	//
	//		xgwCluster := map[string]string{
	//			"4": "xgw_eip_default",
	//			"6": "xgw_eip_ipv6_1",
	//		}
	//		m := eipmodels.Eip{
	//			Id:         j.Id,
	//			XgwCluster: xgwCluster[j.IpVersion],
	//			Eip:        j.IpAddr,
	//			State:      BandStateMap[j.BoundState],
	//			Region:     j.RegionName,
	//			NetSegment: j.Cidr,
	//			LineType:   j.WayType,
	//			BandWidth:  j.Bandwidth,
	//			IpVersion:  j.IpVersion,
	//			HostId:     j.BoundId,
	//			CreateTime: j.CreateTime,
	//		}
	//		rst.DataList = append(rst.DataList, m)
	//	}
	//
	//	//segMentMap
	//	if !services.In(rst.NetSegmentList, j.Cidr) {
	//		rst.NetSegmentList = append(rst.NetSegmentList, j.Cidr)
	//	}
	//	// for _, v := range rst.NetSegmentList {
	//	// 	if v == j.Cidr {
	//	// 		continue
	//	// 	} else {
	//	// 		rst.NetSegmentList = append(rst.NetSegmentList, j.Cidr)
	//	// 	}
	//	// }
	//
	//}
	//
	//low := (q.PageNo - 1) * q.PageSize
	//if low > len(rst.DataList) {
	//	return rst, nil
	//}
	//
	//hight := low + q.PageSize
	//if hight > len(rst.DataList) {
	//	hight = len(rst.DataList)
	//}
	//
	//rst.PageNo = q.PageNo
	//rst.PageSize = q.PageSize
	//rst.TotalCount = len(rst.DataList)
	//rst.DataList = rst.DataList[low:hight]
	//
	// 获取监控数据
	//for j := 0; j < len(rst.DataList); j++ {
	//	m := &rst.DataList[j]
	//	eipId := "ksceip--" + m.Id
	//	//if m.HostId == ""{
	//	//	klog.Infof("弹性ip未绑定 IP:",m.Eip)
	//	//	continue
	//	//}
	//	klog.Infof("弹性IP id:%s", m.Id)
	//
	//	//outBandRate  出向带宽利用率
	//	outBandRateTag := map[string]string{
	//		"host": eipId,
	//	}
	//	outBandRateLast := kts.LastQuery{
	//		Metric: "eip.utilization.out" + "." + eipId,
	//		Tags:   outBandRateTag,
	//	}
	//	outBandRate, _ := kts.TSDBLastQuery(outBandRateLast)
	//	if len(outBandRate) > 0 {
	//		outBandRateFloat, _ := strconv.ParseFloat(outBandRate[0].Value, 64)
	//		m.OutBandRate = services.FormPercent(outBandRateFloat / 100)
	//	}
	//
	//	//inBandRate  入向带宽利用率
	//	inBandRateTag := map[string]string{
	//		"host": eipId,
	//	}
	//	inBandRateLast := kts.LastQuery{
	//		Metric: "eip.utilization.in" + "." + eipId,
	//		Tags:   inBandRateTag,
	//	}
	//	inBandRate, _ := kts.TSDBLastQuery(inBandRateLast)
	//	if len(outBandRate) > 0 {
	//		inBandRateFloat, _ := strconv.ParseFloat(inBandRate[0].Value, 64)
	//		m.InBandRate = services.FormPercent(inBandRateFloat / 100)
	//	}
	//
	//	//outFlow 出网流量
	//	outFlowTag := map[string]string{
	//		"host": eipId,
	//	}
	//	outFlowLast := kts.LastQuery{
	//		Metric: "eip.bps.out" + "." + eipId,
	//		Tags:   outFlowTag,
	//	}
	//	outFlow, _ := kts.TSDBLastQuery(outFlowLast)
	//	if len(outFlow) > 0 {
	//		outFlowFloat, _ := strconv.ParseFloat(outFlow[0].Value, 64)
	//		m.OutFlow = outFlowFloat
	//	}
	//
	//	//inFlow 入网流量
	//	inFlowTag := map[string]string{
	//		"host": eipId,
	//	}
	//	inFlowLast := kts.LastQuery{
	//		Metric: "eip.bps.in" + "." + eipId,
	//		Tags:   inFlowTag,
	//	}
	//	inFlow, _ := kts.TSDBLastQuery(inFlowLast)
	//	if len(inFlow) > 0 {
	//		inFlowFloat, _ := strconv.ParseFloat(inFlow[0].Value, 64)
	//		m.InFlow = inFlowFloat
	//	}
	//
	//	//outPackages 每秒流出包数
	//	outPackagesTag := map[string]string{
	//		"host": eipId,
	//	}
	//	outPackagesLast := kts.LastQuery{
	//		Metric: "eip.pps.out" + "." + eipId,
	//		Tags:   outPackagesTag,
	//	}
	//	outPackages, _ := kts.TSDBLastQuery(outPackagesLast)
	//	if len(inFlow) > 0 {
	//		outPackagesFloat, _ := strconv.ParseFloat(outPackages[0].Value, 64)
	//		m.OutPackages = outPackagesFloat
	//	}
	//
	//	//inPackages 每秒流入包数
	//	inPackagesTag := map[string]string{
	//		"host": eipId,
	//	}
	//	inPackagesLast := kts.LastQuery{
	//		Metric: "eip.pps.in" + "." + eipId,
	//		Tags:   inPackagesTag,
	//	}
	//	inPackages, _ := kts.TSDBLastQuery(inPackagesLast)
	//	if len(inFlow) > 0 {
	//		inPackagesFloat, _ := strconv.ParseFloat(inPackages[0].Value, 64)
	//		m.InPackages = inPackagesFloat
	//	}
	//}

	return rst, nil
}

var eipMetricMap = map[string]func(id, ip, start, end, step string) (eipmodels.MetricLineType, error){
	"outBandRate": QueryOutBandRate,
	"inBandRate":  QueryInBandRate,
	"outFlow":     QueryOutFlow,
	"inFlow":      QueryInFlow,
	"outPackages": QueryOutPackages,
	"inPackages":  QueryInPackages,
}

func (ps *EipService) GetEipMetricLine(q *eipmodels.EipMetricLineQuery) (rst []eipmodels.MetricLineType, err error) {
	klog.Infof("get eip metric ,id: %s", q.Id)
	//todo test get demo swtich metrics
	//rst := []eipmodels.MetricLineType{}
	start := strconv.FormatFloat(q.Start, 'f', 3, 64)
	end := strconv.FormatFloat(q.End, 'f', 3, 64)
	//start := strconv.FormatFloat(q.Start/1000, 'f', 3, 64)
	//end := strconv.FormatFloat(q.End/1000, 'f', 3, 64)
	step := services.TimeToStep(q.End - q.Start)
	//k, _ := strconv.Atoi(q.TopK)
	for _, name := range q.Name {
		if op, ok := eipMetricMap[name]; ok {
			result, errOp := op("ksceip--"+q.Id, q.Ip, start, end, step)
			if errOp != nil {
				klog.Error(errOp)
				continue
			}
			rst = append(rst, result)
		}
	}

	return rst, nil
}

//metric
func QueryOutBandRate(id, ip, start, end, step string) (rst eipmodels.MetricLineType, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "出口向带宽使用百分比",
		Unit:     "%",
		UnitType: "percent",
	}

	//query
	tags := map[string]string{
		"host": id,
	}
	rangeQ := kts.RangeQuery{
		Aggregator: "sum",
		Metric:     temp.OpenTsdbMetricsMap["eip_band_rate_out"].Sql + "." + id,
		Tags:       tags,
	}
	rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		r.Values = kts.KtsResultToValues(rangeRst[0].Dps)

	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryInBandRate(id, ip, start, end, step string) (rst eipmodels.MetricLineType, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "入口向带宽使用百分比",
		Unit:     "%",
		UnitType: "percent",
	}

	//query
	tags := map[string]string{
		"host": id,
	}
	rangeQ := kts.RangeQuery{
		Aggregator: "sum",
		Metric:     temp.OpenTsdbMetricsMap["eip_band_rate_in"].Sql + "." + id,
		Tags:       tags,
	}
	rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		r.Values = kts.KtsResultToValues(rangeRst[0].Dps)

	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryOutFlow(id, ip, start, end, step string) (rst eipmodels.MetricLineType, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "出口流量",
		Unit:     "bps",
		UnitType: "storage",
	}

	//query
	tags := map[string]string{
		"host": id,
	}
	rangeQ := kts.RangeQuery{
		Aggregator: "sum",
		Metric:     temp.OpenTsdbMetricsMap["eip_flow_out"].Sql + "." + id,
		Tags:       tags,
	}
	rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		r.Values = kts.KtsResultToValues(rangeRst[0].Dps)

	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryInFlow(id, ip, start, end, step string) (rst eipmodels.MetricLineType, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "入口流量",
		Unit:     "bps",
		UnitType: "storage",
	}

	//query
	tags := map[string]string{
		"host": id,
	}
	rangeQ := kts.RangeQuery{
		Aggregator: "sum",
		Metric:     temp.OpenTsdbMetricsMap["eip_flow_in"].Sql + "." + id,
		Tags:       tags,
	}
	rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		r.Values = kts.KtsResultToValues(rangeRst[0].Dps)

	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryOutPackages(id, ip, start, end, step string) (rst eipmodels.MetricLineType, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "每秒流出包数",
		Unit:     "pps",
		UnitType: "number",
	}

	//query
	tags := map[string]string{
		"host": id,
	}
	rangeQ := kts.RangeQuery{
		Aggregator: "sum",
		Metric:     temp.OpenTsdbMetricsMap["eip_pps_out"].Sql + "." + id,
		Tags:       tags,
	}
	rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		r.Values = kts.KtsResultToValues(rangeRst[0].Dps)

	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}
func QueryInPackages(id, ip, start, end, step string) (rst eipmodels.MetricLineType, err error) {
	r := eipmodels.Echart{}
	info := eipmodels.MetricLineInfo{
		Name:     "每秒流入包数",
		Unit:     "pps",
		UnitType: "number",
	}

	//query
	tags := map[string]string{
		"host": id,
	}
	rangeQ := kts.RangeQuery{
		Aggregator: "sum",
		Metric:     temp.OpenTsdbMetricsMap["eip_pps_in"].Sql + "." + id,
		Tags:       tags,
	}
	rangeRst, _ := kts.TSDBRangeQuery(start, end, rangeQ)
	if len(rangeRst) > 0 {
		r.Values = kts.KtsResultToValues(rangeRst[0].Dps)

	}

	r.Info = info
	rst.Echarts = append(rst.Echarts, r)
	return
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/chargeinfomanager/service.go
```golang
package chargeinfomanager

import (
	"bytes"
	"encoding/json"
	"fmt"
	"gitlab.inner.galaxy.ksyun.com/luban/luban_server/pkg/config"
	"io"
	"net/http"
	"net/url"
	"time"
)

// ChargeInfoManager url 10.177.9.26:18080/chargeInfoInternal/count?region=CN-SHANGHAI-2&date=20210816&bucketId=4183992385
type ChargeInfoManager struct {
	client *http.Client
	url    url.URL
}

func NewChargeInfoManager() *ChargeInfoManager {
	return &ChargeInfoManager{client: http.DefaultClient, url: url.URL{
		Scheme: "http",
		Host:   config.DefaultChargeInfoService,
		Path:   "/chargeInfoInternal/count",
	}}
}

// List 获取一段时间的结果列表
func (c *ChargeInfoManager) List(bucketId string, start, end time.Time) (chargeInfos []ChargeInfo, err error) {
	dates := IntervalToCycle(start, end)
	for _, date := range dates {
		infos, err := c.GetById(bucketId, date)
		if err != nil || len(*infos) == 0 {
			continue
		}
		mergeInfo := ChargeInfo{}
		for _, info := range *infos {
			mergeInfo.BucketCreatedTime = info.BucketCreatedTime
			mergeInfo.BucketDeletedFlag = info.BucketDeletedFlag
			mergeInfo.BucketLastModifiedTime = info.BucketLastModifiedTime
			mergeInfo.Date = info.Date
			mergeInfo.ID = info.ID
			mergeInfo.Name = info.Name
			mergeInfo.Region = info.Region
			mergeInfo.UserID = info.UserID

			mergeInfo.Total += info.Total
			mergeInfo.DeleteSize += info.DeleteSize
			mergeInfo.PutSize += info.PutSize
			mergeInfo.StorageClass = "mergeStorageClass"
		}
		chargeInfos = append(chargeInfos, mergeInfo)
	}
	return
}

func (c *ChargeInfoManager) GetById(bucketId, date string) (chargeInfos *[]ChargeInfo, err error) {
	c.url.RawQuery = fmt.Sprintf("region=%s&date=%s&bucketId=%s", config.CurrentRegion, date, bucketId)
	chargeInfos = &[]ChargeInfo{}
	err = c.QueryBind(chargeInfos)
	if err != nil {
		return nil, err
	}
	return
}

func (c *ChargeInfoManager) Current(bucketId string) (chargeInfos *[]ChargeInfo, err error) {
	date := time.Now().Format("20060102")
	c.url.RawQuery = fmt.Sprintf("region=%s&date=%s&bucketId=%s", config.CurrentRegion, date, bucketId)
	chargeInfos = &[]ChargeInfo{}
	err = c.QueryBind(chargeInfos)
	if err != nil {
		return nil, err
	}
	return
}

func (c *ChargeInfoManager) QueryBind(chargeInfos *[]ChargeInfo) (err error) {
	response, err := c.client.Get(c.url.String())
	defer response.Body.Close()
	if err != nil {
		return err
	}
	if response.StatusCode != http.StatusOK {
		return fmt.Errorf("response.StatusCode != 200, code is %v", response.StatusCode)
	}
	resp, err := io.ReadAll(response.Body)
	if err != nil {
		return err
	}
	items := bytes.Split(resp, []byte{'\r'})
	for _, item := range items {
		chargeInfo := ChargeInfo{}
		err = json.NewDecoder(bytes.NewBuffer(item)).Decode(&chargeInfo)
		if err != nil {
			continue
		}
		*chargeInfos = append(*chargeInfos, chargeInfo)
	}
	return nil
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/chargeinfomanager/service_test.go
```golang
package chargeinfomanager

import (
	"testing"
	"time"
)

func TestChargeInfoManager_GetById(t *testing.T) {
	infos, err := NewChargeInfoManager().List("4183992385", time.Now().Add(-time.Hour*24*10), time.Now())
	if err != nil {
		t.Error(err)
		return
	}
	t.Log(infos)
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/chargeinfomanager/utils.go
```golang
package chargeinfomanager

import "time"

func IntervalToCycle(start, end time.Time) (date []string) {
	if end.Sub(start) < time.Hour*24 {
		date = append(date, end.Format("20060102"))
		return
	}
redo:
	if start.Add(time.Hour * 24).Before(end) {
		date = append(date, start.Format("20060102"))
		start = start.Add(time.Hour * 24)
		goto redo
	}
	return
}

```

File path: /Users/mac/Desktop/woker_code/luban_server_copy/pkg/services/chargeinfomanager/model.go
```golang
package chargeinfomanager

type ChargeInfo struct {
	BucketCreatedTime      string `json:"bucketCreatedTime"`
	BucketDeletedFlag      bool   `json:"bucketDeletedFlag"`
	BucketLastModifiedTime string `json:"bucketLastModifiedTime"`
	Date                   string `json:"date"`
	DeleteSize             int    `json:"deleteSize"`
	ID                     int    `json:"id"`
	Name                   string `json:"name"`
	PutSize                int    `json:"putSize"`
	Region                 string `json:"region"`
	StorageClass           string `json:"storageClass"`
	Total                  int    `json:"total"`
	UserID                 string `json:"userId"`
}

```

