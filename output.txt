##File: /Users/mac/Desktop/gpt_test/langchain-test/server.py
#!/usr/bin/env python
from typing import List

from fastapi import FastAPI
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_community.document_loaders import WebBaseLoader
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.tools.retriever import create_retriever_tool
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain import hub
from langchain.agents import create_openai_functions_agent
from langchain.agents import AgentExecutor
from langchain.pydantic_v1 import BaseModel, Field
from langchain_core.messages import BaseMessage
from langserve import add_routes
import os


# 1. Load Retriever
# loader = WebBaseLoader("https://docs.smith.langchain.com/user_guide")
# docs = loader.load()
# text_splitter = RecursiveCharacterTextSplitter()
# documents = text_splitter.split_documents(docs)


from langchain_community.document_loaders.generic import GenericLoader
from langchain_community.document_loaders.parsers import LanguageParser
from langchain_text_splitters import Language
from langchain_text_splitters.python import PythonCodeTextSplitter


# 设置代码库路径
repo_path = "/Users/mac/Desktop/gpt_test/langchain-test"

# 创建一个GenericLoader实例
loader = GenericLoader.from_filesystem(
    repo_path,
    glob="**/*",
    suffixes=[".py"],
    parser=LanguageParser(language=Language.PYTHON, parser_threshold=500),
)

# 加载代码文档
docs = loader.load()
text_splitter = PythonCodeTextSplitter()
documents = text_splitter.split_documents(docs)


embeddings = OpenAIEmbeddings()
vector = FAISS.from_documents(documents, embeddings)
retriever = vector.as_retriever()

# 2. Create Tools
retriever_tool = create_retriever_tool(
    retriever,
    "mycode_search",
    "Search for information about mycode. For any questions about mycode, you must use this tool!",
)


#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
os.environ["TAVILY_API_KEY"] = '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'
search = TavilySearchResults()
tools = [retriever_tool, search]


# 3. Create Agent
prompt = hub.pull("hwchase17/openai-functions-agent")
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
agent = create_openai_functions_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)


# 4. App definition
app = FastAPI(
  title="LangChain Server",
  version="1.0",
  description="A simple API server using LangChain's Runnable interfaces",
)

# 5. Adding chain route

# We need to add these input/output schemas because the current AgentExecutor
# is lacking in schemas.

class Input(BaseModel):
    input: str
    chat_history: List[BaseMessage] = Field(
        ...,
        extra={"widget": {"type": "chat", "input": "location"}},
    )


class Output(BaseModel):
    output: str

add_routes(
    app,
    agent_executor.with_types(input_type=Input, output_type=Output),
    path="/agent",
)

if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="localhost", port=8000)

##File: /Users/mac/Desktop/gpt_test/langchain-test/code_load.py
import warnings

warnings.filterwarnings("ignore")

from langchain.globals import set_debug

set_debug(True)

from langchain.globals import set_verbose

set_verbose(True)



from pprint import pprint

from langchain_community.document_loaders.generic import GenericLoader
from langchain_community.document_loaders.parsers import LanguageParser
from langchain_text_splitters import Language





loader = GenericLoader.from_filesystem(
    "/Users/mac/Desktop/gpt_test/langchain-test",
    glob="*",
    suffixes=[".py", ".js"],
    parser=LanguageParser(language=Language.PYTHON, parser_threshold=1000),
)
docs = loader.load()


# for document in docs:
#     pprint(document.metadata)



# # print("\n\n--8<--\n\n".join([document.page_content for document in docs]))
# print("============ doc ==========")
# print(docs[0].page_content)
# print("============ doc ==========")



from langchain_text_splitters import RecursiveCharacterTextSplitter

python_splitter = RecursiveCharacterTextSplitter.from_language(
    language=Language.PYTHON, chunk_size=1000, chunk_overlap=0
)
texts = python_splitter.split_documents(docs)


# print("============ text ==========")
# print(texts[0].page_content)
# print("============ text ==========")




from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

db = Chroma.from_documents(texts, OpenAIEmbeddings(disallowed_special=()))
retriever = db.as_retriever(
    search_type="mmr",  # Also test "similarity"
    search_kwargs={"k": 8},
)





from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
# from langsmith.wrappers import wrap_openai
# from langsmith import traceable


llm = ChatOpenAI(model="gpt-4-turbo-2024-04-09", temperature=0, verbose=True)


# First we need a prompt that we can pass into an LLM to generate this search query

prompt = ChatPromptTemplate.from_messages(
    [
        ("placeholder", "{chat_history}"),
        ("user", "{input}"),
        (
            "user",
            "Given the above conversation, generate a search query to look up to get information relevant to the conversation",
        ),
    ]
)

retriever_chain = create_history_aware_retriever(llm, retriever, prompt)

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "Answer the user's questions based on the below context:\n\n{context}",
        ),
        ("placeholder", "{chat_history}"),
        ("user", "{input}"),
    ]
)
document_chain = create_stuff_documents_chain(llm, prompt)

qa = create_retrieval_chain(retriever_chain, document_chain)



question = "main.py文件中代码提出3点优化建议,每个建议需要提供原代码出处"
result = qa.invoke({"input": question})
result["answer"]
print(result["answer"])

##File: /Users/mac/Desktop/gpt_test/langchain-test/toolsx.py
from langchain_openai import ChatOpenAI

from operator import itemgetter
from typing import Dict, List, Union

from langchain_core.messages import AIMessage
from langchain_core.runnables import (
    Runnable,
    RunnableLambda,
    RunnableMap,
    RunnablePassthrough,
)

from langchain_core.tools import tool

from langchain.globals import set_debug

set_debug(True)

import json


@tool
def multiply(first_int: int, second_int: int) -> int:
    """Multiply two integers together."""
    return first_int * second_int

@tool
def add(first_int: int, second_int: int) -> int:
    "Add two integers."
    return first_int + second_int


@tool
def exponentiate(base: int, exponent: int) -> int:
    "Exponentiate the base to the exponent power."
    return base**exponent



llm = ChatOpenAI(model="gpt-4-turbo-2024-04-09")



tools = [multiply, exponentiate, add]
llm_with_tools = llm.bind_tools(tools)
tool_map = {tool.name: tool for tool in tools}


def call_tools(msg: AIMessage) -> Runnable:
    """Simple sequential tool calling helper."""
    tool_map = {tool.name: tool for tool in tools}
    tool_calls = msg.tool_calls.copy()
    for tool_call in tool_calls:
        tool_call["output"] = tool_map[tool_call["name"]].invoke(tool_call["args"])
    return tool_calls




def human_approval(msg: AIMessage) -> Runnable:
    tool_strs = "\n\n".join(
        json.dumps(tool_call, indent=2) for tool_call in msg.tool_calls
    )
    input_msg = (
        f"Do you approve of the following tool invocations\n\n{tool_strs}\n\n"
        "Anything except 'Y'/'Yes' (case-insensitive) will be treated as a no."
    )
    resp = input(input_msg)
    if resp.lower() not in ("yes", "y"):
        raise ValueError(f"Tool invocations not approved:\n\n{tool_strs}")
    return msg

chain = llm_with_tools | human_approval | call_tools
print(chain.invoke("What's 1+1+1"))

##File: /Users/mac/Desktop/gpt_test/langchain-test/scarp.py
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(temperature=0, model="gpt-3.5-turbo-0613")


from langchain.chains import create_extraction_chain

schema = {
    "properties": {
        "news_article_title": {"type": "string"},
        "news_article_summary": {"type": "string"},
    },
    "required": ["news_article_title", "news_article_summary"],
}


def extract(content: str, schema: dict):
    return create_extraction_chain(schema=schema, llm=llm).run(content)




import pprint
from langchain_community.document_loaders import AsyncChromiumLoader
from langchain_community.document_transformers import BeautifulSoupTransformer
from langchain_text_splitters import RecursiveCharacterTextSplitter


def scrape_with_playwright(urls, schema):
    loader = AsyncChromiumLoader(urls)
    docs = loader.load()
    bs_transformer = BeautifulSoupTransformer()
    docs_transformed = bs_transformer.transform_documents(
        docs, tags_to_extract=["span"]
    )
    print("Extracting content with LLM")

    # Grab the first 1000 tokens of the site
    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=1000, chunk_overlap=0
    )
    splits = splitter.split_documents(docs_transformed)

    print(f"Extracting content from {len(splits)} splits")

    print(splits[0].page_content)

    # Process the first split
    extracted_content = extract(schema=schema, content=splits[0].page_content)
    pprint.pprint(extracted_content)
    return extracted_content


# urls = ["https://www.wsj.com"]

urls = ["https://news.baidu.com"]
extracted_content = scrape_with_playwright(urls, schema=schema)




##File: /Users/mac/Desktop/gpt_test/langchain-test/main.py
#使用 Python f 字符串模板：
from langchain.prompts import PromptTemplate
fstring_template = """Tell me a {adjective} joke about {content}"""
prompt = PromptTemplate.from_template(fstring_template)
print(prompt.format(adjective="funny", content="chickens"))




#ChatPromptTemplate.from_messages 接受各种消息表示形式。
from langchain.prompts import ChatPromptTemplate
template = ChatPromptTemplate.from_messages([
("system", "You are a helpful AI bot. Your name is {name}."),
("human", "Hello, how are you doing?"),
("ai", "I'm doing well, thanks!"),
("human", "{user_input}"),
])
messages = template.format_messages(
name="Bob",
user_input="What is your name?"
)
print(messages)


#模型调用
from langchain.llms import OpenAI
llm = OpenAI()
print(llm('你是谁'))





#fake model call
# 从langchain.llms.fake模块导入FakeListLLM类，此类可能用于模拟或伪造某种行为
from langchain.llms.fake import FakeListLLM
from langchain.agents import load_tools
from langchain.agents import initialize_agent
from langchain.agents import AgentType

# 调用load_tools函数，加载"python_repl"的工具
tools = load_tools(["python_repl"])
# 定义一个响应列表，这些响应可能是模拟LLM的预期响应
responses = ["Action: Python REPL\nAction Input: print(2 + 2)", "Final Answer: 4"]
# 使用上面定义的responses初始化一个FakeListLLM对象
llm = FakeListLLM(responses=responses)
# 调用initialize_agent函数，使用上面的tools和llm，以及指定的代理类型和verbose参数来初始化一个代理
agent = initialize_agent(
    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True
)
# 调用代理的run方法，传递字符串"whats 2 + 2"作为输入，询问代理2加2的结果
agent.run("whats 2 + 2")




#chain

from langchain import PromptTemplate, OpenAI, LLMChain

prompt_template = "What is a good name for a company that makes {product}?"

llm = OpenAI(temperature=0)
chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate.from_template(prompt_template)
)
print(chain("colorful socks")) 

##File: /Users/mac/Desktop/gpt_test/crew_test/src/crew_test/__init__.py


##File: /Users/mac/Desktop/gpt_test/crew_test/src/crew_test/crew.py
from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task

# Uncomment the following line to use an example of a custom tool
# from crew_test.tools.custom_tool import MyCustomTool

# Check our tools documentations for more information on how to use them
# from crewai_tools import SerperDevTool

@CrewBase
class CrewTestCrew():
	"""CrewTest crew"""
	agents_config = 'config/agents.yaml'
	tasks_config = 'config/tasks.yaml'

	@agent
	def researcher(self) -> Agent:
		return Agent(
			config=self.agents_config['researcher'],
			# tools=[MyCustomTool()], # Example of custom tool, loaded on the beginning of file
			verbose=True
		)

	@agent
	def reporting_analyst(self) -> Agent:
		return Agent(
			config=self.agents_config['reporting_analyst'],
			verbose=True
		)

	@task
	def research_task(self) -> Task:
		return Task(
			config=self.tasks_config['research_task'],
			agent=self.researcher()
		)

	@task
	def reporting_task(self) -> Task:
		return Task(
			config=self.tasks_config['reporting_task'],
			agent=self.reporting_analyst(),
			output_file='report.md'
		)

	@crew
	def crew(self) -> Crew:
		"""Creates the CrewTest crew"""
		return Crew(
			agents=self.agents, # Automatically created by the @agent decorator
			tasks=self.tasks, # Automatically created by the @task decorator
			process=Process.sequential,
			verbose=2,
			# process=Process.hierarchical, # In case you wanna use that instead https://docs.crewai.com/how-to/Hierarchical/
		)

##File: /Users/mac/Desktop/gpt_test/crew_test/src/crew_test/main.py
#!/usr/bin/env python
from crew_test.crew import CrewTestCrew


def run():
    # Replace with your inputs, it will automatically interpolate any tasks and agents information
    inputs = {
        'topic': 'AI LLMs'
    }
    CrewTestCrew().crew().kickoff(inputs=inputs)

##File: /Users/mac/Desktop/gpt_test/crew_test/src/crew_test/tools/__init__.py


##File: /Users/mac/Desktop/gpt_test/crew_test/src/crew_test/tools/custom_tool.py
from crewai_tools import BaseTool


class MyCustomTool(BaseTool):
    name: str = "Name of my tool"
    description: str = (
        "Clear description for what this tool is useful for, you agent will need this information to use it."
    )

    def _run(self, argument: str) -> str:
        # Implementation goes here
        return "this is an example of a tool output, ignore it and move along."


##File: /Users/mac/Desktop/gpt_test/fast-test/main.py
from fastapi import FastAPI, Request
from pydantic import BaseModel

app = FastAPI()

class Cookie(BaseModel):
    key: str
    value: str

@app.get("/get-all-cookie", response_model=dict)
def get_all_cookies(request: Request):
    print("in ------------")
    cookies = request.cookies
    print(cookies)

    # all_cookies = {cookie_name: cookie_value for cookie_name, cookie_value in cookies.items()}
    return cookies

@app.get("/hi")
def say_hi():
    return "ok"
@app.get("/healthz")
def health_check():
    return "ok"




##File: /Users/mac/Desktop/gpt_test/aider_code_test/main.py
from aider.coders import Coder
from aider.models import Model
from aider.io import InputOutput


# This is a list of files to add to the chat
fnames = ["./../aider_auto_code_test/main.py"]

model = Model("gemini/gemini-1.5-pro-latest",
              weak_model="gemini/gemini-1.5-pro-latest")

io = InputOutput(yes=True)

# Create a coder object
coder = Coder.create(main_model=model, fnames=fnames, io=io)

# # This will execute one instruction on those files and then return
# coder.run("make a script that prints hello world")

# # Send another instruction
# coder.run("make it say goodbye")


tasks = [
    "使用 fastapi, 添加端点 /hello should return 'hello world'",
    "添加端点 /healthz should return 'ok'"
]

for task in tasks:
    coder.run(task)
    # Add completion flag after running the task
    print(f"Task '{task}' completed.")




##File: /Users/mac/Desktop/gpt_test/aider_auto_code_test/main.py
from fastapi import FastAPI

app = FastAPI()


@app.get("/hello")
async def hello():
    return "hello world"


@app.get("/healthz")
async def healthz():
    return "ok"


##File: /Users/mac/Desktop/gpt_test/my_test/douban_scraper.py
import requests
from bs4 import BeautifulSoup
import json

def scrape_douban_top250():
    url = 'https://movie.douban.com/top250'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'
    }
    movie_list = []

    for page in range(0, 250, 25):
        response = requests.get(url, headers=headers, params={'start': page})
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        movie_items = soup.find_all('div', class_='item')

        for movie in movie_items:
            title = movie.find('span', class_='title').text
            rating = movie.find('span', class_='rating_num').text
            movie_list.append({'title': title, 'rating': rating})

    with open('douban_top250.json', 'w', encoding='utf-8') as f:
        json.dump(movie_list, f, ensure_ascii=False, indent=4)

if __name__ == '__main__':
    scrape_douban_top250()


##File: /Users/mac/Desktop/gpt_test/my_test/main.py
import streamlit as st

# 创建一个文本输入框
user_input = st.text_input("请输入一些文本：", "")

# 创建一个按钮
if st.button("显示输入"):
    # 当按钮被点击时，显示用户输入的内容
    st.write("你输入了：", user_input)

##File: /Users/mac/Desktop/gpt_test/crew_agents/game/main.py
from textwrap import dedent
from crewai import Agent

class GameAgents():
	def senior_engineer_agent(self):
		return Agent(
			role='Senior Software Engineer',
			goal='Create software as needed',
			backstory=dedent("""\
				You are a Senior Software Engineer at a leading tech think tank.
				Your expertise in programming in python. and do your best to
				produce perfect code"""),
			allow_delegation=False,
			verbose=True
		)

	def qa_engineer_agent(self):
		return Agent(
			role='Software Quality Control Engineer',
  		goal='create prefect code, by analizing the code that is given for errors',
  		backstory=dedent("""\
				You are a software engineer that specializes in checking code
  			for errors. You have an eye for detail and a knack for finding
				hidden bugs.
  			You check for missing imports, variable declarations, mismatched
				brackets and syntax errors.
  			You also check for security vulnerabilities, and logic errors"""),
			allow_delegation=False,
			verbose=True
		)

	def chief_qa_engineer_agent(self):
		return Agent(
			role='Chief Software Quality Control Engineer',
  		goal='Ensure that the code does the job that it is supposed to do',
  		backstory=dedent("""\
				You feel that programmers always do only half the job, so you are
				super dedicate to make high quality code."""),
			allow_delegation=False,
			verbose=True
		)




from textwrap import dedent
from crewai import Task

class GameTasks():
	def code_task(self, agent, game):
		return Task(description=dedent(f"""You will create a game using python, these are the instructions:

			Instructions
			------------
    	{game}

			Your Final answer must be the full python code, only the python code and nothing else.
			"""),
			agent=agent,
            expected_output="full python code, only the python code and nothing else"

		)

	def review_task(self, agent, game):
		return Task(description=dedent(f"""\
			You are helping create a game using python, these are the instructions:

			Instructions
			------------
			{game}

			Using the code you got, check for errors. Check for logic errors,
			syntax errors, missing imports, variable declarations, mismatched brackets,
			and security vulnerabilities.

			Your Final answer must be the full python code, only the python code and nothing else.
			"""),
			agent=agent,
            expected_output="full python code, only the python code and nothing else"

		)

	def evaluate_task(self, agent, game):
		return Task(description=dedent(f"""\
			You are helping create a game using python, these are the instructions:

			Instructions
			------------
			{game}

			You will look over the code to insure that it is complete and
			does the job that it is supposed to do.

			Your Final answer must be the full python code, only the python code and nothing else.
			"""),
			agent=agent,
            expected_output="full python code, only the python code and nothing else"
            
		)




from dotenv import load_dotenv
load_dotenv()

from crewai import Crew


tasks = GameTasks()
agents = GameAgents()

print("## Welcome to the Game Crew")
print('-------------------------------')
# game = input("What is the game you would like to build? What will be the mechanics?\n")

# game = {"game":"2048"}
game = "2048"

# Create Agents
senior_engineer_agent = agents.senior_engineer_agent()
qa_engineer_agent = agents.qa_engineer_agent()
chief_qa_engineer_agent = agents.chief_qa_engineer_agent()

# Create Tasks
code_game = tasks.code_task(senior_engineer_agent, game)
review_game = tasks.review_task(qa_engineer_agent, game)
approve_game = tasks.evaluate_task(chief_qa_engineer_agent, game)

# Create Crew responsible for Copy
crew = Crew(
	agents=[
		senior_engineer_agent,
		qa_engineer_agent,
		chief_qa_engineer_agent
	],
	tasks=[
		code_game,
		review_game,
		approve_game
	],
	verbose=True
)

game1 = crew.kickoff()


# Print results
print("\n\n########################")
print("## Here is the result")
print("########################\n")
print("final code for the game:")
print(game1)

##File: /Users/mac/Desktop/gpt_test/crew_agents/writer/main.py
from dotenv import load_dotenv
load_dotenv()


from crewai import Agent
from crewai_tools import SerperDevTool

search_tool = SerperDevTool()

researcher = Agent(
  role='Senior Researcher',
  goal='Uncover groundbreaking technologies in AI in healthcare',
  backstory='You have a PhD in AI and have been researching AI in healthcare for 10 years.',
  verbose=True,
  memory=True,
  tools=[search_tool],
  allow_delegation=True
)

writer = Agent(
  role='Writer',
  goal='Narrate compelling tech stories about AI in healthcare',
  backstory='You have a degree in journalism and have been writing about tech for 5 years.',
  verbose=True,
  memory=True,
  tools=[search_tool],
  allow_delegation=False
)


from crewai import Task

research_task = Task(
  description="Identify the next big trend in AI in healthcare.",
  expected_output='A comprehensive 3 paragraphs long report on the latest AI trends.',
  tools=[search_tool],
  agent=researcher,
)

write_task = Task(
  description="Compose an insightful article on AI in healthcare.",
  expected_output='A 4 paragraph article on AI in healthcare advancements formatted as markdown.',
  tools=[search_tool],
  agent=writer,
  async_execution=False,
  output_file='new-blog-post.md'
)



from crewai import Crew, Process

crew = Crew(
  agents=[researcher, writer],
  tasks=[research_task, write_task],
  process=Process.sequential
)

result = crew.kickoff(inputs={'topic': 'AI in healthcare'})
print(result)


##File: /Users/mac/Desktop/gpt_test/crew_agents/coder/__init__.py


##File: /Users/mac/Desktop/gpt_test/crew_agents/coder/coder_agent.py
from crewai import Agent, Task
from textwrap import dedent


class CoderAgent(Agent):
    def __init__(self):
        super().__init__(
            role='Software Developer',
            goal='Write high-quality code based on given specifications',
            backstory=dedent("""\
                You are a skilled software developer with a strong background in Python.
                Your primary task is to write clean, efficient, and maintainable code.
                You are proficient in various programming paradigms and design patterns."""),
            allow_delegation=False,
            verbose=True
        )


def web_scraping_task(self, agent, url):
    return Task(description=dedent(f"""\
			You are tasked with creating a web scraping program to fetch the top 250 movies from Douban.
			The URL for the data is: {url}

			Instructions
			------------
			Write a Python script using libraries like requests and BeautifulSoup to scrape the data.
			Ensure the script handles pagination to collect all 250 movie entries.

			Your Final answer must be the full python code, only the python code and nothing else.
			"""),
                agent=agent,
                expected_output="full python code, only the python code and nothing else"
            )




##File: /Users/mac/Desktop/gpt_test/crew_agents/coder/main.py
from coder_agent import CoderAgent, web_scraping_task
from crewai import Crew

agent = CoderAgent()
task = web_scraping_task(agent, "https://movie.douban.com/top250")

crew = Crew(
    agents=[agent],
    tasks=[task],
    verbose=True
)

crew.kickoff()


##File: /Users/mac/Desktop/gpt_test/mycode/file_reader.py
import os
from pathlib import Path

class FileReader:
    def __init__(self, root_dir):
        self.root_dir = root_dir

    def traverse_and_write(self, output_file):
        with open(output_file, 'w') as out:
            for root, dirs, files in os.walk(self.root_dir):
                # Mapping of file extensions to language names
                extension_to_language = {
                    '.py': 'python',
                    '.go': 'golang',
                    # Add other languages and extensions as needed
                }
                for file in files:
                    file_extension = Path(file).suffix
                    if file_extension in extension_to_language:
                        file_path = Path(root) / file
                        language = extension_to_language[file_extension]
                        out.write(f"File path: {file_path}\n```{language}\n")

                        with open(file_path, 'r') as f:
                            out.write(f.read())
                        out.write("\n```\n\n")
                    

##File: /Users/mac/Desktop/gpt_test/mycode/main.py
import sys
import os
from file_reader import FileReader


def main():
    if len(sys.argv) != 2:
        print("Usage: python main.py <root_directory>")
        sys.exit(1)

    root_directory = sys.argv[1]
    output_file = root_directory.split('/')[-1] + '.txt'
    current_path = "/Users/mac/Desktop/gpt_test/mycode/"
    output_file = os.path.join(current_path, output_file)



    file_reader = FileReader(root_directory)
    file_reader.traverse_and_write(output_file)


if __name__ == "__main__":
    main()


